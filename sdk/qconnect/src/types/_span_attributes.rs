// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Contextual attributes capturing operation details, LLM configuration, usage metrics, and conversation data</p>
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct SpanAttributes {
    /// <p>Action being performed</p>
    pub operation_name: ::std::option::Option<::std::string::String>,
    /// <p>Model provider identifier (e.g., aws.bedrock)</p>
    pub provider_name: ::std::option::Option<::std::string::String>,
    /// <p>Error classification if span failed (e.g., throttle, timeout)</p>
    pub error_type: ::std::option::Option<::std::string::String>,
    /// <p>Amazon Connect agent ID</p>
    pub agent_id: ::std::option::Option<::std::string::String>,
    /// <p>Amazon Connect instance ARN</p>
    pub instance_arn: ::std::option::Option<::std::string::String>,
    /// <p>Amazon Connect contact identifier</p>
    pub contact_id: ::std::option::Option<::std::string::String>,
    /// <p>Amazon Connect contact identifier</p>
    pub initial_contact_id: ::std::option::Option<::std::string::String>,
    /// <p>Session name</p>
    pub session_name: ::std::option::Option<::std::string::String>,
    /// <p>AI agent ARN</p>
    pub ai_agent_arn: ::std::option::Option<::std::string::String>,
    /// <p>AI agent type</p>
    pub ai_agent_type: ::std::option::Option<crate::types::AiAgentType>,
    /// <p>AI agent name</p>
    pub ai_agent_name: ::std::option::Option<::std::string::String>,
    /// <p>AI agent identifier</p>
    pub ai_agent_id: ::std::option::Option<::std::string::String>,
    /// <p>AI agent version number</p>
    pub ai_agent_version: ::std::option::Option<i32>,
    /// <p>Entity that invoked the AI agent</p>
    pub ai_agent_invoker: ::std::option::Option<::std::string::String>,
    /// <p>AI agent orchestrator use case</p>
    pub ai_agent_orchestrator_use_case: ::std::option::Option<::std::string::String>,
    /// <p>LLM model ID for request (e.g., anthropic.claude-3-sonnet)</p>
    pub request_model: ::std::option::Option<::std::string::String>,
    /// <p>Maximum tokens configured for generation</p>
    pub request_max_tokens: ::std::option::Option<i32>,
    /// <p>Sampling temperature for generation</p>
    pub temperature: ::std::option::Option<f32>,
    /// <p>Top-p sampling parameter for generation</p>
    pub top_p: ::std::option::Option<f32>,
    /// <p>Actual model used for response (usually matches requestModel)</p>
    pub response_model: ::std::option::Option<::std::string::String>,
    /// <p>Generation termination reasons (e.g., stop, max_tokens)</p>
    pub response_finish_reasons: ::std::option::Option<::std::vec::Vec<::std::string::String>>,
    /// <p>Number of input tokens in prompt</p>
    pub usage_input_tokens: ::std::option::Option<i32>,
    /// <p>Number of output tokens in response</p>
    pub usage_output_tokens: ::std::option::Option<i32>,
    /// <p>Total tokens consumed (input + output)</p>
    pub usage_total_tokens: ::std::option::Option<i32>,
    /// <p>Number of input tokens that were retrieved from cache</p>
    pub cache_read_input_tokens: ::std::option::Option<i32>,
    /// <p>Number of input tokens that were written to cache in this request</p>
    pub cache_write_input_tokens: ::std::option::Option<i32>,
    /// <p>Input message collection sent to LLM</p>
    pub input_messages: ::std::option::Option<::std::vec::Vec<crate::types::SpanMessage>>,
    /// <p>Output message collection received from LLM</p>
    pub output_messages: ::std::option::Option<::std::vec::Vec<crate::types::SpanMessage>>,
    /// <p>System prompt instructions</p>
    pub system_instructions: ::std::option::Option<::std::vec::Vec<crate::types::SpanMessageValue>>,
    /// <p>AI prompt ARN</p>
    pub prompt_arn: ::std::option::Option<::std::string::String>,
    /// <p>AI prompt identifier</p>
    pub prompt_id: ::std::option::Option<::std::string::String>,
    /// <p>AI prompt type</p>
    pub prompt_type: ::std::option::Option<crate::types::AiPromptType>,
    /// <p>AI prompt name</p>
    pub prompt_name: ::std::option::Option<::std::string::String>,
    /// <p>AI prompt version number</p>
    pub prompt_version: ::std::option::Option<i32>,
}
impl SpanAttributes {
    /// <p>Action being performed</p>
    pub fn operation_name(&self) -> ::std::option::Option<&str> {
        self.operation_name.as_deref()
    }
    /// <p>Model provider identifier (e.g., aws.bedrock)</p>
    pub fn provider_name(&self) -> ::std::option::Option<&str> {
        self.provider_name.as_deref()
    }
    /// <p>Error classification if span failed (e.g., throttle, timeout)</p>
    pub fn error_type(&self) -> ::std::option::Option<&str> {
        self.error_type.as_deref()
    }
    /// <p>Amazon Connect agent ID</p>
    pub fn agent_id(&self) -> ::std::option::Option<&str> {
        self.agent_id.as_deref()
    }
    /// <p>Amazon Connect instance ARN</p>
    pub fn instance_arn(&self) -> ::std::option::Option<&str> {
        self.instance_arn.as_deref()
    }
    /// <p>Amazon Connect contact identifier</p>
    pub fn contact_id(&self) -> ::std::option::Option<&str> {
        self.contact_id.as_deref()
    }
    /// <p>Amazon Connect contact identifier</p>
    pub fn initial_contact_id(&self) -> ::std::option::Option<&str> {
        self.initial_contact_id.as_deref()
    }
    /// <p>Session name</p>
    pub fn session_name(&self) -> ::std::option::Option<&str> {
        self.session_name.as_deref()
    }
    /// <p>AI agent ARN</p>
    pub fn ai_agent_arn(&self) -> ::std::option::Option<&str> {
        self.ai_agent_arn.as_deref()
    }
    /// <p>AI agent type</p>
    pub fn ai_agent_type(&self) -> ::std::option::Option<&crate::types::AiAgentType> {
        self.ai_agent_type.as_ref()
    }
    /// <p>AI agent name</p>
    pub fn ai_agent_name(&self) -> ::std::option::Option<&str> {
        self.ai_agent_name.as_deref()
    }
    /// <p>AI agent identifier</p>
    pub fn ai_agent_id(&self) -> ::std::option::Option<&str> {
        self.ai_agent_id.as_deref()
    }
    /// <p>AI agent version number</p>
    pub fn ai_agent_version(&self) -> ::std::option::Option<i32> {
        self.ai_agent_version
    }
    /// <p>Entity that invoked the AI agent</p>
    pub fn ai_agent_invoker(&self) -> ::std::option::Option<&str> {
        self.ai_agent_invoker.as_deref()
    }
    /// <p>AI agent orchestrator use case</p>
    pub fn ai_agent_orchestrator_use_case(&self) -> ::std::option::Option<&str> {
        self.ai_agent_orchestrator_use_case.as_deref()
    }
    /// <p>LLM model ID for request (e.g., anthropic.claude-3-sonnet)</p>
    pub fn request_model(&self) -> ::std::option::Option<&str> {
        self.request_model.as_deref()
    }
    /// <p>Maximum tokens configured for generation</p>
    pub fn request_max_tokens(&self) -> ::std::option::Option<i32> {
        self.request_max_tokens
    }
    /// <p>Sampling temperature for generation</p>
    pub fn temperature(&self) -> ::std::option::Option<f32> {
        self.temperature
    }
    /// <p>Top-p sampling parameter for generation</p>
    pub fn top_p(&self) -> ::std::option::Option<f32> {
        self.top_p
    }
    /// <p>Actual model used for response (usually matches requestModel)</p>
    pub fn response_model(&self) -> ::std::option::Option<&str> {
        self.response_model.as_deref()
    }
    /// <p>Generation termination reasons (e.g., stop, max_tokens)</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.response_finish_reasons.is_none()`.
    pub fn response_finish_reasons(&self) -> &[::std::string::String] {
        self.response_finish_reasons.as_deref().unwrap_or_default()
    }
    /// <p>Number of input tokens in prompt</p>
    pub fn usage_input_tokens(&self) -> ::std::option::Option<i32> {
        self.usage_input_tokens
    }
    /// <p>Number of output tokens in response</p>
    pub fn usage_output_tokens(&self) -> ::std::option::Option<i32> {
        self.usage_output_tokens
    }
    /// <p>Total tokens consumed (input + output)</p>
    pub fn usage_total_tokens(&self) -> ::std::option::Option<i32> {
        self.usage_total_tokens
    }
    /// <p>Number of input tokens that were retrieved from cache</p>
    pub fn cache_read_input_tokens(&self) -> ::std::option::Option<i32> {
        self.cache_read_input_tokens
    }
    /// <p>Number of input tokens that were written to cache in this request</p>
    pub fn cache_write_input_tokens(&self) -> ::std::option::Option<i32> {
        self.cache_write_input_tokens
    }
    /// <p>Input message collection sent to LLM</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.input_messages.is_none()`.
    pub fn input_messages(&self) -> &[crate::types::SpanMessage] {
        self.input_messages.as_deref().unwrap_or_default()
    }
    /// <p>Output message collection received from LLM</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.output_messages.is_none()`.
    pub fn output_messages(&self) -> &[crate::types::SpanMessage] {
        self.output_messages.as_deref().unwrap_or_default()
    }
    /// <p>System prompt instructions</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.system_instructions.is_none()`.
    pub fn system_instructions(&self) -> &[crate::types::SpanMessageValue] {
        self.system_instructions.as_deref().unwrap_or_default()
    }
    /// <p>AI prompt ARN</p>
    pub fn prompt_arn(&self) -> ::std::option::Option<&str> {
        self.prompt_arn.as_deref()
    }
    /// <p>AI prompt identifier</p>
    pub fn prompt_id(&self) -> ::std::option::Option<&str> {
        self.prompt_id.as_deref()
    }
    /// <p>AI prompt type</p>
    pub fn prompt_type(&self) -> ::std::option::Option<&crate::types::AiPromptType> {
        self.prompt_type.as_ref()
    }
    /// <p>AI prompt name</p>
    pub fn prompt_name(&self) -> ::std::option::Option<&str> {
        self.prompt_name.as_deref()
    }
    /// <p>AI prompt version number</p>
    pub fn prompt_version(&self) -> ::std::option::Option<i32> {
        self.prompt_version
    }
}
impl SpanAttributes {
    /// Creates a new builder-style object to manufacture [`SpanAttributes`](crate::types::SpanAttributes).
    pub fn builder() -> crate::types::builders::SpanAttributesBuilder {
        crate::types::builders::SpanAttributesBuilder::default()
    }
}

/// A builder for [`SpanAttributes`](crate::types::SpanAttributes).
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
#[non_exhaustive]
pub struct SpanAttributesBuilder {
    pub(crate) operation_name: ::std::option::Option<::std::string::String>,
    pub(crate) provider_name: ::std::option::Option<::std::string::String>,
    pub(crate) error_type: ::std::option::Option<::std::string::String>,
    pub(crate) agent_id: ::std::option::Option<::std::string::String>,
    pub(crate) instance_arn: ::std::option::Option<::std::string::String>,
    pub(crate) contact_id: ::std::option::Option<::std::string::String>,
    pub(crate) initial_contact_id: ::std::option::Option<::std::string::String>,
    pub(crate) session_name: ::std::option::Option<::std::string::String>,
    pub(crate) ai_agent_arn: ::std::option::Option<::std::string::String>,
    pub(crate) ai_agent_type: ::std::option::Option<crate::types::AiAgentType>,
    pub(crate) ai_agent_name: ::std::option::Option<::std::string::String>,
    pub(crate) ai_agent_id: ::std::option::Option<::std::string::String>,
    pub(crate) ai_agent_version: ::std::option::Option<i32>,
    pub(crate) ai_agent_invoker: ::std::option::Option<::std::string::String>,
    pub(crate) ai_agent_orchestrator_use_case: ::std::option::Option<::std::string::String>,
    pub(crate) request_model: ::std::option::Option<::std::string::String>,
    pub(crate) request_max_tokens: ::std::option::Option<i32>,
    pub(crate) temperature: ::std::option::Option<f32>,
    pub(crate) top_p: ::std::option::Option<f32>,
    pub(crate) response_model: ::std::option::Option<::std::string::String>,
    pub(crate) response_finish_reasons: ::std::option::Option<::std::vec::Vec<::std::string::String>>,
    pub(crate) usage_input_tokens: ::std::option::Option<i32>,
    pub(crate) usage_output_tokens: ::std::option::Option<i32>,
    pub(crate) usage_total_tokens: ::std::option::Option<i32>,
    pub(crate) cache_read_input_tokens: ::std::option::Option<i32>,
    pub(crate) cache_write_input_tokens: ::std::option::Option<i32>,
    pub(crate) input_messages: ::std::option::Option<::std::vec::Vec<crate::types::SpanMessage>>,
    pub(crate) output_messages: ::std::option::Option<::std::vec::Vec<crate::types::SpanMessage>>,
    pub(crate) system_instructions: ::std::option::Option<::std::vec::Vec<crate::types::SpanMessageValue>>,
    pub(crate) prompt_arn: ::std::option::Option<::std::string::String>,
    pub(crate) prompt_id: ::std::option::Option<::std::string::String>,
    pub(crate) prompt_type: ::std::option::Option<crate::types::AiPromptType>,
    pub(crate) prompt_name: ::std::option::Option<::std::string::String>,
    pub(crate) prompt_version: ::std::option::Option<i32>,
}
impl SpanAttributesBuilder {
    /// <p>Action being performed</p>
    pub fn operation_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.operation_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Action being performed</p>
    pub fn set_operation_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.operation_name = input;
        self
    }
    /// <p>Action being performed</p>
    pub fn get_operation_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.operation_name
    }
    /// <p>Model provider identifier (e.g., aws.bedrock)</p>
    pub fn provider_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.provider_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Model provider identifier (e.g., aws.bedrock)</p>
    pub fn set_provider_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.provider_name = input;
        self
    }
    /// <p>Model provider identifier (e.g., aws.bedrock)</p>
    pub fn get_provider_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.provider_name
    }
    /// <p>Error classification if span failed (e.g., throttle, timeout)</p>
    pub fn error_type(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.error_type = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Error classification if span failed (e.g., throttle, timeout)</p>
    pub fn set_error_type(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.error_type = input;
        self
    }
    /// <p>Error classification if span failed (e.g., throttle, timeout)</p>
    pub fn get_error_type(&self) -> &::std::option::Option<::std::string::String> {
        &self.error_type
    }
    /// <p>Amazon Connect agent ID</p>
    pub fn agent_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.agent_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Amazon Connect agent ID</p>
    pub fn set_agent_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.agent_id = input;
        self
    }
    /// <p>Amazon Connect agent ID</p>
    pub fn get_agent_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.agent_id
    }
    /// <p>Amazon Connect instance ARN</p>
    pub fn instance_arn(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.instance_arn = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Amazon Connect instance ARN</p>
    pub fn set_instance_arn(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.instance_arn = input;
        self
    }
    /// <p>Amazon Connect instance ARN</p>
    pub fn get_instance_arn(&self) -> &::std::option::Option<::std::string::String> {
        &self.instance_arn
    }
    /// <p>Amazon Connect contact identifier</p>
    pub fn contact_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.contact_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Amazon Connect contact identifier</p>
    pub fn set_contact_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.contact_id = input;
        self
    }
    /// <p>Amazon Connect contact identifier</p>
    pub fn get_contact_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.contact_id
    }
    /// <p>Amazon Connect contact identifier</p>
    pub fn initial_contact_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.initial_contact_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Amazon Connect contact identifier</p>
    pub fn set_initial_contact_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.initial_contact_id = input;
        self
    }
    /// <p>Amazon Connect contact identifier</p>
    pub fn get_initial_contact_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.initial_contact_id
    }
    /// <p>Session name</p>
    pub fn session_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.session_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Session name</p>
    pub fn set_session_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.session_name = input;
        self
    }
    /// <p>Session name</p>
    pub fn get_session_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.session_name
    }
    /// <p>AI agent ARN</p>
    pub fn ai_agent_arn(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.ai_agent_arn = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>AI agent ARN</p>
    pub fn set_ai_agent_arn(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.ai_agent_arn = input;
        self
    }
    /// <p>AI agent ARN</p>
    pub fn get_ai_agent_arn(&self) -> &::std::option::Option<::std::string::String> {
        &self.ai_agent_arn
    }
    /// <p>AI agent type</p>
    pub fn ai_agent_type(mut self, input: crate::types::AiAgentType) -> Self {
        self.ai_agent_type = ::std::option::Option::Some(input);
        self
    }
    /// <p>AI agent type</p>
    pub fn set_ai_agent_type(mut self, input: ::std::option::Option<crate::types::AiAgentType>) -> Self {
        self.ai_agent_type = input;
        self
    }
    /// <p>AI agent type</p>
    pub fn get_ai_agent_type(&self) -> &::std::option::Option<crate::types::AiAgentType> {
        &self.ai_agent_type
    }
    /// <p>AI agent name</p>
    pub fn ai_agent_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.ai_agent_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>AI agent name</p>
    pub fn set_ai_agent_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.ai_agent_name = input;
        self
    }
    /// <p>AI agent name</p>
    pub fn get_ai_agent_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.ai_agent_name
    }
    /// <p>AI agent identifier</p>
    pub fn ai_agent_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.ai_agent_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>AI agent identifier</p>
    pub fn set_ai_agent_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.ai_agent_id = input;
        self
    }
    /// <p>AI agent identifier</p>
    pub fn get_ai_agent_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.ai_agent_id
    }
    /// <p>AI agent version number</p>
    pub fn ai_agent_version(mut self, input: i32) -> Self {
        self.ai_agent_version = ::std::option::Option::Some(input);
        self
    }
    /// <p>AI agent version number</p>
    pub fn set_ai_agent_version(mut self, input: ::std::option::Option<i32>) -> Self {
        self.ai_agent_version = input;
        self
    }
    /// <p>AI agent version number</p>
    pub fn get_ai_agent_version(&self) -> &::std::option::Option<i32> {
        &self.ai_agent_version
    }
    /// <p>Entity that invoked the AI agent</p>
    pub fn ai_agent_invoker(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.ai_agent_invoker = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Entity that invoked the AI agent</p>
    pub fn set_ai_agent_invoker(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.ai_agent_invoker = input;
        self
    }
    /// <p>Entity that invoked the AI agent</p>
    pub fn get_ai_agent_invoker(&self) -> &::std::option::Option<::std::string::String> {
        &self.ai_agent_invoker
    }
    /// <p>AI agent orchestrator use case</p>
    pub fn ai_agent_orchestrator_use_case(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.ai_agent_orchestrator_use_case = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>AI agent orchestrator use case</p>
    pub fn set_ai_agent_orchestrator_use_case(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.ai_agent_orchestrator_use_case = input;
        self
    }
    /// <p>AI agent orchestrator use case</p>
    pub fn get_ai_agent_orchestrator_use_case(&self) -> &::std::option::Option<::std::string::String> {
        &self.ai_agent_orchestrator_use_case
    }
    /// <p>LLM model ID for request (e.g., anthropic.claude-3-sonnet)</p>
    pub fn request_model(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.request_model = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>LLM model ID for request (e.g., anthropic.claude-3-sonnet)</p>
    pub fn set_request_model(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.request_model = input;
        self
    }
    /// <p>LLM model ID for request (e.g., anthropic.claude-3-sonnet)</p>
    pub fn get_request_model(&self) -> &::std::option::Option<::std::string::String> {
        &self.request_model
    }
    /// <p>Maximum tokens configured for generation</p>
    pub fn request_max_tokens(mut self, input: i32) -> Self {
        self.request_max_tokens = ::std::option::Option::Some(input);
        self
    }
    /// <p>Maximum tokens configured for generation</p>
    pub fn set_request_max_tokens(mut self, input: ::std::option::Option<i32>) -> Self {
        self.request_max_tokens = input;
        self
    }
    /// <p>Maximum tokens configured for generation</p>
    pub fn get_request_max_tokens(&self) -> &::std::option::Option<i32> {
        &self.request_max_tokens
    }
    /// <p>Sampling temperature for generation</p>
    pub fn temperature(mut self, input: f32) -> Self {
        self.temperature = ::std::option::Option::Some(input);
        self
    }
    /// <p>Sampling temperature for generation</p>
    pub fn set_temperature(mut self, input: ::std::option::Option<f32>) -> Self {
        self.temperature = input;
        self
    }
    /// <p>Sampling temperature for generation</p>
    pub fn get_temperature(&self) -> &::std::option::Option<f32> {
        &self.temperature
    }
    /// <p>Top-p sampling parameter for generation</p>
    pub fn top_p(mut self, input: f32) -> Self {
        self.top_p = ::std::option::Option::Some(input);
        self
    }
    /// <p>Top-p sampling parameter for generation</p>
    pub fn set_top_p(mut self, input: ::std::option::Option<f32>) -> Self {
        self.top_p = input;
        self
    }
    /// <p>Top-p sampling parameter for generation</p>
    pub fn get_top_p(&self) -> &::std::option::Option<f32> {
        &self.top_p
    }
    /// <p>Actual model used for response (usually matches requestModel)</p>
    pub fn response_model(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.response_model = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Actual model used for response (usually matches requestModel)</p>
    pub fn set_response_model(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.response_model = input;
        self
    }
    /// <p>Actual model used for response (usually matches requestModel)</p>
    pub fn get_response_model(&self) -> &::std::option::Option<::std::string::String> {
        &self.response_model
    }
    /// Appends an item to `response_finish_reasons`.
    ///
    /// To override the contents of this collection use [`set_response_finish_reasons`](Self::set_response_finish_reasons).
    ///
    /// <p>Generation termination reasons (e.g., stop, max_tokens)</p>
    pub fn response_finish_reasons(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        let mut v = self.response_finish_reasons.unwrap_or_default();
        v.push(input.into());
        self.response_finish_reasons = ::std::option::Option::Some(v);
        self
    }
    /// <p>Generation termination reasons (e.g., stop, max_tokens)</p>
    pub fn set_response_finish_reasons(mut self, input: ::std::option::Option<::std::vec::Vec<::std::string::String>>) -> Self {
        self.response_finish_reasons = input;
        self
    }
    /// <p>Generation termination reasons (e.g., stop, max_tokens)</p>
    pub fn get_response_finish_reasons(&self) -> &::std::option::Option<::std::vec::Vec<::std::string::String>> {
        &self.response_finish_reasons
    }
    /// <p>Number of input tokens in prompt</p>
    pub fn usage_input_tokens(mut self, input: i32) -> Self {
        self.usage_input_tokens = ::std::option::Option::Some(input);
        self
    }
    /// <p>Number of input tokens in prompt</p>
    pub fn set_usage_input_tokens(mut self, input: ::std::option::Option<i32>) -> Self {
        self.usage_input_tokens = input;
        self
    }
    /// <p>Number of input tokens in prompt</p>
    pub fn get_usage_input_tokens(&self) -> &::std::option::Option<i32> {
        &self.usage_input_tokens
    }
    /// <p>Number of output tokens in response</p>
    pub fn usage_output_tokens(mut self, input: i32) -> Self {
        self.usage_output_tokens = ::std::option::Option::Some(input);
        self
    }
    /// <p>Number of output tokens in response</p>
    pub fn set_usage_output_tokens(mut self, input: ::std::option::Option<i32>) -> Self {
        self.usage_output_tokens = input;
        self
    }
    /// <p>Number of output tokens in response</p>
    pub fn get_usage_output_tokens(&self) -> &::std::option::Option<i32> {
        &self.usage_output_tokens
    }
    /// <p>Total tokens consumed (input + output)</p>
    pub fn usage_total_tokens(mut self, input: i32) -> Self {
        self.usage_total_tokens = ::std::option::Option::Some(input);
        self
    }
    /// <p>Total tokens consumed (input + output)</p>
    pub fn set_usage_total_tokens(mut self, input: ::std::option::Option<i32>) -> Self {
        self.usage_total_tokens = input;
        self
    }
    /// <p>Total tokens consumed (input + output)</p>
    pub fn get_usage_total_tokens(&self) -> &::std::option::Option<i32> {
        &self.usage_total_tokens
    }
    /// <p>Number of input tokens that were retrieved from cache</p>
    pub fn cache_read_input_tokens(mut self, input: i32) -> Self {
        self.cache_read_input_tokens = ::std::option::Option::Some(input);
        self
    }
    /// <p>Number of input tokens that were retrieved from cache</p>
    pub fn set_cache_read_input_tokens(mut self, input: ::std::option::Option<i32>) -> Self {
        self.cache_read_input_tokens = input;
        self
    }
    /// <p>Number of input tokens that were retrieved from cache</p>
    pub fn get_cache_read_input_tokens(&self) -> &::std::option::Option<i32> {
        &self.cache_read_input_tokens
    }
    /// <p>Number of input tokens that were written to cache in this request</p>
    pub fn cache_write_input_tokens(mut self, input: i32) -> Self {
        self.cache_write_input_tokens = ::std::option::Option::Some(input);
        self
    }
    /// <p>Number of input tokens that were written to cache in this request</p>
    pub fn set_cache_write_input_tokens(mut self, input: ::std::option::Option<i32>) -> Self {
        self.cache_write_input_tokens = input;
        self
    }
    /// <p>Number of input tokens that were written to cache in this request</p>
    pub fn get_cache_write_input_tokens(&self) -> &::std::option::Option<i32> {
        &self.cache_write_input_tokens
    }
    /// Appends an item to `input_messages`.
    ///
    /// To override the contents of this collection use [`set_input_messages`](Self::set_input_messages).
    ///
    /// <p>Input message collection sent to LLM</p>
    pub fn input_messages(mut self, input: crate::types::SpanMessage) -> Self {
        let mut v = self.input_messages.unwrap_or_default();
        v.push(input);
        self.input_messages = ::std::option::Option::Some(v);
        self
    }
    /// <p>Input message collection sent to LLM</p>
    pub fn set_input_messages(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::SpanMessage>>) -> Self {
        self.input_messages = input;
        self
    }
    /// <p>Input message collection sent to LLM</p>
    pub fn get_input_messages(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::SpanMessage>> {
        &self.input_messages
    }
    /// Appends an item to `output_messages`.
    ///
    /// To override the contents of this collection use [`set_output_messages`](Self::set_output_messages).
    ///
    /// <p>Output message collection received from LLM</p>
    pub fn output_messages(mut self, input: crate::types::SpanMessage) -> Self {
        let mut v = self.output_messages.unwrap_or_default();
        v.push(input);
        self.output_messages = ::std::option::Option::Some(v);
        self
    }
    /// <p>Output message collection received from LLM</p>
    pub fn set_output_messages(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::SpanMessage>>) -> Self {
        self.output_messages = input;
        self
    }
    /// <p>Output message collection received from LLM</p>
    pub fn get_output_messages(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::SpanMessage>> {
        &self.output_messages
    }
    /// Appends an item to `system_instructions`.
    ///
    /// To override the contents of this collection use [`set_system_instructions`](Self::set_system_instructions).
    ///
    /// <p>System prompt instructions</p>
    pub fn system_instructions(mut self, input: crate::types::SpanMessageValue) -> Self {
        let mut v = self.system_instructions.unwrap_or_default();
        v.push(input);
        self.system_instructions = ::std::option::Option::Some(v);
        self
    }
    /// <p>System prompt instructions</p>
    pub fn set_system_instructions(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::SpanMessageValue>>) -> Self {
        self.system_instructions = input;
        self
    }
    /// <p>System prompt instructions</p>
    pub fn get_system_instructions(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::SpanMessageValue>> {
        &self.system_instructions
    }
    /// <p>AI prompt ARN</p>
    pub fn prompt_arn(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.prompt_arn = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>AI prompt ARN</p>
    pub fn set_prompt_arn(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.prompt_arn = input;
        self
    }
    /// <p>AI prompt ARN</p>
    pub fn get_prompt_arn(&self) -> &::std::option::Option<::std::string::String> {
        &self.prompt_arn
    }
    /// <p>AI prompt identifier</p>
    pub fn prompt_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.prompt_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>AI prompt identifier</p>
    pub fn set_prompt_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.prompt_id = input;
        self
    }
    /// <p>AI prompt identifier</p>
    pub fn get_prompt_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.prompt_id
    }
    /// <p>AI prompt type</p>
    pub fn prompt_type(mut self, input: crate::types::AiPromptType) -> Self {
        self.prompt_type = ::std::option::Option::Some(input);
        self
    }
    /// <p>AI prompt type</p>
    pub fn set_prompt_type(mut self, input: ::std::option::Option<crate::types::AiPromptType>) -> Self {
        self.prompt_type = input;
        self
    }
    /// <p>AI prompt type</p>
    pub fn get_prompt_type(&self) -> &::std::option::Option<crate::types::AiPromptType> {
        &self.prompt_type
    }
    /// <p>AI prompt name</p>
    pub fn prompt_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.prompt_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>AI prompt name</p>
    pub fn set_prompt_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.prompt_name = input;
        self
    }
    /// <p>AI prompt name</p>
    pub fn get_prompt_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.prompt_name
    }
    /// <p>AI prompt version number</p>
    pub fn prompt_version(mut self, input: i32) -> Self {
        self.prompt_version = ::std::option::Option::Some(input);
        self
    }
    /// <p>AI prompt version number</p>
    pub fn set_prompt_version(mut self, input: ::std::option::Option<i32>) -> Self {
        self.prompt_version = input;
        self
    }
    /// <p>AI prompt version number</p>
    pub fn get_prompt_version(&self) -> &::std::option::Option<i32> {
        &self.prompt_version
    }
    /// Consumes the builder and constructs a [`SpanAttributes`](crate::types::SpanAttributes).
    pub fn build(self) -> crate::types::SpanAttributes {
        crate::types::SpanAttributes {
            operation_name: self.operation_name,
            provider_name: self.provider_name,
            error_type: self.error_type,
            agent_id: self.agent_id,
            instance_arn: self.instance_arn,
            contact_id: self.contact_id,
            initial_contact_id: self.initial_contact_id,
            session_name: self.session_name,
            ai_agent_arn: self.ai_agent_arn,
            ai_agent_type: self.ai_agent_type,
            ai_agent_name: self.ai_agent_name,
            ai_agent_id: self.ai_agent_id,
            ai_agent_version: self.ai_agent_version,
            ai_agent_invoker: self.ai_agent_invoker,
            ai_agent_orchestrator_use_case: self.ai_agent_orchestrator_use_case,
            request_model: self.request_model,
            request_max_tokens: self.request_max_tokens,
            temperature: self.temperature,
            top_p: self.top_p,
            response_model: self.response_model,
            response_finish_reasons: self.response_finish_reasons,
            usage_input_tokens: self.usage_input_tokens,
            usage_output_tokens: self.usage_output_tokens,
            usage_total_tokens: self.usage_total_tokens,
            cache_read_input_tokens: self.cache_read_input_tokens,
            cache_write_input_tokens: self.cache_write_input_tokens,
            input_messages: self.input_messages,
            output_messages: self.output_messages,
            system_instructions: self.system_instructions,
            prompt_arn: self.prompt_arn,
            prompt_id: self.prompt_id,
            prompt_type: self.prompt_type,
            prompt_name: self.prompt_name,
            prompt_version: self.prompt_version,
        }
    }
}
