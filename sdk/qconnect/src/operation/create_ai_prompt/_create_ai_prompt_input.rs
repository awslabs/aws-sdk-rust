// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct CreateAiPromptInput {
    /// <p>A unique, case-sensitive identifier that you provide to ensure the idempotency of the request. If not provided, the Amazon Web Services SDK populates this field. For more information about idempotency, see <a href="http://aws.amazon.com/builders-library/making-retries-safe-with-idempotent-APIs/">Making retries safe with idempotent APIs</a>..</p>
    pub client_token: ::std::option::Option<::std::string::String>,
    /// <p>The identifier of the Amazon Q in Connect assistant. Can be either the ID or the ARN. URLs cannot contain the ARN.</p>
    pub assistant_id: ::std::option::Option<::std::string::String>,
    /// <p>The name of the AI Prompt.</p>
    pub name: ::std::option::Option<::std::string::String>,
    /// <p>The type of this AI Prompt.</p>
    pub r#type: ::std::option::Option<crate::types::AiPromptType>,
    /// <p>The configuration of the prompt template for this AI Prompt.</p>
    pub template_configuration: ::std::option::Option<crate::types::AiPromptTemplateConfiguration>,
    /// <p>The visibility status of the AI Prompt.</p>
    pub visibility_status: ::std::option::Option<crate::types::VisibilityStatus>,
    /// <p>The type of the prompt template for this AI Prompt.</p>
    pub template_type: ::std::option::Option<crate::types::AiPromptTemplateType>,
    /// <p>The identifier of the model used for this AI Prompt.</p><note>
    /// <p>For information about which models are supported in each Amazon Web Services Region, see <a href="https://docs.aws.amazon.com/connect/latest/adminguide/create-ai-prompts.html#cli-create-aiprompt">Supported models for system/custom prompts</a>.</p>
    /// </note>
    pub model_id: ::std::option::Option<::std::string::String>,
    /// <p>The API Format of the AI Prompt.</p>
    /// <p>Recommended values: <code>MESSAGES | TEXT_COMPLETIONS</code></p><note>
    /// <p>The values <code>ANTHROPIC_CLAUDE_MESSAGES | ANTHROPIC_CLAUDE_TEXT_COMPLETIONS</code> will be deprecated.</p>
    /// </note>
    pub api_format: ::std::option::Option<crate::types::AiPromptApiFormat>,
    /// <p>The tags used to organize, track, or control access for this resource.</p>
    pub tags: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    /// <p>The description of the AI Prompt.</p>
    pub description: ::std::option::Option<::std::string::String>,
    /// <p>The inference configuration for the AI Prompt being created.</p>
    pub inference_configuration: ::std::option::Option<crate::types::AiPromptInferenceConfiguration>,
}
impl CreateAiPromptInput {
    /// <p>A unique, case-sensitive identifier that you provide to ensure the idempotency of the request. If not provided, the Amazon Web Services SDK populates this field. For more information about idempotency, see <a href="http://aws.amazon.com/builders-library/making-retries-safe-with-idempotent-APIs/">Making retries safe with idempotent APIs</a>..</p>
    pub fn client_token(&self) -> ::std::option::Option<&str> {
        self.client_token.as_deref()
    }
    /// <p>The identifier of the Amazon Q in Connect assistant. Can be either the ID or the ARN. URLs cannot contain the ARN.</p>
    pub fn assistant_id(&self) -> ::std::option::Option<&str> {
        self.assistant_id.as_deref()
    }
    /// <p>The name of the AI Prompt.</p>
    pub fn name(&self) -> ::std::option::Option<&str> {
        self.name.as_deref()
    }
    /// <p>The type of this AI Prompt.</p>
    pub fn r#type(&self) -> ::std::option::Option<&crate::types::AiPromptType> {
        self.r#type.as_ref()
    }
    /// <p>The configuration of the prompt template for this AI Prompt.</p>
    pub fn template_configuration(&self) -> ::std::option::Option<&crate::types::AiPromptTemplateConfiguration> {
        self.template_configuration.as_ref()
    }
    /// <p>The visibility status of the AI Prompt.</p>
    pub fn visibility_status(&self) -> ::std::option::Option<&crate::types::VisibilityStatus> {
        self.visibility_status.as_ref()
    }
    /// <p>The type of the prompt template for this AI Prompt.</p>
    pub fn template_type(&self) -> ::std::option::Option<&crate::types::AiPromptTemplateType> {
        self.template_type.as_ref()
    }
    /// <p>The identifier of the model used for this AI Prompt.</p><note>
    /// <p>For information about which models are supported in each Amazon Web Services Region, see <a href="https://docs.aws.amazon.com/connect/latest/adminguide/create-ai-prompts.html#cli-create-aiprompt">Supported models for system/custom prompts</a>.</p>
    /// </note>
    pub fn model_id(&self) -> ::std::option::Option<&str> {
        self.model_id.as_deref()
    }
    /// <p>The API Format of the AI Prompt.</p>
    /// <p>Recommended values: <code>MESSAGES | TEXT_COMPLETIONS</code></p><note>
    /// <p>The values <code>ANTHROPIC_CLAUDE_MESSAGES | ANTHROPIC_CLAUDE_TEXT_COMPLETIONS</code> will be deprecated.</p>
    /// </note>
    pub fn api_format(&self) -> ::std::option::Option<&crate::types::AiPromptApiFormat> {
        self.api_format.as_ref()
    }
    /// <p>The tags used to organize, track, or control access for this resource.</p>
    pub fn tags(&self) -> ::std::option::Option<&::std::collections::HashMap<::std::string::String, ::std::string::String>> {
        self.tags.as_ref()
    }
    /// <p>The description of the AI Prompt.</p>
    pub fn description(&self) -> ::std::option::Option<&str> {
        self.description.as_deref()
    }
    /// <p>The inference configuration for the AI Prompt being created.</p>
    pub fn inference_configuration(&self) -> ::std::option::Option<&crate::types::AiPromptInferenceConfiguration> {
        self.inference_configuration.as_ref()
    }
}
impl CreateAiPromptInput {
    /// Creates a new builder-style object to manufacture [`CreateAiPromptInput`](crate::operation::create_ai_prompt::CreateAiPromptInput).
    pub fn builder() -> crate::operation::create_ai_prompt::builders::CreateAiPromptInputBuilder {
        crate::operation::create_ai_prompt::builders::CreateAiPromptInputBuilder::default()
    }
}

/// A builder for [`CreateAiPromptInput`](crate::operation::create_ai_prompt::CreateAiPromptInput).
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
#[non_exhaustive]
pub struct CreateAiPromptInputBuilder {
    pub(crate) client_token: ::std::option::Option<::std::string::String>,
    pub(crate) assistant_id: ::std::option::Option<::std::string::String>,
    pub(crate) name: ::std::option::Option<::std::string::String>,
    pub(crate) r#type: ::std::option::Option<crate::types::AiPromptType>,
    pub(crate) template_configuration: ::std::option::Option<crate::types::AiPromptTemplateConfiguration>,
    pub(crate) visibility_status: ::std::option::Option<crate::types::VisibilityStatus>,
    pub(crate) template_type: ::std::option::Option<crate::types::AiPromptTemplateType>,
    pub(crate) model_id: ::std::option::Option<::std::string::String>,
    pub(crate) api_format: ::std::option::Option<crate::types::AiPromptApiFormat>,
    pub(crate) tags: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    pub(crate) description: ::std::option::Option<::std::string::String>,
    pub(crate) inference_configuration: ::std::option::Option<crate::types::AiPromptInferenceConfiguration>,
}
impl CreateAiPromptInputBuilder {
    /// <p>A unique, case-sensitive identifier that you provide to ensure the idempotency of the request. If not provided, the Amazon Web Services SDK populates this field. For more information about idempotency, see <a href="http://aws.amazon.com/builders-library/making-retries-safe-with-idempotent-APIs/">Making retries safe with idempotent APIs</a>..</p>
    pub fn client_token(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.client_token = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>A unique, case-sensitive identifier that you provide to ensure the idempotency of the request. If not provided, the Amazon Web Services SDK populates this field. For more information about idempotency, see <a href="http://aws.amazon.com/builders-library/making-retries-safe-with-idempotent-APIs/">Making retries safe with idempotent APIs</a>..</p>
    pub fn set_client_token(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.client_token = input;
        self
    }
    /// <p>A unique, case-sensitive identifier that you provide to ensure the idempotency of the request. If not provided, the Amazon Web Services SDK populates this field. For more information about idempotency, see <a href="http://aws.amazon.com/builders-library/making-retries-safe-with-idempotent-APIs/">Making retries safe with idempotent APIs</a>..</p>
    pub fn get_client_token(&self) -> &::std::option::Option<::std::string::String> {
        &self.client_token
    }
    /// <p>The identifier of the Amazon Q in Connect assistant. Can be either the ID or the ARN. URLs cannot contain the ARN.</p>
    /// This field is required.
    pub fn assistant_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.assistant_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The identifier of the Amazon Q in Connect assistant. Can be either the ID or the ARN. URLs cannot contain the ARN.</p>
    pub fn set_assistant_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.assistant_id = input;
        self
    }
    /// <p>The identifier of the Amazon Q in Connect assistant. Can be either the ID or the ARN. URLs cannot contain the ARN.</p>
    pub fn get_assistant_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.assistant_id
    }
    /// <p>The name of the AI Prompt.</p>
    /// This field is required.
    pub fn name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The name of the AI Prompt.</p>
    pub fn set_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.name = input;
        self
    }
    /// <p>The name of the AI Prompt.</p>
    pub fn get_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.name
    }
    /// <p>The type of this AI Prompt.</p>
    /// This field is required.
    pub fn r#type(mut self, input: crate::types::AiPromptType) -> Self {
        self.r#type = ::std::option::Option::Some(input);
        self
    }
    /// <p>The type of this AI Prompt.</p>
    pub fn set_type(mut self, input: ::std::option::Option<crate::types::AiPromptType>) -> Self {
        self.r#type = input;
        self
    }
    /// <p>The type of this AI Prompt.</p>
    pub fn get_type(&self) -> &::std::option::Option<crate::types::AiPromptType> {
        &self.r#type
    }
    /// <p>The configuration of the prompt template for this AI Prompt.</p>
    /// This field is required.
    pub fn template_configuration(mut self, input: crate::types::AiPromptTemplateConfiguration) -> Self {
        self.template_configuration = ::std::option::Option::Some(input);
        self
    }
    /// <p>The configuration of the prompt template for this AI Prompt.</p>
    pub fn set_template_configuration(mut self, input: ::std::option::Option<crate::types::AiPromptTemplateConfiguration>) -> Self {
        self.template_configuration = input;
        self
    }
    /// <p>The configuration of the prompt template for this AI Prompt.</p>
    pub fn get_template_configuration(&self) -> &::std::option::Option<crate::types::AiPromptTemplateConfiguration> {
        &self.template_configuration
    }
    /// <p>The visibility status of the AI Prompt.</p>
    /// This field is required.
    pub fn visibility_status(mut self, input: crate::types::VisibilityStatus) -> Self {
        self.visibility_status = ::std::option::Option::Some(input);
        self
    }
    /// <p>The visibility status of the AI Prompt.</p>
    pub fn set_visibility_status(mut self, input: ::std::option::Option<crate::types::VisibilityStatus>) -> Self {
        self.visibility_status = input;
        self
    }
    /// <p>The visibility status of the AI Prompt.</p>
    pub fn get_visibility_status(&self) -> &::std::option::Option<crate::types::VisibilityStatus> {
        &self.visibility_status
    }
    /// <p>The type of the prompt template for this AI Prompt.</p>
    /// This field is required.
    pub fn template_type(mut self, input: crate::types::AiPromptTemplateType) -> Self {
        self.template_type = ::std::option::Option::Some(input);
        self
    }
    /// <p>The type of the prompt template for this AI Prompt.</p>
    pub fn set_template_type(mut self, input: ::std::option::Option<crate::types::AiPromptTemplateType>) -> Self {
        self.template_type = input;
        self
    }
    /// <p>The type of the prompt template for this AI Prompt.</p>
    pub fn get_template_type(&self) -> &::std::option::Option<crate::types::AiPromptTemplateType> {
        &self.template_type
    }
    /// <p>The identifier of the model used for this AI Prompt.</p><note>
    /// <p>For information about which models are supported in each Amazon Web Services Region, see <a href="https://docs.aws.amazon.com/connect/latest/adminguide/create-ai-prompts.html#cli-create-aiprompt">Supported models for system/custom prompts</a>.</p>
    /// </note>
    /// This field is required.
    pub fn model_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.model_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The identifier of the model used for this AI Prompt.</p><note>
    /// <p>For information about which models are supported in each Amazon Web Services Region, see <a href="https://docs.aws.amazon.com/connect/latest/adminguide/create-ai-prompts.html#cli-create-aiprompt">Supported models for system/custom prompts</a>.</p>
    /// </note>
    pub fn set_model_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.model_id = input;
        self
    }
    /// <p>The identifier of the model used for this AI Prompt.</p><note>
    /// <p>For information about which models are supported in each Amazon Web Services Region, see <a href="https://docs.aws.amazon.com/connect/latest/adminguide/create-ai-prompts.html#cli-create-aiprompt">Supported models for system/custom prompts</a>.</p>
    /// </note>
    pub fn get_model_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.model_id
    }
    /// <p>The API Format of the AI Prompt.</p>
    /// <p>Recommended values: <code>MESSAGES | TEXT_COMPLETIONS</code></p><note>
    /// <p>The values <code>ANTHROPIC_CLAUDE_MESSAGES | ANTHROPIC_CLAUDE_TEXT_COMPLETIONS</code> will be deprecated.</p>
    /// </note>
    /// This field is required.
    pub fn api_format(mut self, input: crate::types::AiPromptApiFormat) -> Self {
        self.api_format = ::std::option::Option::Some(input);
        self
    }
    /// <p>The API Format of the AI Prompt.</p>
    /// <p>Recommended values: <code>MESSAGES | TEXT_COMPLETIONS</code></p><note>
    /// <p>The values <code>ANTHROPIC_CLAUDE_MESSAGES | ANTHROPIC_CLAUDE_TEXT_COMPLETIONS</code> will be deprecated.</p>
    /// </note>
    pub fn set_api_format(mut self, input: ::std::option::Option<crate::types::AiPromptApiFormat>) -> Self {
        self.api_format = input;
        self
    }
    /// <p>The API Format of the AI Prompt.</p>
    /// <p>Recommended values: <code>MESSAGES | TEXT_COMPLETIONS</code></p><note>
    /// <p>The values <code>ANTHROPIC_CLAUDE_MESSAGES | ANTHROPIC_CLAUDE_TEXT_COMPLETIONS</code> will be deprecated.</p>
    /// </note>
    pub fn get_api_format(&self) -> &::std::option::Option<crate::types::AiPromptApiFormat> {
        &self.api_format
    }
    /// Adds a key-value pair to `tags`.
    ///
    /// To override the contents of this collection use [`set_tags`](Self::set_tags).
    ///
    /// <p>The tags used to organize, track, or control access for this resource.</p>
    pub fn tags(mut self, k: impl ::std::convert::Into<::std::string::String>, v: impl ::std::convert::Into<::std::string::String>) -> Self {
        let mut hash_map = self.tags.unwrap_or_default();
        hash_map.insert(k.into(), v.into());
        self.tags = ::std::option::Option::Some(hash_map);
        self
    }
    /// <p>The tags used to organize, track, or control access for this resource.</p>
    pub fn set_tags(mut self, input: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>) -> Self {
        self.tags = input;
        self
    }
    /// <p>The tags used to organize, track, or control access for this resource.</p>
    pub fn get_tags(&self) -> &::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>> {
        &self.tags
    }
    /// <p>The description of the AI Prompt.</p>
    pub fn description(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.description = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The description of the AI Prompt.</p>
    pub fn set_description(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.description = input;
        self
    }
    /// <p>The description of the AI Prompt.</p>
    pub fn get_description(&self) -> &::std::option::Option<::std::string::String> {
        &self.description
    }
    /// <p>The inference configuration for the AI Prompt being created.</p>
    pub fn inference_configuration(mut self, input: crate::types::AiPromptInferenceConfiguration) -> Self {
        self.inference_configuration = ::std::option::Option::Some(input);
        self
    }
    /// <p>The inference configuration for the AI Prompt being created.</p>
    pub fn set_inference_configuration(mut self, input: ::std::option::Option<crate::types::AiPromptInferenceConfiguration>) -> Self {
        self.inference_configuration = input;
        self
    }
    /// <p>The inference configuration for the AI Prompt being created.</p>
    pub fn get_inference_configuration(&self) -> &::std::option::Option<crate::types::AiPromptInferenceConfiguration> {
        &self.inference_configuration
    }
    /// Consumes the builder and constructs a [`CreateAiPromptInput`](crate::operation::create_ai_prompt::CreateAiPromptInput).
    pub fn build(
        self,
    ) -> ::std::result::Result<crate::operation::create_ai_prompt::CreateAiPromptInput, ::aws_smithy_types::error::operation::BuildError> {
        ::std::result::Result::Ok(crate::operation::create_ai_prompt::CreateAiPromptInput {
            client_token: self.client_token,
            assistant_id: self.assistant_id,
            name: self.name,
            r#type: self.r#type,
            template_configuration: self.template_configuration,
            visibility_status: self.visibility_status,
            template_type: self.template_type,
            model_id: self.model_id,
            api_format: self.api_format,
            tags: self.tags,
            description: self.description,
            inference_configuration: self.inference_configuration,
        })
    }
}
