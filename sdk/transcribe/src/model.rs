// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum LanguageCode {
    #[allow(missing_docs)] // documentation missing in model
    AfZa,
    #[allow(missing_docs)] // documentation missing in model
    ArAe,
    #[allow(missing_docs)] // documentation missing in model
    ArSa,
    #[allow(missing_docs)] // documentation missing in model
    CyGb,
    #[allow(missing_docs)] // documentation missing in model
    DaDk,
    #[allow(missing_docs)] // documentation missing in model
    DeCh,
    #[allow(missing_docs)] // documentation missing in model
    DeDe,
    #[allow(missing_docs)] // documentation missing in model
    EnAb,
    #[allow(missing_docs)] // documentation missing in model
    EnAu,
    #[allow(missing_docs)] // documentation missing in model
    EnGb,
    #[allow(missing_docs)] // documentation missing in model
    EnIe,
    #[allow(missing_docs)] // documentation missing in model
    EnIn,
    #[allow(missing_docs)] // documentation missing in model
    EnNz,
    #[allow(missing_docs)] // documentation missing in model
    EnUs,
    #[allow(missing_docs)] // documentation missing in model
    EnWl,
    #[allow(missing_docs)] // documentation missing in model
    EnZa,
    #[allow(missing_docs)] // documentation missing in model
    EsEs,
    #[allow(missing_docs)] // documentation missing in model
    EsUs,
    #[allow(missing_docs)] // documentation missing in model
    FaIr,
    #[allow(missing_docs)] // documentation missing in model
    FrCa,
    #[allow(missing_docs)] // documentation missing in model
    FrFr,
    #[allow(missing_docs)] // documentation missing in model
    GaIe,
    #[allow(missing_docs)] // documentation missing in model
    GdGb,
    #[allow(missing_docs)] // documentation missing in model
    HeIl,
    #[allow(missing_docs)] // documentation missing in model
    HiIn,
    #[allow(missing_docs)] // documentation missing in model
    IdId,
    #[allow(missing_docs)] // documentation missing in model
    ItIt,
    #[allow(missing_docs)] // documentation missing in model
    JaJp,
    #[allow(missing_docs)] // documentation missing in model
    KoKr,
    #[allow(missing_docs)] // documentation missing in model
    MsMy,
    #[allow(missing_docs)] // documentation missing in model
    NlNl,
    #[allow(missing_docs)] // documentation missing in model
    PtBr,
    #[allow(missing_docs)] // documentation missing in model
    PtPt,
    #[allow(missing_docs)] // documentation missing in model
    RuRu,
    #[allow(missing_docs)] // documentation missing in model
    TaIn,
    #[allow(missing_docs)] // documentation missing in model
    TeIn,
    #[allow(missing_docs)] // documentation missing in model
    ThTh,
    #[allow(missing_docs)] // documentation missing in model
    TrTr,
    #[allow(missing_docs)] // documentation missing in model
    ZhCn,
    #[allow(missing_docs)] // documentation missing in model
    ZhTw,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for LanguageCode {
    fn from(s: &str) -> Self {
        match s {
            "af-ZA" => LanguageCode::AfZa,
            "ar-AE" => LanguageCode::ArAe,
            "ar-SA" => LanguageCode::ArSa,
            "cy-GB" => LanguageCode::CyGb,
            "da-DK" => LanguageCode::DaDk,
            "de-CH" => LanguageCode::DeCh,
            "de-DE" => LanguageCode::DeDe,
            "en-AB" => LanguageCode::EnAb,
            "en-AU" => LanguageCode::EnAu,
            "en-GB" => LanguageCode::EnGb,
            "en-IE" => LanguageCode::EnIe,
            "en-IN" => LanguageCode::EnIn,
            "en-NZ" => LanguageCode::EnNz,
            "en-US" => LanguageCode::EnUs,
            "en-WL" => LanguageCode::EnWl,
            "en-ZA" => LanguageCode::EnZa,
            "es-ES" => LanguageCode::EsEs,
            "es-US" => LanguageCode::EsUs,
            "fa-IR" => LanguageCode::FaIr,
            "fr-CA" => LanguageCode::FrCa,
            "fr-FR" => LanguageCode::FrFr,
            "ga-IE" => LanguageCode::GaIe,
            "gd-GB" => LanguageCode::GdGb,
            "he-IL" => LanguageCode::HeIl,
            "hi-IN" => LanguageCode::HiIn,
            "id-ID" => LanguageCode::IdId,
            "it-IT" => LanguageCode::ItIt,
            "ja-JP" => LanguageCode::JaJp,
            "ko-KR" => LanguageCode::KoKr,
            "ms-MY" => LanguageCode::MsMy,
            "nl-NL" => LanguageCode::NlNl,
            "pt-BR" => LanguageCode::PtBr,
            "pt-PT" => LanguageCode::PtPt,
            "ru-RU" => LanguageCode::RuRu,
            "ta-IN" => LanguageCode::TaIn,
            "te-IN" => LanguageCode::TeIn,
            "th-TH" => LanguageCode::ThTh,
            "tr-TR" => LanguageCode::TrTr,
            "zh-CN" => LanguageCode::ZhCn,
            "zh-TW" => LanguageCode::ZhTw,
            other => LanguageCode::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for LanguageCode {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(LanguageCode::from(s))
    }
}
impl LanguageCode {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            LanguageCode::AfZa => "af-ZA",
            LanguageCode::ArAe => "ar-AE",
            LanguageCode::ArSa => "ar-SA",
            LanguageCode::CyGb => "cy-GB",
            LanguageCode::DaDk => "da-DK",
            LanguageCode::DeCh => "de-CH",
            LanguageCode::DeDe => "de-DE",
            LanguageCode::EnAb => "en-AB",
            LanguageCode::EnAu => "en-AU",
            LanguageCode::EnGb => "en-GB",
            LanguageCode::EnIe => "en-IE",
            LanguageCode::EnIn => "en-IN",
            LanguageCode::EnNz => "en-NZ",
            LanguageCode::EnUs => "en-US",
            LanguageCode::EnWl => "en-WL",
            LanguageCode::EnZa => "en-ZA",
            LanguageCode::EsEs => "es-ES",
            LanguageCode::EsUs => "es-US",
            LanguageCode::FaIr => "fa-IR",
            LanguageCode::FrCa => "fr-CA",
            LanguageCode::FrFr => "fr-FR",
            LanguageCode::GaIe => "ga-IE",
            LanguageCode::GdGb => "gd-GB",
            LanguageCode::HeIl => "he-IL",
            LanguageCode::HiIn => "hi-IN",
            LanguageCode::IdId => "id-ID",
            LanguageCode::ItIt => "it-IT",
            LanguageCode::JaJp => "ja-JP",
            LanguageCode::KoKr => "ko-KR",
            LanguageCode::MsMy => "ms-MY",
            LanguageCode::NlNl => "nl-NL",
            LanguageCode::PtBr => "pt-BR",
            LanguageCode::PtPt => "pt-PT",
            LanguageCode::RuRu => "ru-RU",
            LanguageCode::TaIn => "ta-IN",
            LanguageCode::TeIn => "te-IN",
            LanguageCode::ThTh => "th-TH",
            LanguageCode::TrTr => "tr-TR",
            LanguageCode::ZhCn => "zh-CN",
            LanguageCode::ZhTw => "zh-TW",
            LanguageCode::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &[
            "af-ZA", "ar-AE", "ar-SA", "cy-GB", "da-DK", "de-CH", "de-DE", "en-AB", "en-AU",
            "en-GB", "en-IE", "en-IN", "en-NZ", "en-US", "en-WL", "en-ZA", "es-ES", "es-US",
            "fa-IR", "fr-CA", "fr-FR", "ga-IE", "gd-GB", "he-IL", "hi-IN", "id-ID", "it-IT",
            "ja-JP", "ko-KR", "ms-MY", "nl-NL", "pt-BR", "pt-PT", "ru-RU", "ta-IN", "te-IN",
            "th-TH", "tr-TR", "zh-CN", "zh-TW",
        ]
    }
}
impl AsRef<str> for LanguageCode {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum VocabularyState {
    #[allow(missing_docs)] // documentation missing in model
    Failed,
    #[allow(missing_docs)] // documentation missing in model
    Pending,
    #[allow(missing_docs)] // documentation missing in model
    Ready,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for VocabularyState {
    fn from(s: &str) -> Self {
        match s {
            "FAILED" => VocabularyState::Failed,
            "PENDING" => VocabularyState::Pending,
            "READY" => VocabularyState::Ready,
            other => VocabularyState::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for VocabularyState {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(VocabularyState::from(s))
    }
}
impl VocabularyState {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            VocabularyState::Failed => "FAILED",
            VocabularyState::Pending => "PENDING",
            VocabularyState::Ready => "READY",
            VocabularyState::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["FAILED", "PENDING", "READY"]
    }
}
impl AsRef<str> for VocabularyState {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Provides you with the properties of the Call Analytics category you specified in your request. This includes the list of rules that define the specified category.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct CategoryProperties {
    /// <p>The name of the Call Analytics category. Category names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub category_name: std::option::Option<std::string::String>,
    /// <p>The rules used to define a Call Analytics category. Each category can have between 1 and 20 rules.</p>
    pub rules: std::option::Option<std::vec::Vec<crate::model::Rule>>,
    /// <p>The date and time the specified Call Analytics category was created.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
    pub create_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time the specified Call Analytics category was last updated.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-05T12:45:32.691000-07:00</code> represents 12:45 PM UTC-7 on May 5, 2022.</p>
    pub last_update_time: std::option::Option<aws_smithy_types::DateTime>,
}
impl CategoryProperties {
    /// <p>The name of the Call Analytics category. Category names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub fn category_name(&self) -> std::option::Option<&str> {
        self.category_name.as_deref()
    }
    /// <p>The rules used to define a Call Analytics category. Each category can have between 1 and 20 rules.</p>
    pub fn rules(&self) -> std::option::Option<&[crate::model::Rule]> {
        self.rules.as_deref()
    }
    /// <p>The date and time the specified Call Analytics category was created.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn create_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.create_time.as_ref()
    }
    /// <p>The date and time the specified Call Analytics category was last updated.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-05T12:45:32.691000-07:00</code> represents 12:45 PM UTC-7 on May 5, 2022.</p>
    pub fn last_update_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.last_update_time.as_ref()
    }
}
impl std::fmt::Debug for CategoryProperties {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("CategoryProperties");
        formatter.field("category_name", &self.category_name);
        formatter.field("rules", &self.rules);
        formatter.field("create_time", &self.create_time);
        formatter.field("last_update_time", &self.last_update_time);
        formatter.finish()
    }
}
/// See [`CategoryProperties`](crate::model::CategoryProperties)
pub mod category_properties {

    /// A builder for [`CategoryProperties`](crate::model::CategoryProperties)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) category_name: std::option::Option<std::string::String>,
        pub(crate) rules: std::option::Option<std::vec::Vec<crate::model::Rule>>,
        pub(crate) create_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) last_update_time: std::option::Option<aws_smithy_types::DateTime>,
    }
    impl Builder {
        /// <p>The name of the Call Analytics category. Category names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn category_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.category_name = Some(input.into());
            self
        }
        /// <p>The name of the Call Analytics category. Category names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn set_category_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.category_name = input;
            self
        }
        /// Appends an item to `rules`.
        ///
        /// To override the contents of this collection use [`set_rules`](Self::set_rules).
        ///
        /// <p>The rules used to define a Call Analytics category. Each category can have between 1 and 20 rules.</p>
        pub fn rules(mut self, input: crate::model::Rule) -> Self {
            let mut v = self.rules.unwrap_or_default();
            v.push(input);
            self.rules = Some(v);
            self
        }
        /// <p>The rules used to define a Call Analytics category. Each category can have between 1 and 20 rules.</p>
        pub fn set_rules(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Rule>>,
        ) -> Self {
            self.rules = input;
            self
        }
        /// <p>The date and time the specified Call Analytics category was created.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn create_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.create_time = Some(input);
            self
        }
        /// <p>The date and time the specified Call Analytics category was created.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_create_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.create_time = input;
            self
        }
        /// <p>The date and time the specified Call Analytics category was last updated.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-05T12:45:32.691000-07:00</code> represents 12:45 PM UTC-7 on May 5, 2022.</p>
        pub fn last_update_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.last_update_time = Some(input);
            self
        }
        /// <p>The date and time the specified Call Analytics category was last updated.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-05T12:45:32.691000-07:00</code> represents 12:45 PM UTC-7 on May 5, 2022.</p>
        pub fn set_last_update_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.last_update_time = input;
            self
        }
        /// Consumes the builder and constructs a [`CategoryProperties`](crate::model::CategoryProperties)
        pub fn build(self) -> crate::model::CategoryProperties {
            crate::model::CategoryProperties {
                category_name: self.category_name,
                rules: self.rules,
                create_time: self.create_time,
                last_update_time: self.last_update_time,
            }
        }
    }
}
impl CategoryProperties {
    /// Creates a new builder-style object to manufacture [`CategoryProperties`](crate::model::CategoryProperties)
    pub fn builder() -> crate::model::category_properties::Builder {
        crate::model::category_properties::Builder::default()
    }
}

/// <p>A rule is a set of criteria you can specify to flag an attribute in your Call Analytics output. Rules define a Call Analytics category.</p>
/// <p>Rules can include these parameters: , , , and . To learn more about these parameters, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/call-analytics-create-categories.html#call-analytics-create-categories-rules">Rule criteria</a>.</p>
/// <p>To learn more about Call Analytics categories, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/call-analytics-create-categories.html">Creating categories</a>.</p>
/// <p>To learn more about Call Analytics, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/call-analytics.html">Analyzing call center audio with Call Analytics</a>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub enum Rule {
    /// <p>Flag the presence or absence of interruptions in your Call Analytics transcription output. Refer to for more detail.</p>
    InterruptionFilter(crate::model::InterruptionFilter),
    /// <p>Flag the presence or absence of periods of silence in your Call Analytics transcription output. Refer to for more detail.</p>
    NonTalkTimeFilter(crate::model::NonTalkTimeFilter),
    /// <p>Flag the presence or absence of specific sentiments in your Call Analytics transcription output. Refer to for more detail.</p>
    SentimentFilter(crate::model::SentimentFilter),
    /// <p>Flag the presence or absence of specific words or phrases in your Call Analytics transcription output. Refer to for more detail.</p>
    TranscriptFilter(crate::model::TranscriptFilter),
    /// The `Unknown` variant represents cases where new union variant was received. Consider upgrading the SDK to the latest available version.
    /// An unknown enum variant
    ///
    /// _Note: If you encounter this error, consider upgrading your SDK to the latest version._
    /// The `Unknown` variant represents cases where the server sent a value that wasn't recognized
    /// by the client. This can happen when the server adds new functionality, but the client has not been updated.
    /// To investigate this, consider turning on debug logging to print the raw HTTP response.
    #[non_exhaustive]
    Unknown,
}
impl Rule {
    /// Tries to convert the enum instance into [`InterruptionFilter`](crate::model::Rule::InterruptionFilter), extracting the inner [`InterruptionFilter`](crate::model::InterruptionFilter).
    /// Returns `Err(&Self)` if it can't be converted.
    pub fn as_interruption_filter(
        &self,
    ) -> std::result::Result<&crate::model::InterruptionFilter, &Self> {
        if let Rule::InterruptionFilter(val) = &self {
            Ok(val)
        } else {
            Err(self)
        }
    }
    /// Returns true if this is a [`InterruptionFilter`](crate::model::Rule::InterruptionFilter).
    pub fn is_interruption_filter(&self) -> bool {
        self.as_interruption_filter().is_ok()
    }
    /// Tries to convert the enum instance into [`NonTalkTimeFilter`](crate::model::Rule::NonTalkTimeFilter), extracting the inner [`NonTalkTimeFilter`](crate::model::NonTalkTimeFilter).
    /// Returns `Err(&Self)` if it can't be converted.
    pub fn as_non_talk_time_filter(
        &self,
    ) -> std::result::Result<&crate::model::NonTalkTimeFilter, &Self> {
        if let Rule::NonTalkTimeFilter(val) = &self {
            Ok(val)
        } else {
            Err(self)
        }
    }
    /// Returns true if this is a [`NonTalkTimeFilter`](crate::model::Rule::NonTalkTimeFilter).
    pub fn is_non_talk_time_filter(&self) -> bool {
        self.as_non_talk_time_filter().is_ok()
    }
    /// Tries to convert the enum instance into [`SentimentFilter`](crate::model::Rule::SentimentFilter), extracting the inner [`SentimentFilter`](crate::model::SentimentFilter).
    /// Returns `Err(&Self)` if it can't be converted.
    pub fn as_sentiment_filter(
        &self,
    ) -> std::result::Result<&crate::model::SentimentFilter, &Self> {
        if let Rule::SentimentFilter(val) = &self {
            Ok(val)
        } else {
            Err(self)
        }
    }
    /// Returns true if this is a [`SentimentFilter`](crate::model::Rule::SentimentFilter).
    pub fn is_sentiment_filter(&self) -> bool {
        self.as_sentiment_filter().is_ok()
    }
    /// Tries to convert the enum instance into [`TranscriptFilter`](crate::model::Rule::TranscriptFilter), extracting the inner [`TranscriptFilter`](crate::model::TranscriptFilter).
    /// Returns `Err(&Self)` if it can't be converted.
    pub fn as_transcript_filter(
        &self,
    ) -> std::result::Result<&crate::model::TranscriptFilter, &Self> {
        if let Rule::TranscriptFilter(val) = &self {
            Ok(val)
        } else {
            Err(self)
        }
    }
    /// Returns true if this is a [`TranscriptFilter`](crate::model::Rule::TranscriptFilter).
    pub fn is_transcript_filter(&self) -> bool {
        self.as_transcript_filter().is_ok()
    }
    /// Returns true if the enum instance is the `Unknown` variant.
    pub fn is_unknown(&self) -> bool {
        matches!(self, Self::Unknown)
    }
}

/// <p>Flag the presence or absence of specific sentiments detected in your Call Analytics transcription output.</p>
/// <p>Rules using <code>SentimentFilter</code> are designed to match:</p>
/// <ul>
/// <li> <p>The presence or absence of a positive sentiment felt by the customer, agent, or both at specified points in the call</p> </li>
/// <li> <p>The presence or absence of a negative sentiment felt by the customer, agent, or both at specified points in the call</p> </li>
/// <li> <p>The presence or absence of a neutral sentiment felt by the customer, agent, or both at specified points in the call</p> </li>
/// <li> <p>The presence or absence of a mixed sentiment felt by the customer, the agent, or both at specified points in the call</p> </li>
/// </ul>
/// <p>See <a href="https://docs.aws.amazon.com/transcribe/latest/dg/call-analytics-create-categories.html#call-analytics-create-categories-rules">Rule criteria</a> for examples.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct SentimentFilter {
    /// <p>Specify the sentiments you want to flag.</p>
    pub sentiments: std::option::Option<std::vec::Vec<crate::model::SentimentValue>>,
    /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for the specified sentiments. See for more detail.</p>
    pub absolute_time_range: std::option::Option<crate::model::AbsoluteTimeRange>,
    /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for the specified sentiments. See for more detail.</p>
    pub relative_time_range: std::option::Option<crate::model::RelativeTimeRange>,
    /// <p>Specify the participant you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
    pub participant_role: std::option::Option<crate::model::ParticipantRole>,
    /// <p>Set to <code>TRUE</code> to flag the sentiments you didn't include in your request. Set to <code>FALSE</code> to flag the sentiments you specified in your request.</p>
    pub negate: std::option::Option<bool>,
}
impl SentimentFilter {
    /// <p>Specify the sentiments you want to flag.</p>
    pub fn sentiments(&self) -> std::option::Option<&[crate::model::SentimentValue]> {
        self.sentiments.as_deref()
    }
    /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for the specified sentiments. See for more detail.</p>
    pub fn absolute_time_range(&self) -> std::option::Option<&crate::model::AbsoluteTimeRange> {
        self.absolute_time_range.as_ref()
    }
    /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for the specified sentiments. See for more detail.</p>
    pub fn relative_time_range(&self) -> std::option::Option<&crate::model::RelativeTimeRange> {
        self.relative_time_range.as_ref()
    }
    /// <p>Specify the participant you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
    pub fn participant_role(&self) -> std::option::Option<&crate::model::ParticipantRole> {
        self.participant_role.as_ref()
    }
    /// <p>Set to <code>TRUE</code> to flag the sentiments you didn't include in your request. Set to <code>FALSE</code> to flag the sentiments you specified in your request.</p>
    pub fn negate(&self) -> std::option::Option<bool> {
        self.negate
    }
}
impl std::fmt::Debug for SentimentFilter {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("SentimentFilter");
        formatter.field("sentiments", &self.sentiments);
        formatter.field("absolute_time_range", &self.absolute_time_range);
        formatter.field("relative_time_range", &self.relative_time_range);
        formatter.field("participant_role", &self.participant_role);
        formatter.field("negate", &self.negate);
        formatter.finish()
    }
}
/// See [`SentimentFilter`](crate::model::SentimentFilter)
pub mod sentiment_filter {

    /// A builder for [`SentimentFilter`](crate::model::SentimentFilter)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) sentiments: std::option::Option<std::vec::Vec<crate::model::SentimentValue>>,
        pub(crate) absolute_time_range: std::option::Option<crate::model::AbsoluteTimeRange>,
        pub(crate) relative_time_range: std::option::Option<crate::model::RelativeTimeRange>,
        pub(crate) participant_role: std::option::Option<crate::model::ParticipantRole>,
        pub(crate) negate: std::option::Option<bool>,
    }
    impl Builder {
        /// Appends an item to `sentiments`.
        ///
        /// To override the contents of this collection use [`set_sentiments`](Self::set_sentiments).
        ///
        /// <p>Specify the sentiments you want to flag.</p>
        pub fn sentiments(mut self, input: crate::model::SentimentValue) -> Self {
            let mut v = self.sentiments.unwrap_or_default();
            v.push(input);
            self.sentiments = Some(v);
            self
        }
        /// <p>Specify the sentiments you want to flag.</p>
        pub fn set_sentiments(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::SentimentValue>>,
        ) -> Self {
            self.sentiments = input;
            self
        }
        /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for the specified sentiments. See for more detail.</p>
        pub fn absolute_time_range(mut self, input: crate::model::AbsoluteTimeRange) -> Self {
            self.absolute_time_range = Some(input);
            self
        }
        /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for the specified sentiments. See for more detail.</p>
        pub fn set_absolute_time_range(
            mut self,
            input: std::option::Option<crate::model::AbsoluteTimeRange>,
        ) -> Self {
            self.absolute_time_range = input;
            self
        }
        /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for the specified sentiments. See for more detail.</p>
        pub fn relative_time_range(mut self, input: crate::model::RelativeTimeRange) -> Self {
            self.relative_time_range = Some(input);
            self
        }
        /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for the specified sentiments. See for more detail.</p>
        pub fn set_relative_time_range(
            mut self,
            input: std::option::Option<crate::model::RelativeTimeRange>,
        ) -> Self {
            self.relative_time_range = input;
            self
        }
        /// <p>Specify the participant you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
        pub fn participant_role(mut self, input: crate::model::ParticipantRole) -> Self {
            self.participant_role = Some(input);
            self
        }
        /// <p>Specify the participant you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
        pub fn set_participant_role(
            mut self,
            input: std::option::Option<crate::model::ParticipantRole>,
        ) -> Self {
            self.participant_role = input;
            self
        }
        /// <p>Set to <code>TRUE</code> to flag the sentiments you didn't include in your request. Set to <code>FALSE</code> to flag the sentiments you specified in your request.</p>
        pub fn negate(mut self, input: bool) -> Self {
            self.negate = Some(input);
            self
        }
        /// <p>Set to <code>TRUE</code> to flag the sentiments you didn't include in your request. Set to <code>FALSE</code> to flag the sentiments you specified in your request.</p>
        pub fn set_negate(mut self, input: std::option::Option<bool>) -> Self {
            self.negate = input;
            self
        }
        /// Consumes the builder and constructs a [`SentimentFilter`](crate::model::SentimentFilter)
        pub fn build(self) -> crate::model::SentimentFilter {
            crate::model::SentimentFilter {
                sentiments: self.sentiments,
                absolute_time_range: self.absolute_time_range,
                relative_time_range: self.relative_time_range,
                participant_role: self.participant_role,
                negate: self.negate,
            }
        }
    }
}
impl SentimentFilter {
    /// Creates a new builder-style object to manufacture [`SentimentFilter`](crate::model::SentimentFilter)
    pub fn builder() -> crate::model::sentiment_filter::Builder {
        crate::model::sentiment_filter::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum ParticipantRole {
    #[allow(missing_docs)] // documentation missing in model
    Agent,
    #[allow(missing_docs)] // documentation missing in model
    Customer,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for ParticipantRole {
    fn from(s: &str) -> Self {
        match s {
            "AGENT" => ParticipantRole::Agent,
            "CUSTOMER" => ParticipantRole::Customer,
            other => ParticipantRole::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for ParticipantRole {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(ParticipantRole::from(s))
    }
}
impl ParticipantRole {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            ParticipantRole::Agent => "AGENT",
            ParticipantRole::Customer => "CUSTOMER",
            ParticipantRole::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["AGENT", "CUSTOMER"]
    }
}
impl AsRef<str> for ParticipantRole {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>A time range, in percentage, between two points in your media file.</p>
/// <p>You can use <code>StartPercentage</code> and <code>EndPercentage</code> to search a custom segment. For example, setting <code>StartPercentage</code> to 10 and <code>EndPercentage</code> to 50 only searches for your specified criteria in the audio contained between the 10 percent mark and the 50 percent mark of your media file.</p>
/// <p>You can use also <code>First</code> to search from the start of the media file until the time you specify, or <code>Last</code> to search from the time you specify until the end of the media file. For example, setting <code>First</code> to 10 only searches for your specified criteria in the audio contained in the first 10 percent of the media file.</p>
/// <p>If you prefer to use milliseconds instead of percentage, see .</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct RelativeTimeRange {
    /// <p>The time, in percentage, when Amazon Transcribe starts searching for the specified criteria in your media file. If you include <code>StartPercentage</code> in your request, you must also include <code>EndPercentage</code>.</p>
    pub start_percentage: std::option::Option<i32>,
    /// <p>The time, in percentage, when Amazon Transcribe stops searching for the specified criteria in your media file. If you include <code>EndPercentage</code> in your request, you must also include <code>StartPercentage</code>.</p>
    pub end_percentage: std::option::Option<i32>,
    /// <p>The time, in percentage, from the start of your media file until the value you specify in which Amazon Transcribe searches for your specified criteria.</p>
    pub first: std::option::Option<i32>,
    /// <p>The time, in percentage, from the value you specify until the end of your media file in which Amazon Transcribe searches for your specified criteria.</p>
    pub last: std::option::Option<i32>,
}
impl RelativeTimeRange {
    /// <p>The time, in percentage, when Amazon Transcribe starts searching for the specified criteria in your media file. If you include <code>StartPercentage</code> in your request, you must also include <code>EndPercentage</code>.</p>
    pub fn start_percentage(&self) -> std::option::Option<i32> {
        self.start_percentage
    }
    /// <p>The time, in percentage, when Amazon Transcribe stops searching for the specified criteria in your media file. If you include <code>EndPercentage</code> in your request, you must also include <code>StartPercentage</code>.</p>
    pub fn end_percentage(&self) -> std::option::Option<i32> {
        self.end_percentage
    }
    /// <p>The time, in percentage, from the start of your media file until the value you specify in which Amazon Transcribe searches for your specified criteria.</p>
    pub fn first(&self) -> std::option::Option<i32> {
        self.first
    }
    /// <p>The time, in percentage, from the value you specify until the end of your media file in which Amazon Transcribe searches for your specified criteria.</p>
    pub fn last(&self) -> std::option::Option<i32> {
        self.last
    }
}
impl std::fmt::Debug for RelativeTimeRange {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("RelativeTimeRange");
        formatter.field("start_percentage", &self.start_percentage);
        formatter.field("end_percentage", &self.end_percentage);
        formatter.field("first", &self.first);
        formatter.field("last", &self.last);
        formatter.finish()
    }
}
/// See [`RelativeTimeRange`](crate::model::RelativeTimeRange)
pub mod relative_time_range {

    /// A builder for [`RelativeTimeRange`](crate::model::RelativeTimeRange)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) start_percentage: std::option::Option<i32>,
        pub(crate) end_percentage: std::option::Option<i32>,
        pub(crate) first: std::option::Option<i32>,
        pub(crate) last: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The time, in percentage, when Amazon Transcribe starts searching for the specified criteria in your media file. If you include <code>StartPercentage</code> in your request, you must also include <code>EndPercentage</code>.</p>
        pub fn start_percentage(mut self, input: i32) -> Self {
            self.start_percentage = Some(input);
            self
        }
        /// <p>The time, in percentage, when Amazon Transcribe starts searching for the specified criteria in your media file. If you include <code>StartPercentage</code> in your request, you must also include <code>EndPercentage</code>.</p>
        pub fn set_start_percentage(mut self, input: std::option::Option<i32>) -> Self {
            self.start_percentage = input;
            self
        }
        /// <p>The time, in percentage, when Amazon Transcribe stops searching for the specified criteria in your media file. If you include <code>EndPercentage</code> in your request, you must also include <code>StartPercentage</code>.</p>
        pub fn end_percentage(mut self, input: i32) -> Self {
            self.end_percentage = Some(input);
            self
        }
        /// <p>The time, in percentage, when Amazon Transcribe stops searching for the specified criteria in your media file. If you include <code>EndPercentage</code> in your request, you must also include <code>StartPercentage</code>.</p>
        pub fn set_end_percentage(mut self, input: std::option::Option<i32>) -> Self {
            self.end_percentage = input;
            self
        }
        /// <p>The time, in percentage, from the start of your media file until the value you specify in which Amazon Transcribe searches for your specified criteria.</p>
        pub fn first(mut self, input: i32) -> Self {
            self.first = Some(input);
            self
        }
        /// <p>The time, in percentage, from the start of your media file until the value you specify in which Amazon Transcribe searches for your specified criteria.</p>
        pub fn set_first(mut self, input: std::option::Option<i32>) -> Self {
            self.first = input;
            self
        }
        /// <p>The time, in percentage, from the value you specify until the end of your media file in which Amazon Transcribe searches for your specified criteria.</p>
        pub fn last(mut self, input: i32) -> Self {
            self.last = Some(input);
            self
        }
        /// <p>The time, in percentage, from the value you specify until the end of your media file in which Amazon Transcribe searches for your specified criteria.</p>
        pub fn set_last(mut self, input: std::option::Option<i32>) -> Self {
            self.last = input;
            self
        }
        /// Consumes the builder and constructs a [`RelativeTimeRange`](crate::model::RelativeTimeRange)
        pub fn build(self) -> crate::model::RelativeTimeRange {
            crate::model::RelativeTimeRange {
                start_percentage: self.start_percentage,
                end_percentage: self.end_percentage,
                first: self.first,
                last: self.last,
            }
        }
    }
}
impl RelativeTimeRange {
    /// Creates a new builder-style object to manufacture [`RelativeTimeRange`](crate::model::RelativeTimeRange)
    pub fn builder() -> crate::model::relative_time_range::Builder {
        crate::model::relative_time_range::Builder::default()
    }
}

/// <p>A time range, in milliseconds, between two points in your media file.</p>
/// <p>You can use <code>StartTime</code> and <code>EndTime</code> to search a custom segment. For example, setting <code>StartTime</code> to 10000 and <code>EndTime</code> to 50000 only searches for your specified criteria in the audio contained between the 10,000 millisecond mark and the 50,000 millisecond mark of your media file. You must use <code>StartTime</code> and <code>EndTime</code> as a set; that is, if you include one, you must include both.</p>
/// <p>You can use also <code>First</code> to search from the start of the audio until the time you specify, or <code>Last</code> to search from the time you specify until the end of the audio. For example, setting <code>First</code> to 50000 only searches for your specified criteria in the audio contained between the start of the media file to the 50,000 millisecond mark. You can use <code>First</code> and <code>Last</code> independently of each other.</p>
/// <p>If you prefer to use percentage instead of milliseconds, see .</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct AbsoluteTimeRange {
    /// <p>The time, in milliseconds, when Amazon Transcribe starts searching for the specified criteria in your audio. If you include <code>StartTime</code> in your request, you must also include <code>EndTime</code>.</p>
    pub start_time: std::option::Option<i64>,
    /// <p>The time, in milliseconds, when Amazon Transcribe stops searching for the specified criteria in your audio. If you include <code>EndTime</code> in your request, you must also include <code>StartTime</code>.</p>
    pub end_time: std::option::Option<i64>,
    /// <p>The time, in milliseconds, from the start of your media file until the value you specify in which Amazon Transcribe searches for your specified criteria.</p>
    pub first: std::option::Option<i64>,
    /// <p>The time, in milliseconds, from the value you specify until the end of your media file in which Amazon Transcribe searches for your specified criteria.</p>
    pub last: std::option::Option<i64>,
}
impl AbsoluteTimeRange {
    /// <p>The time, in milliseconds, when Amazon Transcribe starts searching for the specified criteria in your audio. If you include <code>StartTime</code> in your request, you must also include <code>EndTime</code>.</p>
    pub fn start_time(&self) -> std::option::Option<i64> {
        self.start_time
    }
    /// <p>The time, in milliseconds, when Amazon Transcribe stops searching for the specified criteria in your audio. If you include <code>EndTime</code> in your request, you must also include <code>StartTime</code>.</p>
    pub fn end_time(&self) -> std::option::Option<i64> {
        self.end_time
    }
    /// <p>The time, in milliseconds, from the start of your media file until the value you specify in which Amazon Transcribe searches for your specified criteria.</p>
    pub fn first(&self) -> std::option::Option<i64> {
        self.first
    }
    /// <p>The time, in milliseconds, from the value you specify until the end of your media file in which Amazon Transcribe searches for your specified criteria.</p>
    pub fn last(&self) -> std::option::Option<i64> {
        self.last
    }
}
impl std::fmt::Debug for AbsoluteTimeRange {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("AbsoluteTimeRange");
        formatter.field("start_time", &self.start_time);
        formatter.field("end_time", &self.end_time);
        formatter.field("first", &self.first);
        formatter.field("last", &self.last);
        formatter.finish()
    }
}
/// See [`AbsoluteTimeRange`](crate::model::AbsoluteTimeRange)
pub mod absolute_time_range {

    /// A builder for [`AbsoluteTimeRange`](crate::model::AbsoluteTimeRange)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) start_time: std::option::Option<i64>,
        pub(crate) end_time: std::option::Option<i64>,
        pub(crate) first: std::option::Option<i64>,
        pub(crate) last: std::option::Option<i64>,
    }
    impl Builder {
        /// <p>The time, in milliseconds, when Amazon Transcribe starts searching for the specified criteria in your audio. If you include <code>StartTime</code> in your request, you must also include <code>EndTime</code>.</p>
        pub fn start_time(mut self, input: i64) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p>The time, in milliseconds, when Amazon Transcribe starts searching for the specified criteria in your audio. If you include <code>StartTime</code> in your request, you must also include <code>EndTime</code>.</p>
        pub fn set_start_time(mut self, input: std::option::Option<i64>) -> Self {
            self.start_time = input;
            self
        }
        /// <p>The time, in milliseconds, when Amazon Transcribe stops searching for the specified criteria in your audio. If you include <code>EndTime</code> in your request, you must also include <code>StartTime</code>.</p>
        pub fn end_time(mut self, input: i64) -> Self {
            self.end_time = Some(input);
            self
        }
        /// <p>The time, in milliseconds, when Amazon Transcribe stops searching for the specified criteria in your audio. If you include <code>EndTime</code> in your request, you must also include <code>StartTime</code>.</p>
        pub fn set_end_time(mut self, input: std::option::Option<i64>) -> Self {
            self.end_time = input;
            self
        }
        /// <p>The time, in milliseconds, from the start of your media file until the value you specify in which Amazon Transcribe searches for your specified criteria.</p>
        pub fn first(mut self, input: i64) -> Self {
            self.first = Some(input);
            self
        }
        /// <p>The time, in milliseconds, from the start of your media file until the value you specify in which Amazon Transcribe searches for your specified criteria.</p>
        pub fn set_first(mut self, input: std::option::Option<i64>) -> Self {
            self.first = input;
            self
        }
        /// <p>The time, in milliseconds, from the value you specify until the end of your media file in which Amazon Transcribe searches for your specified criteria.</p>
        pub fn last(mut self, input: i64) -> Self {
            self.last = Some(input);
            self
        }
        /// <p>The time, in milliseconds, from the value you specify until the end of your media file in which Amazon Transcribe searches for your specified criteria.</p>
        pub fn set_last(mut self, input: std::option::Option<i64>) -> Self {
            self.last = input;
            self
        }
        /// Consumes the builder and constructs a [`AbsoluteTimeRange`](crate::model::AbsoluteTimeRange)
        pub fn build(self) -> crate::model::AbsoluteTimeRange {
            crate::model::AbsoluteTimeRange {
                start_time: self.start_time,
                end_time: self.end_time,
                first: self.first,
                last: self.last,
            }
        }
    }
}
impl AbsoluteTimeRange {
    /// Creates a new builder-style object to manufacture [`AbsoluteTimeRange`](crate::model::AbsoluteTimeRange)
    pub fn builder() -> crate::model::absolute_time_range::Builder {
        crate::model::absolute_time_range::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum SentimentValue {
    #[allow(missing_docs)] // documentation missing in model
    Mixed,
    #[allow(missing_docs)] // documentation missing in model
    Negative,
    #[allow(missing_docs)] // documentation missing in model
    Neutral,
    #[allow(missing_docs)] // documentation missing in model
    Positive,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for SentimentValue {
    fn from(s: &str) -> Self {
        match s {
            "MIXED" => SentimentValue::Mixed,
            "NEGATIVE" => SentimentValue::Negative,
            "NEUTRAL" => SentimentValue::Neutral,
            "POSITIVE" => SentimentValue::Positive,
            other => SentimentValue::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for SentimentValue {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(SentimentValue::from(s))
    }
}
impl SentimentValue {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            SentimentValue::Mixed => "MIXED",
            SentimentValue::Negative => "NEGATIVE",
            SentimentValue::Neutral => "NEUTRAL",
            SentimentValue::Positive => "POSITIVE",
            SentimentValue::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["MIXED", "NEGATIVE", "NEUTRAL", "POSITIVE"]
    }
}
impl AsRef<str> for SentimentValue {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Flag the presence or absence of specific words or phrases detected in your Call Analytics transcription output.</p>
/// <p>Rules using <code>TranscriptFilter</code> are designed to match:</p>
/// <ul>
/// <li> <p>Custom words or phrases spoken by the agent, the customer, or both</p> </li>
/// <li> <p>Custom words or phrases <b>not</b> spoken by the agent, the customer, or either</p> </li>
/// <li> <p>Custom words or phrases that occur at a specific time frame</p> </li>
/// </ul>
/// <p>See <a href="https://docs.aws.amazon.com/transcribe/latest/dg/call-analytics-create-categories.html#call-analytics-create-categories-rules">Rule criteria</a> for examples.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct TranscriptFilter {
    /// <p>Flag the presence or absence of an exact match to the phrases you specify. For example, if you specify the phrase "speak to a manager" as your <code>Targets</code> value, only that exact phrase is flagged.</p>
    /// <p>Note that semantic matching is not supported. For example, if your customer says "speak to <i>the</i> manager", instead of "speak to <i>a</i> manager", your content is not flagged.</p>
    pub transcript_filter_type: std::option::Option<crate::model::TranscriptFilterType>,
    /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for the specified key words or phrases. See for more detail.</p>
    pub absolute_time_range: std::option::Option<crate::model::AbsoluteTimeRange>,
    /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for the specified key words or phrases. See for more detail.</p>
    pub relative_time_range: std::option::Option<crate::model::RelativeTimeRange>,
    /// <p>Specify the participant you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
    pub participant_role: std::option::Option<crate::model::ParticipantRole>,
    /// <p>Set to <code>TRUE</code> to flag the absence of the phrase you specified in your request. Set to <code>FALSE</code> to flag the presence of the phrase you specified in your request.</p>
    pub negate: std::option::Option<bool>,
    /// <p>Specify the phrases you want to flag.</p>
    pub targets: std::option::Option<std::vec::Vec<std::string::String>>,
}
impl TranscriptFilter {
    /// <p>Flag the presence or absence of an exact match to the phrases you specify. For example, if you specify the phrase "speak to a manager" as your <code>Targets</code> value, only that exact phrase is flagged.</p>
    /// <p>Note that semantic matching is not supported. For example, if your customer says "speak to <i>the</i> manager", instead of "speak to <i>a</i> manager", your content is not flagged.</p>
    pub fn transcript_filter_type(
        &self,
    ) -> std::option::Option<&crate::model::TranscriptFilterType> {
        self.transcript_filter_type.as_ref()
    }
    /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for the specified key words or phrases. See for more detail.</p>
    pub fn absolute_time_range(&self) -> std::option::Option<&crate::model::AbsoluteTimeRange> {
        self.absolute_time_range.as_ref()
    }
    /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for the specified key words or phrases. See for more detail.</p>
    pub fn relative_time_range(&self) -> std::option::Option<&crate::model::RelativeTimeRange> {
        self.relative_time_range.as_ref()
    }
    /// <p>Specify the participant you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
    pub fn participant_role(&self) -> std::option::Option<&crate::model::ParticipantRole> {
        self.participant_role.as_ref()
    }
    /// <p>Set to <code>TRUE</code> to flag the absence of the phrase you specified in your request. Set to <code>FALSE</code> to flag the presence of the phrase you specified in your request.</p>
    pub fn negate(&self) -> std::option::Option<bool> {
        self.negate
    }
    /// <p>Specify the phrases you want to flag.</p>
    pub fn targets(&self) -> std::option::Option<&[std::string::String]> {
        self.targets.as_deref()
    }
}
impl std::fmt::Debug for TranscriptFilter {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("TranscriptFilter");
        formatter.field("transcript_filter_type", &self.transcript_filter_type);
        formatter.field("absolute_time_range", &self.absolute_time_range);
        formatter.field("relative_time_range", &self.relative_time_range);
        formatter.field("participant_role", &self.participant_role);
        formatter.field("negate", &self.negate);
        formatter.field("targets", &self.targets);
        formatter.finish()
    }
}
/// See [`TranscriptFilter`](crate::model::TranscriptFilter)
pub mod transcript_filter {

    /// A builder for [`TranscriptFilter`](crate::model::TranscriptFilter)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) transcript_filter_type: std::option::Option<crate::model::TranscriptFilterType>,
        pub(crate) absolute_time_range: std::option::Option<crate::model::AbsoluteTimeRange>,
        pub(crate) relative_time_range: std::option::Option<crate::model::RelativeTimeRange>,
        pub(crate) participant_role: std::option::Option<crate::model::ParticipantRole>,
        pub(crate) negate: std::option::Option<bool>,
        pub(crate) targets: std::option::Option<std::vec::Vec<std::string::String>>,
    }
    impl Builder {
        /// <p>Flag the presence or absence of an exact match to the phrases you specify. For example, if you specify the phrase "speak to a manager" as your <code>Targets</code> value, only that exact phrase is flagged.</p>
        /// <p>Note that semantic matching is not supported. For example, if your customer says "speak to <i>the</i> manager", instead of "speak to <i>a</i> manager", your content is not flagged.</p>
        pub fn transcript_filter_type(mut self, input: crate::model::TranscriptFilterType) -> Self {
            self.transcript_filter_type = Some(input);
            self
        }
        /// <p>Flag the presence or absence of an exact match to the phrases you specify. For example, if you specify the phrase "speak to a manager" as your <code>Targets</code> value, only that exact phrase is flagged.</p>
        /// <p>Note that semantic matching is not supported. For example, if your customer says "speak to <i>the</i> manager", instead of "speak to <i>a</i> manager", your content is not flagged.</p>
        pub fn set_transcript_filter_type(
            mut self,
            input: std::option::Option<crate::model::TranscriptFilterType>,
        ) -> Self {
            self.transcript_filter_type = input;
            self
        }
        /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for the specified key words or phrases. See for more detail.</p>
        pub fn absolute_time_range(mut self, input: crate::model::AbsoluteTimeRange) -> Self {
            self.absolute_time_range = Some(input);
            self
        }
        /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for the specified key words or phrases. See for more detail.</p>
        pub fn set_absolute_time_range(
            mut self,
            input: std::option::Option<crate::model::AbsoluteTimeRange>,
        ) -> Self {
            self.absolute_time_range = input;
            self
        }
        /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for the specified key words or phrases. See for more detail.</p>
        pub fn relative_time_range(mut self, input: crate::model::RelativeTimeRange) -> Self {
            self.relative_time_range = Some(input);
            self
        }
        /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for the specified key words or phrases. See for more detail.</p>
        pub fn set_relative_time_range(
            mut self,
            input: std::option::Option<crate::model::RelativeTimeRange>,
        ) -> Self {
            self.relative_time_range = input;
            self
        }
        /// <p>Specify the participant you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
        pub fn participant_role(mut self, input: crate::model::ParticipantRole) -> Self {
            self.participant_role = Some(input);
            self
        }
        /// <p>Specify the participant you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
        pub fn set_participant_role(
            mut self,
            input: std::option::Option<crate::model::ParticipantRole>,
        ) -> Self {
            self.participant_role = input;
            self
        }
        /// <p>Set to <code>TRUE</code> to flag the absence of the phrase you specified in your request. Set to <code>FALSE</code> to flag the presence of the phrase you specified in your request.</p>
        pub fn negate(mut self, input: bool) -> Self {
            self.negate = Some(input);
            self
        }
        /// <p>Set to <code>TRUE</code> to flag the absence of the phrase you specified in your request. Set to <code>FALSE</code> to flag the presence of the phrase you specified in your request.</p>
        pub fn set_negate(mut self, input: std::option::Option<bool>) -> Self {
            self.negate = input;
            self
        }
        /// Appends an item to `targets`.
        ///
        /// To override the contents of this collection use [`set_targets`](Self::set_targets).
        ///
        /// <p>Specify the phrases you want to flag.</p>
        pub fn targets(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.targets.unwrap_or_default();
            v.push(input.into());
            self.targets = Some(v);
            self
        }
        /// <p>Specify the phrases you want to flag.</p>
        pub fn set_targets(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.targets = input;
            self
        }
        /// Consumes the builder and constructs a [`TranscriptFilter`](crate::model::TranscriptFilter)
        pub fn build(self) -> crate::model::TranscriptFilter {
            crate::model::TranscriptFilter {
                transcript_filter_type: self.transcript_filter_type,
                absolute_time_range: self.absolute_time_range,
                relative_time_range: self.relative_time_range,
                participant_role: self.participant_role,
                negate: self.negate,
                targets: self.targets,
            }
        }
    }
}
impl TranscriptFilter {
    /// Creates a new builder-style object to manufacture [`TranscriptFilter`](crate::model::TranscriptFilter)
    pub fn builder() -> crate::model::transcript_filter::Builder {
        crate::model::transcript_filter::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum TranscriptFilterType {
    #[allow(missing_docs)] // documentation missing in model
    Exact,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for TranscriptFilterType {
    fn from(s: &str) -> Self {
        match s {
            "EXACT" => TranscriptFilterType::Exact,
            other => TranscriptFilterType::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for TranscriptFilterType {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(TranscriptFilterType::from(s))
    }
}
impl TranscriptFilterType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            TranscriptFilterType::Exact => "EXACT",
            TranscriptFilterType::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["EXACT"]
    }
}
impl AsRef<str> for TranscriptFilterType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Flag the presence or absence of interruptions in your Call Analytics transcription output.</p>
/// <p>Rules using <code>InterruptionFilter</code> are designed to match:</p>
/// <ul>
/// <li> <p>Instances where an agent interrupts a customer</p> </li>
/// <li> <p>Instances where a customer interrupts an agent</p> </li>
/// <li> <p>Either participant interrupting the other</p> </li>
/// <li> <p>A lack of interruptions</p> </li>
/// </ul>
/// <p>See <a href="https://docs.aws.amazon.com/transcribe/latest/dg/call-analytics-create-categories.html#call-analytics-create-categories-rules">Rule criteria</a> for usage examples.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct InterruptionFilter {
    /// <p>Specify the duration of the interruptions in milliseconds. For example, you can flag speech that contains more than 10000 milliseconds of interruptions.</p>
    pub threshold: std::option::Option<i64>,
    /// <p>Specify the interrupter you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
    pub participant_role: std::option::Option<crate::model::ParticipantRole>,
    /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for an interruption. See for more detail.</p>
    pub absolute_time_range: std::option::Option<crate::model::AbsoluteTimeRange>,
    /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for an interruption. See for more detail.</p>
    pub relative_time_range: std::option::Option<crate::model::RelativeTimeRange>,
    /// <p>Set to <code>TRUE</code> to flag speech that does not contain interruptions. Set to <code>FALSE</code> to flag speech that contains interruptions.</p>
    pub negate: std::option::Option<bool>,
}
impl InterruptionFilter {
    /// <p>Specify the duration of the interruptions in milliseconds. For example, you can flag speech that contains more than 10000 milliseconds of interruptions.</p>
    pub fn threshold(&self) -> std::option::Option<i64> {
        self.threshold
    }
    /// <p>Specify the interrupter you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
    pub fn participant_role(&self) -> std::option::Option<&crate::model::ParticipantRole> {
        self.participant_role.as_ref()
    }
    /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for an interruption. See for more detail.</p>
    pub fn absolute_time_range(&self) -> std::option::Option<&crate::model::AbsoluteTimeRange> {
        self.absolute_time_range.as_ref()
    }
    /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for an interruption. See for more detail.</p>
    pub fn relative_time_range(&self) -> std::option::Option<&crate::model::RelativeTimeRange> {
        self.relative_time_range.as_ref()
    }
    /// <p>Set to <code>TRUE</code> to flag speech that does not contain interruptions. Set to <code>FALSE</code> to flag speech that contains interruptions.</p>
    pub fn negate(&self) -> std::option::Option<bool> {
        self.negate
    }
}
impl std::fmt::Debug for InterruptionFilter {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("InterruptionFilter");
        formatter.field("threshold", &self.threshold);
        formatter.field("participant_role", &self.participant_role);
        formatter.field("absolute_time_range", &self.absolute_time_range);
        formatter.field("relative_time_range", &self.relative_time_range);
        formatter.field("negate", &self.negate);
        formatter.finish()
    }
}
/// See [`InterruptionFilter`](crate::model::InterruptionFilter)
pub mod interruption_filter {

    /// A builder for [`InterruptionFilter`](crate::model::InterruptionFilter)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) threshold: std::option::Option<i64>,
        pub(crate) participant_role: std::option::Option<crate::model::ParticipantRole>,
        pub(crate) absolute_time_range: std::option::Option<crate::model::AbsoluteTimeRange>,
        pub(crate) relative_time_range: std::option::Option<crate::model::RelativeTimeRange>,
        pub(crate) negate: std::option::Option<bool>,
    }
    impl Builder {
        /// <p>Specify the duration of the interruptions in milliseconds. For example, you can flag speech that contains more than 10000 milliseconds of interruptions.</p>
        pub fn threshold(mut self, input: i64) -> Self {
            self.threshold = Some(input);
            self
        }
        /// <p>Specify the duration of the interruptions in milliseconds. For example, you can flag speech that contains more than 10000 milliseconds of interruptions.</p>
        pub fn set_threshold(mut self, input: std::option::Option<i64>) -> Self {
            self.threshold = input;
            self
        }
        /// <p>Specify the interrupter you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
        pub fn participant_role(mut self, input: crate::model::ParticipantRole) -> Self {
            self.participant_role = Some(input);
            self
        }
        /// <p>Specify the interrupter you want to flag. Omitting this parameter is equivalent to specifying both participants.</p>
        pub fn set_participant_role(
            mut self,
            input: std::option::Option<crate::model::ParticipantRole>,
        ) -> Self {
            self.participant_role = input;
            self
        }
        /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for an interruption. See for more detail.</p>
        pub fn absolute_time_range(mut self, input: crate::model::AbsoluteTimeRange) -> Self {
            self.absolute_time_range = Some(input);
            self
        }
        /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for an interruption. See for more detail.</p>
        pub fn set_absolute_time_range(
            mut self,
            input: std::option::Option<crate::model::AbsoluteTimeRange>,
        ) -> Self {
            self.absolute_time_range = input;
            self
        }
        /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for an interruption. See for more detail.</p>
        pub fn relative_time_range(mut self, input: crate::model::RelativeTimeRange) -> Self {
            self.relative_time_range = Some(input);
            self
        }
        /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for an interruption. See for more detail.</p>
        pub fn set_relative_time_range(
            mut self,
            input: std::option::Option<crate::model::RelativeTimeRange>,
        ) -> Self {
            self.relative_time_range = input;
            self
        }
        /// <p>Set to <code>TRUE</code> to flag speech that does not contain interruptions. Set to <code>FALSE</code> to flag speech that contains interruptions.</p>
        pub fn negate(mut self, input: bool) -> Self {
            self.negate = Some(input);
            self
        }
        /// <p>Set to <code>TRUE</code> to flag speech that does not contain interruptions. Set to <code>FALSE</code> to flag speech that contains interruptions.</p>
        pub fn set_negate(mut self, input: std::option::Option<bool>) -> Self {
            self.negate = input;
            self
        }
        /// Consumes the builder and constructs a [`InterruptionFilter`](crate::model::InterruptionFilter)
        pub fn build(self) -> crate::model::InterruptionFilter {
            crate::model::InterruptionFilter {
                threshold: self.threshold,
                participant_role: self.participant_role,
                absolute_time_range: self.absolute_time_range,
                relative_time_range: self.relative_time_range,
                negate: self.negate,
            }
        }
    }
}
impl InterruptionFilter {
    /// Creates a new builder-style object to manufacture [`InterruptionFilter`](crate::model::InterruptionFilter)
    pub fn builder() -> crate::model::interruption_filter::Builder {
        crate::model::interruption_filter::Builder::default()
    }
}

/// <p>Flag the presence or absence of periods of silence in your Call Analytics transcription output.</p>
/// <p>Rules using <code>NonTalkTimeFilter</code> are designed to match:</p>
/// <ul>
/// <li> <p>The presence of silence at specified periods throughout the call</p> </li>
/// <li> <p>The presence of speech at specified periods throughout the call</p> </li>
/// </ul>
/// <p>See <a href="https://docs.aws.amazon.com/transcribe/latest/dg/call-analytics-create-categories.html#call-analytics-create-categories-rules">Rule criteria</a> for usage examples.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct NonTalkTimeFilter {
    /// <p>Specify the duration, in milliseconds, of the period of silence you want to flag. For example, you can flag a silent period that lasts 30000 milliseconds.</p>
    pub threshold: std::option::Option<i64>,
    /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for a period of silence. See for more detail.</p>
    pub absolute_time_range: std::option::Option<crate::model::AbsoluteTimeRange>,
    /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for a period of silence. See for more detail.</p>
    pub relative_time_range: std::option::Option<crate::model::RelativeTimeRange>,
    /// <p>Set to <code>TRUE</code> to flag periods of speech. Set to <code>FALSE</code> to flag periods of silence</p>
    pub negate: std::option::Option<bool>,
}
impl NonTalkTimeFilter {
    /// <p>Specify the duration, in milliseconds, of the period of silence you want to flag. For example, you can flag a silent period that lasts 30000 milliseconds.</p>
    pub fn threshold(&self) -> std::option::Option<i64> {
        self.threshold
    }
    /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for a period of silence. See for more detail.</p>
    pub fn absolute_time_range(&self) -> std::option::Option<&crate::model::AbsoluteTimeRange> {
        self.absolute_time_range.as_ref()
    }
    /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for a period of silence. See for more detail.</p>
    pub fn relative_time_range(&self) -> std::option::Option<&crate::model::RelativeTimeRange> {
        self.relative_time_range.as_ref()
    }
    /// <p>Set to <code>TRUE</code> to flag periods of speech. Set to <code>FALSE</code> to flag periods of silence</p>
    pub fn negate(&self) -> std::option::Option<bool> {
        self.negate
    }
}
impl std::fmt::Debug for NonTalkTimeFilter {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("NonTalkTimeFilter");
        formatter.field("threshold", &self.threshold);
        formatter.field("absolute_time_range", &self.absolute_time_range);
        formatter.field("relative_time_range", &self.relative_time_range);
        formatter.field("negate", &self.negate);
        formatter.finish()
    }
}
/// See [`NonTalkTimeFilter`](crate::model::NonTalkTimeFilter)
pub mod non_talk_time_filter {

    /// A builder for [`NonTalkTimeFilter`](crate::model::NonTalkTimeFilter)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) threshold: std::option::Option<i64>,
        pub(crate) absolute_time_range: std::option::Option<crate::model::AbsoluteTimeRange>,
        pub(crate) relative_time_range: std::option::Option<crate::model::RelativeTimeRange>,
        pub(crate) negate: std::option::Option<bool>,
    }
    impl Builder {
        /// <p>Specify the duration, in milliseconds, of the period of silence you want to flag. For example, you can flag a silent period that lasts 30000 milliseconds.</p>
        pub fn threshold(mut self, input: i64) -> Self {
            self.threshold = Some(input);
            self
        }
        /// <p>Specify the duration, in milliseconds, of the period of silence you want to flag. For example, you can flag a silent period that lasts 30000 milliseconds.</p>
        pub fn set_threshold(mut self, input: std::option::Option<i64>) -> Self {
            self.threshold = input;
            self
        }
        /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for a period of silence. See for more detail.</p>
        pub fn absolute_time_range(mut self, input: crate::model::AbsoluteTimeRange) -> Self {
            self.absolute_time_range = Some(input);
            self
        }
        /// <p>Allows you to specify a time range (in milliseconds) in your audio, during which you want to search for a period of silence. See for more detail.</p>
        pub fn set_absolute_time_range(
            mut self,
            input: std::option::Option<crate::model::AbsoluteTimeRange>,
        ) -> Self {
            self.absolute_time_range = input;
            self
        }
        /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for a period of silence. See for more detail.</p>
        pub fn relative_time_range(mut self, input: crate::model::RelativeTimeRange) -> Self {
            self.relative_time_range = Some(input);
            self
        }
        /// <p>Allows you to specify a time range (in percentage) in your media file, during which you want to search for a period of silence. See for more detail.</p>
        pub fn set_relative_time_range(
            mut self,
            input: std::option::Option<crate::model::RelativeTimeRange>,
        ) -> Self {
            self.relative_time_range = input;
            self
        }
        /// <p>Set to <code>TRUE</code> to flag periods of speech. Set to <code>FALSE</code> to flag periods of silence</p>
        pub fn negate(mut self, input: bool) -> Self {
            self.negate = Some(input);
            self
        }
        /// <p>Set to <code>TRUE</code> to flag periods of speech. Set to <code>FALSE</code> to flag periods of silence</p>
        pub fn set_negate(mut self, input: std::option::Option<bool>) -> Self {
            self.negate = input;
            self
        }
        /// Consumes the builder and constructs a [`NonTalkTimeFilter`](crate::model::NonTalkTimeFilter)
        pub fn build(self) -> crate::model::NonTalkTimeFilter {
            crate::model::NonTalkTimeFilter {
                threshold: self.threshold,
                absolute_time_range: self.absolute_time_range,
                relative_time_range: self.relative_time_range,
                negate: self.negate,
            }
        }
    }
}
impl NonTalkTimeFilter {
    /// Creates a new builder-style object to manufacture [`NonTalkTimeFilter`](crate::model::NonTalkTimeFilter)
    pub fn builder() -> crate::model::non_talk_time_filter::Builder {
        crate::model::non_talk_time_filter::Builder::default()
    }
}

/// <p>Adds metadata, in the form of a key:value pair, to the specified resource.</p>
/// <p>For example, you could add the tag <code>Department:Sales</code> to a resource to indicate that it pertains to your organization's sales department. You can also use tags for tag-based access control.</p>
/// <p>To learn more about tagging, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/tagging.html">Tagging resources</a>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct Tag {
    /// <p>The first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag <code>Department:Sales</code>, the key is 'Department'.</p>
    pub key: std::option::Option<std::string::String>,
    /// <p>The second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag <code>Department:Sales</code>, the value is 'Sales'.</p>
    /// <p>Note that you can set the value of a tag to an empty string, but you can't set the value of a tag to null. Omitting the tag value is the same as using an empty string.</p>
    pub value: std::option::Option<std::string::String>,
}
impl Tag {
    /// <p>The first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag <code>Department:Sales</code>, the key is 'Department'.</p>
    pub fn key(&self) -> std::option::Option<&str> {
        self.key.as_deref()
    }
    /// <p>The second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag <code>Department:Sales</code>, the value is 'Sales'.</p>
    /// <p>Note that you can set the value of a tag to an empty string, but you can't set the value of a tag to null. Omitting the tag value is the same as using an empty string.</p>
    pub fn value(&self) -> std::option::Option<&str> {
        self.value.as_deref()
    }
}
impl std::fmt::Debug for Tag {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("Tag");
        formatter.field("key", &self.key);
        formatter.field("value", &self.value);
        formatter.finish()
    }
}
/// See [`Tag`](crate::model::Tag)
pub mod tag {

    /// A builder for [`Tag`](crate::model::Tag)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) key: std::option::Option<std::string::String>,
        pub(crate) value: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag <code>Department:Sales</code>, the key is 'Department'.</p>
        pub fn key(mut self, input: impl Into<std::string::String>) -> Self {
            self.key = Some(input.into());
            self
        }
        /// <p>The first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag <code>Department:Sales</code>, the key is 'Department'.</p>
        pub fn set_key(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.key = input;
            self
        }
        /// <p>The second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag <code>Department:Sales</code>, the value is 'Sales'.</p>
        /// <p>Note that you can set the value of a tag to an empty string, but you can't set the value of a tag to null. Omitting the tag value is the same as using an empty string.</p>
        pub fn value(mut self, input: impl Into<std::string::String>) -> Self {
            self.value = Some(input.into());
            self
        }
        /// <p>The second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag <code>Department:Sales</code>, the value is 'Sales'.</p>
        /// <p>Note that you can set the value of a tag to an empty string, but you can't set the value of a tag to null. Omitting the tag value is the same as using an empty string.</p>
        pub fn set_value(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.value = input;
            self
        }
        /// Consumes the builder and constructs a [`Tag`](crate::model::Tag)
        pub fn build(self) -> crate::model::Tag {
            crate::model::Tag {
                key: self.key,
                value: self.value,
            }
        }
    }
}
impl Tag {
    /// Creates a new builder-style object to manufacture [`Tag`](crate::model::Tag)
    pub fn builder() -> crate::model::tag::Builder {
        crate::model::tag::Builder::default()
    }
}

/// <p>Provides detailed information about a transcription job.</p>
/// <p>To view the status of the specified transcription job, check the <code>TranscriptionJobStatus</code> field. If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code>. If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
/// <p>If you enabled content redaction, the redacted transcript can be found at the location specified in <code>RedactedTranscriptFileUri</code>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct TranscriptionJob {
    /// <p>The name of the transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub transcription_job_name: std::option::Option<std::string::String>,
    /// <p>Provides the status of the specified transcription job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub transcription_job_status: std::option::Option<crate::model::TranscriptionJobStatus>,
    /// <p>The language code used to create your transcription job. For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
    /// <p>Note that you must include one of <code>LanguageCode</code>, <code>IdentifyLanguage</code>, or <code>IdentifyMultipleLanguages</code> in your request. If you include more than one of these parameters, your transcription job fails.</p>
    pub language_code: std::option::Option<crate::model::LanguageCode>,
    /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
    pub media_sample_rate_hertz: std::option::Option<i32>,
    /// <p>The format of the input media file.</p>
    pub media_format: std::option::Option<crate::model::MediaFormat>,
    /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
    pub media: std::option::Option<crate::model::Media>,
    /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
    pub transcript: std::option::Option<crate::model::Transcript>,
    /// <p>The date and time the specified transcription job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time the specified transcription job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub creation_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time the specified transcription job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub completion_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job request failed.</p>
    /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
    /// <ul>
    /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
    /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 8,000 and 48,000 Hertz.</p> </li>
    /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// </ul>
    pub failure_reason: std::option::Option<std::string::String>,
    /// <p>Specify additional optional settings in your request, including channel identification, alternative transcriptions, speaker labeling; allows you to apply custom vocabularies and vocabulary filters.</p>
    /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use <code>Settings</code> with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
    /// <p>If you're using automatic language identification with your request and want to include a custom language model, a custom vocabulary, or a custom vocabulary filter, do not use the <code>Settings</code> parameter; use instead the <code></code> parameter with the <code>LanguageModelName</code>, <code>VocabularyName</code> or <code>VocabularyFilterName</code> sub-parameters.</p>
    pub settings: std::option::Option<crate::model::Settings>,
    /// <p>The custom language model you want to include with your transcription job. If you include <code>ModelSettings</code> in your request, you must include the <code>LanguageModelName</code> sub-parameter.</p>
    pub model_settings: std::option::Option<crate::model::ModelSettings>,
    /// <p>Provides information about how your transcription job is being processed. This parameter shows if your request is queued and what data access role is being used.</p>
    pub job_execution_settings: std::option::Option<crate::model::JobExecutionSettings>,
    /// <p>Redacts or flags specified personally identifiable information (PII) in your transcript.</p>
    pub content_redaction: std::option::Option<crate::model::ContentRedaction>,
    /// <p>Indicates whether automatic language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
    pub identify_language: std::option::Option<bool>,
    /// <p>Indicates whether automatic multi-language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
    pub identify_multiple_languages: std::option::Option<bool>,
    /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. If you're unsure what languages are present, do not include this parameter.</p>
    /// <p>If you include <code>LanguageOptions</code> in your request, you must also include <code>IdentifyLanguage</code>.</p>
    /// <p>For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a>.</p>
    /// <p>To transcribe speech in Modern Standard Arabic (<code>ar-SA</code>), your media file must be encoded at a sample rate of 16,000 Hz or higher.</p>
    pub language_options: std::option::Option<std::vec::Vec<crate::model::LanguageCode>>,
    /// <p>The confidence score associated with the language identified in your media file.</p>
    /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
    pub identified_language_score: std::option::Option<f32>,
    /// <p>The language codes used to create your transcription job. This parameter is used with multi-language identification. For single-language identification requests, refer to the singular version of this parameter, <code>LanguageCode</code>.</p>
    /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
    pub language_codes: std::option::Option<std::vec::Vec<crate::model::LanguageCodeItem>>,
    /// <p>Adds one or more custom tags, each in the form of a key:value pair, to a new transcription job at the time you start this new job.</p>
    /// <p>To learn more about using tags with Amazon Transcribe, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/tagging.html">Tagging resources</a>.</p>
    pub tags: std::option::Option<std::vec::Vec<crate::model::Tag>>,
    /// <p>Generate subtitles for your media file with your transcription request.</p>
    pub subtitles: std::option::Option<crate::model::SubtitlesOutput>,
    /// <p>If using automatic language identification (<code>IdentifyLanguage</code>) in your request and you want to apply a custom language model, a custom vocabulary, or a custom vocabulary filter, include <code>LanguageIdSettings</code> with the relevant sub-parameters (<code>VocabularyName</code>, <code>LanguageModelName</code>, and <code>VocabularyFilterName</code>).</p>
    /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. Each language code you include can have an associated custom language model, custom vocabulary, and custom vocabulary filter. The languages you specify must match the languages of the specified custom language models, custom vocabularies, and custom vocabulary filters.</p>
    /// <p>To include language options using <code>IdentifyLanguage</code> <b>without</b> including a custom language model, a custom vocabulary, or a custom vocabulary filter, use <code>LanguageOptions</code> instead of <code>LanguageIdSettings</code>. Including language options can improve the accuracy of automatic language identification.</p>
    /// <p>If you want to include a custom language model with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>LanguageModelName</code> sub-parameter.</p>
    /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
    pub language_id_settings: std::option::Option<
        std::collections::HashMap<crate::model::LanguageCode, crate::model::LanguageIdSettings>,
    >,
}
impl TranscriptionJob {
    /// <p>The name of the transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub fn transcription_job_name(&self) -> std::option::Option<&str> {
        self.transcription_job_name.as_deref()
    }
    /// <p>Provides the status of the specified transcription job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub fn transcription_job_status(
        &self,
    ) -> std::option::Option<&crate::model::TranscriptionJobStatus> {
        self.transcription_job_status.as_ref()
    }
    /// <p>The language code used to create your transcription job. For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
    /// <p>Note that you must include one of <code>LanguageCode</code>, <code>IdentifyLanguage</code>, or <code>IdentifyMultipleLanguages</code> in your request. If you include more than one of these parameters, your transcription job fails.</p>
    pub fn language_code(&self) -> std::option::Option<&crate::model::LanguageCode> {
        self.language_code.as_ref()
    }
    /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
    pub fn media_sample_rate_hertz(&self) -> std::option::Option<i32> {
        self.media_sample_rate_hertz
    }
    /// <p>The format of the input media file.</p>
    pub fn media_format(&self) -> std::option::Option<&crate::model::MediaFormat> {
        self.media_format.as_ref()
    }
    /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
    pub fn media(&self) -> std::option::Option<&crate::model::Media> {
        self.media.as_ref()
    }
    /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
    pub fn transcript(&self) -> std::option::Option<&crate::model::Transcript> {
        self.transcript.as_ref()
    }
    /// <p>The date and time the specified transcription job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p>The date and time the specified transcription job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn creation_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.creation_time.as_ref()
    }
    /// <p>The date and time the specified transcription job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub fn completion_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.completion_time.as_ref()
    }
    /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job request failed.</p>
    /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
    /// <ul>
    /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
    /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 8,000 and 48,000 Hertz.</p> </li>
    /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// </ul>
    pub fn failure_reason(&self) -> std::option::Option<&str> {
        self.failure_reason.as_deref()
    }
    /// <p>Specify additional optional settings in your request, including channel identification, alternative transcriptions, speaker labeling; allows you to apply custom vocabularies and vocabulary filters.</p>
    /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use <code>Settings</code> with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
    /// <p>If you're using automatic language identification with your request and want to include a custom language model, a custom vocabulary, or a custom vocabulary filter, do not use the <code>Settings</code> parameter; use instead the <code></code> parameter with the <code>LanguageModelName</code>, <code>VocabularyName</code> or <code>VocabularyFilterName</code> sub-parameters.</p>
    pub fn settings(&self) -> std::option::Option<&crate::model::Settings> {
        self.settings.as_ref()
    }
    /// <p>The custom language model you want to include with your transcription job. If you include <code>ModelSettings</code> in your request, you must include the <code>LanguageModelName</code> sub-parameter.</p>
    pub fn model_settings(&self) -> std::option::Option<&crate::model::ModelSettings> {
        self.model_settings.as_ref()
    }
    /// <p>Provides information about how your transcription job is being processed. This parameter shows if your request is queued and what data access role is being used.</p>
    pub fn job_execution_settings(
        &self,
    ) -> std::option::Option<&crate::model::JobExecutionSettings> {
        self.job_execution_settings.as_ref()
    }
    /// <p>Redacts or flags specified personally identifiable information (PII) in your transcript.</p>
    pub fn content_redaction(&self) -> std::option::Option<&crate::model::ContentRedaction> {
        self.content_redaction.as_ref()
    }
    /// <p>Indicates whether automatic language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
    pub fn identify_language(&self) -> std::option::Option<bool> {
        self.identify_language
    }
    /// <p>Indicates whether automatic multi-language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
    pub fn identify_multiple_languages(&self) -> std::option::Option<bool> {
        self.identify_multiple_languages
    }
    /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. If you're unsure what languages are present, do not include this parameter.</p>
    /// <p>If you include <code>LanguageOptions</code> in your request, you must also include <code>IdentifyLanguage</code>.</p>
    /// <p>For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a>.</p>
    /// <p>To transcribe speech in Modern Standard Arabic (<code>ar-SA</code>), your media file must be encoded at a sample rate of 16,000 Hz or higher.</p>
    pub fn language_options(&self) -> std::option::Option<&[crate::model::LanguageCode]> {
        self.language_options.as_deref()
    }
    /// <p>The confidence score associated with the language identified in your media file.</p>
    /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
    pub fn identified_language_score(&self) -> std::option::Option<f32> {
        self.identified_language_score
    }
    /// <p>The language codes used to create your transcription job. This parameter is used with multi-language identification. For single-language identification requests, refer to the singular version of this parameter, <code>LanguageCode</code>.</p>
    /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
    pub fn language_codes(&self) -> std::option::Option<&[crate::model::LanguageCodeItem]> {
        self.language_codes.as_deref()
    }
    /// <p>Adds one or more custom tags, each in the form of a key:value pair, to a new transcription job at the time you start this new job.</p>
    /// <p>To learn more about using tags with Amazon Transcribe, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/tagging.html">Tagging resources</a>.</p>
    pub fn tags(&self) -> std::option::Option<&[crate::model::Tag]> {
        self.tags.as_deref()
    }
    /// <p>Generate subtitles for your media file with your transcription request.</p>
    pub fn subtitles(&self) -> std::option::Option<&crate::model::SubtitlesOutput> {
        self.subtitles.as_ref()
    }
    /// <p>If using automatic language identification (<code>IdentifyLanguage</code>) in your request and you want to apply a custom language model, a custom vocabulary, or a custom vocabulary filter, include <code>LanguageIdSettings</code> with the relevant sub-parameters (<code>VocabularyName</code>, <code>LanguageModelName</code>, and <code>VocabularyFilterName</code>).</p>
    /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. Each language code you include can have an associated custom language model, custom vocabulary, and custom vocabulary filter. The languages you specify must match the languages of the specified custom language models, custom vocabularies, and custom vocabulary filters.</p>
    /// <p>To include language options using <code>IdentifyLanguage</code> <b>without</b> including a custom language model, a custom vocabulary, or a custom vocabulary filter, use <code>LanguageOptions</code> instead of <code>LanguageIdSettings</code>. Including language options can improve the accuracy of automatic language identification.</p>
    /// <p>If you want to include a custom language model with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>LanguageModelName</code> sub-parameter.</p>
    /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
    pub fn language_id_settings(
        &self,
    ) -> std::option::Option<
        &std::collections::HashMap<crate::model::LanguageCode, crate::model::LanguageIdSettings>,
    > {
        self.language_id_settings.as_ref()
    }
}
impl std::fmt::Debug for TranscriptionJob {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("TranscriptionJob");
        formatter.field("transcription_job_name", &self.transcription_job_name);
        formatter.field("transcription_job_status", &self.transcription_job_status);
        formatter.field("language_code", &self.language_code);
        formatter.field("media_sample_rate_hertz", &self.media_sample_rate_hertz);
        formatter.field("media_format", &self.media_format);
        formatter.field("media", &self.media);
        formatter.field("transcript", &self.transcript);
        formatter.field("start_time", &self.start_time);
        formatter.field("creation_time", &self.creation_time);
        formatter.field("completion_time", &self.completion_time);
        formatter.field("failure_reason", &self.failure_reason);
        formatter.field("settings", &self.settings);
        formatter.field("model_settings", &self.model_settings);
        formatter.field("job_execution_settings", &self.job_execution_settings);
        formatter.field("content_redaction", &self.content_redaction);
        formatter.field("identify_language", &self.identify_language);
        formatter.field(
            "identify_multiple_languages",
            &self.identify_multiple_languages,
        );
        formatter.field("language_options", &self.language_options);
        formatter.field("identified_language_score", &self.identified_language_score);
        formatter.field("language_codes", &self.language_codes);
        formatter.field("tags", &self.tags);
        formatter.field("subtitles", &self.subtitles);
        formatter.field("language_id_settings", &self.language_id_settings);
        formatter.finish()
    }
}
/// See [`TranscriptionJob`](crate::model::TranscriptionJob)
pub mod transcription_job {

    /// A builder for [`TranscriptionJob`](crate::model::TranscriptionJob)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) transcription_job_name: std::option::Option<std::string::String>,
        pub(crate) transcription_job_status:
            std::option::Option<crate::model::TranscriptionJobStatus>,
        pub(crate) language_code: std::option::Option<crate::model::LanguageCode>,
        pub(crate) media_sample_rate_hertz: std::option::Option<i32>,
        pub(crate) media_format: std::option::Option<crate::model::MediaFormat>,
        pub(crate) media: std::option::Option<crate::model::Media>,
        pub(crate) transcript: std::option::Option<crate::model::Transcript>,
        pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) creation_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) completion_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) failure_reason: std::option::Option<std::string::String>,
        pub(crate) settings: std::option::Option<crate::model::Settings>,
        pub(crate) model_settings: std::option::Option<crate::model::ModelSettings>,
        pub(crate) job_execution_settings: std::option::Option<crate::model::JobExecutionSettings>,
        pub(crate) content_redaction: std::option::Option<crate::model::ContentRedaction>,
        pub(crate) identify_language: std::option::Option<bool>,
        pub(crate) identify_multiple_languages: std::option::Option<bool>,
        pub(crate) language_options: std::option::Option<std::vec::Vec<crate::model::LanguageCode>>,
        pub(crate) identified_language_score: std::option::Option<f32>,
        pub(crate) language_codes:
            std::option::Option<std::vec::Vec<crate::model::LanguageCodeItem>>,
        pub(crate) tags: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        pub(crate) subtitles: std::option::Option<crate::model::SubtitlesOutput>,
        pub(crate) language_id_settings: std::option::Option<
            std::collections::HashMap<crate::model::LanguageCode, crate::model::LanguageIdSettings>,
        >,
    }
    impl Builder {
        /// <p>The name of the transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn transcription_job_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.transcription_job_name = Some(input.into());
            self
        }
        /// <p>The name of the transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn set_transcription_job_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.transcription_job_name = input;
            self
        }
        /// <p>Provides the status of the specified transcription job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn transcription_job_status(
            mut self,
            input: crate::model::TranscriptionJobStatus,
        ) -> Self {
            self.transcription_job_status = Some(input);
            self
        }
        /// <p>Provides the status of the specified transcription job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn set_transcription_job_status(
            mut self,
            input: std::option::Option<crate::model::TranscriptionJobStatus>,
        ) -> Self {
            self.transcription_job_status = input;
            self
        }
        /// <p>The language code used to create your transcription job. For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
        /// <p>Note that you must include one of <code>LanguageCode</code>, <code>IdentifyLanguage</code>, or <code>IdentifyMultipleLanguages</code> in your request. If you include more than one of these parameters, your transcription job fails.</p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.language_code = Some(input);
            self
        }
        /// <p>The language code used to create your transcription job. For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
        /// <p>Note that you must include one of <code>LanguageCode</code>, <code>IdentifyLanguage</code>, or <code>IdentifyMultipleLanguages</code> in your request. If you include more than one of these parameters, your transcription job fails.</p>
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.language_code = input;
            self
        }
        /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
        pub fn media_sample_rate_hertz(mut self, input: i32) -> Self {
            self.media_sample_rate_hertz = Some(input);
            self
        }
        /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
        pub fn set_media_sample_rate_hertz(mut self, input: std::option::Option<i32>) -> Self {
            self.media_sample_rate_hertz = input;
            self
        }
        /// <p>The format of the input media file.</p>
        pub fn media_format(mut self, input: crate::model::MediaFormat) -> Self {
            self.media_format = Some(input);
            self
        }
        /// <p>The format of the input media file.</p>
        pub fn set_media_format(
            mut self,
            input: std::option::Option<crate::model::MediaFormat>,
        ) -> Self {
            self.media_format = input;
            self
        }
        /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
        pub fn media(mut self, input: crate::model::Media) -> Self {
            self.media = Some(input);
            self
        }
        /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
        pub fn set_media(mut self, input: std::option::Option<crate::model::Media>) -> Self {
            self.media = input;
            self
        }
        /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
        pub fn transcript(mut self, input: crate::model::Transcript) -> Self {
            self.transcript = Some(input);
            self
        }
        /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
        pub fn set_transcript(
            mut self,
            input: std::option::Option<crate::model::Transcript>,
        ) -> Self {
            self.transcript = input;
            self
        }
        /// <p>The date and time the specified transcription job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p>The date and time the specified transcription job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.start_time = input;
            self
        }
        /// <p>The date and time the specified transcription job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn creation_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.creation_time = Some(input);
            self
        }
        /// <p>The date and time the specified transcription job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_creation_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.creation_time = input;
            self
        }
        /// <p>The date and time the specified transcription job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn completion_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.completion_time = Some(input);
            self
        }
        /// <p>The date and time the specified transcription job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn set_completion_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.completion_time = input;
            self
        }
        /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job request failed.</p>
        /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
        /// <ul>
        /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
        /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 8,000 and 48,000 Hertz.</p> </li>
        /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// </ul>
        pub fn failure_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.failure_reason = Some(input.into());
            self
        }
        /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job request failed.</p>
        /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
        /// <ul>
        /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
        /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 8,000 and 48,000 Hertz.</p> </li>
        /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// </ul>
        pub fn set_failure_reason(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.failure_reason = input;
            self
        }
        /// <p>Specify additional optional settings in your request, including channel identification, alternative transcriptions, speaker labeling; allows you to apply custom vocabularies and vocabulary filters.</p>
        /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use <code>Settings</code> with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
        /// <p>If you're using automatic language identification with your request and want to include a custom language model, a custom vocabulary, or a custom vocabulary filter, do not use the <code>Settings</code> parameter; use instead the <code></code> parameter with the <code>LanguageModelName</code>, <code>VocabularyName</code> or <code>VocabularyFilterName</code> sub-parameters.</p>
        pub fn settings(mut self, input: crate::model::Settings) -> Self {
            self.settings = Some(input);
            self
        }
        /// <p>Specify additional optional settings in your request, including channel identification, alternative transcriptions, speaker labeling; allows you to apply custom vocabularies and vocabulary filters.</p>
        /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use <code>Settings</code> with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
        /// <p>If you're using automatic language identification with your request and want to include a custom language model, a custom vocabulary, or a custom vocabulary filter, do not use the <code>Settings</code> parameter; use instead the <code></code> parameter with the <code>LanguageModelName</code>, <code>VocabularyName</code> or <code>VocabularyFilterName</code> sub-parameters.</p>
        pub fn set_settings(mut self, input: std::option::Option<crate::model::Settings>) -> Self {
            self.settings = input;
            self
        }
        /// <p>The custom language model you want to include with your transcription job. If you include <code>ModelSettings</code> in your request, you must include the <code>LanguageModelName</code> sub-parameter.</p>
        pub fn model_settings(mut self, input: crate::model::ModelSettings) -> Self {
            self.model_settings = Some(input);
            self
        }
        /// <p>The custom language model you want to include with your transcription job. If you include <code>ModelSettings</code> in your request, you must include the <code>LanguageModelName</code> sub-parameter.</p>
        pub fn set_model_settings(
            mut self,
            input: std::option::Option<crate::model::ModelSettings>,
        ) -> Self {
            self.model_settings = input;
            self
        }
        /// <p>Provides information about how your transcription job is being processed. This parameter shows if your request is queued and what data access role is being used.</p>
        pub fn job_execution_settings(mut self, input: crate::model::JobExecutionSettings) -> Self {
            self.job_execution_settings = Some(input);
            self
        }
        /// <p>Provides information about how your transcription job is being processed. This parameter shows if your request is queued and what data access role is being used.</p>
        pub fn set_job_execution_settings(
            mut self,
            input: std::option::Option<crate::model::JobExecutionSettings>,
        ) -> Self {
            self.job_execution_settings = input;
            self
        }
        /// <p>Redacts or flags specified personally identifiable information (PII) in your transcript.</p>
        pub fn content_redaction(mut self, input: crate::model::ContentRedaction) -> Self {
            self.content_redaction = Some(input);
            self
        }
        /// <p>Redacts or flags specified personally identifiable information (PII) in your transcript.</p>
        pub fn set_content_redaction(
            mut self,
            input: std::option::Option<crate::model::ContentRedaction>,
        ) -> Self {
            self.content_redaction = input;
            self
        }
        /// <p>Indicates whether automatic language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
        pub fn identify_language(mut self, input: bool) -> Self {
            self.identify_language = Some(input);
            self
        }
        /// <p>Indicates whether automatic language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
        pub fn set_identify_language(mut self, input: std::option::Option<bool>) -> Self {
            self.identify_language = input;
            self
        }
        /// <p>Indicates whether automatic multi-language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
        pub fn identify_multiple_languages(mut self, input: bool) -> Self {
            self.identify_multiple_languages = Some(input);
            self
        }
        /// <p>Indicates whether automatic multi-language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
        pub fn set_identify_multiple_languages(mut self, input: std::option::Option<bool>) -> Self {
            self.identify_multiple_languages = input;
            self
        }
        /// Appends an item to `language_options`.
        ///
        /// To override the contents of this collection use [`set_language_options`](Self::set_language_options).
        ///
        /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. If you're unsure what languages are present, do not include this parameter.</p>
        /// <p>If you include <code>LanguageOptions</code> in your request, you must also include <code>IdentifyLanguage</code>.</p>
        /// <p>For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a>.</p>
        /// <p>To transcribe speech in Modern Standard Arabic (<code>ar-SA</code>), your media file must be encoded at a sample rate of 16,000 Hz or higher.</p>
        pub fn language_options(mut self, input: crate::model::LanguageCode) -> Self {
            let mut v = self.language_options.unwrap_or_default();
            v.push(input);
            self.language_options = Some(v);
            self
        }
        /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. If you're unsure what languages are present, do not include this parameter.</p>
        /// <p>If you include <code>LanguageOptions</code> in your request, you must also include <code>IdentifyLanguage</code>.</p>
        /// <p>For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a>.</p>
        /// <p>To transcribe speech in Modern Standard Arabic (<code>ar-SA</code>), your media file must be encoded at a sample rate of 16,000 Hz or higher.</p>
        pub fn set_language_options(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::LanguageCode>>,
        ) -> Self {
            self.language_options = input;
            self
        }
        /// <p>The confidence score associated with the language identified in your media file.</p>
        /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
        pub fn identified_language_score(mut self, input: f32) -> Self {
            self.identified_language_score = Some(input);
            self
        }
        /// <p>The confidence score associated with the language identified in your media file.</p>
        /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
        pub fn set_identified_language_score(mut self, input: std::option::Option<f32>) -> Self {
            self.identified_language_score = input;
            self
        }
        /// Appends an item to `language_codes`.
        ///
        /// To override the contents of this collection use [`set_language_codes`](Self::set_language_codes).
        ///
        /// <p>The language codes used to create your transcription job. This parameter is used with multi-language identification. For single-language identification requests, refer to the singular version of this parameter, <code>LanguageCode</code>.</p>
        /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
        pub fn language_codes(mut self, input: crate::model::LanguageCodeItem) -> Self {
            let mut v = self.language_codes.unwrap_or_default();
            v.push(input);
            self.language_codes = Some(v);
            self
        }
        /// <p>The language codes used to create your transcription job. This parameter is used with multi-language identification. For single-language identification requests, refer to the singular version of this parameter, <code>LanguageCode</code>.</p>
        /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
        pub fn set_language_codes(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::LanguageCodeItem>>,
        ) -> Self {
            self.language_codes = input;
            self
        }
        /// Appends an item to `tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p>Adds one or more custom tags, each in the form of a key:value pair, to a new transcription job at the time you start this new job.</p>
        /// <p>To learn more about using tags with Amazon Transcribe, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/tagging.html">Tagging resources</a>.</p>
        pub fn tags(mut self, input: crate::model::Tag) -> Self {
            let mut v = self.tags.unwrap_or_default();
            v.push(input);
            self.tags = Some(v);
            self
        }
        /// <p>Adds one or more custom tags, each in the form of a key:value pair, to a new transcription job at the time you start this new job.</p>
        /// <p>To learn more about using tags with Amazon Transcribe, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/tagging.html">Tagging resources</a>.</p>
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.tags = input;
            self
        }
        /// <p>Generate subtitles for your media file with your transcription request.</p>
        pub fn subtitles(mut self, input: crate::model::SubtitlesOutput) -> Self {
            self.subtitles = Some(input);
            self
        }
        /// <p>Generate subtitles for your media file with your transcription request.</p>
        pub fn set_subtitles(
            mut self,
            input: std::option::Option<crate::model::SubtitlesOutput>,
        ) -> Self {
            self.subtitles = input;
            self
        }
        /// Adds a key-value pair to `language_id_settings`.
        ///
        /// To override the contents of this collection use [`set_language_id_settings`](Self::set_language_id_settings).
        ///
        /// <p>If using automatic language identification (<code>IdentifyLanguage</code>) in your request and you want to apply a custom language model, a custom vocabulary, or a custom vocabulary filter, include <code>LanguageIdSettings</code> with the relevant sub-parameters (<code>VocabularyName</code>, <code>LanguageModelName</code>, and <code>VocabularyFilterName</code>).</p>
        /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. Each language code you include can have an associated custom language model, custom vocabulary, and custom vocabulary filter. The languages you specify must match the languages of the specified custom language models, custom vocabularies, and custom vocabulary filters.</p>
        /// <p>To include language options using <code>IdentifyLanguage</code> <b>without</b> including a custom language model, a custom vocabulary, or a custom vocabulary filter, use <code>LanguageOptions</code> instead of <code>LanguageIdSettings</code>. Including language options can improve the accuracy of automatic language identification.</p>
        /// <p>If you want to include a custom language model with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>LanguageModelName</code> sub-parameter.</p>
        /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
        pub fn language_id_settings(
            mut self,
            k: crate::model::LanguageCode,
            v: crate::model::LanguageIdSettings,
        ) -> Self {
            let mut hash_map = self.language_id_settings.unwrap_or_default();
            hash_map.insert(k, v);
            self.language_id_settings = Some(hash_map);
            self
        }
        /// <p>If using automatic language identification (<code>IdentifyLanguage</code>) in your request and you want to apply a custom language model, a custom vocabulary, or a custom vocabulary filter, include <code>LanguageIdSettings</code> with the relevant sub-parameters (<code>VocabularyName</code>, <code>LanguageModelName</code>, and <code>VocabularyFilterName</code>).</p>
        /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. Each language code you include can have an associated custom language model, custom vocabulary, and custom vocabulary filter. The languages you specify must match the languages of the specified custom language models, custom vocabularies, and custom vocabulary filters.</p>
        /// <p>To include language options using <code>IdentifyLanguage</code> <b>without</b> including a custom language model, a custom vocabulary, or a custom vocabulary filter, use <code>LanguageOptions</code> instead of <code>LanguageIdSettings</code>. Including language options can improve the accuracy of automatic language identification.</p>
        /// <p>If you want to include a custom language model with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>LanguageModelName</code> sub-parameter.</p>
        /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
        pub fn set_language_id_settings(
            mut self,
            input: std::option::Option<
                std::collections::HashMap<
                    crate::model::LanguageCode,
                    crate::model::LanguageIdSettings,
                >,
            >,
        ) -> Self {
            self.language_id_settings = input;
            self
        }
        /// Consumes the builder and constructs a [`TranscriptionJob`](crate::model::TranscriptionJob)
        pub fn build(self) -> crate::model::TranscriptionJob {
            crate::model::TranscriptionJob {
                transcription_job_name: self.transcription_job_name,
                transcription_job_status: self.transcription_job_status,
                language_code: self.language_code,
                media_sample_rate_hertz: self.media_sample_rate_hertz,
                media_format: self.media_format,
                media: self.media,
                transcript: self.transcript,
                start_time: self.start_time,
                creation_time: self.creation_time,
                completion_time: self.completion_time,
                failure_reason: self.failure_reason,
                settings: self.settings,
                model_settings: self.model_settings,
                job_execution_settings: self.job_execution_settings,
                content_redaction: self.content_redaction,
                identify_language: self.identify_language,
                identify_multiple_languages: self.identify_multiple_languages,
                language_options: self.language_options,
                identified_language_score: self.identified_language_score,
                language_codes: self.language_codes,
                tags: self.tags,
                subtitles: self.subtitles,
                language_id_settings: self.language_id_settings,
            }
        }
    }
}
impl TranscriptionJob {
    /// Creates a new builder-style object to manufacture [`TranscriptionJob`](crate::model::TranscriptionJob)
    pub fn builder() -> crate::model::transcription_job::Builder {
        crate::model::transcription_job::Builder::default()
    }
}

/// <p>If using automatic language identification (<code>IdentifyLanguage</code>) in your request and you want to apply a custom language model, a custom vocabulary, or a custom vocabulary filter, include <code>LanguageIdSettings</code> with the relevant sub-parameters (<code>VocabularyName</code>, <code>LanguageModelName</code>, and <code>VocabularyFilterName</code>).</p>
/// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. Each language code you include can have an associated custom language model, custom vocabulary, and custom vocabulary filter. The languages you specify must match the languages of the specified custom language models, custom vocabularies, and custom vocabulary filters.</p>
/// <p>To include language options using <code>IdentifyLanguage</code> <b>without</b> including a custom language model, a custom vocabulary, or a custom vocabulary filter, use <code>LanguageOptions</code> instead of <code>LanguageIdSettings</code>. Including language options can improve the accuracy of automatic language identification.</p>
/// <p>If you want to include a custom language model with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>LanguageModelName</code> sub-parameter.</p>
/// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct LanguageIdSettings {
    /// <p>The name of the custom vocabulary you want to use when processing your transcription job. Vocabulary names are case sensitive.</p>
    /// <p>The language of the specified vocabulary must match the language code you specify in your transcription request. If the languages don't match, the vocabulary isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    pub vocabulary_name: std::option::Option<std::string::String>,
    /// <p>The name of the custom vocabulary filter you want to use when processing your transcription job. Vocabulary filter names are case sensitive.</p>
    /// <p>The language of the specified vocabulary filter must match the language code you specify in your transcription request. If the languages don't match, the vocabulary filter isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
    pub vocabulary_filter_name: std::option::Option<std::string::String>,
    /// <p>The name of the custom language model you want to use when processing your transcription job. Note that language model names are case sensitive.</p>
    /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    pub language_model_name: std::option::Option<std::string::String>,
}
impl LanguageIdSettings {
    /// <p>The name of the custom vocabulary you want to use when processing your transcription job. Vocabulary names are case sensitive.</p>
    /// <p>The language of the specified vocabulary must match the language code you specify in your transcription request. If the languages don't match, the vocabulary isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    pub fn vocabulary_name(&self) -> std::option::Option<&str> {
        self.vocabulary_name.as_deref()
    }
    /// <p>The name of the custom vocabulary filter you want to use when processing your transcription job. Vocabulary filter names are case sensitive.</p>
    /// <p>The language of the specified vocabulary filter must match the language code you specify in your transcription request. If the languages don't match, the vocabulary filter isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
    pub fn vocabulary_filter_name(&self) -> std::option::Option<&str> {
        self.vocabulary_filter_name.as_deref()
    }
    /// <p>The name of the custom language model you want to use when processing your transcription job. Note that language model names are case sensitive.</p>
    /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    pub fn language_model_name(&self) -> std::option::Option<&str> {
        self.language_model_name.as_deref()
    }
}
impl std::fmt::Debug for LanguageIdSettings {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("LanguageIdSettings");
        formatter.field("vocabulary_name", &self.vocabulary_name);
        formatter.field("vocabulary_filter_name", &self.vocabulary_filter_name);
        formatter.field("language_model_name", &self.language_model_name);
        formatter.finish()
    }
}
/// See [`LanguageIdSettings`](crate::model::LanguageIdSettings)
pub mod language_id_settings {

    /// A builder for [`LanguageIdSettings`](crate::model::LanguageIdSettings)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) vocabulary_name: std::option::Option<std::string::String>,
        pub(crate) vocabulary_filter_name: std::option::Option<std::string::String>,
        pub(crate) language_model_name: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the custom vocabulary you want to use when processing your transcription job. Vocabulary names are case sensitive.</p>
        /// <p>The language of the specified vocabulary must match the language code you specify in your transcription request. If the languages don't match, the vocabulary isn't applied. There are no errors or warnings associated with a language mismatch.</p>
        pub fn vocabulary_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.vocabulary_name = Some(input.into());
            self
        }
        /// <p>The name of the custom vocabulary you want to use when processing your transcription job. Vocabulary names are case sensitive.</p>
        /// <p>The language of the specified vocabulary must match the language code you specify in your transcription request. If the languages don't match, the vocabulary isn't applied. There are no errors or warnings associated with a language mismatch.</p>
        pub fn set_vocabulary_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.vocabulary_name = input;
            self
        }
        /// <p>The name of the custom vocabulary filter you want to use when processing your transcription job. Vocabulary filter names are case sensitive.</p>
        /// <p>The language of the specified vocabulary filter must match the language code you specify in your transcription request. If the languages don't match, the vocabulary filter isn't applied. There are no errors or warnings associated with a language mismatch.</p>
        /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
        pub fn vocabulary_filter_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.vocabulary_filter_name = Some(input.into());
            self
        }
        /// <p>The name of the custom vocabulary filter you want to use when processing your transcription job. Vocabulary filter names are case sensitive.</p>
        /// <p>The language of the specified vocabulary filter must match the language code you specify in your transcription request. If the languages don't match, the vocabulary filter isn't applied. There are no errors or warnings associated with a language mismatch.</p>
        /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
        pub fn set_vocabulary_filter_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.vocabulary_filter_name = input;
            self
        }
        /// <p>The name of the custom language model you want to use when processing your transcription job. Note that language model names are case sensitive.</p>
        /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
        pub fn language_model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.language_model_name = Some(input.into());
            self
        }
        /// <p>The name of the custom language model you want to use when processing your transcription job. Note that language model names are case sensitive.</p>
        /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
        pub fn set_language_model_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.language_model_name = input;
            self
        }
        /// Consumes the builder and constructs a [`LanguageIdSettings`](crate::model::LanguageIdSettings)
        pub fn build(self) -> crate::model::LanguageIdSettings {
            crate::model::LanguageIdSettings {
                vocabulary_name: self.vocabulary_name,
                vocabulary_filter_name: self.vocabulary_filter_name,
                language_model_name: self.language_model_name,
            }
        }
    }
}
impl LanguageIdSettings {
    /// Creates a new builder-style object to manufacture [`LanguageIdSettings`](crate::model::LanguageIdSettings)
    pub fn builder() -> crate::model::language_id_settings::Builder {
        crate::model::language_id_settings::Builder::default()
    }
}

/// <p>Provides information about your subtitle file, including format, start index, and Amazon S3 location.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct SubtitlesOutput {
    /// <p>Provides the format of your subtitle files. If your request included both WebVTT (<code>vtt</code>) and SubRip (<code>srt</code>) formats, both formats are shown.</p>
    pub formats: std::option::Option<std::vec::Vec<crate::model::SubtitleFormat>>,
    /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your subtitle file. Your subtitle file is stored in the same location as your transcript. If you specified both WebVTT and SubRip subtitle formats, two URIs are provided.</p>
    /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your subtitle file is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your subtitle file.</p> <note>
    /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
    /// </note>
    pub subtitle_file_uris: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>Provides the start index value for your subtitle files. If you did not specify a value in your request, the default value of <code>0</code> is used.</p>
    pub output_start_index: std::option::Option<i32>,
}
impl SubtitlesOutput {
    /// <p>Provides the format of your subtitle files. If your request included both WebVTT (<code>vtt</code>) and SubRip (<code>srt</code>) formats, both formats are shown.</p>
    pub fn formats(&self) -> std::option::Option<&[crate::model::SubtitleFormat]> {
        self.formats.as_deref()
    }
    /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your subtitle file. Your subtitle file is stored in the same location as your transcript. If you specified both WebVTT and SubRip subtitle formats, two URIs are provided.</p>
    /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your subtitle file is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your subtitle file.</p> <note>
    /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
    /// </note>
    pub fn subtitle_file_uris(&self) -> std::option::Option<&[std::string::String]> {
        self.subtitle_file_uris.as_deref()
    }
    /// <p>Provides the start index value for your subtitle files. If you did not specify a value in your request, the default value of <code>0</code> is used.</p>
    pub fn output_start_index(&self) -> std::option::Option<i32> {
        self.output_start_index
    }
}
impl std::fmt::Debug for SubtitlesOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("SubtitlesOutput");
        formatter.field("formats", &self.formats);
        formatter.field("subtitle_file_uris", &self.subtitle_file_uris);
        formatter.field("output_start_index", &self.output_start_index);
        formatter.finish()
    }
}
/// See [`SubtitlesOutput`](crate::model::SubtitlesOutput)
pub mod subtitles_output {

    /// A builder for [`SubtitlesOutput`](crate::model::SubtitlesOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) formats: std::option::Option<std::vec::Vec<crate::model::SubtitleFormat>>,
        pub(crate) subtitle_file_uris: std::option::Option<std::vec::Vec<std::string::String>>,
        pub(crate) output_start_index: std::option::Option<i32>,
    }
    impl Builder {
        /// Appends an item to `formats`.
        ///
        /// To override the contents of this collection use [`set_formats`](Self::set_formats).
        ///
        /// <p>Provides the format of your subtitle files. If your request included both WebVTT (<code>vtt</code>) and SubRip (<code>srt</code>) formats, both formats are shown.</p>
        pub fn formats(mut self, input: crate::model::SubtitleFormat) -> Self {
            let mut v = self.formats.unwrap_or_default();
            v.push(input);
            self.formats = Some(v);
            self
        }
        /// <p>Provides the format of your subtitle files. If your request included both WebVTT (<code>vtt</code>) and SubRip (<code>srt</code>) formats, both formats are shown.</p>
        pub fn set_formats(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::SubtitleFormat>>,
        ) -> Self {
            self.formats = input;
            self
        }
        /// Appends an item to `subtitle_file_uris`.
        ///
        /// To override the contents of this collection use [`set_subtitle_file_uris`](Self::set_subtitle_file_uris).
        ///
        /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your subtitle file. Your subtitle file is stored in the same location as your transcript. If you specified both WebVTT and SubRip subtitle formats, two URIs are provided.</p>
        /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your subtitle file is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your subtitle file.</p> <note>
        /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
        /// </note>
        pub fn subtitle_file_uris(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.subtitle_file_uris.unwrap_or_default();
            v.push(input.into());
            self.subtitle_file_uris = Some(v);
            self
        }
        /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your subtitle file. Your subtitle file is stored in the same location as your transcript. If you specified both WebVTT and SubRip subtitle formats, two URIs are provided.</p>
        /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your subtitle file is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your subtitle file.</p> <note>
        /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
        /// </note>
        pub fn set_subtitle_file_uris(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.subtitle_file_uris = input;
            self
        }
        /// <p>Provides the start index value for your subtitle files. If you did not specify a value in your request, the default value of <code>0</code> is used.</p>
        pub fn output_start_index(mut self, input: i32) -> Self {
            self.output_start_index = Some(input);
            self
        }
        /// <p>Provides the start index value for your subtitle files. If you did not specify a value in your request, the default value of <code>0</code> is used.</p>
        pub fn set_output_start_index(mut self, input: std::option::Option<i32>) -> Self {
            self.output_start_index = input;
            self
        }
        /// Consumes the builder and constructs a [`SubtitlesOutput`](crate::model::SubtitlesOutput)
        pub fn build(self) -> crate::model::SubtitlesOutput {
            crate::model::SubtitlesOutput {
                formats: self.formats,
                subtitle_file_uris: self.subtitle_file_uris,
                output_start_index: self.output_start_index,
            }
        }
    }
}
impl SubtitlesOutput {
    /// Creates a new builder-style object to manufacture [`SubtitlesOutput`](crate::model::SubtitlesOutput)
    pub fn builder() -> crate::model::subtitles_output::Builder {
        crate::model::subtitles_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum SubtitleFormat {
    #[allow(missing_docs)] // documentation missing in model
    Srt,
    #[allow(missing_docs)] // documentation missing in model
    Vtt,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for SubtitleFormat {
    fn from(s: &str) -> Self {
        match s {
            "srt" => SubtitleFormat::Srt,
            "vtt" => SubtitleFormat::Vtt,
            other => SubtitleFormat::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for SubtitleFormat {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(SubtitleFormat::from(s))
    }
}
impl SubtitleFormat {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            SubtitleFormat::Srt => "srt",
            SubtitleFormat::Vtt => "vtt",
            SubtitleFormat::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["srt", "vtt"]
    }
}
impl AsRef<str> for SubtitleFormat {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Provides information on the speech contained in a discreet utterance when multi-language identification is enabled in your request. This utterance represents a block of speech consisting of one language, preceded or followed by a block of speech in a different language.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct LanguageCodeItem {
    /// <p>Provides the language code for each language identified in your media.</p>
    pub language_code: std::option::Option<crate::model::LanguageCode>,
    /// <p>Provides the total time, in seconds, each identified language is spoken in your media.</p>
    pub duration_in_seconds: std::option::Option<f32>,
}
impl LanguageCodeItem {
    /// <p>Provides the language code for each language identified in your media.</p>
    pub fn language_code(&self) -> std::option::Option<&crate::model::LanguageCode> {
        self.language_code.as_ref()
    }
    /// <p>Provides the total time, in seconds, each identified language is spoken in your media.</p>
    pub fn duration_in_seconds(&self) -> std::option::Option<f32> {
        self.duration_in_seconds
    }
}
impl std::fmt::Debug for LanguageCodeItem {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("LanguageCodeItem");
        formatter.field("language_code", &self.language_code);
        formatter.field("duration_in_seconds", &self.duration_in_seconds);
        formatter.finish()
    }
}
/// See [`LanguageCodeItem`](crate::model::LanguageCodeItem)
pub mod language_code_item {

    /// A builder for [`LanguageCodeItem`](crate::model::LanguageCodeItem)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) language_code: std::option::Option<crate::model::LanguageCode>,
        pub(crate) duration_in_seconds: std::option::Option<f32>,
    }
    impl Builder {
        /// <p>Provides the language code for each language identified in your media.</p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.language_code = Some(input);
            self
        }
        /// <p>Provides the language code for each language identified in your media.</p>
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.language_code = input;
            self
        }
        /// <p>Provides the total time, in seconds, each identified language is spoken in your media.</p>
        pub fn duration_in_seconds(mut self, input: f32) -> Self {
            self.duration_in_seconds = Some(input);
            self
        }
        /// <p>Provides the total time, in seconds, each identified language is spoken in your media.</p>
        pub fn set_duration_in_seconds(mut self, input: std::option::Option<f32>) -> Self {
            self.duration_in_seconds = input;
            self
        }
        /// Consumes the builder and constructs a [`LanguageCodeItem`](crate::model::LanguageCodeItem)
        pub fn build(self) -> crate::model::LanguageCodeItem {
            crate::model::LanguageCodeItem {
                language_code: self.language_code,
                duration_in_seconds: self.duration_in_seconds,
            }
        }
    }
}
impl LanguageCodeItem {
    /// Creates a new builder-style object to manufacture [`LanguageCodeItem`](crate::model::LanguageCodeItem)
    pub fn builder() -> crate::model::language_code_item::Builder {
        crate::model::language_code_item::Builder::default()
    }
}

/// <p>Allows you to redact or flag specified personally identifiable information (PII) in your transcript. If you use <code>ContentRedaction</code>, you must also include the sub-parameters: <code>PiiEntityTypes</code>, <code>RedactionOutput</code>, and <code>RedactionType</code>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct ContentRedaction {
    /// <p>Specify the category of information you want to redact; <code>PII</code> (personally identifiable information) is the only valid value. You can use <code>PiiEntityTypes</code> to choose which types of PII you want to redact.</p>
    pub redaction_type: std::option::Option<crate::model::RedactionType>,
    /// <p>Specify if you want only a redacted transcript, or if you want a redacted and an unredacted transcript.</p>
    /// <p>When you choose <code>redacted</code> Amazon Transcribe creates only a redacted transcript.</p>
    /// <p>When you choose <code>redacted_and_unredacted</code> Amazon Transcribe creates a redacted and an unredacted transcript (as two separate files).</p>
    pub redaction_output: std::option::Option<crate::model::RedactionOutput>,
    /// <p>Specify which types of personally identifiable information (PII) you want to redact in your transcript. You can include as many types as you'd like, or you can select <code>ALL</code>.</p>
    pub pii_entity_types: std::option::Option<std::vec::Vec<crate::model::PiiEntityType>>,
}
impl ContentRedaction {
    /// <p>Specify the category of information you want to redact; <code>PII</code> (personally identifiable information) is the only valid value. You can use <code>PiiEntityTypes</code> to choose which types of PII you want to redact.</p>
    pub fn redaction_type(&self) -> std::option::Option<&crate::model::RedactionType> {
        self.redaction_type.as_ref()
    }
    /// <p>Specify if you want only a redacted transcript, or if you want a redacted and an unredacted transcript.</p>
    /// <p>When you choose <code>redacted</code> Amazon Transcribe creates only a redacted transcript.</p>
    /// <p>When you choose <code>redacted_and_unredacted</code> Amazon Transcribe creates a redacted and an unredacted transcript (as two separate files).</p>
    pub fn redaction_output(&self) -> std::option::Option<&crate::model::RedactionOutput> {
        self.redaction_output.as_ref()
    }
    /// <p>Specify which types of personally identifiable information (PII) you want to redact in your transcript. You can include as many types as you'd like, or you can select <code>ALL</code>.</p>
    pub fn pii_entity_types(&self) -> std::option::Option<&[crate::model::PiiEntityType]> {
        self.pii_entity_types.as_deref()
    }
}
impl std::fmt::Debug for ContentRedaction {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("ContentRedaction");
        formatter.field("redaction_type", &self.redaction_type);
        formatter.field("redaction_output", &self.redaction_output);
        formatter.field("pii_entity_types", &self.pii_entity_types);
        formatter.finish()
    }
}
/// See [`ContentRedaction`](crate::model::ContentRedaction)
pub mod content_redaction {

    /// A builder for [`ContentRedaction`](crate::model::ContentRedaction)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) redaction_type: std::option::Option<crate::model::RedactionType>,
        pub(crate) redaction_output: std::option::Option<crate::model::RedactionOutput>,
        pub(crate) pii_entity_types:
            std::option::Option<std::vec::Vec<crate::model::PiiEntityType>>,
    }
    impl Builder {
        /// <p>Specify the category of information you want to redact; <code>PII</code> (personally identifiable information) is the only valid value. You can use <code>PiiEntityTypes</code> to choose which types of PII you want to redact.</p>
        pub fn redaction_type(mut self, input: crate::model::RedactionType) -> Self {
            self.redaction_type = Some(input);
            self
        }
        /// <p>Specify the category of information you want to redact; <code>PII</code> (personally identifiable information) is the only valid value. You can use <code>PiiEntityTypes</code> to choose which types of PII you want to redact.</p>
        pub fn set_redaction_type(
            mut self,
            input: std::option::Option<crate::model::RedactionType>,
        ) -> Self {
            self.redaction_type = input;
            self
        }
        /// <p>Specify if you want only a redacted transcript, or if you want a redacted and an unredacted transcript.</p>
        /// <p>When you choose <code>redacted</code> Amazon Transcribe creates only a redacted transcript.</p>
        /// <p>When you choose <code>redacted_and_unredacted</code> Amazon Transcribe creates a redacted and an unredacted transcript (as two separate files).</p>
        pub fn redaction_output(mut self, input: crate::model::RedactionOutput) -> Self {
            self.redaction_output = Some(input);
            self
        }
        /// <p>Specify if you want only a redacted transcript, or if you want a redacted and an unredacted transcript.</p>
        /// <p>When you choose <code>redacted</code> Amazon Transcribe creates only a redacted transcript.</p>
        /// <p>When you choose <code>redacted_and_unredacted</code> Amazon Transcribe creates a redacted and an unredacted transcript (as two separate files).</p>
        pub fn set_redaction_output(
            mut self,
            input: std::option::Option<crate::model::RedactionOutput>,
        ) -> Self {
            self.redaction_output = input;
            self
        }
        /// Appends an item to `pii_entity_types`.
        ///
        /// To override the contents of this collection use [`set_pii_entity_types`](Self::set_pii_entity_types).
        ///
        /// <p>Specify which types of personally identifiable information (PII) you want to redact in your transcript. You can include as many types as you'd like, or you can select <code>ALL</code>.</p>
        pub fn pii_entity_types(mut self, input: crate::model::PiiEntityType) -> Self {
            let mut v = self.pii_entity_types.unwrap_or_default();
            v.push(input);
            self.pii_entity_types = Some(v);
            self
        }
        /// <p>Specify which types of personally identifiable information (PII) you want to redact in your transcript. You can include as many types as you'd like, or you can select <code>ALL</code>.</p>
        pub fn set_pii_entity_types(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::PiiEntityType>>,
        ) -> Self {
            self.pii_entity_types = input;
            self
        }
        /// Consumes the builder and constructs a [`ContentRedaction`](crate::model::ContentRedaction)
        pub fn build(self) -> crate::model::ContentRedaction {
            crate::model::ContentRedaction {
                redaction_type: self.redaction_type,
                redaction_output: self.redaction_output,
                pii_entity_types: self.pii_entity_types,
            }
        }
    }
}
impl ContentRedaction {
    /// Creates a new builder-style object to manufacture [`ContentRedaction`](crate::model::ContentRedaction)
    pub fn builder() -> crate::model::content_redaction::Builder {
        crate::model::content_redaction::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum PiiEntityType {
    #[allow(missing_docs)] // documentation missing in model
    Address,
    #[allow(missing_docs)] // documentation missing in model
    All,
    #[allow(missing_docs)] // documentation missing in model
    BankAccountNumber,
    #[allow(missing_docs)] // documentation missing in model
    BankRouting,
    #[allow(missing_docs)] // documentation missing in model
    CreditDebitCvv,
    #[allow(missing_docs)] // documentation missing in model
    CreditDebitExpiry,
    #[allow(missing_docs)] // documentation missing in model
    CreditDebitNumber,
    #[allow(missing_docs)] // documentation missing in model
    Email,
    #[allow(missing_docs)] // documentation missing in model
    Name,
    #[allow(missing_docs)] // documentation missing in model
    Phone,
    #[allow(missing_docs)] // documentation missing in model
    Pin,
    #[allow(missing_docs)] // documentation missing in model
    Ssn,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for PiiEntityType {
    fn from(s: &str) -> Self {
        match s {
            "ADDRESS" => PiiEntityType::Address,
            "ALL" => PiiEntityType::All,
            "BANK_ACCOUNT_NUMBER" => PiiEntityType::BankAccountNumber,
            "BANK_ROUTING" => PiiEntityType::BankRouting,
            "CREDIT_DEBIT_CVV" => PiiEntityType::CreditDebitCvv,
            "CREDIT_DEBIT_EXPIRY" => PiiEntityType::CreditDebitExpiry,
            "CREDIT_DEBIT_NUMBER" => PiiEntityType::CreditDebitNumber,
            "EMAIL" => PiiEntityType::Email,
            "NAME" => PiiEntityType::Name,
            "PHONE" => PiiEntityType::Phone,
            "PIN" => PiiEntityType::Pin,
            "SSN" => PiiEntityType::Ssn,
            other => PiiEntityType::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for PiiEntityType {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(PiiEntityType::from(s))
    }
}
impl PiiEntityType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            PiiEntityType::Address => "ADDRESS",
            PiiEntityType::All => "ALL",
            PiiEntityType::BankAccountNumber => "BANK_ACCOUNT_NUMBER",
            PiiEntityType::BankRouting => "BANK_ROUTING",
            PiiEntityType::CreditDebitCvv => "CREDIT_DEBIT_CVV",
            PiiEntityType::CreditDebitExpiry => "CREDIT_DEBIT_EXPIRY",
            PiiEntityType::CreditDebitNumber => "CREDIT_DEBIT_NUMBER",
            PiiEntityType::Email => "EMAIL",
            PiiEntityType::Name => "NAME",
            PiiEntityType::Phone => "PHONE",
            PiiEntityType::Pin => "PIN",
            PiiEntityType::Ssn => "SSN",
            PiiEntityType::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &[
            "ADDRESS",
            "ALL",
            "BANK_ACCOUNT_NUMBER",
            "BANK_ROUTING",
            "CREDIT_DEBIT_CVV",
            "CREDIT_DEBIT_EXPIRY",
            "CREDIT_DEBIT_NUMBER",
            "EMAIL",
            "NAME",
            "PHONE",
            "PIN",
            "SSN",
        ]
    }
}
impl AsRef<str> for PiiEntityType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum RedactionOutput {
    #[allow(missing_docs)] // documentation missing in model
    Redacted,
    #[allow(missing_docs)] // documentation missing in model
    RedactedAndUnredacted,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for RedactionOutput {
    fn from(s: &str) -> Self {
        match s {
            "redacted" => RedactionOutput::Redacted,
            "redacted_and_unredacted" => RedactionOutput::RedactedAndUnredacted,
            other => RedactionOutput::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for RedactionOutput {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(RedactionOutput::from(s))
    }
}
impl RedactionOutput {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            RedactionOutput::Redacted => "redacted",
            RedactionOutput::RedactedAndUnredacted => "redacted_and_unredacted",
            RedactionOutput::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["redacted", "redacted_and_unredacted"]
    }
}
impl AsRef<str> for RedactionOutput {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum RedactionType {
    #[allow(missing_docs)] // documentation missing in model
    Pii,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for RedactionType {
    fn from(s: &str) -> Self {
        match s {
            "PII" => RedactionType::Pii,
            other => RedactionType::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for RedactionType {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(RedactionType::from(s))
    }
}
impl RedactionType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            RedactionType::Pii => "PII",
            RedactionType::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["PII"]
    }
}
impl AsRef<str> for RedactionType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Allows you to control how your transcription job is processed. Currently, the only <code>JobExecutionSettings</code> modification you can choose is enabling job queueing using the <code>AllowDeferredExecution</code> sub-parameter.</p>
/// <p>If you include <code>JobExecutionSettings</code> in your request, you must also include the sub-parameters: <code>AllowDeferredExecution</code> and <code>DataAccessRoleArn</code>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct JobExecutionSettings {
    /// <p>Allows you to enable job queuing when your concurrent request limit is exceeded. When <code>AllowDeferredExecution</code> is set to <code>true</code>, transcription job requests are placed in a queue until the number of jobs falls below the concurrent request limit. If <code>AllowDeferredExecution</code> is set to <code>false</code> and the number of transcription job requests exceed the concurrent request limit, you get a <code>LimitExceededException</code> error.</p>
    /// <p>Note that job queuing is enabled by default for Call Analytics jobs.</p>
    /// <p>If you include <code>AllowDeferredExecution</code> in your request, you must also include <code>DataAccessRoleArn</code>.</p>
    pub allow_deferred_execution: std::option::Option<bool>,
    /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
    /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>. For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
    /// <p>Note that if you include <code>DataAccessRoleArn</code> in your request, you must also include <code>AllowDeferredExecution</code>.</p>
    pub data_access_role_arn: std::option::Option<std::string::String>,
}
impl JobExecutionSettings {
    /// <p>Allows you to enable job queuing when your concurrent request limit is exceeded. When <code>AllowDeferredExecution</code> is set to <code>true</code>, transcription job requests are placed in a queue until the number of jobs falls below the concurrent request limit. If <code>AllowDeferredExecution</code> is set to <code>false</code> and the number of transcription job requests exceed the concurrent request limit, you get a <code>LimitExceededException</code> error.</p>
    /// <p>Note that job queuing is enabled by default for Call Analytics jobs.</p>
    /// <p>If you include <code>AllowDeferredExecution</code> in your request, you must also include <code>DataAccessRoleArn</code>.</p>
    pub fn allow_deferred_execution(&self) -> std::option::Option<bool> {
        self.allow_deferred_execution
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
    /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>. For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
    /// <p>Note that if you include <code>DataAccessRoleArn</code> in your request, you must also include <code>AllowDeferredExecution</code>.</p>
    pub fn data_access_role_arn(&self) -> std::option::Option<&str> {
        self.data_access_role_arn.as_deref()
    }
}
impl std::fmt::Debug for JobExecutionSettings {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("JobExecutionSettings");
        formatter.field("allow_deferred_execution", &self.allow_deferred_execution);
        formatter.field("data_access_role_arn", &self.data_access_role_arn);
        formatter.finish()
    }
}
/// See [`JobExecutionSettings`](crate::model::JobExecutionSettings)
pub mod job_execution_settings {

    /// A builder for [`JobExecutionSettings`](crate::model::JobExecutionSettings)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) allow_deferred_execution: std::option::Option<bool>,
        pub(crate) data_access_role_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>Allows you to enable job queuing when your concurrent request limit is exceeded. When <code>AllowDeferredExecution</code> is set to <code>true</code>, transcription job requests are placed in a queue until the number of jobs falls below the concurrent request limit. If <code>AllowDeferredExecution</code> is set to <code>false</code> and the number of transcription job requests exceed the concurrent request limit, you get a <code>LimitExceededException</code> error.</p>
        /// <p>Note that job queuing is enabled by default for Call Analytics jobs.</p>
        /// <p>If you include <code>AllowDeferredExecution</code> in your request, you must also include <code>DataAccessRoleArn</code>.</p>
        pub fn allow_deferred_execution(mut self, input: bool) -> Self {
            self.allow_deferred_execution = Some(input);
            self
        }
        /// <p>Allows you to enable job queuing when your concurrent request limit is exceeded. When <code>AllowDeferredExecution</code> is set to <code>true</code>, transcription job requests are placed in a queue until the number of jobs falls below the concurrent request limit. If <code>AllowDeferredExecution</code> is set to <code>false</code> and the number of transcription job requests exceed the concurrent request limit, you get a <code>LimitExceededException</code> error.</p>
        /// <p>Note that job queuing is enabled by default for Call Analytics jobs.</p>
        /// <p>If you include <code>AllowDeferredExecution</code> in your request, you must also include <code>DataAccessRoleArn</code>.</p>
        pub fn set_allow_deferred_execution(mut self, input: std::option::Option<bool>) -> Self {
            self.allow_deferred_execution = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
        /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>. For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
        /// <p>Note that if you include <code>DataAccessRoleArn</code> in your request, you must also include <code>AllowDeferredExecution</code>.</p>
        pub fn data_access_role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.data_access_role_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
        /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>. For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
        /// <p>Note that if you include <code>DataAccessRoleArn</code> in your request, you must also include <code>AllowDeferredExecution</code>.</p>
        pub fn set_data_access_role_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.data_access_role_arn = input;
            self
        }
        /// Consumes the builder and constructs a [`JobExecutionSettings`](crate::model::JobExecutionSettings)
        pub fn build(self) -> crate::model::JobExecutionSettings {
            crate::model::JobExecutionSettings {
                allow_deferred_execution: self.allow_deferred_execution,
                data_access_role_arn: self.data_access_role_arn,
            }
        }
    }
}
impl JobExecutionSettings {
    /// Creates a new builder-style object to manufacture [`JobExecutionSettings`](crate::model::JobExecutionSettings)
    pub fn builder() -> crate::model::job_execution_settings::Builder {
        crate::model::job_execution_settings::Builder::default()
    }
}

/// <p>Provides the name of the custom language model that was included in the specified transcription job.</p>
/// <p>Only use <code>ModelSettings</code> with the <code>LanguageModelName</code> sub-parameter if you're <b>not</b> using automatic language identification (<code></code>). If using <code>LanguageIdSettings</code> in your request, this parameter contains a <code>LanguageModelName</code> sub-parameter.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct ModelSettings {
    /// <p>The name of the custom language model you want to use when processing your transcription job. Note that language model names are case sensitive.</p>
    /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    pub language_model_name: std::option::Option<std::string::String>,
}
impl ModelSettings {
    /// <p>The name of the custom language model you want to use when processing your transcription job. Note that language model names are case sensitive.</p>
    /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    pub fn language_model_name(&self) -> std::option::Option<&str> {
        self.language_model_name.as_deref()
    }
}
impl std::fmt::Debug for ModelSettings {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("ModelSettings");
        formatter.field("language_model_name", &self.language_model_name);
        formatter.finish()
    }
}
/// See [`ModelSettings`](crate::model::ModelSettings)
pub mod model_settings {

    /// A builder for [`ModelSettings`](crate::model::ModelSettings)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) language_model_name: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the custom language model you want to use when processing your transcription job. Note that language model names are case sensitive.</p>
        /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
        pub fn language_model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.language_model_name = Some(input.into());
            self
        }
        /// <p>The name of the custom language model you want to use when processing your transcription job. Note that language model names are case sensitive.</p>
        /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
        pub fn set_language_model_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.language_model_name = input;
            self
        }
        /// Consumes the builder and constructs a [`ModelSettings`](crate::model::ModelSettings)
        pub fn build(self) -> crate::model::ModelSettings {
            crate::model::ModelSettings {
                language_model_name: self.language_model_name,
            }
        }
    }
}
impl ModelSettings {
    /// Creates a new builder-style object to manufacture [`ModelSettings`](crate::model::ModelSettings)
    pub fn builder() -> crate::model::model_settings::Builder {
        crate::model::model_settings::Builder::default()
    }
}

/// <p>Allows additional optional settings in your request, including channel identification, alternative transcriptions, and speaker labeling; allows you to apply custom vocabularies to your transcription job.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct Settings {
    /// <p>The name of the custom vocabulary you want to use in your transcription job request. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
    pub vocabulary_name: std::option::Option<std::string::String>,
    /// <p>Enables speaker identification (diarization) in your transcription output. Speaker identification labels the speech from individual speakers in your media file.</p>
    /// <p>If you enable <code>ShowSpeakerLabels</code> in your request, you must also include <code>MaxSpeakerLabels</code>.</p>
    /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Identifying speakers (diarization)</a>.</p>
    pub show_speaker_labels: std::option::Option<bool>,
    /// <p>Specify the maximum number of speakers you want to identify in your media.</p>
    /// <p>Note that if your media contains more speakers than the specified number, multiple speakers will be identified as a single speaker.</p>
    /// <p>If you specify the <code>MaxSpeakerLabels</code> field, you must set the <code>ShowSpeakerLabels</code> field to true.</p>
    pub max_speaker_labels: std::option::Option<i32>,
    /// <p>Enables channel identification in multi-channel audio.</p>
    /// <p>Channel identification transcribes the audio on each channel independently, then appends the output for each channel into one transcript.</p>
    /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/channel-id.html">Transcribing multi-channel audio</a>.</p>
    pub channel_identification: std::option::Option<bool>,
    /// <p>To include alternative transcriptions within your transcription output, include <code>ShowAlternatives</code> in your transcription request.</p>
    /// <p>If you have multi-channel audio and do not enable channel identification, your audio is transcribed in a continuous manner and your transcript does not separate the speech by channel.</p>
    /// <p>If you include <code>ShowAlternatives</code>, you must also include <code>MaxAlternatives</code>, which is the maximum number of alternative transcriptions you want Amazon Transcribe to generate.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
    pub show_alternatives: std::option::Option<bool>,
    /// <p>Indicate the maximum number of alternative transcriptions you want Amazon Transcribe to include in your transcript.</p>
    /// <p>If you select a number greater than the number of alternative transcriptions generated by Amazon Transcribe, only the actual number of alternative transcriptions are included.</p>
    /// <p>If you include <code>MaxAlternatives</code> in your request, you must also include <code>ShowAlternatives</code> with a value of <code>true</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
    pub max_alternatives: std::option::Option<i32>,
    /// <p>The name of the custom vocabulary filter you want to use in your transcription job request. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
    /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
    pub vocabulary_filter_name: std::option::Option<std::string::String>,
    /// <p>Specify how you want your vocabulary filter applied to your transcript.</p>
    /// <p>To replace words with <code>***</code>, choose <code>mask</code>.</p>
    /// <p>To delete words, choose <code>remove</code>.</p>
    /// <p>To flag words without changing them, choose <code>tag</code>.</p>
    pub vocabulary_filter_method: std::option::Option<crate::model::VocabularyFilterMethod>,
}
impl Settings {
    /// <p>The name of the custom vocabulary you want to use in your transcription job request. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
    pub fn vocabulary_name(&self) -> std::option::Option<&str> {
        self.vocabulary_name.as_deref()
    }
    /// <p>Enables speaker identification (diarization) in your transcription output. Speaker identification labels the speech from individual speakers in your media file.</p>
    /// <p>If you enable <code>ShowSpeakerLabels</code> in your request, you must also include <code>MaxSpeakerLabels</code>.</p>
    /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Identifying speakers (diarization)</a>.</p>
    pub fn show_speaker_labels(&self) -> std::option::Option<bool> {
        self.show_speaker_labels
    }
    /// <p>Specify the maximum number of speakers you want to identify in your media.</p>
    /// <p>Note that if your media contains more speakers than the specified number, multiple speakers will be identified as a single speaker.</p>
    /// <p>If you specify the <code>MaxSpeakerLabels</code> field, you must set the <code>ShowSpeakerLabels</code> field to true.</p>
    pub fn max_speaker_labels(&self) -> std::option::Option<i32> {
        self.max_speaker_labels
    }
    /// <p>Enables channel identification in multi-channel audio.</p>
    /// <p>Channel identification transcribes the audio on each channel independently, then appends the output for each channel into one transcript.</p>
    /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/channel-id.html">Transcribing multi-channel audio</a>.</p>
    pub fn channel_identification(&self) -> std::option::Option<bool> {
        self.channel_identification
    }
    /// <p>To include alternative transcriptions within your transcription output, include <code>ShowAlternatives</code> in your transcription request.</p>
    /// <p>If you have multi-channel audio and do not enable channel identification, your audio is transcribed in a continuous manner and your transcript does not separate the speech by channel.</p>
    /// <p>If you include <code>ShowAlternatives</code>, you must also include <code>MaxAlternatives</code>, which is the maximum number of alternative transcriptions you want Amazon Transcribe to generate.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
    pub fn show_alternatives(&self) -> std::option::Option<bool> {
        self.show_alternatives
    }
    /// <p>Indicate the maximum number of alternative transcriptions you want Amazon Transcribe to include in your transcript.</p>
    /// <p>If you select a number greater than the number of alternative transcriptions generated by Amazon Transcribe, only the actual number of alternative transcriptions are included.</p>
    /// <p>If you include <code>MaxAlternatives</code> in your request, you must also include <code>ShowAlternatives</code> with a value of <code>true</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
    pub fn max_alternatives(&self) -> std::option::Option<i32> {
        self.max_alternatives
    }
    /// <p>The name of the custom vocabulary filter you want to use in your transcription job request. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
    /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
    pub fn vocabulary_filter_name(&self) -> std::option::Option<&str> {
        self.vocabulary_filter_name.as_deref()
    }
    /// <p>Specify how you want your vocabulary filter applied to your transcript.</p>
    /// <p>To replace words with <code>***</code>, choose <code>mask</code>.</p>
    /// <p>To delete words, choose <code>remove</code>.</p>
    /// <p>To flag words without changing them, choose <code>tag</code>.</p>
    pub fn vocabulary_filter_method(
        &self,
    ) -> std::option::Option<&crate::model::VocabularyFilterMethod> {
        self.vocabulary_filter_method.as_ref()
    }
}
impl std::fmt::Debug for Settings {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("Settings");
        formatter.field("vocabulary_name", &self.vocabulary_name);
        formatter.field("show_speaker_labels", &self.show_speaker_labels);
        formatter.field("max_speaker_labels", &self.max_speaker_labels);
        formatter.field("channel_identification", &self.channel_identification);
        formatter.field("show_alternatives", &self.show_alternatives);
        formatter.field("max_alternatives", &self.max_alternatives);
        formatter.field("vocabulary_filter_name", &self.vocabulary_filter_name);
        formatter.field("vocabulary_filter_method", &self.vocabulary_filter_method);
        formatter.finish()
    }
}
/// See [`Settings`](crate::model::Settings)
pub mod settings {

    /// A builder for [`Settings`](crate::model::Settings)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) vocabulary_name: std::option::Option<std::string::String>,
        pub(crate) show_speaker_labels: std::option::Option<bool>,
        pub(crate) max_speaker_labels: std::option::Option<i32>,
        pub(crate) channel_identification: std::option::Option<bool>,
        pub(crate) show_alternatives: std::option::Option<bool>,
        pub(crate) max_alternatives: std::option::Option<i32>,
        pub(crate) vocabulary_filter_name: std::option::Option<std::string::String>,
        pub(crate) vocabulary_filter_method:
            std::option::Option<crate::model::VocabularyFilterMethod>,
    }
    impl Builder {
        /// <p>The name of the custom vocabulary you want to use in your transcription job request. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
        pub fn vocabulary_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.vocabulary_name = Some(input.into());
            self
        }
        /// <p>The name of the custom vocabulary you want to use in your transcription job request. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
        pub fn set_vocabulary_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.vocabulary_name = input;
            self
        }
        /// <p>Enables speaker identification (diarization) in your transcription output. Speaker identification labels the speech from individual speakers in your media file.</p>
        /// <p>If you enable <code>ShowSpeakerLabels</code> in your request, you must also include <code>MaxSpeakerLabels</code>.</p>
        /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Identifying speakers (diarization)</a>.</p>
        pub fn show_speaker_labels(mut self, input: bool) -> Self {
            self.show_speaker_labels = Some(input);
            self
        }
        /// <p>Enables speaker identification (diarization) in your transcription output. Speaker identification labels the speech from individual speakers in your media file.</p>
        /// <p>If you enable <code>ShowSpeakerLabels</code> in your request, you must also include <code>MaxSpeakerLabels</code>.</p>
        /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Identifying speakers (diarization)</a>.</p>
        pub fn set_show_speaker_labels(mut self, input: std::option::Option<bool>) -> Self {
            self.show_speaker_labels = input;
            self
        }
        /// <p>Specify the maximum number of speakers you want to identify in your media.</p>
        /// <p>Note that if your media contains more speakers than the specified number, multiple speakers will be identified as a single speaker.</p>
        /// <p>If you specify the <code>MaxSpeakerLabels</code> field, you must set the <code>ShowSpeakerLabels</code> field to true.</p>
        pub fn max_speaker_labels(mut self, input: i32) -> Self {
            self.max_speaker_labels = Some(input);
            self
        }
        /// <p>Specify the maximum number of speakers you want to identify in your media.</p>
        /// <p>Note that if your media contains more speakers than the specified number, multiple speakers will be identified as a single speaker.</p>
        /// <p>If you specify the <code>MaxSpeakerLabels</code> field, you must set the <code>ShowSpeakerLabels</code> field to true.</p>
        pub fn set_max_speaker_labels(mut self, input: std::option::Option<i32>) -> Self {
            self.max_speaker_labels = input;
            self
        }
        /// <p>Enables channel identification in multi-channel audio.</p>
        /// <p>Channel identification transcribes the audio on each channel independently, then appends the output for each channel into one transcript.</p>
        /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/channel-id.html">Transcribing multi-channel audio</a>.</p>
        pub fn channel_identification(mut self, input: bool) -> Self {
            self.channel_identification = Some(input);
            self
        }
        /// <p>Enables channel identification in multi-channel audio.</p>
        /// <p>Channel identification transcribes the audio on each channel independently, then appends the output for each channel into one transcript.</p>
        /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/channel-id.html">Transcribing multi-channel audio</a>.</p>
        pub fn set_channel_identification(mut self, input: std::option::Option<bool>) -> Self {
            self.channel_identification = input;
            self
        }
        /// <p>To include alternative transcriptions within your transcription output, include <code>ShowAlternatives</code> in your transcription request.</p>
        /// <p>If you have multi-channel audio and do not enable channel identification, your audio is transcribed in a continuous manner and your transcript does not separate the speech by channel.</p>
        /// <p>If you include <code>ShowAlternatives</code>, you must also include <code>MaxAlternatives</code>, which is the maximum number of alternative transcriptions you want Amazon Transcribe to generate.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
        pub fn show_alternatives(mut self, input: bool) -> Self {
            self.show_alternatives = Some(input);
            self
        }
        /// <p>To include alternative transcriptions within your transcription output, include <code>ShowAlternatives</code> in your transcription request.</p>
        /// <p>If you have multi-channel audio and do not enable channel identification, your audio is transcribed in a continuous manner and your transcript does not separate the speech by channel.</p>
        /// <p>If you include <code>ShowAlternatives</code>, you must also include <code>MaxAlternatives</code>, which is the maximum number of alternative transcriptions you want Amazon Transcribe to generate.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
        pub fn set_show_alternatives(mut self, input: std::option::Option<bool>) -> Self {
            self.show_alternatives = input;
            self
        }
        /// <p>Indicate the maximum number of alternative transcriptions you want Amazon Transcribe to include in your transcript.</p>
        /// <p>If you select a number greater than the number of alternative transcriptions generated by Amazon Transcribe, only the actual number of alternative transcriptions are included.</p>
        /// <p>If you include <code>MaxAlternatives</code> in your request, you must also include <code>ShowAlternatives</code> with a value of <code>true</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
        pub fn max_alternatives(mut self, input: i32) -> Self {
            self.max_alternatives = Some(input);
            self
        }
        /// <p>Indicate the maximum number of alternative transcriptions you want Amazon Transcribe to include in your transcript.</p>
        /// <p>If you select a number greater than the number of alternative transcriptions generated by Amazon Transcribe, only the actual number of alternative transcriptions are included.</p>
        /// <p>If you include <code>MaxAlternatives</code> in your request, you must also include <code>ShowAlternatives</code> with a value of <code>true</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
        pub fn set_max_alternatives(mut self, input: std::option::Option<i32>) -> Self {
            self.max_alternatives = input;
            self
        }
        /// <p>The name of the custom vocabulary filter you want to use in your transcription job request. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
        /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
        pub fn vocabulary_filter_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.vocabulary_filter_name = Some(input.into());
            self
        }
        /// <p>The name of the custom vocabulary filter you want to use in your transcription job request. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
        /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
        pub fn set_vocabulary_filter_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.vocabulary_filter_name = input;
            self
        }
        /// <p>Specify how you want your vocabulary filter applied to your transcript.</p>
        /// <p>To replace words with <code>***</code>, choose <code>mask</code>.</p>
        /// <p>To delete words, choose <code>remove</code>.</p>
        /// <p>To flag words without changing them, choose <code>tag</code>.</p>
        pub fn vocabulary_filter_method(
            mut self,
            input: crate::model::VocabularyFilterMethod,
        ) -> Self {
            self.vocabulary_filter_method = Some(input);
            self
        }
        /// <p>Specify how you want your vocabulary filter applied to your transcript.</p>
        /// <p>To replace words with <code>***</code>, choose <code>mask</code>.</p>
        /// <p>To delete words, choose <code>remove</code>.</p>
        /// <p>To flag words without changing them, choose <code>tag</code>.</p>
        pub fn set_vocabulary_filter_method(
            mut self,
            input: std::option::Option<crate::model::VocabularyFilterMethod>,
        ) -> Self {
            self.vocabulary_filter_method = input;
            self
        }
        /// Consumes the builder and constructs a [`Settings`](crate::model::Settings)
        pub fn build(self) -> crate::model::Settings {
            crate::model::Settings {
                vocabulary_name: self.vocabulary_name,
                show_speaker_labels: self.show_speaker_labels,
                max_speaker_labels: self.max_speaker_labels,
                channel_identification: self.channel_identification,
                show_alternatives: self.show_alternatives,
                max_alternatives: self.max_alternatives,
                vocabulary_filter_name: self.vocabulary_filter_name,
                vocabulary_filter_method: self.vocabulary_filter_method,
            }
        }
    }
}
impl Settings {
    /// Creates a new builder-style object to manufacture [`Settings`](crate::model::Settings)
    pub fn builder() -> crate::model::settings::Builder {
        crate::model::settings::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum VocabularyFilterMethod {
    #[allow(missing_docs)] // documentation missing in model
    Mask,
    #[allow(missing_docs)] // documentation missing in model
    Remove,
    #[allow(missing_docs)] // documentation missing in model
    Tag,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for VocabularyFilterMethod {
    fn from(s: &str) -> Self {
        match s {
            "mask" => VocabularyFilterMethod::Mask,
            "remove" => VocabularyFilterMethod::Remove,
            "tag" => VocabularyFilterMethod::Tag,
            other => VocabularyFilterMethod::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for VocabularyFilterMethod {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(VocabularyFilterMethod::from(s))
    }
}
impl VocabularyFilterMethod {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            VocabularyFilterMethod::Mask => "mask",
            VocabularyFilterMethod::Remove => "remove",
            VocabularyFilterMethod::Tag => "tag",
            VocabularyFilterMethod::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["mask", "remove", "tag"]
    }
}
impl AsRef<str> for VocabularyFilterMethod {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct Transcript {
    /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your transcript.</p>
    /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
    /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
    /// </note>
    pub transcript_file_uri: std::option::Option<std::string::String>,
    /// <p>The Amazon S3 location of your redacted transcript. You can use this URI to access or download your transcript.</p>
    /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>RedactedTranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
    /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
    /// </note>
    pub redacted_transcript_file_uri: std::option::Option<std::string::String>,
}
impl Transcript {
    /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your transcript.</p>
    /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
    /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
    /// </note>
    pub fn transcript_file_uri(&self) -> std::option::Option<&str> {
        self.transcript_file_uri.as_deref()
    }
    /// <p>The Amazon S3 location of your redacted transcript. You can use this URI to access or download your transcript.</p>
    /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>RedactedTranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
    /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
    /// </note>
    pub fn redacted_transcript_file_uri(&self) -> std::option::Option<&str> {
        self.redacted_transcript_file_uri.as_deref()
    }
}
impl std::fmt::Debug for Transcript {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("Transcript");
        formatter.field("transcript_file_uri", &self.transcript_file_uri);
        formatter.field(
            "redacted_transcript_file_uri",
            &self.redacted_transcript_file_uri,
        );
        formatter.finish()
    }
}
/// See [`Transcript`](crate::model::Transcript)
pub mod transcript {

    /// A builder for [`Transcript`](crate::model::Transcript)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) transcript_file_uri: std::option::Option<std::string::String>,
        pub(crate) redacted_transcript_file_uri: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your transcript.</p>
        /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
        /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
        /// </note>
        pub fn transcript_file_uri(mut self, input: impl Into<std::string::String>) -> Self {
            self.transcript_file_uri = Some(input.into());
            self
        }
        /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your transcript.</p>
        /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
        /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
        /// </note>
        pub fn set_transcript_file_uri(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.transcript_file_uri = input;
            self
        }
        /// <p>The Amazon S3 location of your redacted transcript. You can use this URI to access or download your transcript.</p>
        /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>RedactedTranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
        /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
        /// </note>
        pub fn redacted_transcript_file_uri(
            mut self,
            input: impl Into<std::string::String>,
        ) -> Self {
            self.redacted_transcript_file_uri = Some(input.into());
            self
        }
        /// <p>The Amazon S3 location of your redacted transcript. You can use this URI to access or download your transcript.</p>
        /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>RedactedTranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
        /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
        /// </note>
        pub fn set_redacted_transcript_file_uri(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.redacted_transcript_file_uri = input;
            self
        }
        /// Consumes the builder and constructs a [`Transcript`](crate::model::Transcript)
        pub fn build(self) -> crate::model::Transcript {
            crate::model::Transcript {
                transcript_file_uri: self.transcript_file_uri,
                redacted_transcript_file_uri: self.redacted_transcript_file_uri,
            }
        }
    }
}
impl Transcript {
    /// Creates a new builder-style object to manufacture [`Transcript`](crate::model::Transcript)
    pub fn builder() -> crate::model::transcript::Builder {
        crate::model::transcript::Builder::default()
    }
}

/// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct Media {
    /// <p>The Amazon S3 location of the media file you want to transcribe. For example:</p>
    /// <ul>
    /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/my-media-file.flac</code> </p> </li>
    /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac</code> </p> </li>
    /// </ul>
    /// <p>Note that the Amazon S3 bucket that contains your input media must be located in the same Amazon Web Services Region where you're making your transcription request.</p>
    pub media_file_uri: std::option::Option<std::string::String>,
    /// <p>The Amazon S3 location of the media file you want to redact. For example:</p>
    /// <ul>
    /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/my-media-file.flac</code> </p> </li>
    /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac</code> </p> </li>
    /// </ul>
    /// <p>Note that the Amazon S3 bucket that contains your input media must be located in the same Amazon Web Services Region where you're making your transcription request.</p> <important>
    /// <p> <code>RedactedMediaFileUri</code> is only supported for Call Analytics (<code>StartCallAnalyticsJob</code>) transcription requests.</p>
    /// </important>
    pub redacted_media_file_uri: std::option::Option<std::string::String>,
}
impl Media {
    /// <p>The Amazon S3 location of the media file you want to transcribe. For example:</p>
    /// <ul>
    /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/my-media-file.flac</code> </p> </li>
    /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac</code> </p> </li>
    /// </ul>
    /// <p>Note that the Amazon S3 bucket that contains your input media must be located in the same Amazon Web Services Region where you're making your transcription request.</p>
    pub fn media_file_uri(&self) -> std::option::Option<&str> {
        self.media_file_uri.as_deref()
    }
    /// <p>The Amazon S3 location of the media file you want to redact. For example:</p>
    /// <ul>
    /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/my-media-file.flac</code> </p> </li>
    /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac</code> </p> </li>
    /// </ul>
    /// <p>Note that the Amazon S3 bucket that contains your input media must be located in the same Amazon Web Services Region where you're making your transcription request.</p> <important>
    /// <p> <code>RedactedMediaFileUri</code> is only supported for Call Analytics (<code>StartCallAnalyticsJob</code>) transcription requests.</p>
    /// </important>
    pub fn redacted_media_file_uri(&self) -> std::option::Option<&str> {
        self.redacted_media_file_uri.as_deref()
    }
}
impl std::fmt::Debug for Media {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("Media");
        formatter.field("media_file_uri", &self.media_file_uri);
        formatter.field("redacted_media_file_uri", &self.redacted_media_file_uri);
        formatter.finish()
    }
}
/// See [`Media`](crate::model::Media)
pub mod media {

    /// A builder for [`Media`](crate::model::Media)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) media_file_uri: std::option::Option<std::string::String>,
        pub(crate) redacted_media_file_uri: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The Amazon S3 location of the media file you want to transcribe. For example:</p>
        /// <ul>
        /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/my-media-file.flac</code> </p> </li>
        /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac</code> </p> </li>
        /// </ul>
        /// <p>Note that the Amazon S3 bucket that contains your input media must be located in the same Amazon Web Services Region where you're making your transcription request.</p>
        pub fn media_file_uri(mut self, input: impl Into<std::string::String>) -> Self {
            self.media_file_uri = Some(input.into());
            self
        }
        /// <p>The Amazon S3 location of the media file you want to transcribe. For example:</p>
        /// <ul>
        /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/my-media-file.flac</code> </p> </li>
        /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac</code> </p> </li>
        /// </ul>
        /// <p>Note that the Amazon S3 bucket that contains your input media must be located in the same Amazon Web Services Region where you're making your transcription request.</p>
        pub fn set_media_file_uri(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.media_file_uri = input;
            self
        }
        /// <p>The Amazon S3 location of the media file you want to redact. For example:</p>
        /// <ul>
        /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/my-media-file.flac</code> </p> </li>
        /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac</code> </p> </li>
        /// </ul>
        /// <p>Note that the Amazon S3 bucket that contains your input media must be located in the same Amazon Web Services Region where you're making your transcription request.</p> <important>
        /// <p> <code>RedactedMediaFileUri</code> is only supported for Call Analytics (<code>StartCallAnalyticsJob</code>) transcription requests.</p>
        /// </important>
        pub fn redacted_media_file_uri(mut self, input: impl Into<std::string::String>) -> Self {
            self.redacted_media_file_uri = Some(input.into());
            self
        }
        /// <p>The Amazon S3 location of the media file you want to redact. For example:</p>
        /// <ul>
        /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/my-media-file.flac</code> </p> </li>
        /// <li> <p> <code>s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac</code> </p> </li>
        /// </ul>
        /// <p>Note that the Amazon S3 bucket that contains your input media must be located in the same Amazon Web Services Region where you're making your transcription request.</p> <important>
        /// <p> <code>RedactedMediaFileUri</code> is only supported for Call Analytics (<code>StartCallAnalyticsJob</code>) transcription requests.</p>
        /// </important>
        pub fn set_redacted_media_file_uri(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.redacted_media_file_uri = input;
            self
        }
        /// Consumes the builder and constructs a [`Media`](crate::model::Media)
        pub fn build(self) -> crate::model::Media {
            crate::model::Media {
                media_file_uri: self.media_file_uri,
                redacted_media_file_uri: self.redacted_media_file_uri,
            }
        }
    }
}
impl Media {
    /// Creates a new builder-style object to manufacture [`Media`](crate::model::Media)
    pub fn builder() -> crate::model::media::Builder {
        crate::model::media::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum MediaFormat {
    #[allow(missing_docs)] // documentation missing in model
    Amr,
    #[allow(missing_docs)] // documentation missing in model
    Flac,
    #[allow(missing_docs)] // documentation missing in model
    Mp3,
    #[allow(missing_docs)] // documentation missing in model
    Mp4,
    #[allow(missing_docs)] // documentation missing in model
    Ogg,
    #[allow(missing_docs)] // documentation missing in model
    Wav,
    #[allow(missing_docs)] // documentation missing in model
    Webm,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for MediaFormat {
    fn from(s: &str) -> Self {
        match s {
            "amr" => MediaFormat::Amr,
            "flac" => MediaFormat::Flac,
            "mp3" => MediaFormat::Mp3,
            "mp4" => MediaFormat::Mp4,
            "ogg" => MediaFormat::Ogg,
            "wav" => MediaFormat::Wav,
            "webm" => MediaFormat::Webm,
            other => MediaFormat::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for MediaFormat {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(MediaFormat::from(s))
    }
}
impl MediaFormat {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            MediaFormat::Amr => "amr",
            MediaFormat::Flac => "flac",
            MediaFormat::Mp3 => "mp3",
            MediaFormat::Mp4 => "mp4",
            MediaFormat::Ogg => "ogg",
            MediaFormat::Wav => "wav",
            MediaFormat::Webm => "webm",
            MediaFormat::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["amr", "flac", "mp3", "mp4", "ogg", "wav", "webm"]
    }
}
impl AsRef<str> for MediaFormat {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum TranscriptionJobStatus {
    #[allow(missing_docs)] // documentation missing in model
    Completed,
    #[allow(missing_docs)] // documentation missing in model
    Failed,
    #[allow(missing_docs)] // documentation missing in model
    InProgress,
    #[allow(missing_docs)] // documentation missing in model
    Queued,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for TranscriptionJobStatus {
    fn from(s: &str) -> Self {
        match s {
            "COMPLETED" => TranscriptionJobStatus::Completed,
            "FAILED" => TranscriptionJobStatus::Failed,
            "IN_PROGRESS" => TranscriptionJobStatus::InProgress,
            "QUEUED" => TranscriptionJobStatus::Queued,
            other => TranscriptionJobStatus::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for TranscriptionJobStatus {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(TranscriptionJobStatus::from(s))
    }
}
impl TranscriptionJobStatus {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            TranscriptionJobStatus::Completed => "COMPLETED",
            TranscriptionJobStatus::Failed => "FAILED",
            TranscriptionJobStatus::InProgress => "IN_PROGRESS",
            TranscriptionJobStatus::Queued => "QUEUED",
            TranscriptionJobStatus::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["COMPLETED", "FAILED", "IN_PROGRESS", "QUEUED"]
    }
}
impl AsRef<str> for TranscriptionJobStatus {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Generate subtitles for your media file with your transcription request.</p>
/// <p>You can choose a start index of 0 or 1, and you can specify either WebVTT or SubRip (or both) as your output format.</p>
/// <p>Note that your subtitle files are placed in the same location as your transcription output.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct Subtitles {
    /// <p>Specify the output format for your subtitle file; if you select both WebVTT (<code>vtt</code>) and SubRip (<code>srt</code>) formats, two output files are generated.</p>
    pub formats: std::option::Option<std::vec::Vec<crate::model::SubtitleFormat>>,
    /// <p>Specify the starting value that is assigned to the first subtitle segment.</p>
    /// <p>The default start index for Amazon Transcribe is <code>0</code>, which differs from the more widely used standard of <code>1</code>. If you're uncertain which value to use, we recommend choosing <code>1</code>, as this may improve compatibility with other services.</p>
    pub output_start_index: std::option::Option<i32>,
}
impl Subtitles {
    /// <p>Specify the output format for your subtitle file; if you select both WebVTT (<code>vtt</code>) and SubRip (<code>srt</code>) formats, two output files are generated.</p>
    pub fn formats(&self) -> std::option::Option<&[crate::model::SubtitleFormat]> {
        self.formats.as_deref()
    }
    /// <p>Specify the starting value that is assigned to the first subtitle segment.</p>
    /// <p>The default start index for Amazon Transcribe is <code>0</code>, which differs from the more widely used standard of <code>1</code>. If you're uncertain which value to use, we recommend choosing <code>1</code>, as this may improve compatibility with other services.</p>
    pub fn output_start_index(&self) -> std::option::Option<i32> {
        self.output_start_index
    }
}
impl std::fmt::Debug for Subtitles {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("Subtitles");
        formatter.field("formats", &self.formats);
        formatter.field("output_start_index", &self.output_start_index);
        formatter.finish()
    }
}
/// See [`Subtitles`](crate::model::Subtitles)
pub mod subtitles {

    /// A builder for [`Subtitles`](crate::model::Subtitles)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) formats: std::option::Option<std::vec::Vec<crate::model::SubtitleFormat>>,
        pub(crate) output_start_index: std::option::Option<i32>,
    }
    impl Builder {
        /// Appends an item to `formats`.
        ///
        /// To override the contents of this collection use [`set_formats`](Self::set_formats).
        ///
        /// <p>Specify the output format for your subtitle file; if you select both WebVTT (<code>vtt</code>) and SubRip (<code>srt</code>) formats, two output files are generated.</p>
        pub fn formats(mut self, input: crate::model::SubtitleFormat) -> Self {
            let mut v = self.formats.unwrap_or_default();
            v.push(input);
            self.formats = Some(v);
            self
        }
        /// <p>Specify the output format for your subtitle file; if you select both WebVTT (<code>vtt</code>) and SubRip (<code>srt</code>) formats, two output files are generated.</p>
        pub fn set_formats(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::SubtitleFormat>>,
        ) -> Self {
            self.formats = input;
            self
        }
        /// <p>Specify the starting value that is assigned to the first subtitle segment.</p>
        /// <p>The default start index for Amazon Transcribe is <code>0</code>, which differs from the more widely used standard of <code>1</code>. If you're uncertain which value to use, we recommend choosing <code>1</code>, as this may improve compatibility with other services.</p>
        pub fn output_start_index(mut self, input: i32) -> Self {
            self.output_start_index = Some(input);
            self
        }
        /// <p>Specify the starting value that is assigned to the first subtitle segment.</p>
        /// <p>The default start index for Amazon Transcribe is <code>0</code>, which differs from the more widely used standard of <code>1</code>. If you're uncertain which value to use, we recommend choosing <code>1</code>, as this may improve compatibility with other services.</p>
        pub fn set_output_start_index(mut self, input: std::option::Option<i32>) -> Self {
            self.output_start_index = input;
            self
        }
        /// Consumes the builder and constructs a [`Subtitles`](crate::model::Subtitles)
        pub fn build(self) -> crate::model::Subtitles {
            crate::model::Subtitles {
                formats: self.formats,
                output_start_index: self.output_start_index,
            }
        }
    }
}
impl Subtitles {
    /// Creates a new builder-style object to manufacture [`Subtitles`](crate::model::Subtitles)
    pub fn builder() -> crate::model::subtitles::Builder {
        crate::model::subtitles::Builder::default()
    }
}

/// <p>Provides detailed information about a medical transcription job.</p>
/// <p>To view the status of the specified medical transcription job, check the <code>TranscriptionJobStatus</code> field. If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code>. If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct MedicalTranscriptionJob {
    /// <p>The name of the medical transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub medical_transcription_job_name: std::option::Option<std::string::String>,
    /// <p>Provides the status of the specified medical transcription job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code>. If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub transcription_job_status: std::option::Option<crate::model::TranscriptionJobStatus>,
    /// <p>The language code used to create your medical transcription job. US English (<code>en-US</code>) is the only supported language for medical transcriptions.</p>
    pub language_code: std::option::Option<crate::model::LanguageCode>,
    /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
    pub media_sample_rate_hertz: std::option::Option<i32>,
    /// <p>The format of the input media file.</p>
    pub media_format: std::option::Option<crate::model::MediaFormat>,
    /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
    pub media: std::option::Option<crate::model::Media>,
    /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
    pub transcript: std::option::Option<crate::model::MedicalTranscript>,
    /// <p>The date and time the specified medical transcription job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time the specified medical transcription job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub creation_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time the specified medical transcription job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub completion_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job request failed.</p>
    /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
    /// <ul>
    /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
    /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 16,000 and 48,000 Hertz.</p> </li>
    /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// </ul>
    pub failure_reason: std::option::Option<std::string::String>,
    /// <p>Specify additional optional settings in your request, including channel identification, alternative transcriptions, and speaker labeling; allows you to apply custom vocabularies to your medical transcription job.</p>
    pub settings: std::option::Option<crate::model::MedicalTranscriptionSetting>,
    /// <p>Labels all personal health information (PHI) identified in your transcript. For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/phi-id.html">Identifying personal health information (PHI) in a transcription</a>.</p>
    pub content_identification_type:
        std::option::Option<crate::model::MedicalContentIdentificationType>,
    /// <p>Describes the medical specialty represented in your media.</p>
    pub specialty: std::option::Option<crate::model::Specialty>,
    /// <p>Indicates whether the input media is a dictation or a conversation, as specified in the <code>StartMedicalTranscriptionJob</code> request.</p>
    pub r#type: std::option::Option<crate::model::Type>,
    /// <p>The tags, each in the form of a key:value pair, assigned to the specified medical transcription job.</p>
    pub tags: std::option::Option<std::vec::Vec<crate::model::Tag>>,
}
impl MedicalTranscriptionJob {
    /// <p>The name of the medical transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub fn medical_transcription_job_name(&self) -> std::option::Option<&str> {
        self.medical_transcription_job_name.as_deref()
    }
    /// <p>Provides the status of the specified medical transcription job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code>. If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub fn transcription_job_status(
        &self,
    ) -> std::option::Option<&crate::model::TranscriptionJobStatus> {
        self.transcription_job_status.as_ref()
    }
    /// <p>The language code used to create your medical transcription job. US English (<code>en-US</code>) is the only supported language for medical transcriptions.</p>
    pub fn language_code(&self) -> std::option::Option<&crate::model::LanguageCode> {
        self.language_code.as_ref()
    }
    /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
    pub fn media_sample_rate_hertz(&self) -> std::option::Option<i32> {
        self.media_sample_rate_hertz
    }
    /// <p>The format of the input media file.</p>
    pub fn media_format(&self) -> std::option::Option<&crate::model::MediaFormat> {
        self.media_format.as_ref()
    }
    /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
    pub fn media(&self) -> std::option::Option<&crate::model::Media> {
        self.media.as_ref()
    }
    /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
    pub fn transcript(&self) -> std::option::Option<&crate::model::MedicalTranscript> {
        self.transcript.as_ref()
    }
    /// <p>The date and time the specified medical transcription job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p>The date and time the specified medical transcription job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn creation_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.creation_time.as_ref()
    }
    /// <p>The date and time the specified medical transcription job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub fn completion_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.completion_time.as_ref()
    }
    /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job request failed.</p>
    /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
    /// <ul>
    /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
    /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 16,000 and 48,000 Hertz.</p> </li>
    /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// </ul>
    pub fn failure_reason(&self) -> std::option::Option<&str> {
        self.failure_reason.as_deref()
    }
    /// <p>Specify additional optional settings in your request, including channel identification, alternative transcriptions, and speaker labeling; allows you to apply custom vocabularies to your medical transcription job.</p>
    pub fn settings(&self) -> std::option::Option<&crate::model::MedicalTranscriptionSetting> {
        self.settings.as_ref()
    }
    /// <p>Labels all personal health information (PHI) identified in your transcript. For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/phi-id.html">Identifying personal health information (PHI) in a transcription</a>.</p>
    pub fn content_identification_type(
        &self,
    ) -> std::option::Option<&crate::model::MedicalContentIdentificationType> {
        self.content_identification_type.as_ref()
    }
    /// <p>Describes the medical specialty represented in your media.</p>
    pub fn specialty(&self) -> std::option::Option<&crate::model::Specialty> {
        self.specialty.as_ref()
    }
    /// <p>Indicates whether the input media is a dictation or a conversation, as specified in the <code>StartMedicalTranscriptionJob</code> request.</p>
    pub fn r#type(&self) -> std::option::Option<&crate::model::Type> {
        self.r#type.as_ref()
    }
    /// <p>The tags, each in the form of a key:value pair, assigned to the specified medical transcription job.</p>
    pub fn tags(&self) -> std::option::Option<&[crate::model::Tag]> {
        self.tags.as_deref()
    }
}
impl std::fmt::Debug for MedicalTranscriptionJob {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("MedicalTranscriptionJob");
        formatter.field(
            "medical_transcription_job_name",
            &self.medical_transcription_job_name,
        );
        formatter.field("transcription_job_status", &self.transcription_job_status);
        formatter.field("language_code", &self.language_code);
        formatter.field("media_sample_rate_hertz", &self.media_sample_rate_hertz);
        formatter.field("media_format", &self.media_format);
        formatter.field("media", &self.media);
        formatter.field("transcript", &self.transcript);
        formatter.field("start_time", &self.start_time);
        formatter.field("creation_time", &self.creation_time);
        formatter.field("completion_time", &self.completion_time);
        formatter.field("failure_reason", &self.failure_reason);
        formatter.field("settings", &self.settings);
        formatter.field(
            "content_identification_type",
            &self.content_identification_type,
        );
        formatter.field("specialty", &self.specialty);
        formatter.field("r#type", &self.r#type);
        formatter.field("tags", &self.tags);
        formatter.finish()
    }
}
/// See [`MedicalTranscriptionJob`](crate::model::MedicalTranscriptionJob)
pub mod medical_transcription_job {

    /// A builder for [`MedicalTranscriptionJob`](crate::model::MedicalTranscriptionJob)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) medical_transcription_job_name: std::option::Option<std::string::String>,
        pub(crate) transcription_job_status:
            std::option::Option<crate::model::TranscriptionJobStatus>,
        pub(crate) language_code: std::option::Option<crate::model::LanguageCode>,
        pub(crate) media_sample_rate_hertz: std::option::Option<i32>,
        pub(crate) media_format: std::option::Option<crate::model::MediaFormat>,
        pub(crate) media: std::option::Option<crate::model::Media>,
        pub(crate) transcript: std::option::Option<crate::model::MedicalTranscript>,
        pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) creation_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) completion_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) failure_reason: std::option::Option<std::string::String>,
        pub(crate) settings: std::option::Option<crate::model::MedicalTranscriptionSetting>,
        pub(crate) content_identification_type:
            std::option::Option<crate::model::MedicalContentIdentificationType>,
        pub(crate) specialty: std::option::Option<crate::model::Specialty>,
        pub(crate) r#type: std::option::Option<crate::model::Type>,
        pub(crate) tags: std::option::Option<std::vec::Vec<crate::model::Tag>>,
    }
    impl Builder {
        /// <p>The name of the medical transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn medical_transcription_job_name(
            mut self,
            input: impl Into<std::string::String>,
        ) -> Self {
            self.medical_transcription_job_name = Some(input.into());
            self
        }
        /// <p>The name of the medical transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn set_medical_transcription_job_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.medical_transcription_job_name = input;
            self
        }
        /// <p>Provides the status of the specified medical transcription job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code>. If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn transcription_job_status(
            mut self,
            input: crate::model::TranscriptionJobStatus,
        ) -> Self {
            self.transcription_job_status = Some(input);
            self
        }
        /// <p>Provides the status of the specified medical transcription job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code>. If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn set_transcription_job_status(
            mut self,
            input: std::option::Option<crate::model::TranscriptionJobStatus>,
        ) -> Self {
            self.transcription_job_status = input;
            self
        }
        /// <p>The language code used to create your medical transcription job. US English (<code>en-US</code>) is the only supported language for medical transcriptions.</p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.language_code = Some(input);
            self
        }
        /// <p>The language code used to create your medical transcription job. US English (<code>en-US</code>) is the only supported language for medical transcriptions.</p>
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.language_code = input;
            self
        }
        /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
        pub fn media_sample_rate_hertz(mut self, input: i32) -> Self {
            self.media_sample_rate_hertz = Some(input);
            self
        }
        /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
        pub fn set_media_sample_rate_hertz(mut self, input: std::option::Option<i32>) -> Self {
            self.media_sample_rate_hertz = input;
            self
        }
        /// <p>The format of the input media file.</p>
        pub fn media_format(mut self, input: crate::model::MediaFormat) -> Self {
            self.media_format = Some(input);
            self
        }
        /// <p>The format of the input media file.</p>
        pub fn set_media_format(
            mut self,
            input: std::option::Option<crate::model::MediaFormat>,
        ) -> Self {
            self.media_format = input;
            self
        }
        /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
        pub fn media(mut self, input: crate::model::Media) -> Self {
            self.media = Some(input);
            self
        }
        /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
        pub fn set_media(mut self, input: std::option::Option<crate::model::Media>) -> Self {
            self.media = input;
            self
        }
        /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
        pub fn transcript(mut self, input: crate::model::MedicalTranscript) -> Self {
            self.transcript = Some(input);
            self
        }
        /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
        pub fn set_transcript(
            mut self,
            input: std::option::Option<crate::model::MedicalTranscript>,
        ) -> Self {
            self.transcript = input;
            self
        }
        /// <p>The date and time the specified medical transcription job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p>The date and time the specified medical transcription job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.start_time = input;
            self
        }
        /// <p>The date and time the specified medical transcription job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn creation_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.creation_time = Some(input);
            self
        }
        /// <p>The date and time the specified medical transcription job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_creation_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.creation_time = input;
            self
        }
        /// <p>The date and time the specified medical transcription job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn completion_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.completion_time = Some(input);
            self
        }
        /// <p>The date and time the specified medical transcription job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn set_completion_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.completion_time = input;
            self
        }
        /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job request failed.</p>
        /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
        /// <ul>
        /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
        /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 16,000 and 48,000 Hertz.</p> </li>
        /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// </ul>
        pub fn failure_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.failure_reason = Some(input.into());
            self
        }
        /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job request failed.</p>
        /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
        /// <ul>
        /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
        /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 16,000 and 48,000 Hertz.</p> </li>
        /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// </ul>
        pub fn set_failure_reason(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.failure_reason = input;
            self
        }
        /// <p>Specify additional optional settings in your request, including channel identification, alternative transcriptions, and speaker labeling; allows you to apply custom vocabularies to your medical transcription job.</p>
        pub fn settings(mut self, input: crate::model::MedicalTranscriptionSetting) -> Self {
            self.settings = Some(input);
            self
        }
        /// <p>Specify additional optional settings in your request, including channel identification, alternative transcriptions, and speaker labeling; allows you to apply custom vocabularies to your medical transcription job.</p>
        pub fn set_settings(
            mut self,
            input: std::option::Option<crate::model::MedicalTranscriptionSetting>,
        ) -> Self {
            self.settings = input;
            self
        }
        /// <p>Labels all personal health information (PHI) identified in your transcript. For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/phi-id.html">Identifying personal health information (PHI) in a transcription</a>.</p>
        pub fn content_identification_type(
            mut self,
            input: crate::model::MedicalContentIdentificationType,
        ) -> Self {
            self.content_identification_type = Some(input);
            self
        }
        /// <p>Labels all personal health information (PHI) identified in your transcript. For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/phi-id.html">Identifying personal health information (PHI) in a transcription</a>.</p>
        pub fn set_content_identification_type(
            mut self,
            input: std::option::Option<crate::model::MedicalContentIdentificationType>,
        ) -> Self {
            self.content_identification_type = input;
            self
        }
        /// <p>Describes the medical specialty represented in your media.</p>
        pub fn specialty(mut self, input: crate::model::Specialty) -> Self {
            self.specialty = Some(input);
            self
        }
        /// <p>Describes the medical specialty represented in your media.</p>
        pub fn set_specialty(
            mut self,
            input: std::option::Option<crate::model::Specialty>,
        ) -> Self {
            self.specialty = input;
            self
        }
        /// <p>Indicates whether the input media is a dictation or a conversation, as specified in the <code>StartMedicalTranscriptionJob</code> request.</p>
        pub fn r#type(mut self, input: crate::model::Type) -> Self {
            self.r#type = Some(input);
            self
        }
        /// <p>Indicates whether the input media is a dictation or a conversation, as specified in the <code>StartMedicalTranscriptionJob</code> request.</p>
        pub fn set_type(mut self, input: std::option::Option<crate::model::Type>) -> Self {
            self.r#type = input;
            self
        }
        /// Appends an item to `tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p>The tags, each in the form of a key:value pair, assigned to the specified medical transcription job.</p>
        pub fn tags(mut self, input: crate::model::Tag) -> Self {
            let mut v = self.tags.unwrap_or_default();
            v.push(input);
            self.tags = Some(v);
            self
        }
        /// <p>The tags, each in the form of a key:value pair, assigned to the specified medical transcription job.</p>
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.tags = input;
            self
        }
        /// Consumes the builder and constructs a [`MedicalTranscriptionJob`](crate::model::MedicalTranscriptionJob)
        pub fn build(self) -> crate::model::MedicalTranscriptionJob {
            crate::model::MedicalTranscriptionJob {
                medical_transcription_job_name: self.medical_transcription_job_name,
                transcription_job_status: self.transcription_job_status,
                language_code: self.language_code,
                media_sample_rate_hertz: self.media_sample_rate_hertz,
                media_format: self.media_format,
                media: self.media,
                transcript: self.transcript,
                start_time: self.start_time,
                creation_time: self.creation_time,
                completion_time: self.completion_time,
                failure_reason: self.failure_reason,
                settings: self.settings,
                content_identification_type: self.content_identification_type,
                specialty: self.specialty,
                r#type: self.r#type,
                tags: self.tags,
            }
        }
    }
}
impl MedicalTranscriptionJob {
    /// Creates a new builder-style object to manufacture [`MedicalTranscriptionJob`](crate::model::MedicalTranscriptionJob)
    pub fn builder() -> crate::model::medical_transcription_job::Builder {
        crate::model::medical_transcription_job::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum Type {
    #[allow(missing_docs)] // documentation missing in model
    Conversation,
    #[allow(missing_docs)] // documentation missing in model
    Dictation,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for Type {
    fn from(s: &str) -> Self {
        match s {
            "CONVERSATION" => Type::Conversation,
            "DICTATION" => Type::Dictation,
            other => Type::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for Type {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(Type::from(s))
    }
}
impl Type {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            Type::Conversation => "CONVERSATION",
            Type::Dictation => "DICTATION",
            Type::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["CONVERSATION", "DICTATION"]
    }
}
impl AsRef<str> for Type {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum Specialty {
    #[allow(missing_docs)] // documentation missing in model
    Primarycare,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for Specialty {
    fn from(s: &str) -> Self {
        match s {
            "PRIMARYCARE" => Specialty::Primarycare,
            other => Specialty::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for Specialty {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(Specialty::from(s))
    }
}
impl Specialty {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            Specialty::Primarycare => "PRIMARYCARE",
            Specialty::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["PRIMARYCARE"]
    }
}
impl AsRef<str> for Specialty {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum MedicalContentIdentificationType {
    #[allow(missing_docs)] // documentation missing in model
    Phi,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for MedicalContentIdentificationType {
    fn from(s: &str) -> Self {
        match s {
            "PHI" => MedicalContentIdentificationType::Phi,
            other => MedicalContentIdentificationType::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for MedicalContentIdentificationType {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(MedicalContentIdentificationType::from(s))
    }
}
impl MedicalContentIdentificationType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            MedicalContentIdentificationType::Phi => "PHI",
            MedicalContentIdentificationType::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["PHI"]
    }
}
impl AsRef<str> for MedicalContentIdentificationType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Allows additional optional settings in your request, including channel identification, alternative transcriptions, and speaker labeling; allows you to apply custom vocabularies to your medical transcription job.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct MedicalTranscriptionSetting {
    /// <p>Enables speaker identification (diarization) in your transcription output. Speaker identification labels the speech from individual speakers in your media file.</p>
    /// <p>If you enable <code>ShowSpeakerLabels</code> in your request, you must also include <code>MaxSpeakerLabels</code>.</p>
    /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Identifying speakers (diarization)</a>.</p>
    pub show_speaker_labels: std::option::Option<bool>,
    /// <p>Specify the maximum number of speakers you want to identify in your media.</p>
    /// <p>Note that if your media contains more speakers than the specified number, multiple speakers will be identified as a single speaker.</p>
    /// <p>If you specify the <code>MaxSpeakerLabels</code> field, you must set the <code>ShowSpeakerLabels</code> field to true.</p>
    pub max_speaker_labels: std::option::Option<i32>,
    /// <p>Enables channel identification in multi-channel audio.</p>
    /// <p>Channel identification transcribes the audio on each channel independently, then appends the output for each channel into one transcript.</p>
    /// <p>If you have multi-channel audio and do not enable channel identification, your audio is transcribed in a continuous manner and your transcript does not separate the speech by channel.</p>
    /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/channel-id.html">Transcribing multi-channel audio</a>.</p>
    pub channel_identification: std::option::Option<bool>,
    /// <p>To include alternative transcriptions within your transcription output, include <code>ShowAlternatives</code> in your transcription request.</p>
    /// <p>If you include <code>ShowAlternatives</code>, you must also include <code>MaxAlternatives</code>, which is the maximum number of alternative transcriptions you want Amazon Transcribe Medical to generate.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
    pub show_alternatives: std::option::Option<bool>,
    /// <p>Indicate the maximum number of alternative transcriptions you want Amazon Transcribe Medical to include in your transcript.</p>
    /// <p>If you select a number greater than the number of alternative transcriptions generated by Amazon Transcribe Medical, only the actual number of alternative transcriptions are included.</p>
    /// <p>If you include <code>MaxAlternatives</code> in your request, you must also include <code>ShowAlternatives</code> with a value of <code>true</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
    pub max_alternatives: std::option::Option<i32>,
    /// <p>The name of the custom vocabulary you want to use when processing your medical transcription job. Vocabulary names are case sensitive.</p>
    /// <p>The language of the specified vocabulary must match the language code you specify in your transcription request. If the languages don't match, the vocabulary isn't applied. There are no errors or warnings associated with a language mismatch. US English (<code>en-US</code>) is the only valid language for Amazon Transcribe Medical.</p>
    pub vocabulary_name: std::option::Option<std::string::String>,
}
impl MedicalTranscriptionSetting {
    /// <p>Enables speaker identification (diarization) in your transcription output. Speaker identification labels the speech from individual speakers in your media file.</p>
    /// <p>If you enable <code>ShowSpeakerLabels</code> in your request, you must also include <code>MaxSpeakerLabels</code>.</p>
    /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Identifying speakers (diarization)</a>.</p>
    pub fn show_speaker_labels(&self) -> std::option::Option<bool> {
        self.show_speaker_labels
    }
    /// <p>Specify the maximum number of speakers you want to identify in your media.</p>
    /// <p>Note that if your media contains more speakers than the specified number, multiple speakers will be identified as a single speaker.</p>
    /// <p>If you specify the <code>MaxSpeakerLabels</code> field, you must set the <code>ShowSpeakerLabels</code> field to true.</p>
    pub fn max_speaker_labels(&self) -> std::option::Option<i32> {
        self.max_speaker_labels
    }
    /// <p>Enables channel identification in multi-channel audio.</p>
    /// <p>Channel identification transcribes the audio on each channel independently, then appends the output for each channel into one transcript.</p>
    /// <p>If you have multi-channel audio and do not enable channel identification, your audio is transcribed in a continuous manner and your transcript does not separate the speech by channel.</p>
    /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/channel-id.html">Transcribing multi-channel audio</a>.</p>
    pub fn channel_identification(&self) -> std::option::Option<bool> {
        self.channel_identification
    }
    /// <p>To include alternative transcriptions within your transcription output, include <code>ShowAlternatives</code> in your transcription request.</p>
    /// <p>If you include <code>ShowAlternatives</code>, you must also include <code>MaxAlternatives</code>, which is the maximum number of alternative transcriptions you want Amazon Transcribe Medical to generate.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
    pub fn show_alternatives(&self) -> std::option::Option<bool> {
        self.show_alternatives
    }
    /// <p>Indicate the maximum number of alternative transcriptions you want Amazon Transcribe Medical to include in your transcript.</p>
    /// <p>If you select a number greater than the number of alternative transcriptions generated by Amazon Transcribe Medical, only the actual number of alternative transcriptions are included.</p>
    /// <p>If you include <code>MaxAlternatives</code> in your request, you must also include <code>ShowAlternatives</code> with a value of <code>true</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
    pub fn max_alternatives(&self) -> std::option::Option<i32> {
        self.max_alternatives
    }
    /// <p>The name of the custom vocabulary you want to use when processing your medical transcription job. Vocabulary names are case sensitive.</p>
    /// <p>The language of the specified vocabulary must match the language code you specify in your transcription request. If the languages don't match, the vocabulary isn't applied. There are no errors or warnings associated with a language mismatch. US English (<code>en-US</code>) is the only valid language for Amazon Transcribe Medical.</p>
    pub fn vocabulary_name(&self) -> std::option::Option<&str> {
        self.vocabulary_name.as_deref()
    }
}
impl std::fmt::Debug for MedicalTranscriptionSetting {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("MedicalTranscriptionSetting");
        formatter.field("show_speaker_labels", &self.show_speaker_labels);
        formatter.field("max_speaker_labels", &self.max_speaker_labels);
        formatter.field("channel_identification", &self.channel_identification);
        formatter.field("show_alternatives", &self.show_alternatives);
        formatter.field("max_alternatives", &self.max_alternatives);
        formatter.field("vocabulary_name", &self.vocabulary_name);
        formatter.finish()
    }
}
/// See [`MedicalTranscriptionSetting`](crate::model::MedicalTranscriptionSetting)
pub mod medical_transcription_setting {

    /// A builder for [`MedicalTranscriptionSetting`](crate::model::MedicalTranscriptionSetting)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) show_speaker_labels: std::option::Option<bool>,
        pub(crate) max_speaker_labels: std::option::Option<i32>,
        pub(crate) channel_identification: std::option::Option<bool>,
        pub(crate) show_alternatives: std::option::Option<bool>,
        pub(crate) max_alternatives: std::option::Option<i32>,
        pub(crate) vocabulary_name: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>Enables speaker identification (diarization) in your transcription output. Speaker identification labels the speech from individual speakers in your media file.</p>
        /// <p>If you enable <code>ShowSpeakerLabels</code> in your request, you must also include <code>MaxSpeakerLabels</code>.</p>
        /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Identifying speakers (diarization)</a>.</p>
        pub fn show_speaker_labels(mut self, input: bool) -> Self {
            self.show_speaker_labels = Some(input);
            self
        }
        /// <p>Enables speaker identification (diarization) in your transcription output. Speaker identification labels the speech from individual speakers in your media file.</p>
        /// <p>If you enable <code>ShowSpeakerLabels</code> in your request, you must also include <code>MaxSpeakerLabels</code>.</p>
        /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Identifying speakers (diarization)</a>.</p>
        pub fn set_show_speaker_labels(mut self, input: std::option::Option<bool>) -> Self {
            self.show_speaker_labels = input;
            self
        }
        /// <p>Specify the maximum number of speakers you want to identify in your media.</p>
        /// <p>Note that if your media contains more speakers than the specified number, multiple speakers will be identified as a single speaker.</p>
        /// <p>If you specify the <code>MaxSpeakerLabels</code> field, you must set the <code>ShowSpeakerLabels</code> field to true.</p>
        pub fn max_speaker_labels(mut self, input: i32) -> Self {
            self.max_speaker_labels = Some(input);
            self
        }
        /// <p>Specify the maximum number of speakers you want to identify in your media.</p>
        /// <p>Note that if your media contains more speakers than the specified number, multiple speakers will be identified as a single speaker.</p>
        /// <p>If you specify the <code>MaxSpeakerLabels</code> field, you must set the <code>ShowSpeakerLabels</code> field to true.</p>
        pub fn set_max_speaker_labels(mut self, input: std::option::Option<i32>) -> Self {
            self.max_speaker_labels = input;
            self
        }
        /// <p>Enables channel identification in multi-channel audio.</p>
        /// <p>Channel identification transcribes the audio on each channel independently, then appends the output for each channel into one transcript.</p>
        /// <p>If you have multi-channel audio and do not enable channel identification, your audio is transcribed in a continuous manner and your transcript does not separate the speech by channel.</p>
        /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/channel-id.html">Transcribing multi-channel audio</a>.</p>
        pub fn channel_identification(mut self, input: bool) -> Self {
            self.channel_identification = Some(input);
            self
        }
        /// <p>Enables channel identification in multi-channel audio.</p>
        /// <p>Channel identification transcribes the audio on each channel independently, then appends the output for each channel into one transcript.</p>
        /// <p>If you have multi-channel audio and do not enable channel identification, your audio is transcribed in a continuous manner and your transcript does not separate the speech by channel.</p>
        /// <p>You can't include both <code>ShowSpeakerLabels</code> and <code>ChannelIdentification</code> in the same request. Including both parameters returns a <code>BadRequestException</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/channel-id.html">Transcribing multi-channel audio</a>.</p>
        pub fn set_channel_identification(mut self, input: std::option::Option<bool>) -> Self {
            self.channel_identification = input;
            self
        }
        /// <p>To include alternative transcriptions within your transcription output, include <code>ShowAlternatives</code> in your transcription request.</p>
        /// <p>If you include <code>ShowAlternatives</code>, you must also include <code>MaxAlternatives</code>, which is the maximum number of alternative transcriptions you want Amazon Transcribe Medical to generate.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
        pub fn show_alternatives(mut self, input: bool) -> Self {
            self.show_alternatives = Some(input);
            self
        }
        /// <p>To include alternative transcriptions within your transcription output, include <code>ShowAlternatives</code> in your transcription request.</p>
        /// <p>If you include <code>ShowAlternatives</code>, you must also include <code>MaxAlternatives</code>, which is the maximum number of alternative transcriptions you want Amazon Transcribe Medical to generate.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
        pub fn set_show_alternatives(mut self, input: std::option::Option<bool>) -> Self {
            self.show_alternatives = input;
            self
        }
        /// <p>Indicate the maximum number of alternative transcriptions you want Amazon Transcribe Medical to include in your transcript.</p>
        /// <p>If you select a number greater than the number of alternative transcriptions generated by Amazon Transcribe Medical, only the actual number of alternative transcriptions are included.</p>
        /// <p>If you include <code>MaxAlternatives</code> in your request, you must also include <code>ShowAlternatives</code> with a value of <code>true</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
        pub fn max_alternatives(mut self, input: i32) -> Self {
            self.max_alternatives = Some(input);
            self
        }
        /// <p>Indicate the maximum number of alternative transcriptions you want Amazon Transcribe Medical to include in your transcript.</p>
        /// <p>If you select a number greater than the number of alternative transcriptions generated by Amazon Transcribe Medical, only the actual number of alternative transcriptions are included.</p>
        /// <p>If you include <code>MaxAlternatives</code> in your request, you must also include <code>ShowAlternatives</code> with a value of <code>true</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-alternatives.html">Alternative transcriptions</a>.</p>
        pub fn set_max_alternatives(mut self, input: std::option::Option<i32>) -> Self {
            self.max_alternatives = input;
            self
        }
        /// <p>The name of the custom vocabulary you want to use when processing your medical transcription job. Vocabulary names are case sensitive.</p>
        /// <p>The language of the specified vocabulary must match the language code you specify in your transcription request. If the languages don't match, the vocabulary isn't applied. There are no errors or warnings associated with a language mismatch. US English (<code>en-US</code>) is the only valid language for Amazon Transcribe Medical.</p>
        pub fn vocabulary_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.vocabulary_name = Some(input.into());
            self
        }
        /// <p>The name of the custom vocabulary you want to use when processing your medical transcription job. Vocabulary names are case sensitive.</p>
        /// <p>The language of the specified vocabulary must match the language code you specify in your transcription request. If the languages don't match, the vocabulary isn't applied. There are no errors or warnings associated with a language mismatch. US English (<code>en-US</code>) is the only valid language for Amazon Transcribe Medical.</p>
        pub fn set_vocabulary_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.vocabulary_name = input;
            self
        }
        /// Consumes the builder and constructs a [`MedicalTranscriptionSetting`](crate::model::MedicalTranscriptionSetting)
        pub fn build(self) -> crate::model::MedicalTranscriptionSetting {
            crate::model::MedicalTranscriptionSetting {
                show_speaker_labels: self.show_speaker_labels,
                max_speaker_labels: self.max_speaker_labels,
                channel_identification: self.channel_identification,
                show_alternatives: self.show_alternatives,
                max_alternatives: self.max_alternatives,
                vocabulary_name: self.vocabulary_name,
            }
        }
    }
}
impl MedicalTranscriptionSetting {
    /// Creates a new builder-style object to manufacture [`MedicalTranscriptionSetting`](crate::model::MedicalTranscriptionSetting)
    pub fn builder() -> crate::model::medical_transcription_setting::Builder {
        crate::model::medical_transcription_setting::Builder::default()
    }
}

/// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct MedicalTranscript {
    /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your transcript.</p>
    /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
    /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
    /// </note>
    pub transcript_file_uri: std::option::Option<std::string::String>,
}
impl MedicalTranscript {
    /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your transcript.</p>
    /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
    /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
    /// </note>
    pub fn transcript_file_uri(&self) -> std::option::Option<&str> {
        self.transcript_file_uri.as_deref()
    }
}
impl std::fmt::Debug for MedicalTranscript {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("MedicalTranscript");
        formatter.field("transcript_file_uri", &self.transcript_file_uri);
        formatter.finish()
    }
}
/// See [`MedicalTranscript`](crate::model::MedicalTranscript)
pub mod medical_transcript {

    /// A builder for [`MedicalTranscript`](crate::model::MedicalTranscript)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) transcript_file_uri: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your transcript.</p>
        /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
        /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
        /// </note>
        pub fn transcript_file_uri(mut self, input: impl Into<std::string::String>) -> Self {
            self.transcript_file_uri = Some(input.into());
            self
        }
        /// <p>The Amazon S3 location of your transcript. You can use this URI to access or download your transcript.</p>
        /// <p>If you included <code>OutputBucketName</code> in your transcription job request, this is the URI of that bucket. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If you didn't include <code>OutputBucketName</code> in your transcription job request, your transcript is stored in a service-managed bucket, and <code>TranscriptFileUri</code> provides you with a temporary URI you can use for secure access to your transcript.</p> <note>
        /// <p>Temporary URIs for service-managed Amazon S3 buckets are only valid for 15 minutes. If you get an <code>AccesDenied</code> error, you can get a new temporary URI by running a <code>GetTranscriptionJob</code> or <code>ListTranscriptionJob</code> request.</p>
        /// </note>
        pub fn set_transcript_file_uri(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.transcript_file_uri = input;
            self
        }
        /// Consumes the builder and constructs a [`MedicalTranscript`](crate::model::MedicalTranscript)
        pub fn build(self) -> crate::model::MedicalTranscript {
            crate::model::MedicalTranscript {
                transcript_file_uri: self.transcript_file_uri,
            }
        }
    }
}
impl MedicalTranscript {
    /// Creates a new builder-style object to manufacture [`MedicalTranscript`](crate::model::MedicalTranscript)
    pub fn builder() -> crate::model::medical_transcript::Builder {
        crate::model::medical_transcript::Builder::default()
    }
}

/// <p>Provides detailed information about a Call Analytics job.</p>
/// <p>To view the job's status, refer to <code>CallAnalyticsJobStatus</code>. If the status is <code>COMPLETED</code>, the job is finished. You can find your completed transcript at the URI specified in <code>TranscriptFileUri</code>. If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
/// <p>If you enabled personally identifiable information (PII) redaction, the redacted transcript appears at the location specified in <code>RedactedTranscriptFileUri</code>.</p>
/// <p>If you chose to redact the audio in your media file, you can find your redacted media file at the location specified in the <code>RedactedMediaFileUri</code> field of your response.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct CallAnalyticsJob {
    /// <p>The name of the Call Analytics job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub call_analytics_job_name: std::option::Option<std::string::String>,
    /// <p>Provides the status of the specified Call Analytics job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub call_analytics_job_status: std::option::Option<crate::model::CallAnalyticsJobStatus>,
    /// <p>The language code used to create your Call Analytics job. For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
    /// <p>If you don't know the language spoken in your media file, you can omit this field and let Amazon Transcribe automatically identify the language of your media. To improve the accuracy of language identification, you can include several language codes and Amazon Transcribe chooses the closest match for your transcription.</p>
    pub language_code: std::option::Option<crate::model::LanguageCode>,
    /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
    pub media_sample_rate_hertz: std::option::Option<i32>,
    /// <p>The format of the input media file.</p>
    pub media_format: std::option::Option<crate::model::MediaFormat>,
    /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
    pub media: std::option::Option<crate::model::Media>,
    /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
    pub transcript: std::option::Option<crate::model::Transcript>,
    /// <p>The date and time the specified Call Analytics job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time the specified Call Analytics job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub creation_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time the specified Call Analytics job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub completion_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>If <code>CallAnalyticsJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the Call Analytics job request failed.</p>
    /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
    /// <ul>
    /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
    /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 8,000 and 48,000 Hertz.</p> </li>
    /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// </ul>
    pub failure_reason: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
    /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
    pub data_access_role_arn: std::option::Option<std::string::String>,
    /// <p>The confidence score associated with the language identified in your media file.</p>
    /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
    pub identified_language_score: std::option::Option<f32>,
    /// <p>Allows additional optional settings in your request, including content redaction; allows you to apply custom language models, vocabulary filters, and custom vocabularies to your Call Analytics job.</p>
    pub settings: std::option::Option<crate::model::CallAnalyticsJobSettings>,
    /// <p>Allows you to specify which speaker is on which channel in your Call Analytics job request. For example, if your agent is the first participant to speak, you would set <code>ChannelId</code> to <code>0</code> (to indicate the first channel) and <code>ParticipantRole</code> to <code>AGENT</code> (to indicate that it's the agent speaking).</p>
    pub channel_definitions: std::option::Option<std::vec::Vec<crate::model::ChannelDefinition>>,
}
impl CallAnalyticsJob {
    /// <p>The name of the Call Analytics job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub fn call_analytics_job_name(&self) -> std::option::Option<&str> {
        self.call_analytics_job_name.as_deref()
    }
    /// <p>Provides the status of the specified Call Analytics job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub fn call_analytics_job_status(
        &self,
    ) -> std::option::Option<&crate::model::CallAnalyticsJobStatus> {
        self.call_analytics_job_status.as_ref()
    }
    /// <p>The language code used to create your Call Analytics job. For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
    /// <p>If you don't know the language spoken in your media file, you can omit this field and let Amazon Transcribe automatically identify the language of your media. To improve the accuracy of language identification, you can include several language codes and Amazon Transcribe chooses the closest match for your transcription.</p>
    pub fn language_code(&self) -> std::option::Option<&crate::model::LanguageCode> {
        self.language_code.as_ref()
    }
    /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
    pub fn media_sample_rate_hertz(&self) -> std::option::Option<i32> {
        self.media_sample_rate_hertz
    }
    /// <p>The format of the input media file.</p>
    pub fn media_format(&self) -> std::option::Option<&crate::model::MediaFormat> {
        self.media_format.as_ref()
    }
    /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
    pub fn media(&self) -> std::option::Option<&crate::model::Media> {
        self.media.as_ref()
    }
    /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
    pub fn transcript(&self) -> std::option::Option<&crate::model::Transcript> {
        self.transcript.as_ref()
    }
    /// <p>The date and time the specified Call Analytics job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p>The date and time the specified Call Analytics job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn creation_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.creation_time.as_ref()
    }
    /// <p>The date and time the specified Call Analytics job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub fn completion_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.completion_time.as_ref()
    }
    /// <p>If <code>CallAnalyticsJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the Call Analytics job request failed.</p>
    /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
    /// <ul>
    /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
    /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 8,000 and 48,000 Hertz.</p> </li>
    /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
    /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
    /// </ul>
    pub fn failure_reason(&self) -> std::option::Option<&str> {
        self.failure_reason.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
    /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
    pub fn data_access_role_arn(&self) -> std::option::Option<&str> {
        self.data_access_role_arn.as_deref()
    }
    /// <p>The confidence score associated with the language identified in your media file.</p>
    /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
    pub fn identified_language_score(&self) -> std::option::Option<f32> {
        self.identified_language_score
    }
    /// <p>Allows additional optional settings in your request, including content redaction; allows you to apply custom language models, vocabulary filters, and custom vocabularies to your Call Analytics job.</p>
    pub fn settings(&self) -> std::option::Option<&crate::model::CallAnalyticsJobSettings> {
        self.settings.as_ref()
    }
    /// <p>Allows you to specify which speaker is on which channel in your Call Analytics job request. For example, if your agent is the first participant to speak, you would set <code>ChannelId</code> to <code>0</code> (to indicate the first channel) and <code>ParticipantRole</code> to <code>AGENT</code> (to indicate that it's the agent speaking).</p>
    pub fn channel_definitions(&self) -> std::option::Option<&[crate::model::ChannelDefinition]> {
        self.channel_definitions.as_deref()
    }
}
impl std::fmt::Debug for CallAnalyticsJob {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("CallAnalyticsJob");
        formatter.field("call_analytics_job_name", &self.call_analytics_job_name);
        formatter.field("call_analytics_job_status", &self.call_analytics_job_status);
        formatter.field("language_code", &self.language_code);
        formatter.field("media_sample_rate_hertz", &self.media_sample_rate_hertz);
        formatter.field("media_format", &self.media_format);
        formatter.field("media", &self.media);
        formatter.field("transcript", &self.transcript);
        formatter.field("start_time", &self.start_time);
        formatter.field("creation_time", &self.creation_time);
        formatter.field("completion_time", &self.completion_time);
        formatter.field("failure_reason", &self.failure_reason);
        formatter.field("data_access_role_arn", &self.data_access_role_arn);
        formatter.field("identified_language_score", &self.identified_language_score);
        formatter.field("settings", &self.settings);
        formatter.field("channel_definitions", &self.channel_definitions);
        formatter.finish()
    }
}
/// See [`CallAnalyticsJob`](crate::model::CallAnalyticsJob)
pub mod call_analytics_job {

    /// A builder for [`CallAnalyticsJob`](crate::model::CallAnalyticsJob)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) call_analytics_job_name: std::option::Option<std::string::String>,
        pub(crate) call_analytics_job_status:
            std::option::Option<crate::model::CallAnalyticsJobStatus>,
        pub(crate) language_code: std::option::Option<crate::model::LanguageCode>,
        pub(crate) media_sample_rate_hertz: std::option::Option<i32>,
        pub(crate) media_format: std::option::Option<crate::model::MediaFormat>,
        pub(crate) media: std::option::Option<crate::model::Media>,
        pub(crate) transcript: std::option::Option<crate::model::Transcript>,
        pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) creation_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) completion_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) failure_reason: std::option::Option<std::string::String>,
        pub(crate) data_access_role_arn: std::option::Option<std::string::String>,
        pub(crate) identified_language_score: std::option::Option<f32>,
        pub(crate) settings: std::option::Option<crate::model::CallAnalyticsJobSettings>,
        pub(crate) channel_definitions:
            std::option::Option<std::vec::Vec<crate::model::ChannelDefinition>>,
    }
    impl Builder {
        /// <p>The name of the Call Analytics job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn call_analytics_job_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.call_analytics_job_name = Some(input.into());
            self
        }
        /// <p>The name of the Call Analytics job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn set_call_analytics_job_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.call_analytics_job_name = input;
            self
        }
        /// <p>Provides the status of the specified Call Analytics job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn call_analytics_job_status(
            mut self,
            input: crate::model::CallAnalyticsJobStatus,
        ) -> Self {
            self.call_analytics_job_status = Some(input);
            self
        }
        /// <p>Provides the status of the specified Call Analytics job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn set_call_analytics_job_status(
            mut self,
            input: std::option::Option<crate::model::CallAnalyticsJobStatus>,
        ) -> Self {
            self.call_analytics_job_status = input;
            self
        }
        /// <p>The language code used to create your Call Analytics job. For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
        /// <p>If you don't know the language spoken in your media file, you can omit this field and let Amazon Transcribe automatically identify the language of your media. To improve the accuracy of language identification, you can include several language codes and Amazon Transcribe chooses the closest match for your transcription.</p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.language_code = Some(input);
            self
        }
        /// <p>The language code used to create your Call Analytics job. For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
        /// <p>If you don't know the language spoken in your media file, you can omit this field and let Amazon Transcribe automatically identify the language of your media. To improve the accuracy of language identification, you can include several language codes and Amazon Transcribe chooses the closest match for your transcription.</p>
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.language_code = input;
            self
        }
        /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
        pub fn media_sample_rate_hertz(mut self, input: i32) -> Self {
            self.media_sample_rate_hertz = Some(input);
            self
        }
        /// <p>The sample rate, in Hertz, of the audio track in your input media file.</p>
        pub fn set_media_sample_rate_hertz(mut self, input: std::option::Option<i32>) -> Self {
            self.media_sample_rate_hertz = input;
            self
        }
        /// <p>The format of the input media file.</p>
        pub fn media_format(mut self, input: crate::model::MediaFormat) -> Self {
            self.media_format = Some(input);
            self
        }
        /// <p>The format of the input media file.</p>
        pub fn set_media_format(
            mut self,
            input: std::option::Option<crate::model::MediaFormat>,
        ) -> Self {
            self.media_format = input;
            self
        }
        /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
        pub fn media(mut self, input: crate::model::Media) -> Self {
            self.media = Some(input);
            self
        }
        /// <p>Describes the Amazon S3 location of the media file you want to use in your request.</p>
        pub fn set_media(mut self, input: std::option::Option<crate::model::Media>) -> Self {
            self.media = input;
            self
        }
        /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
        pub fn transcript(mut self, input: crate::model::Transcript) -> Self {
            self.transcript = Some(input);
            self
        }
        /// <p>Provides you with the Amazon S3 URI you can use to access your transcript.</p>
        pub fn set_transcript(
            mut self,
            input: std::option::Option<crate::model::Transcript>,
        ) -> Self {
            self.transcript = input;
            self
        }
        /// <p>The date and time the specified Call Analytics job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p>The date and time the specified Call Analytics job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.start_time = input;
            self
        }
        /// <p>The date and time the specified Call Analytics job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn creation_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.creation_time = Some(input);
            self
        }
        /// <p>The date and time the specified Call Analytics job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_creation_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.creation_time = input;
            self
        }
        /// <p>The date and time the specified Call Analytics job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn completion_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.completion_time = Some(input);
            self
        }
        /// <p>The date and time the specified Call Analytics job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn set_completion_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.completion_time = input;
            self
        }
        /// <p>If <code>CallAnalyticsJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the Call Analytics job request failed.</p>
        /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
        /// <ul>
        /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
        /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 8,000 and 48,000 Hertz.</p> </li>
        /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// </ul>
        pub fn failure_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.failure_reason = Some(input.into());
            self
        }
        /// <p>If <code>CallAnalyticsJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the Call Analytics job request failed.</p>
        /// <p>The <code>FailureReason</code> field contains one of the following values:</p>
        /// <ul>
        /// <li> <p> <code>Unsupported media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> isn't valid. Refer to <b>MediaFormat</b> for a list of supported formats.</p> </li>
        /// <li> <p> <code>The media format provided does not match the detected media format</code>.</p> <p>The media format specified in <code>MediaFormat</code> doesn't match the format of the input file. Check the media format of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid sample rate for audio file</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> isn't valid. The sample rate must be between 8,000 and 48,000 Hertz.</p> </li>
        /// <li> <p> <code>The sample rate provided does not match the detected sample rate</code>.</p> <p>The sample rate specified in <code>MediaSampleRateHertz</code> doesn't match the sample rate detected in your input media file. Check the sample rate of your media file and correct the specified value.</p> </li>
        /// <li> <p> <code>Invalid file size: file size too large</code>.</p> <p>The size of your media file is larger than what Amazon Transcribe can process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// <li> <p> <code>Invalid number of channels: number of channels too large</code>.</p> <p>Your audio contains more channels than Amazon Transcribe is able to process. For more information, refer to <a href="https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits">Guidelines and quotas</a>.</p> </li>
        /// </ul>
        pub fn set_failure_reason(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.failure_reason = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
        /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
        pub fn data_access_role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.data_access_role_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
        /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
        pub fn set_data_access_role_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.data_access_role_arn = input;
            self
        }
        /// <p>The confidence score associated with the language identified in your media file.</p>
        /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
        pub fn identified_language_score(mut self, input: f32) -> Self {
            self.identified_language_score = Some(input);
            self
        }
        /// <p>The confidence score associated with the language identified in your media file.</p>
        /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
        pub fn set_identified_language_score(mut self, input: std::option::Option<f32>) -> Self {
            self.identified_language_score = input;
            self
        }
        /// <p>Allows additional optional settings in your request, including content redaction; allows you to apply custom language models, vocabulary filters, and custom vocabularies to your Call Analytics job.</p>
        pub fn settings(mut self, input: crate::model::CallAnalyticsJobSettings) -> Self {
            self.settings = Some(input);
            self
        }
        /// <p>Allows additional optional settings in your request, including content redaction; allows you to apply custom language models, vocabulary filters, and custom vocabularies to your Call Analytics job.</p>
        pub fn set_settings(
            mut self,
            input: std::option::Option<crate::model::CallAnalyticsJobSettings>,
        ) -> Self {
            self.settings = input;
            self
        }
        /// Appends an item to `channel_definitions`.
        ///
        /// To override the contents of this collection use [`set_channel_definitions`](Self::set_channel_definitions).
        ///
        /// <p>Allows you to specify which speaker is on which channel in your Call Analytics job request. For example, if your agent is the first participant to speak, you would set <code>ChannelId</code> to <code>0</code> (to indicate the first channel) and <code>ParticipantRole</code> to <code>AGENT</code> (to indicate that it's the agent speaking).</p>
        pub fn channel_definitions(mut self, input: crate::model::ChannelDefinition) -> Self {
            let mut v = self.channel_definitions.unwrap_or_default();
            v.push(input);
            self.channel_definitions = Some(v);
            self
        }
        /// <p>Allows you to specify which speaker is on which channel in your Call Analytics job request. For example, if your agent is the first participant to speak, you would set <code>ChannelId</code> to <code>0</code> (to indicate the first channel) and <code>ParticipantRole</code> to <code>AGENT</code> (to indicate that it's the agent speaking).</p>
        pub fn set_channel_definitions(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::ChannelDefinition>>,
        ) -> Self {
            self.channel_definitions = input;
            self
        }
        /// Consumes the builder and constructs a [`CallAnalyticsJob`](crate::model::CallAnalyticsJob)
        pub fn build(self) -> crate::model::CallAnalyticsJob {
            crate::model::CallAnalyticsJob {
                call_analytics_job_name: self.call_analytics_job_name,
                call_analytics_job_status: self.call_analytics_job_status,
                language_code: self.language_code,
                media_sample_rate_hertz: self.media_sample_rate_hertz,
                media_format: self.media_format,
                media: self.media,
                transcript: self.transcript,
                start_time: self.start_time,
                creation_time: self.creation_time,
                completion_time: self.completion_time,
                failure_reason: self.failure_reason,
                data_access_role_arn: self.data_access_role_arn,
                identified_language_score: self.identified_language_score,
                settings: self.settings,
                channel_definitions: self.channel_definitions,
            }
        }
    }
}
impl CallAnalyticsJob {
    /// Creates a new builder-style object to manufacture [`CallAnalyticsJob`](crate::model::CallAnalyticsJob)
    pub fn builder() -> crate::model::call_analytics_job::Builder {
        crate::model::call_analytics_job::Builder::default()
    }
}

/// <p>Allows you to specify which speaker is on which channel. For example, if your agent is the first participant to speak, you would set <code>ChannelId</code> to <code>0</code> (to indicate the first channel) and <code>ParticipantRole</code> to <code>AGENT</code> (to indicate that it's the agent speaking).</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct ChannelDefinition {
    /// <p>Specify the audio channel you want to define.</p>
    pub channel_id: i32,
    /// <p>Specify the speaker you want to define. Omitting this parameter is equivalent to specifying both participants.</p>
    pub participant_role: std::option::Option<crate::model::ParticipantRole>,
}
impl ChannelDefinition {
    /// <p>Specify the audio channel you want to define.</p>
    pub fn channel_id(&self) -> i32 {
        self.channel_id
    }
    /// <p>Specify the speaker you want to define. Omitting this parameter is equivalent to specifying both participants.</p>
    pub fn participant_role(&self) -> std::option::Option<&crate::model::ParticipantRole> {
        self.participant_role.as_ref()
    }
}
impl std::fmt::Debug for ChannelDefinition {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("ChannelDefinition");
        formatter.field("channel_id", &self.channel_id);
        formatter.field("participant_role", &self.participant_role);
        formatter.finish()
    }
}
/// See [`ChannelDefinition`](crate::model::ChannelDefinition)
pub mod channel_definition {

    /// A builder for [`ChannelDefinition`](crate::model::ChannelDefinition)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) channel_id: std::option::Option<i32>,
        pub(crate) participant_role: std::option::Option<crate::model::ParticipantRole>,
    }
    impl Builder {
        /// <p>Specify the audio channel you want to define.</p>
        pub fn channel_id(mut self, input: i32) -> Self {
            self.channel_id = Some(input);
            self
        }
        /// <p>Specify the audio channel you want to define.</p>
        pub fn set_channel_id(mut self, input: std::option::Option<i32>) -> Self {
            self.channel_id = input;
            self
        }
        /// <p>Specify the speaker you want to define. Omitting this parameter is equivalent to specifying both participants.</p>
        pub fn participant_role(mut self, input: crate::model::ParticipantRole) -> Self {
            self.participant_role = Some(input);
            self
        }
        /// <p>Specify the speaker you want to define. Omitting this parameter is equivalent to specifying both participants.</p>
        pub fn set_participant_role(
            mut self,
            input: std::option::Option<crate::model::ParticipantRole>,
        ) -> Self {
            self.participant_role = input;
            self
        }
        /// Consumes the builder and constructs a [`ChannelDefinition`](crate::model::ChannelDefinition)
        pub fn build(self) -> crate::model::ChannelDefinition {
            crate::model::ChannelDefinition {
                channel_id: self.channel_id.unwrap_or_default(),
                participant_role: self.participant_role,
            }
        }
    }
}
impl ChannelDefinition {
    /// Creates a new builder-style object to manufacture [`ChannelDefinition`](crate::model::ChannelDefinition)
    pub fn builder() -> crate::model::channel_definition::Builder {
        crate::model::channel_definition::Builder::default()
    }
}

/// <p>Provides additional optional settings for your request, including content redaction, automatic language identification; allows you to apply custom language models, vocabulary filters, and custom vocabularies.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct CallAnalyticsJobSettings {
    /// <p>The name of the custom vocabulary you want to include in your Call Analytics transcription request. Vocabulary names are case sensitive.</p>
    pub vocabulary_name: std::option::Option<std::string::String>,
    /// <p>The name of the custom vocabulary filter you want to include in your Call Analytics transcription request. Vocabulary filter names are case sensitive.</p>
    /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
    pub vocabulary_filter_name: std::option::Option<std::string::String>,
    /// <p>Specify how you want your vocabulary filter applied to your transcript.</p>
    /// <p>To replace words with <code>***</code>, choose <code>mask</code>.</p>
    /// <p>To delete words, choose <code>remove</code>.</p>
    /// <p>To flag words without changing them, choose <code>tag</code>.</p>
    pub vocabulary_filter_method: std::option::Option<crate::model::VocabularyFilterMethod>,
    /// <p>The name of the custom language model you want to use when processing your Call Analytics job. Note that language model names are case sensitive.</p>
    /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    pub language_model_name: std::option::Option<std::string::String>,
    /// <p>Allows you to redact or flag specified personally identifiable information (PII) in your transcript. If you use <code>ContentRedaction</code>, you must also include the sub-parameters: <code>PiiEntityTypes</code>, <code>RedactionOutput</code>, and <code>RedactionType</code>.</p>
    pub content_redaction: std::option::Option<crate::model::ContentRedaction>,
    /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. If you're unsure what languages are present, do not include this parameter.</p>
    /// <p>Including language options can improve the accuracy of language identification.</p>
    /// <p>For a list of languages supported with Call Analytics, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
    pub language_options: std::option::Option<std::vec::Vec<crate::model::LanguageCode>>,
    /// <p>If using automatic language identification (<code>IdentifyLanguage</code>) in your request and you want to apply a custom language model, a custom vocabulary, or a custom vocabulary filter, include <code>LanguageIdSettings</code> with the relevant sub-parameters (<code>VocabularyName</code>, <code>LanguageModelName</code>, and <code>VocabularyFilterName</code>).</p>
    /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. Each language code you include can have an associated custom language model, custom vocabulary, and custom vocabulary filter. The languages you specify must match the languages of the specified custom language models, custom vocabularies, and custom vocabulary filters.</p>
    /// <p>To include language options using <code>IdentifyLanguage</code> <b>without</b> including a custom language model, a custom vocabulary, or a custom vocabulary filter, use <code>LanguageOptions</code> instead of <code>LanguageIdSettings</code>. Including language options can improve the accuracy of automatic language identification.</p>
    /// <p>If you want to include a custom language model with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>LanguageModelName</code> sub-parameter.</p>
    /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
    pub language_id_settings: std::option::Option<
        std::collections::HashMap<crate::model::LanguageCode, crate::model::LanguageIdSettings>,
    >,
}
impl CallAnalyticsJobSettings {
    /// <p>The name of the custom vocabulary you want to include in your Call Analytics transcription request. Vocabulary names are case sensitive.</p>
    pub fn vocabulary_name(&self) -> std::option::Option<&str> {
        self.vocabulary_name.as_deref()
    }
    /// <p>The name of the custom vocabulary filter you want to include in your Call Analytics transcription request. Vocabulary filter names are case sensitive.</p>
    /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
    pub fn vocabulary_filter_name(&self) -> std::option::Option<&str> {
        self.vocabulary_filter_name.as_deref()
    }
    /// <p>Specify how you want your vocabulary filter applied to your transcript.</p>
    /// <p>To replace words with <code>***</code>, choose <code>mask</code>.</p>
    /// <p>To delete words, choose <code>remove</code>.</p>
    /// <p>To flag words without changing them, choose <code>tag</code>.</p>
    pub fn vocabulary_filter_method(
        &self,
    ) -> std::option::Option<&crate::model::VocabularyFilterMethod> {
        self.vocabulary_filter_method.as_ref()
    }
    /// <p>The name of the custom language model you want to use when processing your Call Analytics job. Note that language model names are case sensitive.</p>
    /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    pub fn language_model_name(&self) -> std::option::Option<&str> {
        self.language_model_name.as_deref()
    }
    /// <p>Allows you to redact or flag specified personally identifiable information (PII) in your transcript. If you use <code>ContentRedaction</code>, you must also include the sub-parameters: <code>PiiEntityTypes</code>, <code>RedactionOutput</code>, and <code>RedactionType</code>.</p>
    pub fn content_redaction(&self) -> std::option::Option<&crate::model::ContentRedaction> {
        self.content_redaction.as_ref()
    }
    /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. If you're unsure what languages are present, do not include this parameter.</p>
    /// <p>Including language options can improve the accuracy of language identification.</p>
    /// <p>For a list of languages supported with Call Analytics, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
    pub fn language_options(&self) -> std::option::Option<&[crate::model::LanguageCode]> {
        self.language_options.as_deref()
    }
    /// <p>If using automatic language identification (<code>IdentifyLanguage</code>) in your request and you want to apply a custom language model, a custom vocabulary, or a custom vocabulary filter, include <code>LanguageIdSettings</code> with the relevant sub-parameters (<code>VocabularyName</code>, <code>LanguageModelName</code>, and <code>VocabularyFilterName</code>).</p>
    /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. Each language code you include can have an associated custom language model, custom vocabulary, and custom vocabulary filter. The languages you specify must match the languages of the specified custom language models, custom vocabularies, and custom vocabulary filters.</p>
    /// <p>To include language options using <code>IdentifyLanguage</code> <b>without</b> including a custom language model, a custom vocabulary, or a custom vocabulary filter, use <code>LanguageOptions</code> instead of <code>LanguageIdSettings</code>. Including language options can improve the accuracy of automatic language identification.</p>
    /// <p>If you want to include a custom language model with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>LanguageModelName</code> sub-parameter.</p>
    /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
    pub fn language_id_settings(
        &self,
    ) -> std::option::Option<
        &std::collections::HashMap<crate::model::LanguageCode, crate::model::LanguageIdSettings>,
    > {
        self.language_id_settings.as_ref()
    }
}
impl std::fmt::Debug for CallAnalyticsJobSettings {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("CallAnalyticsJobSettings");
        formatter.field("vocabulary_name", &self.vocabulary_name);
        formatter.field("vocabulary_filter_name", &self.vocabulary_filter_name);
        formatter.field("vocabulary_filter_method", &self.vocabulary_filter_method);
        formatter.field("language_model_name", &self.language_model_name);
        formatter.field("content_redaction", &self.content_redaction);
        formatter.field("language_options", &self.language_options);
        formatter.field("language_id_settings", &self.language_id_settings);
        formatter.finish()
    }
}
/// See [`CallAnalyticsJobSettings`](crate::model::CallAnalyticsJobSettings)
pub mod call_analytics_job_settings {

    /// A builder for [`CallAnalyticsJobSettings`](crate::model::CallAnalyticsJobSettings)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) vocabulary_name: std::option::Option<std::string::String>,
        pub(crate) vocabulary_filter_name: std::option::Option<std::string::String>,
        pub(crate) vocabulary_filter_method:
            std::option::Option<crate::model::VocabularyFilterMethod>,
        pub(crate) language_model_name: std::option::Option<std::string::String>,
        pub(crate) content_redaction: std::option::Option<crate::model::ContentRedaction>,
        pub(crate) language_options: std::option::Option<std::vec::Vec<crate::model::LanguageCode>>,
        pub(crate) language_id_settings: std::option::Option<
            std::collections::HashMap<crate::model::LanguageCode, crate::model::LanguageIdSettings>,
        >,
    }
    impl Builder {
        /// <p>The name of the custom vocabulary you want to include in your Call Analytics transcription request. Vocabulary names are case sensitive.</p>
        pub fn vocabulary_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.vocabulary_name = Some(input.into());
            self
        }
        /// <p>The name of the custom vocabulary you want to include in your Call Analytics transcription request. Vocabulary names are case sensitive.</p>
        pub fn set_vocabulary_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.vocabulary_name = input;
            self
        }
        /// <p>The name of the custom vocabulary filter you want to include in your Call Analytics transcription request. Vocabulary filter names are case sensitive.</p>
        /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
        pub fn vocabulary_filter_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.vocabulary_filter_name = Some(input.into());
            self
        }
        /// <p>The name of the custom vocabulary filter you want to include in your Call Analytics transcription request. Vocabulary filter names are case sensitive.</p>
        /// <p>Note that if you include <code>VocabularyFilterName</code> in your request, you must also include <code>VocabularyFilterMethod</code>.</p>
        pub fn set_vocabulary_filter_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.vocabulary_filter_name = input;
            self
        }
        /// <p>Specify how you want your vocabulary filter applied to your transcript.</p>
        /// <p>To replace words with <code>***</code>, choose <code>mask</code>.</p>
        /// <p>To delete words, choose <code>remove</code>.</p>
        /// <p>To flag words without changing them, choose <code>tag</code>.</p>
        pub fn vocabulary_filter_method(
            mut self,
            input: crate::model::VocabularyFilterMethod,
        ) -> Self {
            self.vocabulary_filter_method = Some(input);
            self
        }
        /// <p>Specify how you want your vocabulary filter applied to your transcript.</p>
        /// <p>To replace words with <code>***</code>, choose <code>mask</code>.</p>
        /// <p>To delete words, choose <code>remove</code>.</p>
        /// <p>To flag words without changing them, choose <code>tag</code>.</p>
        pub fn set_vocabulary_filter_method(
            mut self,
            input: std::option::Option<crate::model::VocabularyFilterMethod>,
        ) -> Self {
            self.vocabulary_filter_method = input;
            self
        }
        /// <p>The name of the custom language model you want to use when processing your Call Analytics job. Note that language model names are case sensitive.</p>
        /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
        pub fn language_model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.language_model_name = Some(input.into());
            self
        }
        /// <p>The name of the custom language model you want to use when processing your Call Analytics job. Note that language model names are case sensitive.</p>
        /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
        pub fn set_language_model_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.language_model_name = input;
            self
        }
        /// <p>Allows you to redact or flag specified personally identifiable information (PII) in your transcript. If you use <code>ContentRedaction</code>, you must also include the sub-parameters: <code>PiiEntityTypes</code>, <code>RedactionOutput</code>, and <code>RedactionType</code>.</p>
        pub fn content_redaction(mut self, input: crate::model::ContentRedaction) -> Self {
            self.content_redaction = Some(input);
            self
        }
        /// <p>Allows you to redact or flag specified personally identifiable information (PII) in your transcript. If you use <code>ContentRedaction</code>, you must also include the sub-parameters: <code>PiiEntityTypes</code>, <code>RedactionOutput</code>, and <code>RedactionType</code>.</p>
        pub fn set_content_redaction(
            mut self,
            input: std::option::Option<crate::model::ContentRedaction>,
        ) -> Self {
            self.content_redaction = input;
            self
        }
        /// Appends an item to `language_options`.
        ///
        /// To override the contents of this collection use [`set_language_options`](Self::set_language_options).
        ///
        /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. If you're unsure what languages are present, do not include this parameter.</p>
        /// <p>Including language options can improve the accuracy of language identification.</p>
        /// <p>For a list of languages supported with Call Analytics, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
        pub fn language_options(mut self, input: crate::model::LanguageCode) -> Self {
            let mut v = self.language_options.unwrap_or_default();
            v.push(input);
            self.language_options = Some(v);
            self
        }
        /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. If you're unsure what languages are present, do not include this parameter.</p>
        /// <p>Including language options can improve the accuracy of language identification.</p>
        /// <p>For a list of languages supported with Call Analytics, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
        pub fn set_language_options(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::LanguageCode>>,
        ) -> Self {
            self.language_options = input;
            self
        }
        /// Adds a key-value pair to `language_id_settings`.
        ///
        /// To override the contents of this collection use [`set_language_id_settings`](Self::set_language_id_settings).
        ///
        /// <p>If using automatic language identification (<code>IdentifyLanguage</code>) in your request and you want to apply a custom language model, a custom vocabulary, or a custom vocabulary filter, include <code>LanguageIdSettings</code> with the relevant sub-parameters (<code>VocabularyName</code>, <code>LanguageModelName</code>, and <code>VocabularyFilterName</code>).</p>
        /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. Each language code you include can have an associated custom language model, custom vocabulary, and custom vocabulary filter. The languages you specify must match the languages of the specified custom language models, custom vocabularies, and custom vocabulary filters.</p>
        /// <p>To include language options using <code>IdentifyLanguage</code> <b>without</b> including a custom language model, a custom vocabulary, or a custom vocabulary filter, use <code>LanguageOptions</code> instead of <code>LanguageIdSettings</code>. Including language options can improve the accuracy of automatic language identification.</p>
        /// <p>If you want to include a custom language model with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>LanguageModelName</code> sub-parameter.</p>
        /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
        pub fn language_id_settings(
            mut self,
            k: crate::model::LanguageCode,
            v: crate::model::LanguageIdSettings,
        ) -> Self {
            let mut hash_map = self.language_id_settings.unwrap_or_default();
            hash_map.insert(k, v);
            self.language_id_settings = Some(hash_map);
            self
        }
        /// <p>If using automatic language identification (<code>IdentifyLanguage</code>) in your request and you want to apply a custom language model, a custom vocabulary, or a custom vocabulary filter, include <code>LanguageIdSettings</code> with the relevant sub-parameters (<code>VocabularyName</code>, <code>LanguageModelName</code>, and <code>VocabularyFilterName</code>).</p>
        /// <p>You can specify two or more language codes that represent the languages you think may be present in your media; including more than five is not recommended. Each language code you include can have an associated custom language model, custom vocabulary, and custom vocabulary filter. The languages you specify must match the languages of the specified custom language models, custom vocabularies, and custom vocabulary filters.</p>
        /// <p>To include language options using <code>IdentifyLanguage</code> <b>without</b> including a custom language model, a custom vocabulary, or a custom vocabulary filter, use <code>LanguageOptions</code> instead of <code>LanguageIdSettings</code>. Including language options can improve the accuracy of automatic language identification.</p>
        /// <p>If you want to include a custom language model with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>LanguageModelName</code> sub-parameter.</p>
        /// <p>If you want to include a custom vocabulary or a custom vocabulary filter (or both) with your request but <b>do not</b> want to use automatic language identification, use instead the <code></code> parameter with the <code>VocabularyName</code> or <code>VocabularyFilterName</code> (or both) sub-parameter.</p>
        pub fn set_language_id_settings(
            mut self,
            input: std::option::Option<
                std::collections::HashMap<
                    crate::model::LanguageCode,
                    crate::model::LanguageIdSettings,
                >,
            >,
        ) -> Self {
            self.language_id_settings = input;
            self
        }
        /// Consumes the builder and constructs a [`CallAnalyticsJobSettings`](crate::model::CallAnalyticsJobSettings)
        pub fn build(self) -> crate::model::CallAnalyticsJobSettings {
            crate::model::CallAnalyticsJobSettings {
                vocabulary_name: self.vocabulary_name,
                vocabulary_filter_name: self.vocabulary_filter_name,
                vocabulary_filter_method: self.vocabulary_filter_method,
                language_model_name: self.language_model_name,
                content_redaction: self.content_redaction,
                language_options: self.language_options,
                language_id_settings: self.language_id_settings,
            }
        }
    }
}
impl CallAnalyticsJobSettings {
    /// Creates a new builder-style object to manufacture [`CallAnalyticsJobSettings`](crate::model::CallAnalyticsJobSettings)
    pub fn builder() -> crate::model::call_analytics_job_settings::Builder {
        crate::model::call_analytics_job_settings::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum CallAnalyticsJobStatus {
    #[allow(missing_docs)] // documentation missing in model
    Completed,
    #[allow(missing_docs)] // documentation missing in model
    Failed,
    #[allow(missing_docs)] // documentation missing in model
    InProgress,
    #[allow(missing_docs)] // documentation missing in model
    Queued,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for CallAnalyticsJobStatus {
    fn from(s: &str) -> Self {
        match s {
            "COMPLETED" => CallAnalyticsJobStatus::Completed,
            "FAILED" => CallAnalyticsJobStatus::Failed,
            "IN_PROGRESS" => CallAnalyticsJobStatus::InProgress,
            "QUEUED" => CallAnalyticsJobStatus::Queued,
            other => CallAnalyticsJobStatus::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for CallAnalyticsJobStatus {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(CallAnalyticsJobStatus::from(s))
    }
}
impl CallAnalyticsJobStatus {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            CallAnalyticsJobStatus::Completed => "COMPLETED",
            CallAnalyticsJobStatus::Failed => "FAILED",
            CallAnalyticsJobStatus::InProgress => "IN_PROGRESS",
            CallAnalyticsJobStatus::Queued => "QUEUED",
            CallAnalyticsJobStatus::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["COMPLETED", "FAILED", "IN_PROGRESS", "QUEUED"]
    }
}
impl AsRef<str> for CallAnalyticsJobStatus {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Provides information about a vocabulary filter, including the language of the filter, when it was last modified, and its name.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct VocabularyFilterInfo {
    /// <p>A unique name, chosen by you, for your custom vocabulary filter. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
    pub vocabulary_filter_name: std::option::Option<std::string::String>,
    /// <p>The language code that represents the language of the entries in your vocabulary filter. Each vocabulary filter must contain terms in only one language.</p>
    /// <p>A vocabulary filter can only be used to transcribe files in the same language as the filter. For example, if you create a vocabulary filter using US English (<code>en-US</code>), you can only apply this filter to files that contain English audio.</p>
    /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
    pub language_code: std::option::Option<crate::model::LanguageCode>,
    /// <p>The date and time the specified vocabulary filter was last modified.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
    pub last_modified_time: std::option::Option<aws_smithy_types::DateTime>,
}
impl VocabularyFilterInfo {
    /// <p>A unique name, chosen by you, for your custom vocabulary filter. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
    pub fn vocabulary_filter_name(&self) -> std::option::Option<&str> {
        self.vocabulary_filter_name.as_deref()
    }
    /// <p>The language code that represents the language of the entries in your vocabulary filter. Each vocabulary filter must contain terms in only one language.</p>
    /// <p>A vocabulary filter can only be used to transcribe files in the same language as the filter. For example, if you create a vocabulary filter using US English (<code>en-US</code>), you can only apply this filter to files that contain English audio.</p>
    /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
    pub fn language_code(&self) -> std::option::Option<&crate::model::LanguageCode> {
        self.language_code.as_ref()
    }
    /// <p>The date and time the specified vocabulary filter was last modified.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn last_modified_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.last_modified_time.as_ref()
    }
}
impl std::fmt::Debug for VocabularyFilterInfo {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("VocabularyFilterInfo");
        formatter.field("vocabulary_filter_name", &self.vocabulary_filter_name);
        formatter.field("language_code", &self.language_code);
        formatter.field("last_modified_time", &self.last_modified_time);
        formatter.finish()
    }
}
/// See [`VocabularyFilterInfo`](crate::model::VocabularyFilterInfo)
pub mod vocabulary_filter_info {

    /// A builder for [`VocabularyFilterInfo`](crate::model::VocabularyFilterInfo)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) vocabulary_filter_name: std::option::Option<std::string::String>,
        pub(crate) language_code: std::option::Option<crate::model::LanguageCode>,
        pub(crate) last_modified_time: std::option::Option<aws_smithy_types::DateTime>,
    }
    impl Builder {
        /// <p>A unique name, chosen by you, for your custom vocabulary filter. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
        pub fn vocabulary_filter_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.vocabulary_filter_name = Some(input.into());
            self
        }
        /// <p>A unique name, chosen by you, for your custom vocabulary filter. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
        pub fn set_vocabulary_filter_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.vocabulary_filter_name = input;
            self
        }
        /// <p>The language code that represents the language of the entries in your vocabulary filter. Each vocabulary filter must contain terms in only one language.</p>
        /// <p>A vocabulary filter can only be used to transcribe files in the same language as the filter. For example, if you create a vocabulary filter using US English (<code>en-US</code>), you can only apply this filter to files that contain English audio.</p>
        /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.language_code = Some(input);
            self
        }
        /// <p>The language code that represents the language of the entries in your vocabulary filter. Each vocabulary filter must contain terms in only one language.</p>
        /// <p>A vocabulary filter can only be used to transcribe files in the same language as the filter. For example, if you create a vocabulary filter using US English (<code>en-US</code>), you can only apply this filter to files that contain English audio.</p>
        /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table.</p>
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.language_code = input;
            self
        }
        /// <p>The date and time the specified vocabulary filter was last modified.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn last_modified_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.last_modified_time = Some(input);
            self
        }
        /// <p>The date and time the specified vocabulary filter was last modified.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_last_modified_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.last_modified_time = input;
            self
        }
        /// Consumes the builder and constructs a [`VocabularyFilterInfo`](crate::model::VocabularyFilterInfo)
        pub fn build(self) -> crate::model::VocabularyFilterInfo {
            crate::model::VocabularyFilterInfo {
                vocabulary_filter_name: self.vocabulary_filter_name,
                language_code: self.language_code,
                last_modified_time: self.last_modified_time,
            }
        }
    }
}
impl VocabularyFilterInfo {
    /// Creates a new builder-style object to manufacture [`VocabularyFilterInfo`](crate::model::VocabularyFilterInfo)
    pub fn builder() -> crate::model::vocabulary_filter_info::Builder {
        crate::model::vocabulary_filter_info::Builder::default()
    }
}

/// <p>Provides information about a custom vocabulary, including the language of the vocabulary, when it was last modified, its name, and the processing state.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct VocabularyInfo {
    /// <p>A unique name, chosen by you, for your custom vocabulary. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
    pub vocabulary_name: std::option::Option<std::string::String>,
    /// <p>The language code used to create your custom vocabulary. Each vocabulary must contain terms in only one language.</p>
    /// <p>A custom vocabulary can only be used to transcribe files in the same language as the vocabulary. For example, if you create a vocabulary using US English (<code>en-US</code>), you can only apply this vocabulary to files that contain English audio.</p>
    pub language_code: std::option::Option<crate::model::LanguageCode>,
    /// <p>The date and time the specified vocabulary was last modified.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
    pub last_modified_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The processing state of your custom vocabulary. If the state is <code>READY</code>, you can use the vocabulary in a <code>StartTranscriptionJob</code> request.</p>
    pub vocabulary_state: std::option::Option<crate::model::VocabularyState>,
}
impl VocabularyInfo {
    /// <p>A unique name, chosen by you, for your custom vocabulary. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
    pub fn vocabulary_name(&self) -> std::option::Option<&str> {
        self.vocabulary_name.as_deref()
    }
    /// <p>The language code used to create your custom vocabulary. Each vocabulary must contain terms in only one language.</p>
    /// <p>A custom vocabulary can only be used to transcribe files in the same language as the vocabulary. For example, if you create a vocabulary using US English (<code>en-US</code>), you can only apply this vocabulary to files that contain English audio.</p>
    pub fn language_code(&self) -> std::option::Option<&crate::model::LanguageCode> {
        self.language_code.as_ref()
    }
    /// <p>The date and time the specified vocabulary was last modified.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn last_modified_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.last_modified_time.as_ref()
    }
    /// <p>The processing state of your custom vocabulary. If the state is <code>READY</code>, you can use the vocabulary in a <code>StartTranscriptionJob</code> request.</p>
    pub fn vocabulary_state(&self) -> std::option::Option<&crate::model::VocabularyState> {
        self.vocabulary_state.as_ref()
    }
}
impl std::fmt::Debug for VocabularyInfo {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("VocabularyInfo");
        formatter.field("vocabulary_name", &self.vocabulary_name);
        formatter.field("language_code", &self.language_code);
        formatter.field("last_modified_time", &self.last_modified_time);
        formatter.field("vocabulary_state", &self.vocabulary_state);
        formatter.finish()
    }
}
/// See [`VocabularyInfo`](crate::model::VocabularyInfo)
pub mod vocabulary_info {

    /// A builder for [`VocabularyInfo`](crate::model::VocabularyInfo)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) vocabulary_name: std::option::Option<std::string::String>,
        pub(crate) language_code: std::option::Option<crate::model::LanguageCode>,
        pub(crate) last_modified_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) vocabulary_state: std::option::Option<crate::model::VocabularyState>,
    }
    impl Builder {
        /// <p>A unique name, chosen by you, for your custom vocabulary. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
        pub fn vocabulary_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.vocabulary_name = Some(input.into());
            self
        }
        /// <p>A unique name, chosen by you, for your custom vocabulary. This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
        pub fn set_vocabulary_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.vocabulary_name = input;
            self
        }
        /// <p>The language code used to create your custom vocabulary. Each vocabulary must contain terms in only one language.</p>
        /// <p>A custom vocabulary can only be used to transcribe files in the same language as the vocabulary. For example, if you create a vocabulary using US English (<code>en-US</code>), you can only apply this vocabulary to files that contain English audio.</p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.language_code = Some(input);
            self
        }
        /// <p>The language code used to create your custom vocabulary. Each vocabulary must contain terms in only one language.</p>
        /// <p>A custom vocabulary can only be used to transcribe files in the same language as the vocabulary. For example, if you create a vocabulary using US English (<code>en-US</code>), you can only apply this vocabulary to files that contain English audio.</p>
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.language_code = input;
            self
        }
        /// <p>The date and time the specified vocabulary was last modified.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn last_modified_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.last_modified_time = Some(input);
            self
        }
        /// <p>The date and time the specified vocabulary was last modified.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_last_modified_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.last_modified_time = input;
            self
        }
        /// <p>The processing state of your custom vocabulary. If the state is <code>READY</code>, you can use the vocabulary in a <code>StartTranscriptionJob</code> request.</p>
        pub fn vocabulary_state(mut self, input: crate::model::VocabularyState) -> Self {
            self.vocabulary_state = Some(input);
            self
        }
        /// <p>The processing state of your custom vocabulary. If the state is <code>READY</code>, you can use the vocabulary in a <code>StartTranscriptionJob</code> request.</p>
        pub fn set_vocabulary_state(
            mut self,
            input: std::option::Option<crate::model::VocabularyState>,
        ) -> Self {
            self.vocabulary_state = input;
            self
        }
        /// Consumes the builder and constructs a [`VocabularyInfo`](crate::model::VocabularyInfo)
        pub fn build(self) -> crate::model::VocabularyInfo {
            crate::model::VocabularyInfo {
                vocabulary_name: self.vocabulary_name,
                language_code: self.language_code,
                last_modified_time: self.last_modified_time,
                vocabulary_state: self.vocabulary_state,
            }
        }
    }
}
impl VocabularyInfo {
    /// Creates a new builder-style object to manufacture [`VocabularyInfo`](crate::model::VocabularyInfo)
    pub fn builder() -> crate::model::vocabulary_info::Builder {
        crate::model::vocabulary_info::Builder::default()
    }
}

/// <p>Provides detailed information about a specific transcription job.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct TranscriptionJobSummary {
    /// <p>The name of the transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub transcription_job_name: std::option::Option<std::string::String>,
    /// <p>The date and time the specified transcription job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub creation_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time your transcription job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time the specified transcription job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub completion_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The language code used to create your transcription.</p>
    pub language_code: std::option::Option<crate::model::LanguageCode>,
    /// <p>Provides the status of your transcription job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub transcription_job_status: std::option::Option<crate::model::TranscriptionJobStatus>,
    /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
    pub failure_reason: std::option::Option<std::string::String>,
    /// <p>Indicates where the specified transcription output is stored.</p>
    /// <p>If the value is <code>CUSTOMER_BUCKET</code>, the location is the Amazon S3 bucket you specified using the <code>OutputBucketName</code> parameter in your request. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If the value is <code>SERVICE_BUCKET</code>, the location is a service-managed Amazon S3 bucket. To access a transcript stored in a service-managed bucket, use the URI shown in the <code>TranscriptFileUri</code> or <code>RedactedTranscriptFileUri</code> field.</p>
    pub output_location_type: std::option::Option<crate::model::OutputLocationType>,
    /// <p>The content redaction settings of the transcription job.</p>
    pub content_redaction: std::option::Option<crate::model::ContentRedaction>,
    /// <p>Provides the name of the custom language model that was included in the specified transcription job.</p>
    /// <p>Only use <code>ModelSettings</code> with the <code>LanguageModelName</code> sub-parameter if you're <b>not</b> using automatic language identification (<code></code>). If using <code>LanguageIdSettings</code> in your request, this parameter contains a <code>LanguageModelName</code> sub-parameter.</p>
    pub model_settings: std::option::Option<crate::model::ModelSettings>,
    /// <p>Indicates whether automatic language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
    pub identify_language: std::option::Option<bool>,
    /// <p>Indicates whether automatic multi-language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
    pub identify_multiple_languages: std::option::Option<bool>,
    /// <p>The confidence score associated with the language identified in your media file.</p>
    /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
    pub identified_language_score: std::option::Option<f32>,
    /// <p>The language codes used to create your transcription job. This parameter is used with multi-language identification. For single-language identification, the singular version of this parameter, <code>LanguageCode</code>, is present.</p>
    pub language_codes: std::option::Option<std::vec::Vec<crate::model::LanguageCodeItem>>,
}
impl TranscriptionJobSummary {
    /// <p>The name of the transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub fn transcription_job_name(&self) -> std::option::Option<&str> {
        self.transcription_job_name.as_deref()
    }
    /// <p>The date and time the specified transcription job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn creation_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.creation_time.as_ref()
    }
    /// <p>The date and time your transcription job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p>The date and time the specified transcription job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub fn completion_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.completion_time.as_ref()
    }
    /// <p>The language code used to create your transcription.</p>
    pub fn language_code(&self) -> std::option::Option<&crate::model::LanguageCode> {
        self.language_code.as_ref()
    }
    /// <p>Provides the status of your transcription job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub fn transcription_job_status(
        &self,
    ) -> std::option::Option<&crate::model::TranscriptionJobStatus> {
        self.transcription_job_status.as_ref()
    }
    /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
    pub fn failure_reason(&self) -> std::option::Option<&str> {
        self.failure_reason.as_deref()
    }
    /// <p>Indicates where the specified transcription output is stored.</p>
    /// <p>If the value is <code>CUSTOMER_BUCKET</code>, the location is the Amazon S3 bucket you specified using the <code>OutputBucketName</code> parameter in your request. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If the value is <code>SERVICE_BUCKET</code>, the location is a service-managed Amazon S3 bucket. To access a transcript stored in a service-managed bucket, use the URI shown in the <code>TranscriptFileUri</code> or <code>RedactedTranscriptFileUri</code> field.</p>
    pub fn output_location_type(&self) -> std::option::Option<&crate::model::OutputLocationType> {
        self.output_location_type.as_ref()
    }
    /// <p>The content redaction settings of the transcription job.</p>
    pub fn content_redaction(&self) -> std::option::Option<&crate::model::ContentRedaction> {
        self.content_redaction.as_ref()
    }
    /// <p>Provides the name of the custom language model that was included in the specified transcription job.</p>
    /// <p>Only use <code>ModelSettings</code> with the <code>LanguageModelName</code> sub-parameter if you're <b>not</b> using automatic language identification (<code></code>). If using <code>LanguageIdSettings</code> in your request, this parameter contains a <code>LanguageModelName</code> sub-parameter.</p>
    pub fn model_settings(&self) -> std::option::Option<&crate::model::ModelSettings> {
        self.model_settings.as_ref()
    }
    /// <p>Indicates whether automatic language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
    pub fn identify_language(&self) -> std::option::Option<bool> {
        self.identify_language
    }
    /// <p>Indicates whether automatic multi-language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
    pub fn identify_multiple_languages(&self) -> std::option::Option<bool> {
        self.identify_multiple_languages
    }
    /// <p>The confidence score associated with the language identified in your media file.</p>
    /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
    pub fn identified_language_score(&self) -> std::option::Option<f32> {
        self.identified_language_score
    }
    /// <p>The language codes used to create your transcription job. This parameter is used with multi-language identification. For single-language identification, the singular version of this parameter, <code>LanguageCode</code>, is present.</p>
    pub fn language_codes(&self) -> std::option::Option<&[crate::model::LanguageCodeItem]> {
        self.language_codes.as_deref()
    }
}
impl std::fmt::Debug for TranscriptionJobSummary {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("TranscriptionJobSummary");
        formatter.field("transcription_job_name", &self.transcription_job_name);
        formatter.field("creation_time", &self.creation_time);
        formatter.field("start_time", &self.start_time);
        formatter.field("completion_time", &self.completion_time);
        formatter.field("language_code", &self.language_code);
        formatter.field("transcription_job_status", &self.transcription_job_status);
        formatter.field("failure_reason", &self.failure_reason);
        formatter.field("output_location_type", &self.output_location_type);
        formatter.field("content_redaction", &self.content_redaction);
        formatter.field("model_settings", &self.model_settings);
        formatter.field("identify_language", &self.identify_language);
        formatter.field(
            "identify_multiple_languages",
            &self.identify_multiple_languages,
        );
        formatter.field("identified_language_score", &self.identified_language_score);
        formatter.field("language_codes", &self.language_codes);
        formatter.finish()
    }
}
/// See [`TranscriptionJobSummary`](crate::model::TranscriptionJobSummary)
pub mod transcription_job_summary {

    /// A builder for [`TranscriptionJobSummary`](crate::model::TranscriptionJobSummary)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) transcription_job_name: std::option::Option<std::string::String>,
        pub(crate) creation_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) completion_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) language_code: std::option::Option<crate::model::LanguageCode>,
        pub(crate) transcription_job_status:
            std::option::Option<crate::model::TranscriptionJobStatus>,
        pub(crate) failure_reason: std::option::Option<std::string::String>,
        pub(crate) output_location_type: std::option::Option<crate::model::OutputLocationType>,
        pub(crate) content_redaction: std::option::Option<crate::model::ContentRedaction>,
        pub(crate) model_settings: std::option::Option<crate::model::ModelSettings>,
        pub(crate) identify_language: std::option::Option<bool>,
        pub(crate) identify_multiple_languages: std::option::Option<bool>,
        pub(crate) identified_language_score: std::option::Option<f32>,
        pub(crate) language_codes:
            std::option::Option<std::vec::Vec<crate::model::LanguageCodeItem>>,
    }
    impl Builder {
        /// <p>The name of the transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn transcription_job_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.transcription_job_name = Some(input.into());
            self
        }
        /// <p>The name of the transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn set_transcription_job_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.transcription_job_name = input;
            self
        }
        /// <p>The date and time the specified transcription job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn creation_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.creation_time = Some(input);
            self
        }
        /// <p>The date and time the specified transcription job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_creation_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.creation_time = input;
            self
        }
        /// <p>The date and time your transcription job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p>The date and time your transcription job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.start_time = input;
            self
        }
        /// <p>The date and time the specified transcription job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn completion_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.completion_time = Some(input);
            self
        }
        /// <p>The date and time the specified transcription job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn set_completion_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.completion_time = input;
            self
        }
        /// <p>The language code used to create your transcription.</p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.language_code = Some(input);
            self
        }
        /// <p>The language code used to create your transcription.</p>
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.language_code = input;
            self
        }
        /// <p>Provides the status of your transcription job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn transcription_job_status(
            mut self,
            input: crate::model::TranscriptionJobStatus,
        ) -> Self {
            self.transcription_job_status = Some(input);
            self
        }
        /// <p>Provides the status of your transcription job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn set_transcription_job_status(
            mut self,
            input: std::option::Option<crate::model::TranscriptionJobStatus>,
        ) -> Self {
            self.transcription_job_status = input;
            self
        }
        /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
        pub fn failure_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.failure_reason = Some(input.into());
            self
        }
        /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
        pub fn set_failure_reason(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.failure_reason = input;
            self
        }
        /// <p>Indicates where the specified transcription output is stored.</p>
        /// <p>If the value is <code>CUSTOMER_BUCKET</code>, the location is the Amazon S3 bucket you specified using the <code>OutputBucketName</code> parameter in your request. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If the value is <code>SERVICE_BUCKET</code>, the location is a service-managed Amazon S3 bucket. To access a transcript stored in a service-managed bucket, use the URI shown in the <code>TranscriptFileUri</code> or <code>RedactedTranscriptFileUri</code> field.</p>
        pub fn output_location_type(mut self, input: crate::model::OutputLocationType) -> Self {
            self.output_location_type = Some(input);
            self
        }
        /// <p>Indicates where the specified transcription output is stored.</p>
        /// <p>If the value is <code>CUSTOMER_BUCKET</code>, the location is the Amazon S3 bucket you specified using the <code>OutputBucketName</code> parameter in your request. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If the value is <code>SERVICE_BUCKET</code>, the location is a service-managed Amazon S3 bucket. To access a transcript stored in a service-managed bucket, use the URI shown in the <code>TranscriptFileUri</code> or <code>RedactedTranscriptFileUri</code> field.</p>
        pub fn set_output_location_type(
            mut self,
            input: std::option::Option<crate::model::OutputLocationType>,
        ) -> Self {
            self.output_location_type = input;
            self
        }
        /// <p>The content redaction settings of the transcription job.</p>
        pub fn content_redaction(mut self, input: crate::model::ContentRedaction) -> Self {
            self.content_redaction = Some(input);
            self
        }
        /// <p>The content redaction settings of the transcription job.</p>
        pub fn set_content_redaction(
            mut self,
            input: std::option::Option<crate::model::ContentRedaction>,
        ) -> Self {
            self.content_redaction = input;
            self
        }
        /// <p>Provides the name of the custom language model that was included in the specified transcription job.</p>
        /// <p>Only use <code>ModelSettings</code> with the <code>LanguageModelName</code> sub-parameter if you're <b>not</b> using automatic language identification (<code></code>). If using <code>LanguageIdSettings</code> in your request, this parameter contains a <code>LanguageModelName</code> sub-parameter.</p>
        pub fn model_settings(mut self, input: crate::model::ModelSettings) -> Self {
            self.model_settings = Some(input);
            self
        }
        /// <p>Provides the name of the custom language model that was included in the specified transcription job.</p>
        /// <p>Only use <code>ModelSettings</code> with the <code>LanguageModelName</code> sub-parameter if you're <b>not</b> using automatic language identification (<code></code>). If using <code>LanguageIdSettings</code> in your request, this parameter contains a <code>LanguageModelName</code> sub-parameter.</p>
        pub fn set_model_settings(
            mut self,
            input: std::option::Option<crate::model::ModelSettings>,
        ) -> Self {
            self.model_settings = input;
            self
        }
        /// <p>Indicates whether automatic language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
        pub fn identify_language(mut self, input: bool) -> Self {
            self.identify_language = Some(input);
            self
        }
        /// <p>Indicates whether automatic language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
        pub fn set_identify_language(mut self, input: std::option::Option<bool>) -> Self {
            self.identify_language = input;
            self
        }
        /// <p>Indicates whether automatic multi-language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
        pub fn identify_multiple_languages(mut self, input: bool) -> Self {
            self.identify_multiple_languages = Some(input);
            self
        }
        /// <p>Indicates whether automatic multi-language identification was enabled (<code>TRUE</code>) for the specified transcription job.</p>
        pub fn set_identify_multiple_languages(mut self, input: std::option::Option<bool>) -> Self {
            self.identify_multiple_languages = input;
            self
        }
        /// <p>The confidence score associated with the language identified in your media file.</p>
        /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
        pub fn identified_language_score(mut self, input: f32) -> Self {
            self.identified_language_score = Some(input);
            self
        }
        /// <p>The confidence score associated with the language identified in your media file.</p>
        /// <p>Confidence scores are values between 0 and 1; a larger value indicates a higher probability that the identified language correctly matches the language spoken in your media.</p>
        pub fn set_identified_language_score(mut self, input: std::option::Option<f32>) -> Self {
            self.identified_language_score = input;
            self
        }
        /// Appends an item to `language_codes`.
        ///
        /// To override the contents of this collection use [`set_language_codes`](Self::set_language_codes).
        ///
        /// <p>The language codes used to create your transcription job. This parameter is used with multi-language identification. For single-language identification, the singular version of this parameter, <code>LanguageCode</code>, is present.</p>
        pub fn language_codes(mut self, input: crate::model::LanguageCodeItem) -> Self {
            let mut v = self.language_codes.unwrap_or_default();
            v.push(input);
            self.language_codes = Some(v);
            self
        }
        /// <p>The language codes used to create your transcription job. This parameter is used with multi-language identification. For single-language identification, the singular version of this parameter, <code>LanguageCode</code>, is present.</p>
        pub fn set_language_codes(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::LanguageCodeItem>>,
        ) -> Self {
            self.language_codes = input;
            self
        }
        /// Consumes the builder and constructs a [`TranscriptionJobSummary`](crate::model::TranscriptionJobSummary)
        pub fn build(self) -> crate::model::TranscriptionJobSummary {
            crate::model::TranscriptionJobSummary {
                transcription_job_name: self.transcription_job_name,
                creation_time: self.creation_time,
                start_time: self.start_time,
                completion_time: self.completion_time,
                language_code: self.language_code,
                transcription_job_status: self.transcription_job_status,
                failure_reason: self.failure_reason,
                output_location_type: self.output_location_type,
                content_redaction: self.content_redaction,
                model_settings: self.model_settings,
                identify_language: self.identify_language,
                identify_multiple_languages: self.identify_multiple_languages,
                identified_language_score: self.identified_language_score,
                language_codes: self.language_codes,
            }
        }
    }
}
impl TranscriptionJobSummary {
    /// Creates a new builder-style object to manufacture [`TranscriptionJobSummary`](crate::model::TranscriptionJobSummary)
    pub fn builder() -> crate::model::transcription_job_summary::Builder {
        crate::model::transcription_job_summary::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum OutputLocationType {
    #[allow(missing_docs)] // documentation missing in model
    CustomerBucket,
    #[allow(missing_docs)] // documentation missing in model
    ServiceBucket,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for OutputLocationType {
    fn from(s: &str) -> Self {
        match s {
            "CUSTOMER_BUCKET" => OutputLocationType::CustomerBucket,
            "SERVICE_BUCKET" => OutputLocationType::ServiceBucket,
            other => OutputLocationType::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for OutputLocationType {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(OutputLocationType::from(s))
    }
}
impl OutputLocationType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            OutputLocationType::CustomerBucket => "CUSTOMER_BUCKET",
            OutputLocationType::ServiceBucket => "SERVICE_BUCKET",
            OutputLocationType::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["CUSTOMER_BUCKET", "SERVICE_BUCKET"]
    }
}
impl AsRef<str> for OutputLocationType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Provides detailed information about a specific medical transcription job.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct MedicalTranscriptionJobSummary {
    /// <p>The name of the medical transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub medical_transcription_job_name: std::option::Option<std::string::String>,
    /// <p>The date and time the specified medical transcription job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub creation_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time your medical transcription job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time the specified medical transcription job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub completion_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The language code used to create your medical transcription. US English (<code>en-US</code>) is the only supported language for medical transcriptions.</p>
    pub language_code: std::option::Option<crate::model::LanguageCode>,
    /// <p>Provides the status of your medical transcription job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code>. If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub transcription_job_status: std::option::Option<crate::model::TranscriptionJobStatus>,
    /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
    pub failure_reason: std::option::Option<std::string::String>,
    /// <p>Indicates where the specified medical transcription output is stored.</p>
    /// <p>If the value is <code>CUSTOMER_BUCKET</code>, the location is the Amazon S3 bucket you specified using the <code>OutputBucketName</code> parameter in your request. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If the value is <code>SERVICE_BUCKET</code>, the location is a service-managed Amazon S3 bucket. To access a transcript stored in a service-managed bucket, use the URI shown in the <code>TranscriptFileUri</code> field.</p>
    pub output_location_type: std::option::Option<crate::model::OutputLocationType>,
    /// <p>Provides the medical specialty represented in your media.</p>
    pub specialty: std::option::Option<crate::model::Specialty>,
    /// <p>Labels all personal health information (PHI) identified in your transcript. For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/phi-id.html">Identifying personal health information (PHI) in a transcription</a>.</p>
    pub content_identification_type:
        std::option::Option<crate::model::MedicalContentIdentificationType>,
    /// <p>Indicates whether the input media is a dictation or a conversation, as specified in the <code>StartMedicalTranscriptionJob</code> request.</p>
    pub r#type: std::option::Option<crate::model::Type>,
}
impl MedicalTranscriptionJobSummary {
    /// <p>The name of the medical transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub fn medical_transcription_job_name(&self) -> std::option::Option<&str> {
        self.medical_transcription_job_name.as_deref()
    }
    /// <p>The date and time the specified medical transcription job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn creation_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.creation_time.as_ref()
    }
    /// <p>The date and time your medical transcription job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p>The date and time the specified medical transcription job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub fn completion_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.completion_time.as_ref()
    }
    /// <p>The language code used to create your medical transcription. US English (<code>en-US</code>) is the only supported language for medical transcriptions.</p>
    pub fn language_code(&self) -> std::option::Option<&crate::model::LanguageCode> {
        self.language_code.as_ref()
    }
    /// <p>Provides the status of your medical transcription job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code>. If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub fn transcription_job_status(
        &self,
    ) -> std::option::Option<&crate::model::TranscriptionJobStatus> {
        self.transcription_job_status.as_ref()
    }
    /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
    pub fn failure_reason(&self) -> std::option::Option<&str> {
        self.failure_reason.as_deref()
    }
    /// <p>Indicates where the specified medical transcription output is stored.</p>
    /// <p>If the value is <code>CUSTOMER_BUCKET</code>, the location is the Amazon S3 bucket you specified using the <code>OutputBucketName</code> parameter in your request. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
    /// <p>If the value is <code>SERVICE_BUCKET</code>, the location is a service-managed Amazon S3 bucket. To access a transcript stored in a service-managed bucket, use the URI shown in the <code>TranscriptFileUri</code> field.</p>
    pub fn output_location_type(&self) -> std::option::Option<&crate::model::OutputLocationType> {
        self.output_location_type.as_ref()
    }
    /// <p>Provides the medical specialty represented in your media.</p>
    pub fn specialty(&self) -> std::option::Option<&crate::model::Specialty> {
        self.specialty.as_ref()
    }
    /// <p>Labels all personal health information (PHI) identified in your transcript. For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/phi-id.html">Identifying personal health information (PHI) in a transcription</a>.</p>
    pub fn content_identification_type(
        &self,
    ) -> std::option::Option<&crate::model::MedicalContentIdentificationType> {
        self.content_identification_type.as_ref()
    }
    /// <p>Indicates whether the input media is a dictation or a conversation, as specified in the <code>StartMedicalTranscriptionJob</code> request.</p>
    pub fn r#type(&self) -> std::option::Option<&crate::model::Type> {
        self.r#type.as_ref()
    }
}
impl std::fmt::Debug for MedicalTranscriptionJobSummary {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("MedicalTranscriptionJobSummary");
        formatter.field(
            "medical_transcription_job_name",
            &self.medical_transcription_job_name,
        );
        formatter.field("creation_time", &self.creation_time);
        formatter.field("start_time", &self.start_time);
        formatter.field("completion_time", &self.completion_time);
        formatter.field("language_code", &self.language_code);
        formatter.field("transcription_job_status", &self.transcription_job_status);
        formatter.field("failure_reason", &self.failure_reason);
        formatter.field("output_location_type", &self.output_location_type);
        formatter.field("specialty", &self.specialty);
        formatter.field(
            "content_identification_type",
            &self.content_identification_type,
        );
        formatter.field("r#type", &self.r#type);
        formatter.finish()
    }
}
/// See [`MedicalTranscriptionJobSummary`](crate::model::MedicalTranscriptionJobSummary)
pub mod medical_transcription_job_summary {

    /// A builder for [`MedicalTranscriptionJobSummary`](crate::model::MedicalTranscriptionJobSummary)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) medical_transcription_job_name: std::option::Option<std::string::String>,
        pub(crate) creation_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) completion_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) language_code: std::option::Option<crate::model::LanguageCode>,
        pub(crate) transcription_job_status:
            std::option::Option<crate::model::TranscriptionJobStatus>,
        pub(crate) failure_reason: std::option::Option<std::string::String>,
        pub(crate) output_location_type: std::option::Option<crate::model::OutputLocationType>,
        pub(crate) specialty: std::option::Option<crate::model::Specialty>,
        pub(crate) content_identification_type:
            std::option::Option<crate::model::MedicalContentIdentificationType>,
        pub(crate) r#type: std::option::Option<crate::model::Type>,
    }
    impl Builder {
        /// <p>The name of the medical transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn medical_transcription_job_name(
            mut self,
            input: impl Into<std::string::String>,
        ) -> Self {
            self.medical_transcription_job_name = Some(input.into());
            self
        }
        /// <p>The name of the medical transcription job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn set_medical_transcription_job_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.medical_transcription_job_name = input;
            self
        }
        /// <p>The date and time the specified medical transcription job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn creation_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.creation_time = Some(input);
            self
        }
        /// <p>The date and time the specified medical transcription job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_creation_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.creation_time = input;
            self
        }
        /// <p>The date and time your medical transcription job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p>The date and time your medical transcription job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.start_time = input;
            self
        }
        /// <p>The date and time the specified medical transcription job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn completion_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.completion_time = Some(input);
            self
        }
        /// <p>The date and time the specified medical transcription job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn set_completion_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.completion_time = input;
            self
        }
        /// <p>The language code used to create your medical transcription. US English (<code>en-US</code>) is the only supported language for medical transcriptions.</p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.language_code = Some(input);
            self
        }
        /// <p>The language code used to create your medical transcription. US English (<code>en-US</code>) is the only supported language for medical transcriptions.</p>
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.language_code = input;
            self
        }
        /// <p>Provides the status of your medical transcription job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code>. If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn transcription_job_status(
            mut self,
            input: crate::model::TranscriptionJobStatus,
        ) -> Self {
            self.transcription_job_status = Some(input);
            self
        }
        /// <p>Provides the status of your medical transcription job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code>. If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn set_transcription_job_status(
            mut self,
            input: std::option::Option<crate::model::TranscriptionJobStatus>,
        ) -> Self {
            self.transcription_job_status = input;
            self
        }
        /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
        pub fn failure_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.failure_reason = Some(input.into());
            self
        }
        /// <p>If <code>TranscriptionJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the transcription job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
        pub fn set_failure_reason(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.failure_reason = input;
            self
        }
        /// <p>Indicates where the specified medical transcription output is stored.</p>
        /// <p>If the value is <code>CUSTOMER_BUCKET</code>, the location is the Amazon S3 bucket you specified using the <code>OutputBucketName</code> parameter in your request. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If the value is <code>SERVICE_BUCKET</code>, the location is a service-managed Amazon S3 bucket. To access a transcript stored in a service-managed bucket, use the URI shown in the <code>TranscriptFileUri</code> field.</p>
        pub fn output_location_type(mut self, input: crate::model::OutputLocationType) -> Self {
            self.output_location_type = Some(input);
            self
        }
        /// <p>Indicates where the specified medical transcription output is stored.</p>
        /// <p>If the value is <code>CUSTOMER_BUCKET</code>, the location is the Amazon S3 bucket you specified using the <code>OutputBucketName</code> parameter in your request. If you also included <code>OutputKey</code> in your request, your output is located in the path you specified in your request.</p>
        /// <p>If the value is <code>SERVICE_BUCKET</code>, the location is a service-managed Amazon S3 bucket. To access a transcript stored in a service-managed bucket, use the URI shown in the <code>TranscriptFileUri</code> field.</p>
        pub fn set_output_location_type(
            mut self,
            input: std::option::Option<crate::model::OutputLocationType>,
        ) -> Self {
            self.output_location_type = input;
            self
        }
        /// <p>Provides the medical specialty represented in your media.</p>
        pub fn specialty(mut self, input: crate::model::Specialty) -> Self {
            self.specialty = Some(input);
            self
        }
        /// <p>Provides the medical specialty represented in your media.</p>
        pub fn set_specialty(
            mut self,
            input: std::option::Option<crate::model::Specialty>,
        ) -> Self {
            self.specialty = input;
            self
        }
        /// <p>Labels all personal health information (PHI) identified in your transcript. For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/phi-id.html">Identifying personal health information (PHI) in a transcription</a>.</p>
        pub fn content_identification_type(
            mut self,
            input: crate::model::MedicalContentIdentificationType,
        ) -> Self {
            self.content_identification_type = Some(input);
            self
        }
        /// <p>Labels all personal health information (PHI) identified in your transcript. For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/phi-id.html">Identifying personal health information (PHI) in a transcription</a>.</p>
        pub fn set_content_identification_type(
            mut self,
            input: std::option::Option<crate::model::MedicalContentIdentificationType>,
        ) -> Self {
            self.content_identification_type = input;
            self
        }
        /// <p>Indicates whether the input media is a dictation or a conversation, as specified in the <code>StartMedicalTranscriptionJob</code> request.</p>
        pub fn r#type(mut self, input: crate::model::Type) -> Self {
            self.r#type = Some(input);
            self
        }
        /// <p>Indicates whether the input media is a dictation or a conversation, as specified in the <code>StartMedicalTranscriptionJob</code> request.</p>
        pub fn set_type(mut self, input: std::option::Option<crate::model::Type>) -> Self {
            self.r#type = input;
            self
        }
        /// Consumes the builder and constructs a [`MedicalTranscriptionJobSummary`](crate::model::MedicalTranscriptionJobSummary)
        pub fn build(self) -> crate::model::MedicalTranscriptionJobSummary {
            crate::model::MedicalTranscriptionJobSummary {
                medical_transcription_job_name: self.medical_transcription_job_name,
                creation_time: self.creation_time,
                start_time: self.start_time,
                completion_time: self.completion_time,
                language_code: self.language_code,
                transcription_job_status: self.transcription_job_status,
                failure_reason: self.failure_reason,
                output_location_type: self.output_location_type,
                specialty: self.specialty,
                content_identification_type: self.content_identification_type,
                r#type: self.r#type,
            }
        }
    }
}
impl MedicalTranscriptionJobSummary {
    /// Creates a new builder-style object to manufacture [`MedicalTranscriptionJobSummary`](crate::model::MedicalTranscriptionJobSummary)
    pub fn builder() -> crate::model::medical_transcription_job_summary::Builder {
        crate::model::medical_transcription_job_summary::Builder::default()
    }
}

/// <p>Provides information about a custom language model, including the base model name, when the model was created, the location of the files used to train the model, when the model was last modified, the name you chose for the model, its language, its processing state, and if there is an upgrade available for the base model.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct LanguageModel {
    /// <p>A unique name, chosen by you, for your custom language model.</p>
    /// <p>This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The date and time the specified custom language model was created.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
    pub create_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time the specified language model was last modified.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
    pub last_modified_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The language code used to create your custom language model. Each language model must contain terms in only one language, and the language you select for your model must match the language of your training and tuning data.</p>
    /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table. Note that U.S. English (<code>en-US</code>) is the only language supported with Amazon Transcribe Medical.</p>
    pub language_code: std::option::Option<crate::model::ClmLanguageCode>,
    /// <p>The Amazon Transcribe standard language model, or base model, used to create your custom language model.</p>
    pub base_model_name: std::option::Option<crate::model::BaseModelName>,
    /// <p>The status of the specified custom language model. When the status displays as <code>COMPLETED</code> the model is ready for use.</p>
    pub model_status: std::option::Option<crate::model::ModelStatus>,
    /// <p>Shows if a more current base model is available for use with the specified custom language model.</p>
    /// <p>If <code>false</code>, your language model is using the most up-to-date base model.</p>
    /// <p>If <code>true</code>, there is a newer base model available than the one your language model is using.</p>
    /// <p>Note that to update a base model, you must recreate the custom language model using the new base model. Base model upgrades for existing custom language models are not supported.</p>
    pub upgrade_availability: std::option::Option<bool>,
    /// <p>If <code>ModelStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the custom language model request failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
    pub failure_reason: std::option::Option<std::string::String>,
    /// <p>The Amazon S3 location of the input files used to train and tune your custom language model, in addition to the data access role ARN (Amazon Resource Name) that has permissions to access these data.</p>
    pub input_data_config: std::option::Option<crate::model::InputDataConfig>,
}
impl LanguageModel {
    /// <p>A unique name, chosen by you, for your custom language model.</p>
    /// <p>This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>The date and time the specified custom language model was created.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn create_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.create_time.as_ref()
    }
    /// <p>The date and time the specified language model was last modified.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn last_modified_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.last_modified_time.as_ref()
    }
    /// <p>The language code used to create your custom language model. Each language model must contain terms in only one language, and the language you select for your model must match the language of your training and tuning data.</p>
    /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table. Note that U.S. English (<code>en-US</code>) is the only language supported with Amazon Transcribe Medical.</p>
    pub fn language_code(&self) -> std::option::Option<&crate::model::ClmLanguageCode> {
        self.language_code.as_ref()
    }
    /// <p>The Amazon Transcribe standard language model, or base model, used to create your custom language model.</p>
    pub fn base_model_name(&self) -> std::option::Option<&crate::model::BaseModelName> {
        self.base_model_name.as_ref()
    }
    /// <p>The status of the specified custom language model. When the status displays as <code>COMPLETED</code> the model is ready for use.</p>
    pub fn model_status(&self) -> std::option::Option<&crate::model::ModelStatus> {
        self.model_status.as_ref()
    }
    /// <p>Shows if a more current base model is available for use with the specified custom language model.</p>
    /// <p>If <code>false</code>, your language model is using the most up-to-date base model.</p>
    /// <p>If <code>true</code>, there is a newer base model available than the one your language model is using.</p>
    /// <p>Note that to update a base model, you must recreate the custom language model using the new base model. Base model upgrades for existing custom language models are not supported.</p>
    pub fn upgrade_availability(&self) -> std::option::Option<bool> {
        self.upgrade_availability
    }
    /// <p>If <code>ModelStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the custom language model request failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
    pub fn failure_reason(&self) -> std::option::Option<&str> {
        self.failure_reason.as_deref()
    }
    /// <p>The Amazon S3 location of the input files used to train and tune your custom language model, in addition to the data access role ARN (Amazon Resource Name) that has permissions to access these data.</p>
    pub fn input_data_config(&self) -> std::option::Option<&crate::model::InputDataConfig> {
        self.input_data_config.as_ref()
    }
}
impl std::fmt::Debug for LanguageModel {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("LanguageModel");
        formatter.field("model_name", &self.model_name);
        formatter.field("create_time", &self.create_time);
        formatter.field("last_modified_time", &self.last_modified_time);
        formatter.field("language_code", &self.language_code);
        formatter.field("base_model_name", &self.base_model_name);
        formatter.field("model_status", &self.model_status);
        formatter.field("upgrade_availability", &self.upgrade_availability);
        formatter.field("failure_reason", &self.failure_reason);
        formatter.field("input_data_config", &self.input_data_config);
        formatter.finish()
    }
}
/// See [`LanguageModel`](crate::model::LanguageModel)
pub mod language_model {

    /// A builder for [`LanguageModel`](crate::model::LanguageModel)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) model_name: std::option::Option<std::string::String>,
        pub(crate) create_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) last_modified_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) language_code: std::option::Option<crate::model::ClmLanguageCode>,
        pub(crate) base_model_name: std::option::Option<crate::model::BaseModelName>,
        pub(crate) model_status: std::option::Option<crate::model::ModelStatus>,
        pub(crate) upgrade_availability: std::option::Option<bool>,
        pub(crate) failure_reason: std::option::Option<std::string::String>,
        pub(crate) input_data_config: std::option::Option<crate::model::InputDataConfig>,
    }
    impl Builder {
        /// <p>A unique name, chosen by you, for your custom language model.</p>
        /// <p>This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_name = Some(input.into());
            self
        }
        /// <p>A unique name, chosen by you, for your custom language model.</p>
        /// <p>This name is case sensitive, cannot contain spaces, and must be unique within an Amazon Web Services account.</p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_name = input;
            self
        }
        /// <p>The date and time the specified custom language model was created.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn create_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.create_time = Some(input);
            self
        }
        /// <p>The date and time the specified custom language model was created.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_create_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.create_time = input;
            self
        }
        /// <p>The date and time the specified language model was last modified.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn last_modified_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.last_modified_time = Some(input);
            self
        }
        /// <p>The date and time the specified language model was last modified.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_last_modified_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.last_modified_time = input;
            self
        }
        /// <p>The language code used to create your custom language model. Each language model must contain terms in only one language, and the language you select for your model must match the language of your training and tuning data.</p>
        /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table. Note that U.S. English (<code>en-US</code>) is the only language supported with Amazon Transcribe Medical.</p>
        pub fn language_code(mut self, input: crate::model::ClmLanguageCode) -> Self {
            self.language_code = Some(input);
            self
        }
        /// <p>The language code used to create your custom language model. Each language model must contain terms in only one language, and the language you select for your model must match the language of your training and tuning data.</p>
        /// <p>For a list of supported languages and their associated language codes, refer to the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages</a> table. Note that U.S. English (<code>en-US</code>) is the only language supported with Amazon Transcribe Medical.</p>
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::ClmLanguageCode>,
        ) -> Self {
            self.language_code = input;
            self
        }
        /// <p>The Amazon Transcribe standard language model, or base model, used to create your custom language model.</p>
        pub fn base_model_name(mut self, input: crate::model::BaseModelName) -> Self {
            self.base_model_name = Some(input);
            self
        }
        /// <p>The Amazon Transcribe standard language model, or base model, used to create your custom language model.</p>
        pub fn set_base_model_name(
            mut self,
            input: std::option::Option<crate::model::BaseModelName>,
        ) -> Self {
            self.base_model_name = input;
            self
        }
        /// <p>The status of the specified custom language model. When the status displays as <code>COMPLETED</code> the model is ready for use.</p>
        pub fn model_status(mut self, input: crate::model::ModelStatus) -> Self {
            self.model_status = Some(input);
            self
        }
        /// <p>The status of the specified custom language model. When the status displays as <code>COMPLETED</code> the model is ready for use.</p>
        pub fn set_model_status(
            mut self,
            input: std::option::Option<crate::model::ModelStatus>,
        ) -> Self {
            self.model_status = input;
            self
        }
        /// <p>Shows if a more current base model is available for use with the specified custom language model.</p>
        /// <p>If <code>false</code>, your language model is using the most up-to-date base model.</p>
        /// <p>If <code>true</code>, there is a newer base model available than the one your language model is using.</p>
        /// <p>Note that to update a base model, you must recreate the custom language model using the new base model. Base model upgrades for existing custom language models are not supported.</p>
        pub fn upgrade_availability(mut self, input: bool) -> Self {
            self.upgrade_availability = Some(input);
            self
        }
        /// <p>Shows if a more current base model is available for use with the specified custom language model.</p>
        /// <p>If <code>false</code>, your language model is using the most up-to-date base model.</p>
        /// <p>If <code>true</code>, there is a newer base model available than the one your language model is using.</p>
        /// <p>Note that to update a base model, you must recreate the custom language model using the new base model. Base model upgrades for existing custom language models are not supported.</p>
        pub fn set_upgrade_availability(mut self, input: std::option::Option<bool>) -> Self {
            self.upgrade_availability = input;
            self
        }
        /// <p>If <code>ModelStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the custom language model request failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
        pub fn failure_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.failure_reason = Some(input.into());
            self
        }
        /// <p>If <code>ModelStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the custom language model request failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
        pub fn set_failure_reason(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.failure_reason = input;
            self
        }
        /// <p>The Amazon S3 location of the input files used to train and tune your custom language model, in addition to the data access role ARN (Amazon Resource Name) that has permissions to access these data.</p>
        pub fn input_data_config(mut self, input: crate::model::InputDataConfig) -> Self {
            self.input_data_config = Some(input);
            self
        }
        /// <p>The Amazon S3 location of the input files used to train and tune your custom language model, in addition to the data access role ARN (Amazon Resource Name) that has permissions to access these data.</p>
        pub fn set_input_data_config(
            mut self,
            input: std::option::Option<crate::model::InputDataConfig>,
        ) -> Self {
            self.input_data_config = input;
            self
        }
        /// Consumes the builder and constructs a [`LanguageModel`](crate::model::LanguageModel)
        pub fn build(self) -> crate::model::LanguageModel {
            crate::model::LanguageModel {
                model_name: self.model_name,
                create_time: self.create_time,
                last_modified_time: self.last_modified_time,
                language_code: self.language_code,
                base_model_name: self.base_model_name,
                model_status: self.model_status,
                upgrade_availability: self.upgrade_availability,
                failure_reason: self.failure_reason,
                input_data_config: self.input_data_config,
            }
        }
    }
}
impl LanguageModel {
    /// Creates a new builder-style object to manufacture [`LanguageModel`](crate::model::LanguageModel)
    pub fn builder() -> crate::model::language_model::Builder {
        crate::model::language_model::Builder::default()
    }
}

/// <p>Contains the Amazon S3 location of the training data you want to use to create a new custom language model, and permissions to access this location.</p>
/// <p>When using <code>InputDataConfig</code>, you must include these sub-parameters: <code>S3Uri</code> and <code>DataAccessRoleArn</code>. You can optionally include <code>TuningDataS3Uri</code>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct InputDataConfig {
    /// <p>The Amazon S3 location (URI) of the text files you want to use to train your custom language model.</p>
    /// <p>Here's an example URI path: <code>s3://DOC-EXAMPLE-BUCKET/my-model-training-data/</code> </p>
    pub s3_uri: std::option::Option<std::string::String>,
    /// <p>The Amazon S3 location (URI) of the text files you want to use to tune your custom language model.</p>
    /// <p>Here's an example URI path: <code>s3://DOC-EXAMPLE-BUCKET/my-model-tuning-data/</code> </p>
    pub tuning_data_s3_uri: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
    /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
    pub data_access_role_arn: std::option::Option<std::string::String>,
}
impl InputDataConfig {
    /// <p>The Amazon S3 location (URI) of the text files you want to use to train your custom language model.</p>
    /// <p>Here's an example URI path: <code>s3://DOC-EXAMPLE-BUCKET/my-model-training-data/</code> </p>
    pub fn s3_uri(&self) -> std::option::Option<&str> {
        self.s3_uri.as_deref()
    }
    /// <p>The Amazon S3 location (URI) of the text files you want to use to tune your custom language model.</p>
    /// <p>Here's an example URI path: <code>s3://DOC-EXAMPLE-BUCKET/my-model-tuning-data/</code> </p>
    pub fn tuning_data_s3_uri(&self) -> std::option::Option<&str> {
        self.tuning_data_s3_uri.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
    /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
    pub fn data_access_role_arn(&self) -> std::option::Option<&str> {
        self.data_access_role_arn.as_deref()
    }
}
impl std::fmt::Debug for InputDataConfig {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("InputDataConfig");
        formatter.field("s3_uri", &self.s3_uri);
        formatter.field("tuning_data_s3_uri", &self.tuning_data_s3_uri);
        formatter.field("data_access_role_arn", &self.data_access_role_arn);
        formatter.finish()
    }
}
/// See [`InputDataConfig`](crate::model::InputDataConfig)
pub mod input_data_config {

    /// A builder for [`InputDataConfig`](crate::model::InputDataConfig)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) s3_uri: std::option::Option<std::string::String>,
        pub(crate) tuning_data_s3_uri: std::option::Option<std::string::String>,
        pub(crate) data_access_role_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The Amazon S3 location (URI) of the text files you want to use to train your custom language model.</p>
        /// <p>Here's an example URI path: <code>s3://DOC-EXAMPLE-BUCKET/my-model-training-data/</code> </p>
        pub fn s3_uri(mut self, input: impl Into<std::string::String>) -> Self {
            self.s3_uri = Some(input.into());
            self
        }
        /// <p>The Amazon S3 location (URI) of the text files you want to use to train your custom language model.</p>
        /// <p>Here's an example URI path: <code>s3://DOC-EXAMPLE-BUCKET/my-model-training-data/</code> </p>
        pub fn set_s3_uri(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.s3_uri = input;
            self
        }
        /// <p>The Amazon S3 location (URI) of the text files you want to use to tune your custom language model.</p>
        /// <p>Here's an example URI path: <code>s3://DOC-EXAMPLE-BUCKET/my-model-tuning-data/</code> </p>
        pub fn tuning_data_s3_uri(mut self, input: impl Into<std::string::String>) -> Self {
            self.tuning_data_s3_uri = Some(input.into());
            self
        }
        /// <p>The Amazon S3 location (URI) of the text files you want to use to tune your custom language model.</p>
        /// <p>Here's an example URI path: <code>s3://DOC-EXAMPLE-BUCKET/my-model-tuning-data/</code> </p>
        pub fn set_tuning_data_s3_uri(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.tuning_data_s3_uri = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
        /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
        pub fn data_access_role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.data_access_role_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of an IAM role that has permissions to access the Amazon S3 bucket that contains your input files. If the role you specify doesnt have the appropriate permissions to access the specified Amazon S3 location, your request fails.</p>
        /// <p>IAM role ARNs have the format <code>arn:partition:iam::account:role/role-name-with-path</code>. For example: <code>arn:aws:iam::111122223333:role/Admin</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns">IAM ARNs</a>.</p>
        pub fn set_data_access_role_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.data_access_role_arn = input;
            self
        }
        /// Consumes the builder and constructs a [`InputDataConfig`](crate::model::InputDataConfig)
        pub fn build(self) -> crate::model::InputDataConfig {
            crate::model::InputDataConfig {
                s3_uri: self.s3_uri,
                tuning_data_s3_uri: self.tuning_data_s3_uri,
                data_access_role_arn: self.data_access_role_arn,
            }
        }
    }
}
impl InputDataConfig {
    /// Creates a new builder-style object to manufacture [`InputDataConfig`](crate::model::InputDataConfig)
    pub fn builder() -> crate::model::input_data_config::Builder {
        crate::model::input_data_config::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum ModelStatus {
    #[allow(missing_docs)] // documentation missing in model
    Completed,
    #[allow(missing_docs)] // documentation missing in model
    Failed,
    #[allow(missing_docs)] // documentation missing in model
    InProgress,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for ModelStatus {
    fn from(s: &str) -> Self {
        match s {
            "COMPLETED" => ModelStatus::Completed,
            "FAILED" => ModelStatus::Failed,
            "IN_PROGRESS" => ModelStatus::InProgress,
            other => ModelStatus::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for ModelStatus {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(ModelStatus::from(s))
    }
}
impl ModelStatus {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            ModelStatus::Completed => "COMPLETED",
            ModelStatus::Failed => "FAILED",
            ModelStatus::InProgress => "IN_PROGRESS",
            ModelStatus::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["COMPLETED", "FAILED", "IN_PROGRESS"]
    }
}
impl AsRef<str> for ModelStatus {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum BaseModelName {
    #[allow(missing_docs)] // documentation missing in model
    NarrowBand,
    #[allow(missing_docs)] // documentation missing in model
    WideBand,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for BaseModelName {
    fn from(s: &str) -> Self {
        match s {
            "NarrowBand" => BaseModelName::NarrowBand,
            "WideBand" => BaseModelName::WideBand,
            other => BaseModelName::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for BaseModelName {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(BaseModelName::from(s))
    }
}
impl BaseModelName {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            BaseModelName::NarrowBand => "NarrowBand",
            BaseModelName::WideBand => "WideBand",
            BaseModelName::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["NarrowBand", "WideBand"]
    }
}
impl AsRef<str> for BaseModelName {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    std::clone::Clone,
    std::cmp::Eq,
    std::cmp::Ord,
    std::cmp::PartialEq,
    std::cmp::PartialOrd,
    std::fmt::Debug,
    std::hash::Hash,
)]
pub enum ClmLanguageCode {
    #[allow(missing_docs)] // documentation missing in model
    EnAu,
    #[allow(missing_docs)] // documentation missing in model
    EnGb,
    #[allow(missing_docs)] // documentation missing in model
    EnUs,
    #[allow(missing_docs)] // documentation missing in model
    EsUs,
    #[allow(missing_docs)] // documentation missing in model
    HiIn,
    /// Unknown contains new variants that have been added since this code was generated.
    Unknown(String),
}
impl std::convert::From<&str> for ClmLanguageCode {
    fn from(s: &str) -> Self {
        match s {
            "en-AU" => ClmLanguageCode::EnAu,
            "en-GB" => ClmLanguageCode::EnGb,
            "en-US" => ClmLanguageCode::EnUs,
            "es-US" => ClmLanguageCode::EsUs,
            "hi-IN" => ClmLanguageCode::HiIn,
            other => ClmLanguageCode::Unknown(other.to_owned()),
        }
    }
}
impl std::str::FromStr for ClmLanguageCode {
    type Err = std::convert::Infallible;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        Ok(ClmLanguageCode::from(s))
    }
}
impl ClmLanguageCode {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            ClmLanguageCode::EnAu => "en-AU",
            ClmLanguageCode::EnGb => "en-GB",
            ClmLanguageCode::EnUs => "en-US",
            ClmLanguageCode::EsUs => "es-US",
            ClmLanguageCode::HiIn => "hi-IN",
            ClmLanguageCode::Unknown(s) => s.as_ref(),
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub fn values() -> &'static [&'static str] {
        &["en-AU", "en-GB", "en-US", "es-US", "hi-IN"]
    }
}
impl AsRef<str> for ClmLanguageCode {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Provides detailed information about a specific Call Analytics job.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct CallAnalyticsJobSummary {
    /// <p>The name of the Call Analytics job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub call_analytics_job_name: std::option::Option<std::string::String>,
    /// <p>The date and time the specified Call Analytics job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub creation_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time your Call Analytics job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time the specified Call Analytics job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub completion_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The language code used to create your Call Analytics transcription.</p>
    pub language_code: std::option::Option<crate::model::LanguageCode>,
    /// <p>Provides the status of your Call Analytics job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub call_analytics_job_status: std::option::Option<crate::model::CallAnalyticsJobStatus>,
    /// <p>If <code>CallAnalyticsJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the Call Analytics job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
    pub failure_reason: std::option::Option<std::string::String>,
}
impl CallAnalyticsJobSummary {
    /// <p>The name of the Call Analytics job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
    pub fn call_analytics_job_name(&self) -> std::option::Option<&str> {
        self.call_analytics_job_name.as_deref()
    }
    /// <p>The date and time the specified Call Analytics job request was made.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn creation_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.creation_time.as_ref()
    }
    /// <p>The date and time your Call Analytics job began processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
    pub fn start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p>The date and time the specified Call Analytics job finished processing.</p>
    /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
    pub fn completion_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.completion_time.as_ref()
    }
    /// <p>The language code used to create your Call Analytics transcription.</p>
    pub fn language_code(&self) -> std::option::Option<&crate::model::LanguageCode> {
        self.language_code.as_ref()
    }
    /// <p>Provides the status of your Call Analytics job.</p>
    /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
    pub fn call_analytics_job_status(
        &self,
    ) -> std::option::Option<&crate::model::CallAnalyticsJobStatus> {
        self.call_analytics_job_status.as_ref()
    }
    /// <p>If <code>CallAnalyticsJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the Call Analytics job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
    pub fn failure_reason(&self) -> std::option::Option<&str> {
        self.failure_reason.as_deref()
    }
}
impl std::fmt::Debug for CallAnalyticsJobSummary {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("CallAnalyticsJobSummary");
        formatter.field("call_analytics_job_name", &self.call_analytics_job_name);
        formatter.field("creation_time", &self.creation_time);
        formatter.field("start_time", &self.start_time);
        formatter.field("completion_time", &self.completion_time);
        formatter.field("language_code", &self.language_code);
        formatter.field("call_analytics_job_status", &self.call_analytics_job_status);
        formatter.field("failure_reason", &self.failure_reason);
        formatter.finish()
    }
}
/// See [`CallAnalyticsJobSummary`](crate::model::CallAnalyticsJobSummary)
pub mod call_analytics_job_summary {

    /// A builder for [`CallAnalyticsJobSummary`](crate::model::CallAnalyticsJobSummary)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) call_analytics_job_name: std::option::Option<std::string::String>,
        pub(crate) creation_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) completion_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) language_code: std::option::Option<crate::model::LanguageCode>,
        pub(crate) call_analytics_job_status:
            std::option::Option<crate::model::CallAnalyticsJobStatus>,
        pub(crate) failure_reason: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the Call Analytics job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn call_analytics_job_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.call_analytics_job_name = Some(input.into());
            self
        }
        /// <p>The name of the Call Analytics job. Job names are case sensitive and must be unique within an Amazon Web Services account.</p>
        pub fn set_call_analytics_job_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.call_analytics_job_name = input;
            self
        }
        /// <p>The date and time the specified Call Analytics job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn creation_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.creation_time = Some(input);
            self
        }
        /// <p>The date and time the specified Call Analytics job request was made.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.761000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_creation_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.creation_time = input;
            self
        }
        /// <p>The date and time your Call Analytics job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p>The date and time your Call Analytics job began processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:32:58.789000-07:00</code> represents a transcription job that started processing at 12:32 PM UTC-7 on May 4, 2022.</p>
        pub fn set_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.start_time = input;
            self
        }
        /// <p>The date and time the specified Call Analytics job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn completion_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.completion_time = Some(input);
            self
        }
        /// <p>The date and time the specified Call Analytics job finished processing.</p>
        /// <p>Timestamps are in the format <code>YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC</code>. For example, <code>2022-05-04T12:33:13.922000-07:00</code> represents a transcription job that started processing at 12:33 PM UTC-7 on May 4, 2022.</p>
        pub fn set_completion_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.completion_time = input;
            self
        }
        /// <p>The language code used to create your Call Analytics transcription.</p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.language_code = Some(input);
            self
        }
        /// <p>The language code used to create your Call Analytics transcription.</p>
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.language_code = input;
            self
        }
        /// <p>Provides the status of your Call Analytics job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn call_analytics_job_status(
            mut self,
            input: crate::model::CallAnalyticsJobStatus,
        ) -> Self {
            self.call_analytics_job_status = Some(input);
            self
        }
        /// <p>Provides the status of your Call Analytics job.</p>
        /// <p>If the status is <code>COMPLETED</code>, the job is finished and you can find the results at the location specified in <code>TranscriptFileUri</code> (or <code>RedactedTranscriptFileUri</code>, if you requested transcript redaction). If the status is <code>FAILED</code>, <code>FailureReason</code> provides details on why your transcription job failed.</p>
        pub fn set_call_analytics_job_status(
            mut self,
            input: std::option::Option<crate::model::CallAnalyticsJobStatus>,
        ) -> Self {
            self.call_analytics_job_status = input;
            self
        }
        /// <p>If <code>CallAnalyticsJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the Call Analytics job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
        pub fn failure_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.failure_reason = Some(input.into());
            self
        }
        /// <p>If <code>CallAnalyticsJobStatus</code> is <code>FAILED</code>, <code>FailureReason</code> contains information about why the Call Analytics job failed. See also: <a href="https://docs.aws.amazon.com/transcribe/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
        pub fn set_failure_reason(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.failure_reason = input;
            self
        }
        /// Consumes the builder and constructs a [`CallAnalyticsJobSummary`](crate::model::CallAnalyticsJobSummary)
        pub fn build(self) -> crate::model::CallAnalyticsJobSummary {
            crate::model::CallAnalyticsJobSummary {
                call_analytics_job_name: self.call_analytics_job_name,
                creation_time: self.creation_time,
                start_time: self.start_time,
                completion_time: self.completion_time,
                language_code: self.language_code,
                call_analytics_job_status: self.call_analytics_job_status,
                failure_reason: self.failure_reason,
            }
        }
    }
}
impl CallAnalyticsJobSummary {
    /// Creates a new builder-style object to manufacture [`CallAnalyticsJobSummary`](crate::model::CallAnalyticsJobSummary)
    pub fn builder() -> crate::model::call_analytics_job_summary::Builder {
        crate::model::call_analytics_job_summary::Builder::default()
    }
}
