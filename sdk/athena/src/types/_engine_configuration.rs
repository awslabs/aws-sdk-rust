// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Contains data processing unit (DPU) configuration settings and parameter mappings for a notebook engine.</p>
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct EngineConfiguration {
    /// <p>The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates processing work and manages other executors in a notebook session. The default is 1.</p>
    pub coordinator_dpu_size: ::std::option::Option<i32>,
    /// <p>The maximum number of DPUs that can run concurrently.</p>
    pub max_concurrent_dpus: i32,
    /// <p>The default number of DPUs to use for executors. An executor is the smallest unit of compute that a notebook session can request from Athena. The default is 1.</p>
    pub default_executor_dpu_size: ::std::option::Option<i32>,
    /// <p>Contains additional notebook engine <code>MAP<string, string></string,></code> parameter mappings in the form of key-value pairs. To specify an Athena notebook that the Jupyter server will download and serve, specify a value for the <code>StartSessionRequest$NotebookVersion</code> field, and then add a key named <code>NotebookId</code> to <code>AdditionalConfigs</code> that has the value of the Athena notebook ID.</p>
    pub additional_configs: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    /// <p>Specifies custom jar files and Spark properties for use cases like cluster encryption, table formats, and general Spark tuning.</p>
    pub spark_properties: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    /// <p>The configuration classifications that can be specified for the engine.</p>
    pub classifications: ::std::option::Option<::std::vec::Vec<crate::types::Classification>>,
}
impl EngineConfiguration {
    /// <p>The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates processing work and manages other executors in a notebook session. The default is 1.</p>
    pub fn coordinator_dpu_size(&self) -> ::std::option::Option<i32> {
        self.coordinator_dpu_size
    }
    /// <p>The maximum number of DPUs that can run concurrently.</p>
    pub fn max_concurrent_dpus(&self) -> i32 {
        self.max_concurrent_dpus
    }
    /// <p>The default number of DPUs to use for executors. An executor is the smallest unit of compute that a notebook session can request from Athena. The default is 1.</p>
    pub fn default_executor_dpu_size(&self) -> ::std::option::Option<i32> {
        self.default_executor_dpu_size
    }
    /// <p>Contains additional notebook engine <code>MAP<string, string></string,></code> parameter mappings in the form of key-value pairs. To specify an Athena notebook that the Jupyter server will download and serve, specify a value for the <code>StartSessionRequest$NotebookVersion</code> field, and then add a key named <code>NotebookId</code> to <code>AdditionalConfigs</code> that has the value of the Athena notebook ID.</p>
    pub fn additional_configs(&self) -> ::std::option::Option<&::std::collections::HashMap<::std::string::String, ::std::string::String>> {
        self.additional_configs.as_ref()
    }
    /// <p>Specifies custom jar files and Spark properties for use cases like cluster encryption, table formats, and general Spark tuning.</p>
    pub fn spark_properties(&self) -> ::std::option::Option<&::std::collections::HashMap<::std::string::String, ::std::string::String>> {
        self.spark_properties.as_ref()
    }
    /// <p>The configuration classifications that can be specified for the engine.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.classifications.is_none()`.
    pub fn classifications(&self) -> &[crate::types::Classification] {
        self.classifications.as_deref().unwrap_or_default()
    }
}
impl EngineConfiguration {
    /// Creates a new builder-style object to manufacture [`EngineConfiguration`](crate::types::EngineConfiguration).
    pub fn builder() -> crate::types::builders::EngineConfigurationBuilder {
        crate::types::builders::EngineConfigurationBuilder::default()
    }
}

/// A builder for [`EngineConfiguration`](crate::types::EngineConfiguration).
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
#[non_exhaustive]
pub struct EngineConfigurationBuilder {
    pub(crate) coordinator_dpu_size: ::std::option::Option<i32>,
    pub(crate) max_concurrent_dpus: ::std::option::Option<i32>,
    pub(crate) default_executor_dpu_size: ::std::option::Option<i32>,
    pub(crate) additional_configs: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    pub(crate) spark_properties: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    pub(crate) classifications: ::std::option::Option<::std::vec::Vec<crate::types::Classification>>,
}
impl EngineConfigurationBuilder {
    /// <p>The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates processing work and manages other executors in a notebook session. The default is 1.</p>
    pub fn coordinator_dpu_size(mut self, input: i32) -> Self {
        self.coordinator_dpu_size = ::std::option::Option::Some(input);
        self
    }
    /// <p>The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates processing work and manages other executors in a notebook session. The default is 1.</p>
    pub fn set_coordinator_dpu_size(mut self, input: ::std::option::Option<i32>) -> Self {
        self.coordinator_dpu_size = input;
        self
    }
    /// <p>The number of DPUs to use for the coordinator. A coordinator is a special executor that orchestrates processing work and manages other executors in a notebook session. The default is 1.</p>
    pub fn get_coordinator_dpu_size(&self) -> &::std::option::Option<i32> {
        &self.coordinator_dpu_size
    }
    /// <p>The maximum number of DPUs that can run concurrently.</p>
    pub fn max_concurrent_dpus(mut self, input: i32) -> Self {
        self.max_concurrent_dpus = ::std::option::Option::Some(input);
        self
    }
    /// <p>The maximum number of DPUs that can run concurrently.</p>
    pub fn set_max_concurrent_dpus(mut self, input: ::std::option::Option<i32>) -> Self {
        self.max_concurrent_dpus = input;
        self
    }
    /// <p>The maximum number of DPUs that can run concurrently.</p>
    pub fn get_max_concurrent_dpus(&self) -> &::std::option::Option<i32> {
        &self.max_concurrent_dpus
    }
    /// <p>The default number of DPUs to use for executors. An executor is the smallest unit of compute that a notebook session can request from Athena. The default is 1.</p>
    pub fn default_executor_dpu_size(mut self, input: i32) -> Self {
        self.default_executor_dpu_size = ::std::option::Option::Some(input);
        self
    }
    /// <p>The default number of DPUs to use for executors. An executor is the smallest unit of compute that a notebook session can request from Athena. The default is 1.</p>
    pub fn set_default_executor_dpu_size(mut self, input: ::std::option::Option<i32>) -> Self {
        self.default_executor_dpu_size = input;
        self
    }
    /// <p>The default number of DPUs to use for executors. An executor is the smallest unit of compute that a notebook session can request from Athena. The default is 1.</p>
    pub fn get_default_executor_dpu_size(&self) -> &::std::option::Option<i32> {
        &self.default_executor_dpu_size
    }
    /// Adds a key-value pair to `additional_configs`.
    ///
    /// To override the contents of this collection use [`set_additional_configs`](Self::set_additional_configs).
    ///
    /// <p>Contains additional notebook engine <code>MAP<string, string></string,></code> parameter mappings in the form of key-value pairs. To specify an Athena notebook that the Jupyter server will download and serve, specify a value for the <code>StartSessionRequest$NotebookVersion</code> field, and then add a key named <code>NotebookId</code> to <code>AdditionalConfigs</code> that has the value of the Athena notebook ID.</p>
    pub fn additional_configs(
        mut self,
        k: impl ::std::convert::Into<::std::string::String>,
        v: impl ::std::convert::Into<::std::string::String>,
    ) -> Self {
        let mut hash_map = self.additional_configs.unwrap_or_default();
        hash_map.insert(k.into(), v.into());
        self.additional_configs = ::std::option::Option::Some(hash_map);
        self
    }
    /// <p>Contains additional notebook engine <code>MAP<string, string></string,></code> parameter mappings in the form of key-value pairs. To specify an Athena notebook that the Jupyter server will download and serve, specify a value for the <code>StartSessionRequest$NotebookVersion</code> field, and then add a key named <code>NotebookId</code> to <code>AdditionalConfigs</code> that has the value of the Athena notebook ID.</p>
    pub fn set_additional_configs(
        mut self,
        input: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    ) -> Self {
        self.additional_configs = input;
        self
    }
    /// <p>Contains additional notebook engine <code>MAP<string, string></string,></code> parameter mappings in the form of key-value pairs. To specify an Athena notebook that the Jupyter server will download and serve, specify a value for the <code>StartSessionRequest$NotebookVersion</code> field, and then add a key named <code>NotebookId</code> to <code>AdditionalConfigs</code> that has the value of the Athena notebook ID.</p>
    pub fn get_additional_configs(&self) -> &::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>> {
        &self.additional_configs
    }
    /// Adds a key-value pair to `spark_properties`.
    ///
    /// To override the contents of this collection use [`set_spark_properties`](Self::set_spark_properties).
    ///
    /// <p>Specifies custom jar files and Spark properties for use cases like cluster encryption, table formats, and general Spark tuning.</p>
    pub fn spark_properties(
        mut self,
        k: impl ::std::convert::Into<::std::string::String>,
        v: impl ::std::convert::Into<::std::string::String>,
    ) -> Self {
        let mut hash_map = self.spark_properties.unwrap_or_default();
        hash_map.insert(k.into(), v.into());
        self.spark_properties = ::std::option::Option::Some(hash_map);
        self
    }
    /// <p>Specifies custom jar files and Spark properties for use cases like cluster encryption, table formats, and general Spark tuning.</p>
    pub fn set_spark_properties(
        mut self,
        input: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    ) -> Self {
        self.spark_properties = input;
        self
    }
    /// <p>Specifies custom jar files and Spark properties for use cases like cluster encryption, table formats, and general Spark tuning.</p>
    pub fn get_spark_properties(&self) -> &::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>> {
        &self.spark_properties
    }
    /// Appends an item to `classifications`.
    ///
    /// To override the contents of this collection use [`set_classifications`](Self::set_classifications).
    ///
    /// <p>The configuration classifications that can be specified for the engine.</p>
    pub fn classifications(mut self, input: crate::types::Classification) -> Self {
        let mut v = self.classifications.unwrap_or_default();
        v.push(input);
        self.classifications = ::std::option::Option::Some(v);
        self
    }
    /// <p>The configuration classifications that can be specified for the engine.</p>
    pub fn set_classifications(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::Classification>>) -> Self {
        self.classifications = input;
        self
    }
    /// <p>The configuration classifications that can be specified for the engine.</p>
    pub fn get_classifications(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::Classification>> {
        &self.classifications
    }
    /// Consumes the builder and constructs a [`EngineConfiguration`](crate::types::EngineConfiguration).
    pub fn build(self) -> crate::types::EngineConfiguration {
        crate::types::EngineConfiguration {
            coordinator_dpu_size: self.coordinator_dpu_size,
            max_concurrent_dpus: self.max_concurrent_dpus.unwrap_or(20),
            default_executor_dpu_size: self.default_executor_dpu_size,
            additional_configs: self.additional_configs,
            spark_properties: self.spark_properties,
            classifications: self.classifications,
        }
    }
}
