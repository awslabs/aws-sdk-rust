// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`DetectDocumentText`](crate::client::fluent_builders::DetectDocumentText) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`document(Document)`](crate::client::fluent_builders::DetectDocumentText::document) / [`set_document(Option<Document>)`](crate::client::fluent_builders::DetectDocumentText::set_document): <p>The input document as base64-encoded bytes or an Amazon S3 object. If you use the AWS CLI to call Amazon Textract operations, you can't pass image bytes. The document must be an image in JPEG or PNG format.</p>  <p>If you're using an AWS SDK to call Amazon Textract, you might not need to base64-encode image bytes that are passed using the <code>Bytes</code> field. </p>
    /// - On success, responds with [`DetectDocumentTextOutput`](crate::output::DetectDocumentTextOutput) with field(s):
    ///   - [`document_metadata(Option<DocumentMetadata>)`](crate::output::DetectDocumentTextOutput::document_metadata): <p>Metadata about the document. It contains the number of pages that are detected in the document.</p>
    ///   - [`blocks(Option<Vec<Block>>)`](crate::output::DetectDocumentTextOutput::blocks): <p>An array of <code>Block</code> objects that contain the text that's detected in the document.</p>
    ///   - [`detect_document_text_model_version(Option<String>)`](crate::output::DetectDocumentTextOutput::detect_document_text_model_version): <p></p>
    /// - On failure, responds with [`SdkError<DetectDocumentTextError>`](crate::error::DetectDocumentTextError)
    pub fn detect_document_text(&self) -> crate::client::fluent_builders::DetectDocumentText {
        crate::client::fluent_builders::DetectDocumentText::new(self.handle.clone())
    }
}
