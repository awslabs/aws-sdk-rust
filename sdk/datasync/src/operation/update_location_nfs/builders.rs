// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
pub use crate::operation::update_location_nfs::_update_location_nfs_output::UpdateLocationNfsOutputBuilder;

pub use crate::operation::update_location_nfs::_update_location_nfs_input::UpdateLocationNfsInputBuilder;

/// Fluent builder constructing a request to `UpdateLocationNfs`.
///
/// <p>Updates some of the parameters of a previously created location for Network File System (NFS) access. For information about creating an NFS location, see <a href="https://docs.aws.amazon.com/datasync/latest/userguide/create-nfs-location.html">Creating a location for NFS</a>.</p>
#[derive(std::clone::Clone, std::fmt::Debug)]
pub struct UpdateLocationNfsFluentBuilder {
    handle: std::sync::Arc<crate::client::Handle>,
    inner: crate::operation::update_location_nfs::builders::UpdateLocationNfsInputBuilder,
}
impl UpdateLocationNfsFluentBuilder {
    /// Creates a new `UpdateLocationNfs`.
    pub(crate) fn new(handle: std::sync::Arc<crate::client::Handle>) -> Self {
        Self {
            handle,
            inner: Default::default(),
        }
    }

    /// Consume this builder, creating a customizable operation that can be modified before being
    /// sent. The operation's inner [http::Request] can be modified as well.
    pub async fn customize(
        self,
    ) -> std::result::Result<
        crate::client::customize::CustomizableOperation<
            crate::operation::update_location_nfs::UpdateLocationNfs,
            aws_http::retry::AwsResponseRetryClassifier,
        >,
        aws_smithy_http::result::SdkError<
            crate::operation::update_location_nfs::UpdateLocationNfsError,
        >,
    > {
        let handle = self.handle.clone();
        let operation = self
            .inner
            .build()
            .map_err(aws_smithy_http::result::SdkError::construction_failure)?
            .make_operation(&handle.conf)
            .await
            .map_err(aws_smithy_http::result::SdkError::construction_failure)?;
        Ok(crate::client::customize::CustomizableOperation { handle, operation })
    }

    /// Sends the request and returns the response.
    ///
    /// If an error occurs, an `SdkError` will be returned with additional details that
    /// can be matched against.
    ///
    /// By default, any retryable failures will be retried twice. Retry behavior
    /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
    /// set when configuring the client.
    pub async fn send(
        self,
    ) -> std::result::Result<
        crate::operation::update_location_nfs::UpdateLocationNfsOutput,
        aws_smithy_http::result::SdkError<
            crate::operation::update_location_nfs::UpdateLocationNfsError,
        >,
    > {
        let op = self
            .inner
            .build()
            .map_err(aws_smithy_http::result::SdkError::construction_failure)?
            .make_operation(&self.handle.conf)
            .await
            .map_err(aws_smithy_http::result::SdkError::construction_failure)?;
        self.handle.client.call(op).await
    }
    /// <p>The Amazon Resource Name (ARN) of the NFS location to update.</p>
    pub fn location_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.location_arn(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the NFS location to update.</p>
    pub fn set_location_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_location_arn(input);
        self
    }
    /// <p>The subdirectory in the NFS file system that is used to read data from the NFS source location or write data to the NFS destination. The NFS path should be a path that's exported by the NFS server, or a subdirectory of that path. The path should be such that it can be mounted by other NFS clients in your network.</p>
    /// <p>To see all the paths exported by your NFS server, run "<code>showmount -e nfs-server-name</code>" from an NFS client that has access to your server. You can specify any directory that appears in the results, and any subdirectory of that directory. Ensure that the NFS export is accessible without Kerberos authentication. </p>
    /// <p>To transfer all the data in the folder that you specified, DataSync must have permissions to read all the data. To ensure this, either configure the NFS export with <code>no_root_squash</code>, or ensure that the files you want DataSync to access have permissions that allow read access for all users. Doing either option enables the agent to read the files. For the agent to access directories, you must additionally enable all execute access.</p>
    /// <p>If you are copying data to or from your Snowcone device, see <a href="https://docs.aws.amazon.com/datasync/latest/userguide/create-nfs-location.html#nfs-on-snowcone">NFS Server on Snowcone</a> for more information.</p>
    /// <p>For information about NFS export configuration, see 18.7. The /etc/exports Configuration File in the Red Hat Enterprise Linux documentation.</p>
    pub fn subdirectory(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.subdirectory(input.into());
        self
    }
    /// <p>The subdirectory in the NFS file system that is used to read data from the NFS source location or write data to the NFS destination. The NFS path should be a path that's exported by the NFS server, or a subdirectory of that path. The path should be such that it can be mounted by other NFS clients in your network.</p>
    /// <p>To see all the paths exported by your NFS server, run "<code>showmount -e nfs-server-name</code>" from an NFS client that has access to your server. You can specify any directory that appears in the results, and any subdirectory of that directory. Ensure that the NFS export is accessible without Kerberos authentication. </p>
    /// <p>To transfer all the data in the folder that you specified, DataSync must have permissions to read all the data. To ensure this, either configure the NFS export with <code>no_root_squash</code>, or ensure that the files you want DataSync to access have permissions that allow read access for all users. Doing either option enables the agent to read the files. For the agent to access directories, you must additionally enable all execute access.</p>
    /// <p>If you are copying data to or from your Snowcone device, see <a href="https://docs.aws.amazon.com/datasync/latest/userguide/create-nfs-location.html#nfs-on-snowcone">NFS Server on Snowcone</a> for more information.</p>
    /// <p>For information about NFS export configuration, see 18.7. The /etc/exports Configuration File in the Red Hat Enterprise Linux documentation.</p>
    pub fn set_subdirectory(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_subdirectory(input);
        self
    }
    /// <p>A list of Amazon Resource Names (ARNs) of agents to use for a Network File System (NFS) location.</p>
    pub fn on_prem_config(mut self, input: crate::types::OnPremConfig) -> Self {
        self.inner = self.inner.on_prem_config(input);
        self
    }
    /// <p>A list of Amazon Resource Names (ARNs) of agents to use for a Network File System (NFS) location.</p>
    pub fn set_on_prem_config(
        mut self,
        input: std::option::Option<crate::types::OnPremConfig>,
    ) -> Self {
        self.inner = self.inner.set_on_prem_config(input);
        self
    }
    /// <p>Specifies how DataSync can access a location using the NFS protocol.</p>
    pub fn mount_options(mut self, input: crate::types::NfsMountOptions) -> Self {
        self.inner = self.inner.mount_options(input);
        self
    }
    /// <p>Specifies how DataSync can access a location using the NFS protocol.</p>
    pub fn set_mount_options(
        mut self,
        input: std::option::Option<crate::types::NfsMountOptions>,
    ) -> Self {
        self.inner = self.inner.set_mount_options(input);
        self
    }
}
