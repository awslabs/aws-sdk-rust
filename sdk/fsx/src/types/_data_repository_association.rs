// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>The configuration of a data repository association that links an Amazon FSx for Lustre file system to an Amazon S3 bucket or an Amazon File Cache resource to an Amazon S3 bucket or an NFS file system. The data repository association configuration object is returned in the response of the following operations:</p> 
/// <ul> 
/// <li> <p> <code>CreateDataRepositoryAssociation</code> </p> </li> 
/// <li> <p> <code>UpdateDataRepositoryAssociation</code> </p> </li> 
/// <li> <p> <code>DescribeDataRepositoryAssociations</code> </p> </li> 
/// </ul> 
/// <p>Data repository associations are supported only for an Amazon FSx for Lustre file system with the <code>Persistent_2</code> deployment type and for an Amazon File Cache resource.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DataRepositoryAssociation  {
    /// <p>The system-generated, unique ID of the data repository association.</p>
    #[doc(hidden)]
    pub association_id: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) for a given resource. ARNs uniquely identify Amazon Web Services resources. We require an ARN when you need to specify a resource unambiguously across all of Amazon Web Services. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs)</a> in the <i>Amazon Web Services General Reference</i>.</p>
    #[doc(hidden)]
    pub resource_arn: std::option::Option<std::string::String>,
    /// <p>The globally unique ID of the file system, assigned by Amazon FSx.</p>
    #[doc(hidden)]
    pub file_system_id: std::option::Option<std::string::String>,
    /// <p>Describes the state of a data repository association. The lifecycle can have the following values:</p> 
    /// <ul> 
    /// <li> <p> <code>CREATING</code> - The data repository association between the file system or cache and the data repository is being created. The data repository is unavailable.</p> </li> 
    /// <li> <p> <code>AVAILABLE</code> - The data repository association is available for use.</p> </li> 
    /// <li> <p> <code>MISCONFIGURED</code> - The data repository association is misconfigured. Until the configuration is corrected, automatic import and automatic export will not work (only for Amazon FSx for Lustre).</p> </li> 
    /// <li> <p> <code>UPDATING</code> - The data repository association is undergoing a customer initiated update that might affect its availability.</p> </li> 
    /// <li> <p> <code>DELETING</code> - The data repository association is undergoing a customer initiated deletion.</p> </li> 
    /// <li> <p> <code>FAILED</code> - The data repository association is in a terminal state that cannot be recovered.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub lifecycle: std::option::Option<crate::types::DataRepositoryLifecycle>,
    /// <p>Provides detailed information about the data repository if its <code>Lifecycle</code> is set to <code>MISCONFIGURED</code> or <code>FAILED</code>.</p>
    #[doc(hidden)]
    pub failure_details: std::option::Option<crate::types::DataRepositoryFailureDetails>,
    /// <p>A path on the Amazon FSx for Lustre file system that points to a high-level directory (such as <code>/ns1/</code>) or subdirectory (such as <code>/ns1/subdir/</code>) that will be mapped 1-1 with <code>DataRepositoryPath</code>. The leading forward slash in the name is required. Two data repository associations cannot have overlapping file system paths. For example, if a data repository is associated with file system path <code>/ns1/</code>, then you cannot link another data repository with file system path <code>/ns1/ns2</code>.</p> 
    /// <p>This path specifies where in your file system files will be exported from or imported to. This file system directory can be linked to only one Amazon S3 bucket, and no other S3 bucket can be linked to the directory.</p> <note> 
    /// <p>If you specify only a forward slash (<code>/</code>) as the file system path, you can link only one data repository to the file system. You can only specify "/" as the file system path for the first data repository associated with a file system.</p> 
    /// </note>
    #[doc(hidden)]
    pub file_system_path: std::option::Option<std::string::String>,
    /// <p>The path to the data repository that will be linked to the cache or file system.</p> 
    /// <ul> 
    /// <li> <p>For Amazon File Cache, the path can be an NFS data repository that will be linked to the cache. The path can be in one of two formats:</p> 
    /// <ul> 
    /// <li> <p>If you are not using the <code>DataRepositorySubdirectories</code> parameter, the path is to an NFS Export directory (or one of its subdirectories) in the format <code>nsf://nfs-domain-name/exportpath</code>. You can therefore link a single NFS Export to a single data repository association.</p> </li> 
    /// <li> <p>If you are using the <code>DataRepositorySubdirectories</code> parameter, the path is the domain name of the NFS file system in the format <code>nfs://filer-domain-name</code>, which indicates the root of the subdirectories specified with the <code>DataRepositorySubdirectories</code> parameter.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>For Amazon File Cache, the path can be an S3 bucket or prefix in the format <code>s3://myBucket/myPrefix/</code>.</p> </li> 
    /// <li> <p>For Amazon FSx for Lustre, the path can be an S3 bucket or prefix in the format <code>s3://myBucket/myPrefix/</code>.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub data_repository_path: std::option::Option<std::string::String>,
    /// <p>A boolean flag indicating whether an import data repository task to import metadata should run after the data repository association is created. The task runs if this flag is set to <code>true</code>.</p> <note> 
    /// <p> <code>BatchImportMetaDataOnCreate</code> is not supported for data repositories linked to an Amazon File Cache resource.</p> 
    /// </note>
    #[doc(hidden)]
    pub batch_import_meta_data_on_create: std::option::Option<bool>,
    /// <p>For files imported from a data repository, this value determines the stripe count and maximum amount of data per file (in MiB) stored on a single physical disk. The maximum number of disks that a single file can be striped across is limited by the total number of disks that make up the file system or cache.</p> 
    /// <p>The default chunk size is 1,024 MiB (1 GiB) and can go as high as 512,000 MiB (500 GiB). Amazon S3 objects have a maximum size of 5 TB.</p>
    #[doc(hidden)]
    pub imported_file_chunk_size: std::option::Option<i32>,
    /// <p>The configuration for an Amazon S3 data repository linked to an Amazon FSx for Lustre file system with a data repository association.</p>
    #[doc(hidden)]
    pub s3: std::option::Option<crate::types::S3DataRepositoryConfiguration>,
    /// <p>A list of <code>Tag</code> values, with a maximum of 50 elements.</p>
    #[doc(hidden)]
    pub tags: std::option::Option<std::vec::Vec<crate::types::Tag>>,
    /// <p>The time that the resource was created, in seconds (since 1970-01-01T00:00:00Z), also known as Unix time.</p>
    #[doc(hidden)]
    pub creation_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The globally unique ID of the Amazon File Cache resource.</p>
    #[doc(hidden)]
    pub file_cache_id: std::option::Option<std::string::String>,
    /// <p>A path on the Amazon File Cache that points to a high-level directory (such as <code>/ns1/</code>) or subdirectory (such as <code>/ns1/subdir/</code>) that will be mapped 1-1 with <code>DataRepositoryPath</code>. The leading forward slash in the path is required. Two data repository associations cannot have overlapping cache paths. For example, if a data repository is associated with cache path <code>/ns1/</code>, then you cannot link another data repository with cache path <code>/ns1/ns2</code>.</p> 
    /// <p>This path specifies the directory in your cache where files will be exported from. This cache directory can be linked to only one data repository (S3 or NFS) and no other data repository can be linked to the directory.</p> <note> 
    /// <p>The cache path can only be set to root (/) on an NFS DRA when <code>DataRepositorySubdirectories</code> is specified. If you specify root (/) as the cache path, you can create only one DRA on the cache.</p> 
    /// <p>The cache path cannot be set to root (/) for an S3 DRA.</p> 
    /// </note>
    #[doc(hidden)]
    pub file_cache_path: std::option::Option<std::string::String>,
    /// <p>For Amazon File Cache, a list of NFS Exports that will be linked with an NFS data repository association. All the subdirectories must be on a single NFS file system. The Export paths are in the format <code>/exportpath1</code>. To use this parameter, you must configure <code>DataRepositoryPath</code> as the domain name of the NFS file system. The NFS file system domain name in effect is the root of the subdirectories. Note that <code>DataRepositorySubdirectories</code> is not supported for S3 data repositories.</p>
    #[doc(hidden)]
    pub data_repository_subdirectories: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>The configuration for an NFS data repository linked to an Amazon File Cache resource with a data repository association.</p>
    #[doc(hidden)]
    pub nfs: std::option::Option<crate::types::NfsDataRepositoryConfiguration>,
}
impl DataRepositoryAssociation {
    /// <p>The system-generated, unique ID of the data repository association.</p>
    pub fn association_id(&self) -> std::option::Option<& str> {
        self.association_id.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) for a given resource. ARNs uniquely identify Amazon Web Services resources. We require an ARN when you need to specify a resource unambiguously across all of Amazon Web Services. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs)</a> in the <i>Amazon Web Services General Reference</i>.</p>
    pub fn resource_arn(&self) -> std::option::Option<& str> {
        self.resource_arn.as_deref()
    }
    /// <p>The globally unique ID of the file system, assigned by Amazon FSx.</p>
    pub fn file_system_id(&self) -> std::option::Option<& str> {
        self.file_system_id.as_deref()
    }
    /// <p>Describes the state of a data repository association. The lifecycle can have the following values:</p> 
    /// <ul> 
    /// <li> <p> <code>CREATING</code> - The data repository association between the file system or cache and the data repository is being created. The data repository is unavailable.</p> </li> 
    /// <li> <p> <code>AVAILABLE</code> - The data repository association is available for use.</p> </li> 
    /// <li> <p> <code>MISCONFIGURED</code> - The data repository association is misconfigured. Until the configuration is corrected, automatic import and automatic export will not work (only for Amazon FSx for Lustre).</p> </li> 
    /// <li> <p> <code>UPDATING</code> - The data repository association is undergoing a customer initiated update that might affect its availability.</p> </li> 
    /// <li> <p> <code>DELETING</code> - The data repository association is undergoing a customer initiated deletion.</p> </li> 
    /// <li> <p> <code>FAILED</code> - The data repository association is in a terminal state that cannot be recovered.</p> </li> 
    /// </ul>
    pub fn lifecycle(&self) -> std::option::Option<& crate::types::DataRepositoryLifecycle> {
        self.lifecycle.as_ref()
    }
    /// <p>Provides detailed information about the data repository if its <code>Lifecycle</code> is set to <code>MISCONFIGURED</code> or <code>FAILED</code>.</p>
    pub fn failure_details(&self) -> std::option::Option<& crate::types::DataRepositoryFailureDetails> {
        self.failure_details.as_ref()
    }
    /// <p>A path on the Amazon FSx for Lustre file system that points to a high-level directory (such as <code>/ns1/</code>) or subdirectory (such as <code>/ns1/subdir/</code>) that will be mapped 1-1 with <code>DataRepositoryPath</code>. The leading forward slash in the name is required. Two data repository associations cannot have overlapping file system paths. For example, if a data repository is associated with file system path <code>/ns1/</code>, then you cannot link another data repository with file system path <code>/ns1/ns2</code>.</p> 
    /// <p>This path specifies where in your file system files will be exported from or imported to. This file system directory can be linked to only one Amazon S3 bucket, and no other S3 bucket can be linked to the directory.</p> <note> 
    /// <p>If you specify only a forward slash (<code>/</code>) as the file system path, you can link only one data repository to the file system. You can only specify "/" as the file system path for the first data repository associated with a file system.</p> 
    /// </note>
    pub fn file_system_path(&self) -> std::option::Option<& str> {
        self.file_system_path.as_deref()
    }
    /// <p>The path to the data repository that will be linked to the cache or file system.</p> 
    /// <ul> 
    /// <li> <p>For Amazon File Cache, the path can be an NFS data repository that will be linked to the cache. The path can be in one of two formats:</p> 
    /// <ul> 
    /// <li> <p>If you are not using the <code>DataRepositorySubdirectories</code> parameter, the path is to an NFS Export directory (or one of its subdirectories) in the format <code>nsf://nfs-domain-name/exportpath</code>. You can therefore link a single NFS Export to a single data repository association.</p> </li> 
    /// <li> <p>If you are using the <code>DataRepositorySubdirectories</code> parameter, the path is the domain name of the NFS file system in the format <code>nfs://filer-domain-name</code>, which indicates the root of the subdirectories specified with the <code>DataRepositorySubdirectories</code> parameter.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>For Amazon File Cache, the path can be an S3 bucket or prefix in the format <code>s3://myBucket/myPrefix/</code>.</p> </li> 
    /// <li> <p>For Amazon FSx for Lustre, the path can be an S3 bucket or prefix in the format <code>s3://myBucket/myPrefix/</code>.</p> </li> 
    /// </ul>
    pub fn data_repository_path(&self) -> std::option::Option<& str> {
        self.data_repository_path.as_deref()
    }
    /// <p>A boolean flag indicating whether an import data repository task to import metadata should run after the data repository association is created. The task runs if this flag is set to <code>true</code>.</p> <note> 
    /// <p> <code>BatchImportMetaDataOnCreate</code> is not supported for data repositories linked to an Amazon File Cache resource.</p> 
    /// </note>
    pub fn batch_import_meta_data_on_create(&self) -> std::option::Option<bool> {
        self.batch_import_meta_data_on_create
    }
    /// <p>For files imported from a data repository, this value determines the stripe count and maximum amount of data per file (in MiB) stored on a single physical disk. The maximum number of disks that a single file can be striped across is limited by the total number of disks that make up the file system or cache.</p> 
    /// <p>The default chunk size is 1,024 MiB (1 GiB) and can go as high as 512,000 MiB (500 GiB). Amazon S3 objects have a maximum size of 5 TB.</p>
    pub fn imported_file_chunk_size(&self) -> std::option::Option<i32> {
        self.imported_file_chunk_size
    }
    /// <p>The configuration for an Amazon S3 data repository linked to an Amazon FSx for Lustre file system with a data repository association.</p>
    pub fn s3(&self) -> std::option::Option<& crate::types::S3DataRepositoryConfiguration> {
        self.s3.as_ref()
    }
    /// <p>A list of <code>Tag</code> values, with a maximum of 50 elements.</p>
    pub fn tags(&self) -> std::option::Option<& [crate::types::Tag]> {
        self.tags.as_deref()
    }
    /// <p>The time that the resource was created, in seconds (since 1970-01-01T00:00:00Z), also known as Unix time.</p>
    pub fn creation_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.creation_time.as_ref()
    }
    /// <p>The globally unique ID of the Amazon File Cache resource.</p>
    pub fn file_cache_id(&self) -> std::option::Option<& str> {
        self.file_cache_id.as_deref()
    }
    /// <p>A path on the Amazon File Cache that points to a high-level directory (such as <code>/ns1/</code>) or subdirectory (such as <code>/ns1/subdir/</code>) that will be mapped 1-1 with <code>DataRepositoryPath</code>. The leading forward slash in the path is required. Two data repository associations cannot have overlapping cache paths. For example, if a data repository is associated with cache path <code>/ns1/</code>, then you cannot link another data repository with cache path <code>/ns1/ns2</code>.</p> 
    /// <p>This path specifies the directory in your cache where files will be exported from. This cache directory can be linked to only one data repository (S3 or NFS) and no other data repository can be linked to the directory.</p> <note> 
    /// <p>The cache path can only be set to root (/) on an NFS DRA when <code>DataRepositorySubdirectories</code> is specified. If you specify root (/) as the cache path, you can create only one DRA on the cache.</p> 
    /// <p>The cache path cannot be set to root (/) for an S3 DRA.</p> 
    /// </note>
    pub fn file_cache_path(&self) -> std::option::Option<& str> {
        self.file_cache_path.as_deref()
    }
    /// <p>For Amazon File Cache, a list of NFS Exports that will be linked with an NFS data repository association. All the subdirectories must be on a single NFS file system. The Export paths are in the format <code>/exportpath1</code>. To use this parameter, you must configure <code>DataRepositoryPath</code> as the domain name of the NFS file system. The NFS file system domain name in effect is the root of the subdirectories. Note that <code>DataRepositorySubdirectories</code> is not supported for S3 data repositories.</p>
    pub fn data_repository_subdirectories(&self) -> std::option::Option<& [std::string::String]> {
        self.data_repository_subdirectories.as_deref()
    }
    /// <p>The configuration for an NFS data repository linked to an Amazon File Cache resource with a data repository association.</p>
    pub fn nfs(&self) -> std::option::Option<& crate::types::NfsDataRepositoryConfiguration> {
        self.nfs.as_ref()
    }
}
impl DataRepositoryAssociation {
    /// Creates a new builder-style object to manufacture [`DataRepositoryAssociation`](crate::types::DataRepositoryAssociation).
    pub fn builder() -> crate::types::builders::DataRepositoryAssociationBuilder {
        crate::types::builders::DataRepositoryAssociationBuilder::default()
    }
}

/// A builder for [`DataRepositoryAssociation`](crate::types::DataRepositoryAssociation).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct DataRepositoryAssociationBuilder {
    pub(crate) association_id: std::option::Option<std::string::String>,
    pub(crate) resource_arn: std::option::Option<std::string::String>,
    pub(crate) file_system_id: std::option::Option<std::string::String>,
    pub(crate) lifecycle: std::option::Option<crate::types::DataRepositoryLifecycle>,
    pub(crate) failure_details: std::option::Option<crate::types::DataRepositoryFailureDetails>,
    pub(crate) file_system_path: std::option::Option<std::string::String>,
    pub(crate) data_repository_path: std::option::Option<std::string::String>,
    pub(crate) batch_import_meta_data_on_create: std::option::Option<bool>,
    pub(crate) imported_file_chunk_size: std::option::Option<i32>,
    pub(crate) s3: std::option::Option<crate::types::S3DataRepositoryConfiguration>,
    pub(crate) tags: std::option::Option<std::vec::Vec<crate::types::Tag>>,
    pub(crate) creation_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) file_cache_id: std::option::Option<std::string::String>,
    pub(crate) file_cache_path: std::option::Option<std::string::String>,
    pub(crate) data_repository_subdirectories: std::option::Option<std::vec::Vec<std::string::String>>,
    pub(crate) nfs: std::option::Option<crate::types::NfsDataRepositoryConfiguration>,
}
impl DataRepositoryAssociationBuilder {
    /// <p>The system-generated, unique ID of the data repository association.</p>
    pub fn association_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.association_id = Some(input.into());
        self
    }
    /// <p>The system-generated, unique ID of the data repository association.</p>
    pub fn set_association_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.association_id = input; self
    }
    /// <p>The Amazon Resource Name (ARN) for a given resource. ARNs uniquely identify Amazon Web Services resources. We require an ARN when you need to specify a resource unambiguously across all of Amazon Web Services. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs)</a> in the <i>Amazon Web Services General Reference</i>.</p>
    pub fn resource_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.resource_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) for a given resource. ARNs uniquely identify Amazon Web Services resources. We require an ARN when you need to specify a resource unambiguously across all of Amazon Web Services. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Names (ARNs)</a> in the <i>Amazon Web Services General Reference</i>.</p>
    pub fn set_resource_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.resource_arn = input; self
    }
    /// <p>The globally unique ID of the file system, assigned by Amazon FSx.</p>
    pub fn file_system_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.file_system_id = Some(input.into());
        self
    }
    /// <p>The globally unique ID of the file system, assigned by Amazon FSx.</p>
    pub fn set_file_system_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.file_system_id = input; self
    }
    /// <p>Describes the state of a data repository association. The lifecycle can have the following values:</p> 
    /// <ul> 
    /// <li> <p> <code>CREATING</code> - The data repository association between the file system or cache and the data repository is being created. The data repository is unavailable.</p> </li> 
    /// <li> <p> <code>AVAILABLE</code> - The data repository association is available for use.</p> </li> 
    /// <li> <p> <code>MISCONFIGURED</code> - The data repository association is misconfigured. Until the configuration is corrected, automatic import and automatic export will not work (only for Amazon FSx for Lustre).</p> </li> 
    /// <li> <p> <code>UPDATING</code> - The data repository association is undergoing a customer initiated update that might affect its availability.</p> </li> 
    /// <li> <p> <code>DELETING</code> - The data repository association is undergoing a customer initiated deletion.</p> </li> 
    /// <li> <p> <code>FAILED</code> - The data repository association is in a terminal state that cannot be recovered.</p> </li> 
    /// </ul>
    pub fn lifecycle(mut self, input: crate::types::DataRepositoryLifecycle) -> Self {
        self.lifecycle = Some(input);
        self
    }
    /// <p>Describes the state of a data repository association. The lifecycle can have the following values:</p> 
    /// <ul> 
    /// <li> <p> <code>CREATING</code> - The data repository association between the file system or cache and the data repository is being created. The data repository is unavailable.</p> </li> 
    /// <li> <p> <code>AVAILABLE</code> - The data repository association is available for use.</p> </li> 
    /// <li> <p> <code>MISCONFIGURED</code> - The data repository association is misconfigured. Until the configuration is corrected, automatic import and automatic export will not work (only for Amazon FSx for Lustre).</p> </li> 
    /// <li> <p> <code>UPDATING</code> - The data repository association is undergoing a customer initiated update that might affect its availability.</p> </li> 
    /// <li> <p> <code>DELETING</code> - The data repository association is undergoing a customer initiated deletion.</p> </li> 
    /// <li> <p> <code>FAILED</code> - The data repository association is in a terminal state that cannot be recovered.</p> </li> 
    /// </ul>
    pub fn set_lifecycle(mut self, input: std::option::Option<crate::types::DataRepositoryLifecycle>) -> Self {
        self.lifecycle = input; self
    }
    /// <p>Provides detailed information about the data repository if its <code>Lifecycle</code> is set to <code>MISCONFIGURED</code> or <code>FAILED</code>.</p>
    pub fn failure_details(mut self, input: crate::types::DataRepositoryFailureDetails) -> Self {
        self.failure_details = Some(input);
        self
    }
    /// <p>Provides detailed information about the data repository if its <code>Lifecycle</code> is set to <code>MISCONFIGURED</code> or <code>FAILED</code>.</p>
    pub fn set_failure_details(mut self, input: std::option::Option<crate::types::DataRepositoryFailureDetails>) -> Self {
        self.failure_details = input; self
    }
    /// <p>A path on the Amazon FSx for Lustre file system that points to a high-level directory (such as <code>/ns1/</code>) or subdirectory (such as <code>/ns1/subdir/</code>) that will be mapped 1-1 with <code>DataRepositoryPath</code>. The leading forward slash in the name is required. Two data repository associations cannot have overlapping file system paths. For example, if a data repository is associated with file system path <code>/ns1/</code>, then you cannot link another data repository with file system path <code>/ns1/ns2</code>.</p> 
    /// <p>This path specifies where in your file system files will be exported from or imported to. This file system directory can be linked to only one Amazon S3 bucket, and no other S3 bucket can be linked to the directory.</p> <note> 
    /// <p>If you specify only a forward slash (<code>/</code>) as the file system path, you can link only one data repository to the file system. You can only specify "/" as the file system path for the first data repository associated with a file system.</p> 
    /// </note>
    pub fn file_system_path(mut self, input: impl Into<std::string::String>) -> Self {
        self.file_system_path = Some(input.into());
        self
    }
    /// <p>A path on the Amazon FSx for Lustre file system that points to a high-level directory (such as <code>/ns1/</code>) or subdirectory (such as <code>/ns1/subdir/</code>) that will be mapped 1-1 with <code>DataRepositoryPath</code>. The leading forward slash in the name is required. Two data repository associations cannot have overlapping file system paths. For example, if a data repository is associated with file system path <code>/ns1/</code>, then you cannot link another data repository with file system path <code>/ns1/ns2</code>.</p> 
    /// <p>This path specifies where in your file system files will be exported from or imported to. This file system directory can be linked to only one Amazon S3 bucket, and no other S3 bucket can be linked to the directory.</p> <note> 
    /// <p>If you specify only a forward slash (<code>/</code>) as the file system path, you can link only one data repository to the file system. You can only specify "/" as the file system path for the first data repository associated with a file system.</p> 
    /// </note>
    pub fn set_file_system_path(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.file_system_path = input; self
    }
    /// <p>The path to the data repository that will be linked to the cache or file system.</p> 
    /// <ul> 
    /// <li> <p>For Amazon File Cache, the path can be an NFS data repository that will be linked to the cache. The path can be in one of two formats:</p> 
    /// <ul> 
    /// <li> <p>If you are not using the <code>DataRepositorySubdirectories</code> parameter, the path is to an NFS Export directory (or one of its subdirectories) in the format <code>nsf://nfs-domain-name/exportpath</code>. You can therefore link a single NFS Export to a single data repository association.</p> </li> 
    /// <li> <p>If you are using the <code>DataRepositorySubdirectories</code> parameter, the path is the domain name of the NFS file system in the format <code>nfs://filer-domain-name</code>, which indicates the root of the subdirectories specified with the <code>DataRepositorySubdirectories</code> parameter.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>For Amazon File Cache, the path can be an S3 bucket or prefix in the format <code>s3://myBucket/myPrefix/</code>.</p> </li> 
    /// <li> <p>For Amazon FSx for Lustre, the path can be an S3 bucket or prefix in the format <code>s3://myBucket/myPrefix/</code>.</p> </li> 
    /// </ul>
    pub fn data_repository_path(mut self, input: impl Into<std::string::String>) -> Self {
        self.data_repository_path = Some(input.into());
        self
    }
    /// <p>The path to the data repository that will be linked to the cache or file system.</p> 
    /// <ul> 
    /// <li> <p>For Amazon File Cache, the path can be an NFS data repository that will be linked to the cache. The path can be in one of two formats:</p> 
    /// <ul> 
    /// <li> <p>If you are not using the <code>DataRepositorySubdirectories</code> parameter, the path is to an NFS Export directory (or one of its subdirectories) in the format <code>nsf://nfs-domain-name/exportpath</code>. You can therefore link a single NFS Export to a single data repository association.</p> </li> 
    /// <li> <p>If you are using the <code>DataRepositorySubdirectories</code> parameter, the path is the domain name of the NFS file system in the format <code>nfs://filer-domain-name</code>, which indicates the root of the subdirectories specified with the <code>DataRepositorySubdirectories</code> parameter.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>For Amazon File Cache, the path can be an S3 bucket or prefix in the format <code>s3://myBucket/myPrefix/</code>.</p> </li> 
    /// <li> <p>For Amazon FSx for Lustre, the path can be an S3 bucket or prefix in the format <code>s3://myBucket/myPrefix/</code>.</p> </li> 
    /// </ul>
    pub fn set_data_repository_path(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.data_repository_path = input; self
    }
    /// <p>A boolean flag indicating whether an import data repository task to import metadata should run after the data repository association is created. The task runs if this flag is set to <code>true</code>.</p> <note> 
    /// <p> <code>BatchImportMetaDataOnCreate</code> is not supported for data repositories linked to an Amazon File Cache resource.</p> 
    /// </note>
    pub fn batch_import_meta_data_on_create(mut self, input: bool) -> Self {
        self.batch_import_meta_data_on_create = Some(input);
        self
    }
    /// <p>A boolean flag indicating whether an import data repository task to import metadata should run after the data repository association is created. The task runs if this flag is set to <code>true</code>.</p> <note> 
    /// <p> <code>BatchImportMetaDataOnCreate</code> is not supported for data repositories linked to an Amazon File Cache resource.</p> 
    /// </note>
    pub fn set_batch_import_meta_data_on_create(mut self, input: std::option::Option<bool>) -> Self {
        self.batch_import_meta_data_on_create = input; self
    }
    /// <p>For files imported from a data repository, this value determines the stripe count and maximum amount of data per file (in MiB) stored on a single physical disk. The maximum number of disks that a single file can be striped across is limited by the total number of disks that make up the file system or cache.</p> 
    /// <p>The default chunk size is 1,024 MiB (1 GiB) and can go as high as 512,000 MiB (500 GiB). Amazon S3 objects have a maximum size of 5 TB.</p>
    pub fn imported_file_chunk_size(mut self, input: i32) -> Self {
        self.imported_file_chunk_size = Some(input);
        self
    }
    /// <p>For files imported from a data repository, this value determines the stripe count and maximum amount of data per file (in MiB) stored on a single physical disk. The maximum number of disks that a single file can be striped across is limited by the total number of disks that make up the file system or cache.</p> 
    /// <p>The default chunk size is 1,024 MiB (1 GiB) and can go as high as 512,000 MiB (500 GiB). Amazon S3 objects have a maximum size of 5 TB.</p>
    pub fn set_imported_file_chunk_size(mut self, input: std::option::Option<i32>) -> Self {
        self.imported_file_chunk_size = input; self
    }
    /// <p>The configuration for an Amazon S3 data repository linked to an Amazon FSx for Lustre file system with a data repository association.</p>
    pub fn s3(mut self, input: crate::types::S3DataRepositoryConfiguration) -> Self {
        self.s3 = Some(input);
        self
    }
    /// <p>The configuration for an Amazon S3 data repository linked to an Amazon FSx for Lustre file system with a data repository association.</p>
    pub fn set_s3(mut self, input: std::option::Option<crate::types::S3DataRepositoryConfiguration>) -> Self {
        self.s3 = input; self
    }
    /// Appends an item to `tags`.
    ///
    /// To override the contents of this collection use [`set_tags`](Self::set_tags).
    ///
    /// <p>A list of <code>Tag</code> values, with a maximum of 50 elements.</p>
    pub fn tags(mut self, input: crate::types::Tag) -> Self {
        let mut v = self.tags.unwrap_or_default();
                        v.push(input);
                        self.tags = Some(v);
                        self
    }
    /// <p>A list of <code>Tag</code> values, with a maximum of 50 elements.</p>
    pub fn set_tags(mut self, input: std::option::Option<std::vec::Vec<crate::types::Tag>>) -> Self {
        self.tags = input; self
    }
    /// <p>The time that the resource was created, in seconds (since 1970-01-01T00:00:00Z), also known as Unix time.</p>
    pub fn creation_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.creation_time = Some(input);
        self
    }
    /// <p>The time that the resource was created, in seconds (since 1970-01-01T00:00:00Z), also known as Unix time.</p>
    pub fn set_creation_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.creation_time = input; self
    }
    /// <p>The globally unique ID of the Amazon File Cache resource.</p>
    pub fn file_cache_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.file_cache_id = Some(input.into());
        self
    }
    /// <p>The globally unique ID of the Amazon File Cache resource.</p>
    pub fn set_file_cache_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.file_cache_id = input; self
    }
    /// <p>A path on the Amazon File Cache that points to a high-level directory (such as <code>/ns1/</code>) or subdirectory (such as <code>/ns1/subdir/</code>) that will be mapped 1-1 with <code>DataRepositoryPath</code>. The leading forward slash in the path is required. Two data repository associations cannot have overlapping cache paths. For example, if a data repository is associated with cache path <code>/ns1/</code>, then you cannot link another data repository with cache path <code>/ns1/ns2</code>.</p> 
    /// <p>This path specifies the directory in your cache where files will be exported from. This cache directory can be linked to only one data repository (S3 or NFS) and no other data repository can be linked to the directory.</p> <note> 
    /// <p>The cache path can only be set to root (/) on an NFS DRA when <code>DataRepositorySubdirectories</code> is specified. If you specify root (/) as the cache path, you can create only one DRA on the cache.</p> 
    /// <p>The cache path cannot be set to root (/) for an S3 DRA.</p> 
    /// </note>
    pub fn file_cache_path(mut self, input: impl Into<std::string::String>) -> Self {
        self.file_cache_path = Some(input.into());
        self
    }
    /// <p>A path on the Amazon File Cache that points to a high-level directory (such as <code>/ns1/</code>) or subdirectory (such as <code>/ns1/subdir/</code>) that will be mapped 1-1 with <code>DataRepositoryPath</code>. The leading forward slash in the path is required. Two data repository associations cannot have overlapping cache paths. For example, if a data repository is associated with cache path <code>/ns1/</code>, then you cannot link another data repository with cache path <code>/ns1/ns2</code>.</p> 
    /// <p>This path specifies the directory in your cache where files will be exported from. This cache directory can be linked to only one data repository (S3 or NFS) and no other data repository can be linked to the directory.</p> <note> 
    /// <p>The cache path can only be set to root (/) on an NFS DRA when <code>DataRepositorySubdirectories</code> is specified. If you specify root (/) as the cache path, you can create only one DRA on the cache.</p> 
    /// <p>The cache path cannot be set to root (/) for an S3 DRA.</p> 
    /// </note>
    pub fn set_file_cache_path(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.file_cache_path = input; self
    }
    /// Appends an item to `data_repository_subdirectories`.
    ///
    /// To override the contents of this collection use [`set_data_repository_subdirectories`](Self::set_data_repository_subdirectories).
    ///
    /// <p>For Amazon File Cache, a list of NFS Exports that will be linked with an NFS data repository association. All the subdirectories must be on a single NFS file system. The Export paths are in the format <code>/exportpath1</code>. To use this parameter, you must configure <code>DataRepositoryPath</code> as the domain name of the NFS file system. The NFS file system domain name in effect is the root of the subdirectories. Note that <code>DataRepositorySubdirectories</code> is not supported for S3 data repositories.</p>
    pub fn data_repository_subdirectories(mut self, input: impl Into<std::string::String>) -> Self {
        let mut v = self.data_repository_subdirectories.unwrap_or_default();
                        v.push(input.into());
                        self.data_repository_subdirectories = Some(v);
                        self
    }
    /// <p>For Amazon File Cache, a list of NFS Exports that will be linked with an NFS data repository association. All the subdirectories must be on a single NFS file system. The Export paths are in the format <code>/exportpath1</code>. To use this parameter, you must configure <code>DataRepositoryPath</code> as the domain name of the NFS file system. The NFS file system domain name in effect is the root of the subdirectories. Note that <code>DataRepositorySubdirectories</code> is not supported for S3 data repositories.</p>
    pub fn set_data_repository_subdirectories(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
        self.data_repository_subdirectories = input; self
    }
    /// <p>The configuration for an NFS data repository linked to an Amazon File Cache resource with a data repository association.</p>
    pub fn nfs(mut self, input: crate::types::NfsDataRepositoryConfiguration) -> Self {
        self.nfs = Some(input);
        self
    }
    /// <p>The configuration for an NFS data repository linked to an Amazon File Cache resource with a data repository association.</p>
    pub fn set_nfs(mut self, input: std::option::Option<crate::types::NfsDataRepositoryConfiguration>) -> Self {
        self.nfs = input; self
    }
    /// Consumes the builder and constructs a [`DataRepositoryAssociation`](crate::types::DataRepositoryAssociation).
    pub fn build(self) -> crate::types::DataRepositoryAssociation {
        crate::types::DataRepositoryAssociation {
            association_id: self.association_id
            ,
            resource_arn: self.resource_arn
            ,
            file_system_id: self.file_system_id
            ,
            lifecycle: self.lifecycle
            ,
            failure_details: self.failure_details
            ,
            file_system_path: self.file_system_path
            ,
            data_repository_path: self.data_repository_path
            ,
            batch_import_meta_data_on_create: self.batch_import_meta_data_on_create
            ,
            imported_file_chunk_size: self.imported_file_chunk_size
            ,
            s3: self.s3
            ,
            tags: self.tags
            ,
            creation_time: self.creation_time
            ,
            file_cache_id: self.file_cache_id
            ,
            file_cache_path: self.file_cache_path
            ,
            data_repository_subdirectories: self.data_repository_subdirectories
            ,
            nfs: self.nfs
            ,
        }
    }
}

