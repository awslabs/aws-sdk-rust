// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client  {
    /// Constructs a fluent builder for the [`CreateDatasetImportJob`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder) operation.
                            ///
                            /// - The fluent builder is configurable:
    ///   - [`job_name(impl Into<String>)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::job_name) / [`set_job_name(Option<String>)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::set_job_name): <p>The name for the dataset import job.</p>
    ///   - [`dataset_arn(impl Into<String>)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::dataset_arn) / [`set_dataset_arn(Option<String>)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::set_dataset_arn): <p>The ARN of the dataset that receives the imported data.</p>
    ///   - [`data_source(DataSource)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::data_source) / [`set_data_source(Option<DataSource>)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::set_data_source): <p>The Amazon S3 bucket that contains the training data to import.</p>
    ///   - [`role_arn(impl Into<String>)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::role_arn) / [`set_role_arn(Option<String>)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::set_role_arn): <p>The ARN of the IAM role that has permissions to read from the Amazon S3 data source.</p>
    ///   - [`tags(Vec<Tag>)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::tags) / [`set_tags(Option<Vec<Tag>>)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::set_tags): <p>A list of <a href="https://docs.aws.amazon.com/personalize/latest/dev/tagging-resources.html">tags</a> to apply to the dataset import job.</p>
    ///   - [`import_mode(ImportMode)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::import_mode) / [`set_import_mode(Option<ImportMode>)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::set_import_mode): <p>Specify how to add the new records to an existing dataset. The default import mode is <code>FULL</code>. If you haven't imported bulk records into the dataset previously, you can only specify <code>FULL</code>.</p>  <ul>   <li> <p>Specify <code>FULL</code> to overwrite all existing bulk data in your dataset. Data you imported individually is not replaced.</p> </li>   <li> <p>Specify <code>INCREMENTAL</code> to append the new records to the existing data in your dataset. Amazon Personalize replaces any record with the same ID with the new one.</p> </li>  </ul>
    ///   - [`publish_attribution_metrics_to_s3(bool)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::publish_attribution_metrics_to_s3) / [`set_publish_attribution_metrics_to_s3(Option<bool>)`](crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::set_publish_attribution_metrics_to_s3): <p>If you created a metric attribution, specify whether to publish metrics for this import job to Amazon S3</p>
                            /// - On success, responds with [`CreateDatasetImportJobOutput`](crate::operation::create_dataset_import_job::CreateDatasetImportJobOutput) with field(s):
    ///   - [`dataset_import_job_arn(Option<String>)`](crate::operation::create_dataset_import_job::CreateDatasetImportJobOutput::dataset_import_job_arn): <p>The ARN of the dataset import job.</p>
                            /// - On failure, responds with [`SdkError<CreateDatasetImportJobError>`](crate::operation::create_dataset_import_job::CreateDatasetImportJobError)
    pub fn create_dataset_import_job(&self) -> crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder {
                                crate::operation::create_dataset_import_job::builders::CreateDatasetImportJobFluentBuilder::new(self.handle.clone())
                            }
}

