// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// When writing a match expression against `ToxicContentType`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
///
/// Here is an example of how you can make a match expression forward-compatible:
///
/// ```text
/// # let toxiccontenttype = unimplemented!();
/// match toxiccontenttype {
///     ToxicContentType::Graphic => { /* ... */ },
///     ToxicContentType::HarassmentOrAbuse => { /* ... */ },
///     ToxicContentType::HateSpeech => { /* ... */ },
///     ToxicContentType::Insult => { /* ... */ },
///     ToxicContentType::Profanity => { /* ... */ },
///     ToxicContentType::Sexual => { /* ... */ },
///     ToxicContentType::ViolenceOrThreat => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `toxiccontenttype` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `ToxicContentType::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `ToxicContentType::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `ToxicContentType::NewFeature` is defined.
/// Specifically, when `toxiccontenttype` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `ToxicContentType::NewFeature` also yielding `"NewFeature"`.
///
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
///
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(
    ::std::clone::Clone, ::std::cmp::Eq, ::std::cmp::Ord, ::std::cmp::PartialEq, ::std::cmp::PartialOrd, ::std::fmt::Debug, ::std::hash::Hash,
)]
pub enum ToxicContentType {
    #[allow(missing_docs)] // documentation missing in model
    Graphic,
    #[allow(missing_docs)] // documentation missing in model
    HarassmentOrAbuse,
    #[allow(missing_docs)] // documentation missing in model
    HateSpeech,
    #[allow(missing_docs)] // documentation missing in model
    Insult,
    #[allow(missing_docs)] // documentation missing in model
    Profanity,
    #[allow(missing_docs)] // documentation missing in model
    Sexual,
    #[allow(missing_docs)] // documentation missing in model
    ViolenceOrThreat,
    /// `Unknown` contains new variants that have been added since this code was generated.
    #[deprecated(note = "Don't directly match on `Unknown`. See the docs on this enum for the correct way to handle unknown variants.")]
    Unknown(crate::primitives::sealed_enum_unknown::UnknownVariantValue),
}
impl ::std::convert::From<&str> for ToxicContentType {
    fn from(s: &str) -> Self {
        match s {
            "GRAPHIC" => ToxicContentType::Graphic,
            "HARASSMENT_OR_ABUSE" => ToxicContentType::HarassmentOrAbuse,
            "HATE_SPEECH" => ToxicContentType::HateSpeech,
            "INSULT" => ToxicContentType::Insult,
            "PROFANITY" => ToxicContentType::Profanity,
            "SEXUAL" => ToxicContentType::Sexual,
            "VIOLENCE_OR_THREAT" => ToxicContentType::ViolenceOrThreat,
            other => ToxicContentType::Unknown(crate::primitives::sealed_enum_unknown::UnknownVariantValue(other.to_owned())),
        }
    }
}
impl ::std::str::FromStr for ToxicContentType {
    type Err = ::std::convert::Infallible;

    fn from_str(s: &str) -> ::std::result::Result<Self, <Self as ::std::str::FromStr>::Err> {
        ::std::result::Result::Ok(ToxicContentType::from(s))
    }
}
impl ToxicContentType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            ToxicContentType::Graphic => "GRAPHIC",
            ToxicContentType::HarassmentOrAbuse => "HARASSMENT_OR_ABUSE",
            ToxicContentType::HateSpeech => "HATE_SPEECH",
            ToxicContentType::Insult => "INSULT",
            ToxicContentType::Profanity => "PROFANITY",
            ToxicContentType::Sexual => "SEXUAL",
            ToxicContentType::ViolenceOrThreat => "VIOLENCE_OR_THREAT",
            ToxicContentType::Unknown(value) => value.as_str(),
        }
    }
    /// Returns all the `&str` representations of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "GRAPHIC",
            "HARASSMENT_OR_ABUSE",
            "HATE_SPEECH",
            "INSULT",
            "PROFANITY",
            "SEXUAL",
            "VIOLENCE_OR_THREAT",
        ]
    }
}
impl ::std::convert::AsRef<str> for ToxicContentType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}
impl ToxicContentType {
    /// Parses the enum value while disallowing unknown variants.
    ///
    /// Unknown variants will result in an error.
    pub fn try_parse(value: &str) -> ::std::result::Result<Self, crate::error::UnknownVariantError> {
        match Self::from(value) {
            #[allow(deprecated)]
            Self::Unknown(_) => ::std::result::Result::Err(crate::error::UnknownVariantError::new(value)),
            known => Ok(known),
        }
    }
}
impl ::std::fmt::Display for ToxicContentType {
    fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {
        match self {
            ToxicContentType::Graphic => write!(f, "GRAPHIC"),
            ToxicContentType::HarassmentOrAbuse => write!(f, "HARASSMENT_OR_ABUSE"),
            ToxicContentType::HateSpeech => write!(f, "HATE_SPEECH"),
            ToxicContentType::Insult => write!(f, "INSULT"),
            ToxicContentType::Profanity => write!(f, "PROFANITY"),
            ToxicContentType::Sexual => write!(f, "SEXUAL"),
            ToxicContentType::ViolenceOrThreat => write!(f, "VIOLENCE_OR_THREAT"),
            ToxicContentType::Unknown(value) => write!(f, "{value}"),
        }
    }
}
