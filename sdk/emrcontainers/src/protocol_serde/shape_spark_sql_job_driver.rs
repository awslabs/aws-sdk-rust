// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
pub fn ser_spark_sql_job_driver(object: &mut aws_smithy_json::serialize::JsonObjectWriter, input: &crate::types::SparkSqlJobDriver) -> Result<(), aws_smithy_http::operation::error::SerializationError> {
    if let Some(var_1) = &input.entry_point {
        object.key("entryPoint").string(var_1.as_str());
    }
    if let Some(var_2) = &input.spark_sql_parameters {
        object.key("sparkSqlParameters").string(var_2.as_str());
    }
    Ok(())
}

pub(crate) fn de_spark_sql_job_driver<'a, I>(tokens: &mut std::iter::Peekable<I>) -> Result<Option<crate::types::SparkSqlJobDriver>, aws_smithy_json::deserialize::error::DeserializeError>
                    where I: Iterator<Item = Result<aws_smithy_json::deserialize::Token<'a>, aws_smithy_json::deserialize::error::DeserializeError>> {
    match tokens.next().transpose()? {
        Some(aws_smithy_json::deserialize::Token::ValueNull { .. }) => Ok(None),
                        Some(aws_smithy_json::deserialize::Token::StartObject { .. }) => {
            #[allow(unused_mut)]
            let mut builder = crate::types::builders::SparkSqlJobDriverBuilder::default();
            loop {
                match tokens.next().transpose()? {
                    Some(aws_smithy_json::deserialize::Token::EndObject { .. }) => break,
                                            Some(aws_smithy_json::deserialize::Token::ObjectKey { key, .. }) => {
                        match key.to_unescaped()?.as_ref() {
                            "entryPoint" => {
                                builder = builder.set_entry_point(
                                    aws_smithy_json::deserialize::token::expect_string_or_null(tokens.next())?.map(|s|
                                        s.to_unescaped().map(|u|
                                            u.into_owned()
                                        )
                                    ).transpose()?
                                );
                            }
                            "sparkSqlParameters" => {
                                builder = builder.set_spark_sql_parameters(
                                    aws_smithy_json::deserialize::token::expect_string_or_null(tokens.next())?.map(|s|
                                        s.to_unescaped().map(|u|
                                            u.into_owned()
                                        )
                                    ).transpose()?
                                );
                            }
                            _ => aws_smithy_json::deserialize::token::skip_value(tokens)?
                        }
                    }
                    other => return Err(aws_smithy_json::deserialize::error::DeserializeError::custom(format!("expected object key or end object, found: {:?}", other)))
                }
            }
            Ok(Some(builder.build()))
        }
        _ => {
            Err(aws_smithy_json::deserialize::error::DeserializeError::custom("expected start object or null"))
        }
    }
}

