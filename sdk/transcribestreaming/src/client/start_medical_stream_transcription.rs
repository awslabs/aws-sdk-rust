// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`StartMedicalStreamTranscription`](crate::client::fluent_builders::StartMedicalStreamTranscription) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`language_code(LanguageCode)`](crate::client::fluent_builders::StartMedicalStreamTranscription::language_code) / [`set_language_code(Option<LanguageCode>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_language_code): <p>Specify the language code that represents the language spoken in your audio.</p> <important>   <p>Amazon Transcribe Medical only supports US English (<code>en-US</code>).</p>  </important>
    ///   - [`media_sample_rate_hertz(i32)`](crate::client::fluent_builders::StartMedicalStreamTranscription::media_sample_rate_hertz) / [`set_media_sample_rate_hertz(Option<i32>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_media_sample_rate_hertz): <p>The sample rate of the input audio (in hertz). Amazon Transcribe Medical supports a range from 16,000 Hz to 48,000 Hz. Note that the sample rate you specify must match that of your audio.</p>
    ///   - [`media_encoding(MediaEncoding)`](crate::client::fluent_builders::StartMedicalStreamTranscription::media_encoding) / [`set_media_encoding(Option<MediaEncoding>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_media_encoding): <p>Specify the encoding used for the input audio. Supported formats are:</p>  <ul>   <li> <p>FLAC</p> </li>   <li> <p>OPUS-encoded audio in an Ogg container</p> </li>   <li> <p>PCM (only signed 16-bit little-endian audio formats, which does not include WAV)</p> </li>  </ul>  <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-input.html#how-input-audio">Media formats</a>.</p>
    ///   - [`vocabulary_name(impl Into<String>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::vocabulary_name) / [`set_vocabulary_name(Option<String>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_vocabulary_name): <p>Specify the name of the custom vocabulary that you want to use when processing your transcription. Note that vocabulary names are case sensitive.</p>
    ///   - [`specialty(Specialty)`](crate::client::fluent_builders::StartMedicalStreamTranscription::specialty) / [`set_specialty(Option<Specialty>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_specialty): <p>Specify the medical specialty contained in your audio.</p>
    ///   - [`r#type(Type)`](crate::client::fluent_builders::StartMedicalStreamTranscription::type) / [`set_type(Option<Type>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_type): <p>Specify the type of input audio. For example, choose <code>DICTATION</code> for a provider dictating patient notes and <code>CONVERSATION</code> for a dialogue between a patient and a medical professional.</p>
    ///   - [`show_speaker_label(bool)`](crate::client::fluent_builders::StartMedicalStreamTranscription::show_speaker_label) / [`set_show_speaker_label(bool)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_show_speaker_label): <p>Enables speaker partitioning (diarization) in your transcription output. Speaker partitioning labels the speech from individual speakers in your media file.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Partitioning speakers (diarization)</a>.</p>
    ///   - [`session_id(impl Into<String>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::session_id) / [`set_session_id(Option<String>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_session_id): <p>Specify a name for your transcription session. If you don't include this parameter in your request, Amazon Transcribe Medical generates an ID and returns it in the response.</p>  <p>You can use a session ID to retry a streaming session.</p>
    ///   - [`audio_stream(EventStreamSender<crate::model::AudioStream, crate::error::AudioStreamError>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::audio_stream) / [`set_audio_stream(EventStreamSender<crate::model::AudioStream, crate::error::AudioStreamError>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_audio_stream): <p>An encoded stream of audio blobs. Audio streams are encoded as either HTTP/2 or WebSocket data frames.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html">Transcribing streaming audio</a>.</p>
    ///   - [`enable_channel_identification(bool)`](crate::client::fluent_builders::StartMedicalStreamTranscription::enable_channel_identification) / [`set_enable_channel_identification(bool)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_enable_channel_identification): <p>Enables channel identification in multi-channel audio.</p>  <p>Channel identification transcribes the audio on each channel independently, then appends the output for each channel into one transcript.</p>  <p>If you have multi-channel audio and do not enable channel identification, your audio is transcribed in a continuous manner and your transcript is not separated by channel.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/channel-id.html">Transcribing multi-channel audio</a>.</p>
    ///   - [`number_of_channels(i32)`](crate::client::fluent_builders::StartMedicalStreamTranscription::number_of_channels) / [`set_number_of_channels(Option<i32>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_number_of_channels): <p>Specify the number of channels in your audio stream. Up to two channels are supported.</p>
    ///   - [`content_identification_type(MedicalContentIdentificationType)`](crate::client::fluent_builders::StartMedicalStreamTranscription::content_identification_type) / [`set_content_identification_type(Option<MedicalContentIdentificationType>)`](crate::client::fluent_builders::StartMedicalStreamTranscription::set_content_identification_type): <p>Labels all personal health information (PHI) identified in your transcript.</p>  <p>Content identification is performed at the segment level; PHI is flagged upon complete transcription of an audio segment.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/phi-id.html">Identifying personal health information (PHI) in a transcription</a>.</p>
    /// - On success, responds with [`StartMedicalStreamTranscriptionOutput`](crate::output::StartMedicalStreamTranscriptionOutput) with field(s):
    ///   - [`request_id(Option<String>)`](crate::output::StartMedicalStreamTranscriptionOutput::request_id): <p>Provides the identifier for your streaming request.</p>
    ///   - [`language_code(Option<LanguageCode>)`](crate::output::StartMedicalStreamTranscriptionOutput::language_code): <p>Provides the language code that you specified in your request. This must be <code>en-US</code>.</p>
    ///   - [`media_sample_rate_hertz(Option<i32>)`](crate::output::StartMedicalStreamTranscriptionOutput::media_sample_rate_hertz): <p>Provides the sample rate that you specified in your request.</p>
    ///   - [`media_encoding(Option<MediaEncoding>)`](crate::output::StartMedicalStreamTranscriptionOutput::media_encoding): <p>Provides the media encoding you specified in your request.</p>
    ///   - [`vocabulary_name(Option<String>)`](crate::output::StartMedicalStreamTranscriptionOutput::vocabulary_name): <p>Provides the name of the custom vocabulary that you specified in your request.</p>
    ///   - [`specialty(Option<Specialty>)`](crate::output::StartMedicalStreamTranscriptionOutput::specialty): <p>Provides the medical specialty that you specified in your request.</p>
    ///   - [`r#type(Option<Type>)`](crate::output::StartMedicalStreamTranscriptionOutput::type): <p>Provides the type of audio you specified in your request.</p>
    ///   - [`show_speaker_label(bool)`](crate::output::StartMedicalStreamTranscriptionOutput::show_speaker_label): <p>Shows whether speaker partitioning was enabled for your transcription.</p>
    ///   - [`session_id(Option<String>)`](crate::output::StartMedicalStreamTranscriptionOutput::session_id): <p>Provides the identifier for your transcription session.</p>
    ///   - [`transcript_result_stream(Receiver<crate::model::MedicalTranscriptResultStream, crate::error::MedicalTranscriptResultStreamError>)`](crate::output::StartMedicalStreamTranscriptionOutput::transcript_result_stream): <p>Provides detailed information about your streaming session.</p>
    ///   - [`enable_channel_identification(bool)`](crate::output::StartMedicalStreamTranscriptionOutput::enable_channel_identification): <p>Shows whether channel identification was enabled for your transcription.</p>
    ///   - [`number_of_channels(Option<i32>)`](crate::output::StartMedicalStreamTranscriptionOutput::number_of_channels): <p>Provides the number of channels that you specified in your request.</p>
    ///   - [`content_identification_type(Option<MedicalContentIdentificationType>)`](crate::output::StartMedicalStreamTranscriptionOutput::content_identification_type): <p>Shows whether content identification was enabled for your transcription.</p>
    /// - On failure, responds with [`SdkError<StartMedicalStreamTranscriptionError>`](crate::error::StartMedicalStreamTranscriptionError)
    pub fn start_medical_stream_transcription(
        &self,
    ) -> crate::client::fluent_builders::StartMedicalStreamTranscription {
        crate::client::fluent_builders::StartMedicalStreamTranscription::new(self.handle.clone())
    }
}
