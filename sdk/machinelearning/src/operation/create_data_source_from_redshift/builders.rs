// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
pub use crate::operation::create_data_source_from_redshift::_create_data_source_from_redshift_output::CreateDataSourceFromRedshiftOutputBuilder;

pub use crate::operation::create_data_source_from_redshift::_create_data_source_from_redshift_input::CreateDataSourceFromRedshiftInputBuilder;

/// Fluent builder constructing a request to `CreateDataSourceFromRedshift`.
/// 
/// <p>Creates a <code>DataSource</code> from a database hosted on an Amazon Redshift cluster. A <code>DataSource</code> references data that can be used to perform either <code>CreateMLModel</code>, <code>CreateEvaluation</code>, or <code>CreateBatchPrediction</code> operations.</p> 
/// <p> <code>CreateDataSourceFromRedshift</code> is an asynchronous operation. In response to <code>CreateDataSourceFromRedshift</code>, Amazon Machine Learning (Amazon ML) immediately returns and sets the <code>DataSource</code> status to <code>PENDING</code>. After the <code>DataSource</code> is created and ready for use, Amazon ML sets the <code>Status</code> parameter to <code>COMPLETED</code>. <code>DataSource</code> in <code>COMPLETED</code> or <code>PENDING</code> states can be used to perform only <code>CreateMLModel</code>, <code>CreateEvaluation</code>, or <code>CreateBatchPrediction</code> operations. </p> 
/// <p> If Amazon ML can't accept the input source, it sets the <code>Status</code> parameter to <code>FAILED</code> and includes an error message in the <code>Message</code> attribute of the <code>GetDataSource</code> operation response. </p> 
/// <p>The observations should be contained in the database hosted on an Amazon Redshift cluster and should be specified by a <code>SelectSqlQuery</code> query. Amazon ML executes an <code>Unload</code> command in Amazon Redshift to transfer the result set of the <code>SelectSqlQuery</code> query to <code>S3StagingLocation</code>.</p> 
/// <p>After the <code>DataSource</code> has been created, it's ready for use in evaluations and batch predictions. If you plan to use the <code>DataSource</code> to train an <code>MLModel</code>, the <code>DataSource</code> also requires a recipe. A recipe describes how each input variable will be used in training an <code>MLModel</code>. Will the variable be included or excluded from training? Will the variable be manipulated; for example, will it be combined with another variable or will it be split apart into word combinations? The recipe provides answers to these questions.</p> 
/// <p>You can't change an existing datasource, but you can copy and modify the settings from an existing Amazon Redshift datasource to create a new datasource. To do so, call <code>GetDataSource</code> for an existing datasource and copy the values to a <code>CreateDataSource</code> call. Change the settings that you want to change and make sure that all required fields have the appropriate values.</p>
#[derive(std::clone::Clone, std::fmt::Debug)]
pub struct CreateDataSourceFromRedshiftFluentBuilder {
                handle: std::sync::Arc<crate::client::Handle>,
                inner: crate::operation::create_data_source_from_redshift::builders::CreateDataSourceFromRedshiftInputBuilder
            }
impl CreateDataSourceFromRedshiftFluentBuilder  {
    /// Creates a new `CreateDataSourceFromRedshift`.
                    pub(crate) fn new(handle: std::sync::Arc<crate::client::Handle>) -> Self {
                        Self { handle, inner: Default::default() }
                    }
    
                    /// Consume this builder, creating a customizable operation that can be modified before being
                    /// sent. The operation's inner [http::Request] can be modified as well.
                    pub async fn customize(self) -> std::result::Result<
                        crate::client::customize::CustomizableOperation<crate::operation::create_data_source_from_redshift::CreateDataSourceFromRedshift, aws_http::retry::AwsResponseRetryClassifier,>,
                        aws_smithy_http::result::SdkError<crate::operation::create_data_source_from_redshift::CreateDataSourceFromRedshiftError>
                    >  {
                        let handle = self.handle.clone();
                        let operation = self.inner.build().map_err(aws_smithy_http::result::SdkError::construction_failure)?
                            .make_operation(&handle.conf)
                            .await
                            .map_err(aws_smithy_http::result::SdkError::construction_failure)?;
                        Ok(crate::client::customize::CustomizableOperation { handle, operation })
                    }
    
                    /// Sends the request and returns the response.
                    ///
                    /// If an error occurs, an `SdkError` will be returned with additional details that
                    /// can be matched against.
                    ///
                    /// By default, any retryable failures will be retried twice. Retry behavior
                    /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
                    /// set when configuring the client.
                    pub async fn send(self) -> std::result::Result<crate::operation::create_data_source_from_redshift::CreateDataSourceFromRedshiftOutput, aws_smithy_http::result::SdkError<crate::operation::create_data_source_from_redshift::CreateDataSourceFromRedshiftError>>
                     {
                        let op = self.inner.build().map_err(aws_smithy_http::result::SdkError::construction_failure)?
                            .make_operation(&self.handle.conf)
                            .await
                            .map_err(aws_smithy_http::result::SdkError::construction_failure)?;
                        self.handle.client.call(op).await
                    }
    /// <p>A user-supplied ID that uniquely identifies the <code>DataSource</code>.</p>
    pub fn data_source_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.data_source_id(input.into());
        self
    }
    /// <p>A user-supplied ID that uniquely identifies the <code>DataSource</code>.</p>
    pub fn set_data_source_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_data_source_id(input);
        self
    }
    /// <p>A user-supplied name or description of the <code>DataSource</code>. </p>
    pub fn data_source_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.data_source_name(input.into());
        self
    }
    /// <p>A user-supplied name or description of the <code>DataSource</code>. </p>
    pub fn set_data_source_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_data_source_name(input);
        self
    }
    /// <p>The data specification of an Amazon Redshift <code>DataSource</code>:</p> 
    /// <ul> 
    /// <li> <p>DatabaseInformation -</p> 
    /// <ul> 
    /// <li> <p> <code>DatabaseName</code> - The name of the Amazon Redshift database.</p> </li> 
    /// <li> <p> <code> ClusterIdentifier</code> - The unique ID for the Amazon Redshift cluster.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>DatabaseCredentials - The AWS Identity and Access Management (IAM) credentials that are used to connect to the Amazon Redshift database.</p> </li> 
    /// <li> <p>SelectSqlQuery - The query that is used to retrieve the observation data for the <code>Datasource</code>.</p> </li> 
    /// <li> <p>S3StagingLocation - The Amazon Simple Storage Service (Amazon S3) location for staging Amazon Redshift data. The data retrieved from Amazon Redshift using the <code>SelectSqlQuery</code> query is stored in this location.</p> </li> 
    /// <li> <p>DataSchemaUri - The Amazon S3 location of the <code>DataSchema</code>.</p> </li> 
    /// <li> <p>DataSchema - A JSON string representing the schema. This is not required if <code>DataSchemaUri</code> is specified. </p> </li> 
    /// <li> <p>DataRearrangement - A JSON string that represents the splitting and rearrangement requirements for the <code>DataSource</code>.</p> <p> Sample - <code> "{\"splitting\":{\"percentBegin\":10,\"percentEnd\":60}}"</code> </p> </li> 
    /// </ul>
    pub fn data_spec(mut self, input: crate::types::RedshiftDataSpec) -> Self {
        self.inner = self.inner.data_spec(input);
        self
    }
    /// <p>The data specification of an Amazon Redshift <code>DataSource</code>:</p> 
    /// <ul> 
    /// <li> <p>DatabaseInformation -</p> 
    /// <ul> 
    /// <li> <p> <code>DatabaseName</code> - The name of the Amazon Redshift database.</p> </li> 
    /// <li> <p> <code> ClusterIdentifier</code> - The unique ID for the Amazon Redshift cluster.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>DatabaseCredentials - The AWS Identity and Access Management (IAM) credentials that are used to connect to the Amazon Redshift database.</p> </li> 
    /// <li> <p>SelectSqlQuery - The query that is used to retrieve the observation data for the <code>Datasource</code>.</p> </li> 
    /// <li> <p>S3StagingLocation - The Amazon Simple Storage Service (Amazon S3) location for staging Amazon Redshift data. The data retrieved from Amazon Redshift using the <code>SelectSqlQuery</code> query is stored in this location.</p> </li> 
    /// <li> <p>DataSchemaUri - The Amazon S3 location of the <code>DataSchema</code>.</p> </li> 
    /// <li> <p>DataSchema - A JSON string representing the schema. This is not required if <code>DataSchemaUri</code> is specified. </p> </li> 
    /// <li> <p>DataRearrangement - A JSON string that represents the splitting and rearrangement requirements for the <code>DataSource</code>.</p> <p> Sample - <code> "{\"splitting\":{\"percentBegin\":10,\"percentEnd\":60}}"</code> </p> </li> 
    /// </ul>
    pub fn set_data_spec(mut self, input: std::option::Option<crate::types::RedshiftDataSpec>) -> Self {
        self.inner = self.inner.set_data_spec(input);
        self
    }
    /// <p>A fully specified role Amazon Resource Name (ARN). Amazon ML assumes the role on behalf of the user to create the following:</p> 
    /// <ul> 
    /// <li> <p>A security group to allow Amazon ML to execute the <code>SelectSqlQuery</code> query on an Amazon Redshift cluster</p> </li> 
    /// <li> <p>An Amazon S3 bucket policy to grant Amazon ML read/write permissions on the <code>S3StagingLocation</code> </p> </li> 
    /// </ul>
    pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.role_arn(input.into());
        self
    }
    /// <p>A fully specified role Amazon Resource Name (ARN). Amazon ML assumes the role on behalf of the user to create the following:</p> 
    /// <ul> 
    /// <li> <p>A security group to allow Amazon ML to execute the <code>SelectSqlQuery</code> query on an Amazon Redshift cluster</p> </li> 
    /// <li> <p>An Amazon S3 bucket policy to grant Amazon ML read/write permissions on the <code>S3StagingLocation</code> </p> </li> 
    /// </ul>
    pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_role_arn(input);
        self
    }
    /// <p>The compute statistics for a <code>DataSource</code>. The statistics are generated from the observation data referenced by a <code>DataSource</code>. Amazon ML uses the statistics internally during <code>MLModel</code> training. This parameter must be set to <code>true</code> if the <code>DataSource</code> needs to be used for <code>MLModel</code> training.</p>
    pub fn compute_statistics(mut self, input: bool) -> Self {
        self.inner = self.inner.compute_statistics(input);
        self
    }
    /// <p>The compute statistics for a <code>DataSource</code>. The statistics are generated from the observation data referenced by a <code>DataSource</code>. Amazon ML uses the statistics internally during <code>MLModel</code> training. This parameter must be set to <code>true</code> if the <code>DataSource</code> needs to be used for <code>MLModel</code> training.</p>
    pub fn set_compute_statistics(mut self, input: std::option::Option<bool>) -> Self {
        self.inner = self.inner.set_compute_statistics(input);
        self
    }
}

