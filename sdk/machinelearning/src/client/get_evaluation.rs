// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client  {
    /// Constructs a fluent builder for the [`GetEvaluation`](crate::operation::get_evaluation::builders::GetEvaluationFluentBuilder) operation.
                            ///
                            /// - The fluent builder is configurable:
    ///   - [`evaluation_id(impl Into<String>)`](crate::operation::get_evaluation::builders::GetEvaluationFluentBuilder::evaluation_id) / [`set_evaluation_id(Option<String>)`](crate::operation::get_evaluation::builders::GetEvaluationFluentBuilder::set_evaluation_id): <p>The ID of the <code>Evaluation</code> to retrieve. The evaluation of each <code>MLModel</code> is recorded and cataloged. The ID provides the means to access the information. </p>
                            /// - On success, responds with [`GetEvaluationOutput`](crate::operation::get_evaluation::GetEvaluationOutput) with field(s):
    ///   - [`evaluation_id(Option<String>)`](crate::operation::get_evaluation::GetEvaluationOutput::evaluation_id): <p>The evaluation ID which is same as the <code>EvaluationId</code> in the request.</p>
    ///   - [`ml_model_id(Option<String>)`](crate::operation::get_evaluation::GetEvaluationOutput::ml_model_id): <p>The ID of the <code>MLModel</code> that was the focus of the evaluation.</p>
    ///   - [`evaluation_data_source_id(Option<String>)`](crate::operation::get_evaluation::GetEvaluationOutput::evaluation_data_source_id): <p>The <code>DataSource</code> used for this evaluation.</p>
    ///   - [`input_data_location_s3(Option<String>)`](crate::operation::get_evaluation::GetEvaluationOutput::input_data_location_s3): <p>The location of the data file or directory in Amazon Simple Storage Service (Amazon S3).</p>
    ///   - [`created_by_iam_user(Option<String>)`](crate::operation::get_evaluation::GetEvaluationOutput::created_by_iam_user): <p>The AWS user account that invoked the evaluation. The account type can be either an AWS root account or an AWS Identity and Access Management (IAM) user account.</p>
    ///   - [`created_at(Option<DateTime>)`](crate::operation::get_evaluation::GetEvaluationOutput::created_at): <p>The time that the <code>Evaluation</code> was created. The time is expressed in epoch time.</p>
    ///   - [`last_updated_at(Option<DateTime>)`](crate::operation::get_evaluation::GetEvaluationOutput::last_updated_at): <p>The time of the most recent edit to the <code>Evaluation</code>. The time is expressed in epoch time.</p>
    ///   - [`name(Option<String>)`](crate::operation::get_evaluation::GetEvaluationOutput::name): <p>A user-supplied name or description of the <code>Evaluation</code>. </p>
    ///   - [`status(Option<EntityStatus>)`](crate::operation::get_evaluation::GetEvaluationOutput::status): <p>The status of the evaluation. This element can have one of the following values:</p>  <ul>   <li> <p> <code>PENDING</code> - Amazon Machine Language (Amazon ML) submitted a request to evaluate an <code>MLModel</code>.</p> </li>   <li> <p> <code>INPROGRESS</code> - The evaluation is underway.</p> </li>   <li> <p> <code>FAILED</code> - The request to evaluate an <code>MLModel</code> did not run to completion. It is not usable.</p> </li>   <li> <p> <code>COMPLETED</code> - The evaluation process completed successfully.</p> </li>   <li> <p> <code>DELETED</code> - The <code>Evaluation</code> is marked as deleted. It is not usable.</p> </li>  </ul>
    ///   - [`performance_metrics(Option<PerformanceMetrics>)`](crate::operation::get_evaluation::GetEvaluationOutput::performance_metrics): <p>Measurements of how well the <code>MLModel</code> performed using observations referenced by the <code>DataSource</code>. One of the following metric is returned based on the type of the <code>MLModel</code>: </p>  <ul>   <li> <p>BinaryAUC: A binary <code>MLModel</code> uses the Area Under the Curve (AUC) technique to measure performance. </p> </li>   <li> <p>RegressionRMSE: A regression <code>MLModel</code> uses the Root Mean Square Error (RMSE) technique to measure performance. RMSE measures the difference between predicted and actual values for a single variable.</p> </li>   <li> <p>MulticlassAvgFScore: A multiclass <code>MLModel</code> uses the F1 score technique to measure performance. </p> </li>  </ul>  <p> For more information about performance metrics, please see the <a href="https://docs.aws.amazon.com/machine-learning/latest/dg">Amazon Machine Learning Developer Guide</a>. </p>
    ///   - [`log_uri(Option<String>)`](crate::operation::get_evaluation::GetEvaluationOutput::log_uri): <p>A link to the file that contains logs of the <code>CreateEvaluation</code> operation.</p>
    ///   - [`message(Option<String>)`](crate::operation::get_evaluation::GetEvaluationOutput::message): <p>A description of the most recent details about evaluating the <code>MLModel</code>.</p>
    ///   - [`compute_time(Option<i64>)`](crate::operation::get_evaluation::GetEvaluationOutput::compute_time): <p>The approximate CPU time in milliseconds that Amazon Machine Learning spent processing the <code>Evaluation</code>, normalized and scaled on computation resources. <code>ComputeTime</code> is only available if the <code>Evaluation</code> is in the <code>COMPLETED</code> state.</p>
    ///   - [`finished_at(Option<DateTime>)`](crate::operation::get_evaluation::GetEvaluationOutput::finished_at): <p>The epoch time when Amazon Machine Learning marked the <code>Evaluation</code> as <code>COMPLETED</code> or <code>FAILED</code>. <code>FinishedAt</code> is only available when the <code>Evaluation</code> is in the <code>COMPLETED</code> or <code>FAILED</code> state.</p>
    ///   - [`started_at(Option<DateTime>)`](crate::operation::get_evaluation::GetEvaluationOutput::started_at): <p>The epoch time when Amazon Machine Learning marked the <code>Evaluation</code> as <code>INPROGRESS</code>. <code>StartedAt</code> isn't available if the <code>Evaluation</code> is in the <code>PENDING</code> state.</p>
                            /// - On failure, responds with [`SdkError<GetEvaluationError>`](crate::operation::get_evaluation::GetEvaluationError)
    pub fn get_evaluation(&self) -> crate::operation::get_evaluation::builders::GetEvaluationFluentBuilder {
                                crate::operation::get_evaluation::builders::GetEvaluationFluentBuilder::new(self.handle.clone())
                            }
}

