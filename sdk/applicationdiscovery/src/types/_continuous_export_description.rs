// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>A list of continuous export descriptions.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ContinuousExportDescription {
    /// <p>The unique ID assigned to this export.</p>
    #[doc(hidden)]
    pub export_id: std::option::Option<std::string::String>,
    /// <p>Describes the status of the export. Can be one of the following values:</p>
    /// <ul>
    /// <li> <p>START_IN_PROGRESS - setting up resources to start continuous export.</p> </li>
    /// <li> <p>START_FAILED - an error occurred setting up continuous export. To recover, call start-continuous-export again.</p> </li>
    /// <li> <p>ACTIVE - data is being exported to the customer bucket.</p> </li>
    /// <li> <p>ERROR - an error occurred during export. To fix the issue, call stop-continuous-export and start-continuous-export.</p> </li>
    /// <li> <p>STOP_IN_PROGRESS - stopping the export.</p> </li>
    /// <li> <p>STOP_FAILED - an error occurred stopping the export. To recover, call stop-continuous-export again.</p> </li>
    /// <li> <p>INACTIVE - the continuous export has been stopped. Data is no longer being exported to the customer bucket.</p> </li>
    /// </ul>
    #[doc(hidden)]
    pub status: std::option::Option<crate::types::ContinuousExportStatus>,
    /// <p>Contains information about any errors that have occurred. This data type can have the following values:</p>
    /// <ul>
    /// <li> <p>ACCESS_DENIED - You don’t have permission to start Data Exploration in Amazon Athena. Contact your Amazon Web Services administrator for help. For more information, see <a href="http://docs.aws.amazon.com/application-discovery/latest/userguide/setting-up.html">Setting Up Amazon Web Services Application Discovery Service</a> in the Application Discovery Service User Guide.</p> </li>
    /// <li> <p>DELIVERY_STREAM_LIMIT_FAILURE - You reached the limit for Amazon Kinesis Data Firehose delivery streams. Reduce the number of streams or request a limit increase and try again. For more information, see <a href="http://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html">Kinesis Data Streams Limits</a> in the Amazon Kinesis Data Streams Developer Guide.</p> </li>
    /// <li> <p>FIREHOSE_ROLE_MISSING - The Data Exploration feature is in an error state because your IAM User is missing the AWSApplicationDiscoveryServiceFirehose role. Turn on Data Exploration in Amazon Athena and try again. For more information, see <a href="http://docs.aws.amazon.com/application-discovery/latest/userguide/setting-up.html#setting-up-user-policy">Step 3: Provide Application Discovery Service Access to Non-Administrator Users by Attaching Policies</a> in the Application Discovery Service User Guide.</p> </li>
    /// <li> <p>FIREHOSE_STREAM_DOES_NOT_EXIST - The Data Exploration feature is in an error state because your IAM User is missing one or more of the Kinesis data delivery streams.</p> </li>
    /// <li> <p>INTERNAL_FAILURE - The Data Exploration feature is in an error state because of an internal failure. Try again later. If this problem persists, contact Amazon Web Services Support.</p> </li>
    /// <li> <p>LAKE_FORMATION_ACCESS_DENIED - You don't have sufficient lake formation permissions to start continuous export. For more information, see <a href="http://docs.aws.amazon.com/lake-formation/latest/dg/upgrade-glue-lake-formation.html"> Upgrading Amazon Web Services Glue Data Permissions to the Amazon Web Services Lake Formation Model </a> in the Amazon Web Services <i>Lake Formation Developer Guide</i>. </p> <p>You can use one of the following two ways to resolve this issue.</p>
    /// <ol>
    /// <li> <p>If you don’t want to use the Lake Formation permission model, you can change the default Data Catalog settings to use only Amazon Web Services Identity and Access Management (IAM) access control for new databases. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/getting-started-setup.html#setup-change-cat-settings">Change Data Catalog Settings</a> in the <i>Lake Formation Developer Guide</i>.</p> </li>
    /// <li> <p>You can give the service-linked IAM roles AWSServiceRoleForApplicationDiscoveryServiceContinuousExport and AWSApplicationDiscoveryServiceFirehose the required Lake Formation permissions. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/granting-database-permissions.html"> Granting Database Permissions</a> in the <i>Lake Formation Developer Guide</i>. </p>
    /// <ol>
    /// <li> <p>AWSServiceRoleForApplicationDiscoveryServiceContinuousExport - Grant database creator permissions, which gives the role database creation ability and implicit permissions for any created tables. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/implicit-permissions.html"> Implicit Lake Formation Permissions </a> in the <i>Lake Formation Developer Guide</i>.</p> </li>
    /// <li> <p>AWSApplicationDiscoveryServiceFirehose - Grant describe permissions for all tables in the database.</p> </li>
    /// </ol> </li>
    /// </ol> </li>
    /// <li> <p>S3_BUCKET_LIMIT_FAILURE - You reached the limit for Amazon S3 buckets. Reduce the number of S3 buckets or request a limit increase and try again. For more information, see <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html">Bucket Restrictions and Limitations</a> in the Amazon Simple Storage Service Developer Guide.</p> </li>
    /// <li> <p>S3_NOT_SIGNED_UP - Your account is not signed up for the Amazon S3 service. You must sign up before you can use Amazon S3. You can sign up at the following URL: <a href="https://aws.amazon.com/s3">https://aws.amazon.com/s3</a>.</p> </li>
    /// </ul>
    #[doc(hidden)]
    pub status_detail: std::option::Option<std::string::String>,
    /// <p>The name of the s3 bucket where the export data parquet files are stored.</p>
    #[doc(hidden)]
    pub s3_bucket: std::option::Option<std::string::String>,
    /// <p>The timestamp representing when the continuous export was started.</p>
    #[doc(hidden)]
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The timestamp that represents when this continuous export was stopped.</p>
    #[doc(hidden)]
    pub stop_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The type of data collector used to gather this data (currently only offered for AGENT).</p>
    #[doc(hidden)]
    pub data_source: std::option::Option<crate::types::DataSource>,
    /// <p>An object which describes how the data is stored.</p>
    /// <ul>
    /// <li> <p> <code>databaseName</code> - the name of the Glue database used to store the schema.</p> </li>
    /// </ul>
    #[doc(hidden)]
    pub schema_storage_config:
        std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
}
impl ContinuousExportDescription {
    /// <p>The unique ID assigned to this export.</p>
    pub fn export_id(&self) -> std::option::Option<&str> {
        self.export_id.as_deref()
    }
    /// <p>Describes the status of the export. Can be one of the following values:</p>
    /// <ul>
    /// <li> <p>START_IN_PROGRESS - setting up resources to start continuous export.</p> </li>
    /// <li> <p>START_FAILED - an error occurred setting up continuous export. To recover, call start-continuous-export again.</p> </li>
    /// <li> <p>ACTIVE - data is being exported to the customer bucket.</p> </li>
    /// <li> <p>ERROR - an error occurred during export. To fix the issue, call stop-continuous-export and start-continuous-export.</p> </li>
    /// <li> <p>STOP_IN_PROGRESS - stopping the export.</p> </li>
    /// <li> <p>STOP_FAILED - an error occurred stopping the export. To recover, call stop-continuous-export again.</p> </li>
    /// <li> <p>INACTIVE - the continuous export has been stopped. Data is no longer being exported to the customer bucket.</p> </li>
    /// </ul>
    pub fn status(&self) -> std::option::Option<&crate::types::ContinuousExportStatus> {
        self.status.as_ref()
    }
    /// <p>Contains information about any errors that have occurred. This data type can have the following values:</p>
    /// <ul>
    /// <li> <p>ACCESS_DENIED - You don’t have permission to start Data Exploration in Amazon Athena. Contact your Amazon Web Services administrator for help. For more information, see <a href="http://docs.aws.amazon.com/application-discovery/latest/userguide/setting-up.html">Setting Up Amazon Web Services Application Discovery Service</a> in the Application Discovery Service User Guide.</p> </li>
    /// <li> <p>DELIVERY_STREAM_LIMIT_FAILURE - You reached the limit for Amazon Kinesis Data Firehose delivery streams. Reduce the number of streams or request a limit increase and try again. For more information, see <a href="http://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html">Kinesis Data Streams Limits</a> in the Amazon Kinesis Data Streams Developer Guide.</p> </li>
    /// <li> <p>FIREHOSE_ROLE_MISSING - The Data Exploration feature is in an error state because your IAM User is missing the AWSApplicationDiscoveryServiceFirehose role. Turn on Data Exploration in Amazon Athena and try again. For more information, see <a href="http://docs.aws.amazon.com/application-discovery/latest/userguide/setting-up.html#setting-up-user-policy">Step 3: Provide Application Discovery Service Access to Non-Administrator Users by Attaching Policies</a> in the Application Discovery Service User Guide.</p> </li>
    /// <li> <p>FIREHOSE_STREAM_DOES_NOT_EXIST - The Data Exploration feature is in an error state because your IAM User is missing one or more of the Kinesis data delivery streams.</p> </li>
    /// <li> <p>INTERNAL_FAILURE - The Data Exploration feature is in an error state because of an internal failure. Try again later. If this problem persists, contact Amazon Web Services Support.</p> </li>
    /// <li> <p>LAKE_FORMATION_ACCESS_DENIED - You don't have sufficient lake formation permissions to start continuous export. For more information, see <a href="http://docs.aws.amazon.com/lake-formation/latest/dg/upgrade-glue-lake-formation.html"> Upgrading Amazon Web Services Glue Data Permissions to the Amazon Web Services Lake Formation Model </a> in the Amazon Web Services <i>Lake Formation Developer Guide</i>. </p> <p>You can use one of the following two ways to resolve this issue.</p>
    /// <ol>
    /// <li> <p>If you don’t want to use the Lake Formation permission model, you can change the default Data Catalog settings to use only Amazon Web Services Identity and Access Management (IAM) access control for new databases. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/getting-started-setup.html#setup-change-cat-settings">Change Data Catalog Settings</a> in the <i>Lake Formation Developer Guide</i>.</p> </li>
    /// <li> <p>You can give the service-linked IAM roles AWSServiceRoleForApplicationDiscoveryServiceContinuousExport and AWSApplicationDiscoveryServiceFirehose the required Lake Formation permissions. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/granting-database-permissions.html"> Granting Database Permissions</a> in the <i>Lake Formation Developer Guide</i>. </p>
    /// <ol>
    /// <li> <p>AWSServiceRoleForApplicationDiscoveryServiceContinuousExport - Grant database creator permissions, which gives the role database creation ability and implicit permissions for any created tables. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/implicit-permissions.html"> Implicit Lake Formation Permissions </a> in the <i>Lake Formation Developer Guide</i>.</p> </li>
    /// <li> <p>AWSApplicationDiscoveryServiceFirehose - Grant describe permissions for all tables in the database.</p> </li>
    /// </ol> </li>
    /// </ol> </li>
    /// <li> <p>S3_BUCKET_LIMIT_FAILURE - You reached the limit for Amazon S3 buckets. Reduce the number of S3 buckets or request a limit increase and try again. For more information, see <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html">Bucket Restrictions and Limitations</a> in the Amazon Simple Storage Service Developer Guide.</p> </li>
    /// <li> <p>S3_NOT_SIGNED_UP - Your account is not signed up for the Amazon S3 service. You must sign up before you can use Amazon S3. You can sign up at the following URL: <a href="https://aws.amazon.com/s3">https://aws.amazon.com/s3</a>.</p> </li>
    /// </ul>
    pub fn status_detail(&self) -> std::option::Option<&str> {
        self.status_detail.as_deref()
    }
    /// <p>The name of the s3 bucket where the export data parquet files are stored.</p>
    pub fn s3_bucket(&self) -> std::option::Option<&str> {
        self.s3_bucket.as_deref()
    }
    /// <p>The timestamp representing when the continuous export was started.</p>
    pub fn start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p>The timestamp that represents when this continuous export was stopped.</p>
    pub fn stop_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.stop_time.as_ref()
    }
    /// <p>The type of data collector used to gather this data (currently only offered for AGENT).</p>
    pub fn data_source(&self) -> std::option::Option<&crate::types::DataSource> {
        self.data_source.as_ref()
    }
    /// <p>An object which describes how the data is stored.</p>
    /// <ul>
    /// <li> <p> <code>databaseName</code> - the name of the Glue database used to store the schema.</p> </li>
    /// </ul>
    pub fn schema_storage_config(
        &self,
    ) -> std::option::Option<&std::collections::HashMap<std::string::String, std::string::String>>
    {
        self.schema_storage_config.as_ref()
    }
}
impl ContinuousExportDescription {
    /// Creates a new builder-style object to manufacture [`ContinuousExportDescription`](crate::types::ContinuousExportDescription).
    pub fn builder() -> crate::types::builders::ContinuousExportDescriptionBuilder {
        crate::types::builders::ContinuousExportDescriptionBuilder::default()
    }
}

/// A builder for [`ContinuousExportDescription`](crate::types::ContinuousExportDescription).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct ContinuousExportDescriptionBuilder {
    pub(crate) export_id: std::option::Option<std::string::String>,
    pub(crate) status: std::option::Option<crate::types::ContinuousExportStatus>,
    pub(crate) status_detail: std::option::Option<std::string::String>,
    pub(crate) s3_bucket: std::option::Option<std::string::String>,
    pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) stop_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) data_source: std::option::Option<crate::types::DataSource>,
    pub(crate) schema_storage_config:
        std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
}
impl ContinuousExportDescriptionBuilder {
    /// <p>The unique ID assigned to this export.</p>
    pub fn export_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.export_id = Some(input.into());
        self
    }
    /// <p>The unique ID assigned to this export.</p>
    pub fn set_export_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.export_id = input;
        self
    }
    /// <p>Describes the status of the export. Can be one of the following values:</p>
    /// <ul>
    /// <li> <p>START_IN_PROGRESS - setting up resources to start continuous export.</p> </li>
    /// <li> <p>START_FAILED - an error occurred setting up continuous export. To recover, call start-continuous-export again.</p> </li>
    /// <li> <p>ACTIVE - data is being exported to the customer bucket.</p> </li>
    /// <li> <p>ERROR - an error occurred during export. To fix the issue, call stop-continuous-export and start-continuous-export.</p> </li>
    /// <li> <p>STOP_IN_PROGRESS - stopping the export.</p> </li>
    /// <li> <p>STOP_FAILED - an error occurred stopping the export. To recover, call stop-continuous-export again.</p> </li>
    /// <li> <p>INACTIVE - the continuous export has been stopped. Data is no longer being exported to the customer bucket.</p> </li>
    /// </ul>
    pub fn status(mut self, input: crate::types::ContinuousExportStatus) -> Self {
        self.status = Some(input);
        self
    }
    /// <p>Describes the status of the export. Can be one of the following values:</p>
    /// <ul>
    /// <li> <p>START_IN_PROGRESS - setting up resources to start continuous export.</p> </li>
    /// <li> <p>START_FAILED - an error occurred setting up continuous export. To recover, call start-continuous-export again.</p> </li>
    /// <li> <p>ACTIVE - data is being exported to the customer bucket.</p> </li>
    /// <li> <p>ERROR - an error occurred during export. To fix the issue, call stop-continuous-export and start-continuous-export.</p> </li>
    /// <li> <p>STOP_IN_PROGRESS - stopping the export.</p> </li>
    /// <li> <p>STOP_FAILED - an error occurred stopping the export. To recover, call stop-continuous-export again.</p> </li>
    /// <li> <p>INACTIVE - the continuous export has been stopped. Data is no longer being exported to the customer bucket.</p> </li>
    /// </ul>
    pub fn set_status(
        mut self,
        input: std::option::Option<crate::types::ContinuousExportStatus>,
    ) -> Self {
        self.status = input;
        self
    }
    /// <p>Contains information about any errors that have occurred. This data type can have the following values:</p>
    /// <ul>
    /// <li> <p>ACCESS_DENIED - You don’t have permission to start Data Exploration in Amazon Athena. Contact your Amazon Web Services administrator for help. For more information, see <a href="http://docs.aws.amazon.com/application-discovery/latest/userguide/setting-up.html">Setting Up Amazon Web Services Application Discovery Service</a> in the Application Discovery Service User Guide.</p> </li>
    /// <li> <p>DELIVERY_STREAM_LIMIT_FAILURE - You reached the limit for Amazon Kinesis Data Firehose delivery streams. Reduce the number of streams or request a limit increase and try again. For more information, see <a href="http://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html">Kinesis Data Streams Limits</a> in the Amazon Kinesis Data Streams Developer Guide.</p> </li>
    /// <li> <p>FIREHOSE_ROLE_MISSING - The Data Exploration feature is in an error state because your IAM User is missing the AWSApplicationDiscoveryServiceFirehose role. Turn on Data Exploration in Amazon Athena and try again. For more information, see <a href="http://docs.aws.amazon.com/application-discovery/latest/userguide/setting-up.html#setting-up-user-policy">Step 3: Provide Application Discovery Service Access to Non-Administrator Users by Attaching Policies</a> in the Application Discovery Service User Guide.</p> </li>
    /// <li> <p>FIREHOSE_STREAM_DOES_NOT_EXIST - The Data Exploration feature is in an error state because your IAM User is missing one or more of the Kinesis data delivery streams.</p> </li>
    /// <li> <p>INTERNAL_FAILURE - The Data Exploration feature is in an error state because of an internal failure. Try again later. If this problem persists, contact Amazon Web Services Support.</p> </li>
    /// <li> <p>LAKE_FORMATION_ACCESS_DENIED - You don't have sufficient lake formation permissions to start continuous export. For more information, see <a href="http://docs.aws.amazon.com/lake-formation/latest/dg/upgrade-glue-lake-formation.html"> Upgrading Amazon Web Services Glue Data Permissions to the Amazon Web Services Lake Formation Model </a> in the Amazon Web Services <i>Lake Formation Developer Guide</i>. </p> <p>You can use one of the following two ways to resolve this issue.</p>
    /// <ol>
    /// <li> <p>If you don’t want to use the Lake Formation permission model, you can change the default Data Catalog settings to use only Amazon Web Services Identity and Access Management (IAM) access control for new databases. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/getting-started-setup.html#setup-change-cat-settings">Change Data Catalog Settings</a> in the <i>Lake Formation Developer Guide</i>.</p> </li>
    /// <li> <p>You can give the service-linked IAM roles AWSServiceRoleForApplicationDiscoveryServiceContinuousExport and AWSApplicationDiscoveryServiceFirehose the required Lake Formation permissions. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/granting-database-permissions.html"> Granting Database Permissions</a> in the <i>Lake Formation Developer Guide</i>. </p>
    /// <ol>
    /// <li> <p>AWSServiceRoleForApplicationDiscoveryServiceContinuousExport - Grant database creator permissions, which gives the role database creation ability and implicit permissions for any created tables. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/implicit-permissions.html"> Implicit Lake Formation Permissions </a> in the <i>Lake Formation Developer Guide</i>.</p> </li>
    /// <li> <p>AWSApplicationDiscoveryServiceFirehose - Grant describe permissions for all tables in the database.</p> </li>
    /// </ol> </li>
    /// </ol> </li>
    /// <li> <p>S3_BUCKET_LIMIT_FAILURE - You reached the limit for Amazon S3 buckets. Reduce the number of S3 buckets or request a limit increase and try again. For more information, see <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html">Bucket Restrictions and Limitations</a> in the Amazon Simple Storage Service Developer Guide.</p> </li>
    /// <li> <p>S3_NOT_SIGNED_UP - Your account is not signed up for the Amazon S3 service. You must sign up before you can use Amazon S3. You can sign up at the following URL: <a href="https://aws.amazon.com/s3">https://aws.amazon.com/s3</a>.</p> </li>
    /// </ul>
    pub fn status_detail(mut self, input: impl Into<std::string::String>) -> Self {
        self.status_detail = Some(input.into());
        self
    }
    /// <p>Contains information about any errors that have occurred. This data type can have the following values:</p>
    /// <ul>
    /// <li> <p>ACCESS_DENIED - You don’t have permission to start Data Exploration in Amazon Athena. Contact your Amazon Web Services administrator for help. For more information, see <a href="http://docs.aws.amazon.com/application-discovery/latest/userguide/setting-up.html">Setting Up Amazon Web Services Application Discovery Service</a> in the Application Discovery Service User Guide.</p> </li>
    /// <li> <p>DELIVERY_STREAM_LIMIT_FAILURE - You reached the limit for Amazon Kinesis Data Firehose delivery streams. Reduce the number of streams or request a limit increase and try again. For more information, see <a href="http://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html">Kinesis Data Streams Limits</a> in the Amazon Kinesis Data Streams Developer Guide.</p> </li>
    /// <li> <p>FIREHOSE_ROLE_MISSING - The Data Exploration feature is in an error state because your IAM User is missing the AWSApplicationDiscoveryServiceFirehose role. Turn on Data Exploration in Amazon Athena and try again. For more information, see <a href="http://docs.aws.amazon.com/application-discovery/latest/userguide/setting-up.html#setting-up-user-policy">Step 3: Provide Application Discovery Service Access to Non-Administrator Users by Attaching Policies</a> in the Application Discovery Service User Guide.</p> </li>
    /// <li> <p>FIREHOSE_STREAM_DOES_NOT_EXIST - The Data Exploration feature is in an error state because your IAM User is missing one or more of the Kinesis data delivery streams.</p> </li>
    /// <li> <p>INTERNAL_FAILURE - The Data Exploration feature is in an error state because of an internal failure. Try again later. If this problem persists, contact Amazon Web Services Support.</p> </li>
    /// <li> <p>LAKE_FORMATION_ACCESS_DENIED - You don't have sufficient lake formation permissions to start continuous export. For more information, see <a href="http://docs.aws.amazon.com/lake-formation/latest/dg/upgrade-glue-lake-formation.html"> Upgrading Amazon Web Services Glue Data Permissions to the Amazon Web Services Lake Formation Model </a> in the Amazon Web Services <i>Lake Formation Developer Guide</i>. </p> <p>You can use one of the following two ways to resolve this issue.</p>
    /// <ol>
    /// <li> <p>If you don’t want to use the Lake Formation permission model, you can change the default Data Catalog settings to use only Amazon Web Services Identity and Access Management (IAM) access control for new databases. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/getting-started-setup.html#setup-change-cat-settings">Change Data Catalog Settings</a> in the <i>Lake Formation Developer Guide</i>.</p> </li>
    /// <li> <p>You can give the service-linked IAM roles AWSServiceRoleForApplicationDiscoveryServiceContinuousExport and AWSApplicationDiscoveryServiceFirehose the required Lake Formation permissions. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/granting-database-permissions.html"> Granting Database Permissions</a> in the <i>Lake Formation Developer Guide</i>. </p>
    /// <ol>
    /// <li> <p>AWSServiceRoleForApplicationDiscoveryServiceContinuousExport - Grant database creator permissions, which gives the role database creation ability and implicit permissions for any created tables. For more information, see <a href="https://docs.aws.amazon.com/lake-formation/latest/dg/implicit-permissions.html"> Implicit Lake Formation Permissions </a> in the <i>Lake Formation Developer Guide</i>.</p> </li>
    /// <li> <p>AWSApplicationDiscoveryServiceFirehose - Grant describe permissions for all tables in the database.</p> </li>
    /// </ol> </li>
    /// </ol> </li>
    /// <li> <p>S3_BUCKET_LIMIT_FAILURE - You reached the limit for Amazon S3 buckets. Reduce the number of S3 buckets or request a limit increase and try again. For more information, see <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html">Bucket Restrictions and Limitations</a> in the Amazon Simple Storage Service Developer Guide.</p> </li>
    /// <li> <p>S3_NOT_SIGNED_UP - Your account is not signed up for the Amazon S3 service. You must sign up before you can use Amazon S3. You can sign up at the following URL: <a href="https://aws.amazon.com/s3">https://aws.amazon.com/s3</a>.</p> </li>
    /// </ul>
    pub fn set_status_detail(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.status_detail = input;
        self
    }
    /// <p>The name of the s3 bucket where the export data parquet files are stored.</p>
    pub fn s3_bucket(mut self, input: impl Into<std::string::String>) -> Self {
        self.s3_bucket = Some(input.into());
        self
    }
    /// <p>The name of the s3 bucket where the export data parquet files are stored.</p>
    pub fn set_s3_bucket(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.s3_bucket = input;
        self
    }
    /// <p>The timestamp representing when the continuous export was started.</p>
    pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.start_time = Some(input);
        self
    }
    /// <p>The timestamp representing when the continuous export was started.</p>
    pub fn set_start_time(
        mut self,
        input: std::option::Option<aws_smithy_types::DateTime>,
    ) -> Self {
        self.start_time = input;
        self
    }
    /// <p>The timestamp that represents when this continuous export was stopped.</p>
    pub fn stop_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.stop_time = Some(input);
        self
    }
    /// <p>The timestamp that represents when this continuous export was stopped.</p>
    pub fn set_stop_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.stop_time = input;
        self
    }
    /// <p>The type of data collector used to gather this data (currently only offered for AGENT).</p>
    pub fn data_source(mut self, input: crate::types::DataSource) -> Self {
        self.data_source = Some(input);
        self
    }
    /// <p>The type of data collector used to gather this data (currently only offered for AGENT).</p>
    pub fn set_data_source(mut self, input: std::option::Option<crate::types::DataSource>) -> Self {
        self.data_source = input;
        self
    }
    /// Adds a key-value pair to `schema_storage_config`.
    ///
    /// To override the contents of this collection use [`set_schema_storage_config`](Self::set_schema_storage_config).
    ///
    /// <p>An object which describes how the data is stored.</p>
    /// <ul>
    /// <li> <p> <code>databaseName</code> - the name of the Glue database used to store the schema.</p> </li>
    /// </ul>
    pub fn schema_storage_config(
        mut self,
        k: impl Into<std::string::String>,
        v: impl Into<std::string::String>,
    ) -> Self {
        let mut hash_map = self.schema_storage_config.unwrap_or_default();
        hash_map.insert(k.into(), v.into());
        self.schema_storage_config = Some(hash_map);
        self
    }
    /// <p>An object which describes how the data is stored.</p>
    /// <ul>
    /// <li> <p> <code>databaseName</code> - the name of the Glue database used to store the schema.</p> </li>
    /// </ul>
    pub fn set_schema_storage_config(
        mut self,
        input: std::option::Option<
            std::collections::HashMap<std::string::String, std::string::String>,
        >,
    ) -> Self {
        self.schema_storage_config = input;
        self
    }
    /// Consumes the builder and constructs a [`ContinuousExportDescription`](crate::types::ContinuousExportDescription).
    pub fn build(self) -> crate::types::ContinuousExportDescription {
        crate::types::ContinuousExportDescription {
            export_id: self.export_id,
            status: self.status,
            status_detail: self.status_detail,
            s3_bucket: self.s3_bucket,
            start_time: self.start_time,
            stop_time: self.stop_time,
            data_source: self.data_source,
            schema_storage_config: self.schema_storage_config,
        }
    }
}
