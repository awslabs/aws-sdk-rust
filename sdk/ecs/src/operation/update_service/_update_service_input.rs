// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct UpdateServiceInput {
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    /// <p>You can't change the cluster name.</p>
    pub cluster: ::std::option::Option<::std::string::String>,
    /// <p>The name of the service to update.</p>
    pub service: ::std::option::Option<::std::string::String>,
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub desired_count: ::std::option::Option<i32>,
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub task_definition: ::std::option::Option<::std::string::String>,
    /// <p>The details of a capacity provider strategy. You can set a capacity provider when you create a cluster, run a task, or update a service.</p><note>
    /// <p>If you want to use Amazon ECS Managed Instances, you must use the <code>capacityProviderStrategy</code> request parameter.</p>
    /// </note>
    /// <p>When you use Fargate, the capacity providers are <code>FARGATE</code> or <code>FARGATE_SPOT</code>.</p>
    /// <p>When you use Amazon EC2, the capacity providers are Auto Scaling groups.</p>
    /// <p>You can change capacity providers for rolling deployments and blue/green deployments.</p>
    /// <p>The following list provides the valid transitions:</p>
    /// <ul>
    /// <li>
    /// <p>Update the Fargate launch type to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 launch type to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Fargate capacity provider to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 capacity provider to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Auto Scaling group or Fargate capacity provider back to the launch type.</p>
    /// <p>Pass an empty list in the <code>capacityProviderStrategy</code> parameter.</p></li>
    /// </ul>
    /// <p>For information about Amazon Web Services CDK considerations, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service-parameters.html">Amazon Web Services CDK considerations</a>.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub capacity_provider_strategy: ::std::option::Option<::std::vec::Vec<crate::types::CapacityProviderStrategyItem>>,
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub deployment_configuration: ::std::option::Option<crate::types::DeploymentConfiguration>,
    /// <p>Indicates whether to use Availability Zone rebalancing for the service.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-rebalancing.html">Balancing an Amazon ECS service across Availability Zones</a> in the <i> <i>Amazon Elastic Container Service Developer Guide</i> </i>.</p>
    /// <p>The default behavior of <code>AvailabilityZoneRebalancing</code> differs between create and update requests:</p>
    /// <ul>
    /// <li>
    /// <p>For create service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults the value to <code>ENABLED</code>.</p></li>
    /// <li>
    /// <p>For update service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults to the existing serviceâ€™s <code>AvailabilityZoneRebalancing</code> value. If the service never had an <code>AvailabilityZoneRebalancing</code> value set, Amazon ECS treats this as <code>DISABLED</code>.</p></li>
    /// </ul>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub availability_zone_rebalancing: ::std::option::Option<crate::types::AvailabilityZoneRebalancing>,
    /// <p>An object representing the network configuration for the service.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub network_configuration: ::std::option::Option<crate::types::NetworkConfiguration>,
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub placement_constraints: ::std::option::Option<::std::vec::Vec<crate::types::PlacementConstraint>>,
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub placement_strategy: ::std::option::Option<::std::vec::Vec<crate::types::PlacementStrategy>>,
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub platform_version: ::std::option::Option<::std::string::String>,
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    pub force_new_deployment: ::std::option::Option<bool>,
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing, VPC Lattice, and container health checks after a task has first started. If you don't specify a health check grace period value, the default value of <code>0</code> is used. If you don't use any of the health checks, then <code>healthCheckGracePeriodSeconds</code> is unused.</p>
    /// <p>If your service's tasks take a while to start and respond to health checks, you can specify a health check grace period of up to 2,147,483,647 seconds (about 69 years). During that time, the Amazon ECS service scheduler ignores health check status. This grace period can prevent the service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    /// <p>If your service has more running tasks than desired, unhealthy tasks in the grace period might be stopped to reach the desired count.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub health_check_grace_period_seconds: ::std::option::Option<i32>,
    /// <p>The deployment controller to use for the service.</p>
    pub deployment_controller: ::std::option::Option<crate::types::DeploymentController>,
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub enable_execute_command: ::std::option::Option<bool>,
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub enable_ecs_managed_tags: ::std::option::Option<bool>,
    /// <note>
    /// <p>You must have a service-linked role when you update this property</p>
    /// </note>
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub load_balancers: ::std::option::Option<::std::vec::Vec<crate::types::LoadBalancer>>,
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub propagate_tags: ::std::option::Option<crate::types::PropagateTags>,
    /// <note>
    /// <p>You must have a service-linked role when you update this property.</p>
    /// <p>For more information about the role see the <code>CreateService</code> request parameter <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateService.html#ECS-CreateService-request-role"> <code>role</code> </a>.</p>
    /// </note>
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub service_registries: ::std::option::Option<::std::vec::Vec<crate::types::ServiceRegistry>>,
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub service_connect_configuration: ::std::option::Option<crate::types::ServiceConnectConfiguration>,
    /// <p>The details of the volume that was <code>configuredAtLaunch</code>. You can configure the size, volumeType, IOPS, throughput, snapshot and encryption in <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_ServiceManagedEBSVolumeConfiguration.html">ServiceManagedEBSVolumeConfiguration</a>. The <code>name</code> of the volume must match the <code>name</code> from the task definition. If set to null, no new deployment is triggered. Otherwise, if this configuration differs from the existing one, it triggers a new deployment.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub volume_configurations: ::std::option::Option<::std::vec::Vec<crate::types::ServiceVolumeConfiguration>>,
    /// <p>An object representing the VPC Lattice configuration for the service being updated.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub vpc_lattice_configurations: ::std::option::Option<::std::vec::Vec<crate::types::VpcLatticeConfiguration>>,
}
impl UpdateServiceInput {
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    /// <p>You can't change the cluster name.</p>
    pub fn cluster(&self) -> ::std::option::Option<&str> {
        self.cluster.as_deref()
    }
    /// <p>The name of the service to update.</p>
    pub fn service(&self) -> ::std::option::Option<&str> {
        self.service.as_deref()
    }
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn desired_count(&self) -> ::std::option::Option<i32> {
        self.desired_count
    }
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn task_definition(&self) -> ::std::option::Option<&str> {
        self.task_definition.as_deref()
    }
    /// <p>The details of a capacity provider strategy. You can set a capacity provider when you create a cluster, run a task, or update a service.</p><note>
    /// <p>If you want to use Amazon ECS Managed Instances, you must use the <code>capacityProviderStrategy</code> request parameter.</p>
    /// </note>
    /// <p>When you use Fargate, the capacity providers are <code>FARGATE</code> or <code>FARGATE_SPOT</code>.</p>
    /// <p>When you use Amazon EC2, the capacity providers are Auto Scaling groups.</p>
    /// <p>You can change capacity providers for rolling deployments and blue/green deployments.</p>
    /// <p>The following list provides the valid transitions:</p>
    /// <ul>
    /// <li>
    /// <p>Update the Fargate launch type to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 launch type to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Fargate capacity provider to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 capacity provider to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Auto Scaling group or Fargate capacity provider back to the launch type.</p>
    /// <p>Pass an empty list in the <code>capacityProviderStrategy</code> parameter.</p></li>
    /// </ul>
    /// <p>For information about Amazon Web Services CDK considerations, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service-parameters.html">Amazon Web Services CDK considerations</a>.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.capacity_provider_strategy.is_none()`.
    pub fn capacity_provider_strategy(&self) -> &[crate::types::CapacityProviderStrategyItem] {
        self.capacity_provider_strategy.as_deref().unwrap_or_default()
    }
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn deployment_configuration(&self) -> ::std::option::Option<&crate::types::DeploymentConfiguration> {
        self.deployment_configuration.as_ref()
    }
    /// <p>Indicates whether to use Availability Zone rebalancing for the service.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-rebalancing.html">Balancing an Amazon ECS service across Availability Zones</a> in the <i> <i>Amazon Elastic Container Service Developer Guide</i> </i>.</p>
    /// <p>The default behavior of <code>AvailabilityZoneRebalancing</code> differs between create and update requests:</p>
    /// <ul>
    /// <li>
    /// <p>For create service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults the value to <code>ENABLED</code>.</p></li>
    /// <li>
    /// <p>For update service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults to the existing serviceâ€™s <code>AvailabilityZoneRebalancing</code> value. If the service never had an <code>AvailabilityZoneRebalancing</code> value set, Amazon ECS treats this as <code>DISABLED</code>.</p></li>
    /// </ul>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn availability_zone_rebalancing(&self) -> ::std::option::Option<&crate::types::AvailabilityZoneRebalancing> {
        self.availability_zone_rebalancing.as_ref()
    }
    /// <p>An object representing the network configuration for the service.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn network_configuration(&self) -> ::std::option::Option<&crate::types::NetworkConfiguration> {
        self.network_configuration.as_ref()
    }
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.placement_constraints.is_none()`.
    pub fn placement_constraints(&self) -> &[crate::types::PlacementConstraint] {
        self.placement_constraints.as_deref().unwrap_or_default()
    }
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.placement_strategy.is_none()`.
    pub fn placement_strategy(&self) -> &[crate::types::PlacementStrategy] {
        self.placement_strategy.as_deref().unwrap_or_default()
    }
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn platform_version(&self) -> ::std::option::Option<&str> {
        self.platform_version.as_deref()
    }
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    pub fn force_new_deployment(&self) -> ::std::option::Option<bool> {
        self.force_new_deployment
    }
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing, VPC Lattice, and container health checks after a task has first started. If you don't specify a health check grace period value, the default value of <code>0</code> is used. If you don't use any of the health checks, then <code>healthCheckGracePeriodSeconds</code> is unused.</p>
    /// <p>If your service's tasks take a while to start and respond to health checks, you can specify a health check grace period of up to 2,147,483,647 seconds (about 69 years). During that time, the Amazon ECS service scheduler ignores health check status. This grace period can prevent the service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    /// <p>If your service has more running tasks than desired, unhealthy tasks in the grace period might be stopped to reach the desired count.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn health_check_grace_period_seconds(&self) -> ::std::option::Option<i32> {
        self.health_check_grace_period_seconds
    }
    /// <p>The deployment controller to use for the service.</p>
    pub fn deployment_controller(&self) -> ::std::option::Option<&crate::types::DeploymentController> {
        self.deployment_controller.as_ref()
    }
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn enable_execute_command(&self) -> ::std::option::Option<bool> {
        self.enable_execute_command
    }
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn enable_ecs_managed_tags(&self) -> ::std::option::Option<bool> {
        self.enable_ecs_managed_tags
    }
    /// <note>
    /// <p>You must have a service-linked role when you update this property</p>
    /// </note>
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.load_balancers.is_none()`.
    pub fn load_balancers(&self) -> &[crate::types::LoadBalancer] {
        self.load_balancers.as_deref().unwrap_or_default()
    }
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn propagate_tags(&self) -> ::std::option::Option<&crate::types::PropagateTags> {
        self.propagate_tags.as_ref()
    }
    /// <note>
    /// <p>You must have a service-linked role when you update this property.</p>
    /// <p>For more information about the role see the <code>CreateService</code> request parameter <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateService.html#ECS-CreateService-request-role"> <code>role</code> </a>.</p>
    /// </note>
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.service_registries.is_none()`.
    pub fn service_registries(&self) -> &[crate::types::ServiceRegistry] {
        self.service_registries.as_deref().unwrap_or_default()
    }
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn service_connect_configuration(&self) -> ::std::option::Option<&crate::types::ServiceConnectConfiguration> {
        self.service_connect_configuration.as_ref()
    }
    /// <p>The details of the volume that was <code>configuredAtLaunch</code>. You can configure the size, volumeType, IOPS, throughput, snapshot and encryption in <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_ServiceManagedEBSVolumeConfiguration.html">ServiceManagedEBSVolumeConfiguration</a>. The <code>name</code> of the volume must match the <code>name</code> from the task definition. If set to null, no new deployment is triggered. Otherwise, if this configuration differs from the existing one, it triggers a new deployment.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.volume_configurations.is_none()`.
    pub fn volume_configurations(&self) -> &[crate::types::ServiceVolumeConfiguration] {
        self.volume_configurations.as_deref().unwrap_or_default()
    }
    /// <p>An object representing the VPC Lattice configuration for the service being updated.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.vpc_lattice_configurations.is_none()`.
    pub fn vpc_lattice_configurations(&self) -> &[crate::types::VpcLatticeConfiguration] {
        self.vpc_lattice_configurations.as_deref().unwrap_or_default()
    }
}
impl UpdateServiceInput {
    /// Creates a new builder-style object to manufacture [`UpdateServiceInput`](crate::operation::update_service::UpdateServiceInput).
    pub fn builder() -> crate::operation::update_service::builders::UpdateServiceInputBuilder {
        crate::operation::update_service::builders::UpdateServiceInputBuilder::default()
    }
}

/// A builder for [`UpdateServiceInput`](crate::operation::update_service::UpdateServiceInput).
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
#[non_exhaustive]
pub struct UpdateServiceInputBuilder {
    pub(crate) cluster: ::std::option::Option<::std::string::String>,
    pub(crate) service: ::std::option::Option<::std::string::String>,
    pub(crate) desired_count: ::std::option::Option<i32>,
    pub(crate) task_definition: ::std::option::Option<::std::string::String>,
    pub(crate) capacity_provider_strategy: ::std::option::Option<::std::vec::Vec<crate::types::CapacityProviderStrategyItem>>,
    pub(crate) deployment_configuration: ::std::option::Option<crate::types::DeploymentConfiguration>,
    pub(crate) availability_zone_rebalancing: ::std::option::Option<crate::types::AvailabilityZoneRebalancing>,
    pub(crate) network_configuration: ::std::option::Option<crate::types::NetworkConfiguration>,
    pub(crate) placement_constraints: ::std::option::Option<::std::vec::Vec<crate::types::PlacementConstraint>>,
    pub(crate) placement_strategy: ::std::option::Option<::std::vec::Vec<crate::types::PlacementStrategy>>,
    pub(crate) platform_version: ::std::option::Option<::std::string::String>,
    pub(crate) force_new_deployment: ::std::option::Option<bool>,
    pub(crate) health_check_grace_period_seconds: ::std::option::Option<i32>,
    pub(crate) deployment_controller: ::std::option::Option<crate::types::DeploymentController>,
    pub(crate) enable_execute_command: ::std::option::Option<bool>,
    pub(crate) enable_ecs_managed_tags: ::std::option::Option<bool>,
    pub(crate) load_balancers: ::std::option::Option<::std::vec::Vec<crate::types::LoadBalancer>>,
    pub(crate) propagate_tags: ::std::option::Option<crate::types::PropagateTags>,
    pub(crate) service_registries: ::std::option::Option<::std::vec::Vec<crate::types::ServiceRegistry>>,
    pub(crate) service_connect_configuration: ::std::option::Option<crate::types::ServiceConnectConfiguration>,
    pub(crate) volume_configurations: ::std::option::Option<::std::vec::Vec<crate::types::ServiceVolumeConfiguration>>,
    pub(crate) vpc_lattice_configurations: ::std::option::Option<::std::vec::Vec<crate::types::VpcLatticeConfiguration>>,
}
impl UpdateServiceInputBuilder {
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    /// <p>You can't change the cluster name.</p>
    pub fn cluster(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.cluster = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    /// <p>You can't change the cluster name.</p>
    pub fn set_cluster(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.cluster = input;
        self
    }
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    /// <p>You can't change the cluster name.</p>
    pub fn get_cluster(&self) -> &::std::option::Option<::std::string::String> {
        &self.cluster
    }
    /// <p>The name of the service to update.</p>
    /// This field is required.
    pub fn service(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.service = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The name of the service to update.</p>
    pub fn set_service(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.service = input;
        self
    }
    /// <p>The name of the service to update.</p>
    pub fn get_service(&self) -> &::std::option::Option<::std::string::String> {
        &self.service
    }
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn desired_count(mut self, input: i32) -> Self {
        self.desired_count = ::std::option::Option::Some(input);
        self
    }
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_desired_count(mut self, input: ::std::option::Option<i32>) -> Self {
        self.desired_count = input;
        self
    }
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_desired_count(&self) -> &::std::option::Option<i32> {
        &self.desired_count
    }
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn task_definition(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.task_definition = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_task_definition(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.task_definition = input;
        self
    }
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_task_definition(&self) -> &::std::option::Option<::std::string::String> {
        &self.task_definition
    }
    /// Appends an item to `capacity_provider_strategy`.
    ///
    /// To override the contents of this collection use [`set_capacity_provider_strategy`](Self::set_capacity_provider_strategy).
    ///
    /// <p>The details of a capacity provider strategy. You can set a capacity provider when you create a cluster, run a task, or update a service.</p><note>
    /// <p>If you want to use Amazon ECS Managed Instances, you must use the <code>capacityProviderStrategy</code> request parameter.</p>
    /// </note>
    /// <p>When you use Fargate, the capacity providers are <code>FARGATE</code> or <code>FARGATE_SPOT</code>.</p>
    /// <p>When you use Amazon EC2, the capacity providers are Auto Scaling groups.</p>
    /// <p>You can change capacity providers for rolling deployments and blue/green deployments.</p>
    /// <p>The following list provides the valid transitions:</p>
    /// <ul>
    /// <li>
    /// <p>Update the Fargate launch type to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 launch type to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Fargate capacity provider to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 capacity provider to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Auto Scaling group or Fargate capacity provider back to the launch type.</p>
    /// <p>Pass an empty list in the <code>capacityProviderStrategy</code> parameter.</p></li>
    /// </ul>
    /// <p>For information about Amazon Web Services CDK considerations, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service-parameters.html">Amazon Web Services CDK considerations</a>.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn capacity_provider_strategy(mut self, input: crate::types::CapacityProviderStrategyItem) -> Self {
        let mut v = self.capacity_provider_strategy.unwrap_or_default();
        v.push(input);
        self.capacity_provider_strategy = ::std::option::Option::Some(v);
        self
    }
    /// <p>The details of a capacity provider strategy. You can set a capacity provider when you create a cluster, run a task, or update a service.</p><note>
    /// <p>If you want to use Amazon ECS Managed Instances, you must use the <code>capacityProviderStrategy</code> request parameter.</p>
    /// </note>
    /// <p>When you use Fargate, the capacity providers are <code>FARGATE</code> or <code>FARGATE_SPOT</code>.</p>
    /// <p>When you use Amazon EC2, the capacity providers are Auto Scaling groups.</p>
    /// <p>You can change capacity providers for rolling deployments and blue/green deployments.</p>
    /// <p>The following list provides the valid transitions:</p>
    /// <ul>
    /// <li>
    /// <p>Update the Fargate launch type to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 launch type to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Fargate capacity provider to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 capacity provider to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Auto Scaling group or Fargate capacity provider back to the launch type.</p>
    /// <p>Pass an empty list in the <code>capacityProviderStrategy</code> parameter.</p></li>
    /// </ul>
    /// <p>For information about Amazon Web Services CDK considerations, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service-parameters.html">Amazon Web Services CDK considerations</a>.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_capacity_provider_strategy(
        mut self,
        input: ::std::option::Option<::std::vec::Vec<crate::types::CapacityProviderStrategyItem>>,
    ) -> Self {
        self.capacity_provider_strategy = input;
        self
    }
    /// <p>The details of a capacity provider strategy. You can set a capacity provider when you create a cluster, run a task, or update a service.</p><note>
    /// <p>If you want to use Amazon ECS Managed Instances, you must use the <code>capacityProviderStrategy</code> request parameter.</p>
    /// </note>
    /// <p>When you use Fargate, the capacity providers are <code>FARGATE</code> or <code>FARGATE_SPOT</code>.</p>
    /// <p>When you use Amazon EC2, the capacity providers are Auto Scaling groups.</p>
    /// <p>You can change capacity providers for rolling deployments and blue/green deployments.</p>
    /// <p>The following list provides the valid transitions:</p>
    /// <ul>
    /// <li>
    /// <p>Update the Fargate launch type to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 launch type to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Fargate capacity provider to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 capacity provider to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Auto Scaling group or Fargate capacity provider back to the launch type.</p>
    /// <p>Pass an empty list in the <code>capacityProviderStrategy</code> parameter.</p></li>
    /// </ul>
    /// <p>For information about Amazon Web Services CDK considerations, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service-parameters.html">Amazon Web Services CDK considerations</a>.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_capacity_provider_strategy(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::CapacityProviderStrategyItem>> {
        &self.capacity_provider_strategy
    }
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn deployment_configuration(mut self, input: crate::types::DeploymentConfiguration) -> Self {
        self.deployment_configuration = ::std::option::Option::Some(input);
        self
    }
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_deployment_configuration(mut self, input: ::std::option::Option<crate::types::DeploymentConfiguration>) -> Self {
        self.deployment_configuration = input;
        self
    }
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_deployment_configuration(&self) -> &::std::option::Option<crate::types::DeploymentConfiguration> {
        &self.deployment_configuration
    }
    /// <p>Indicates whether to use Availability Zone rebalancing for the service.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-rebalancing.html">Balancing an Amazon ECS service across Availability Zones</a> in the <i> <i>Amazon Elastic Container Service Developer Guide</i> </i>.</p>
    /// <p>The default behavior of <code>AvailabilityZoneRebalancing</code> differs between create and update requests:</p>
    /// <ul>
    /// <li>
    /// <p>For create service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults the value to <code>ENABLED</code>.</p></li>
    /// <li>
    /// <p>For update service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults to the existing serviceâ€™s <code>AvailabilityZoneRebalancing</code> value. If the service never had an <code>AvailabilityZoneRebalancing</code> value set, Amazon ECS treats this as <code>DISABLED</code>.</p></li>
    /// </ul>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn availability_zone_rebalancing(mut self, input: crate::types::AvailabilityZoneRebalancing) -> Self {
        self.availability_zone_rebalancing = ::std::option::Option::Some(input);
        self
    }
    /// <p>Indicates whether to use Availability Zone rebalancing for the service.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-rebalancing.html">Balancing an Amazon ECS service across Availability Zones</a> in the <i> <i>Amazon Elastic Container Service Developer Guide</i> </i>.</p>
    /// <p>The default behavior of <code>AvailabilityZoneRebalancing</code> differs between create and update requests:</p>
    /// <ul>
    /// <li>
    /// <p>For create service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults the value to <code>ENABLED</code>.</p></li>
    /// <li>
    /// <p>For update service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults to the existing serviceâ€™s <code>AvailabilityZoneRebalancing</code> value. If the service never had an <code>AvailabilityZoneRebalancing</code> value set, Amazon ECS treats this as <code>DISABLED</code>.</p></li>
    /// </ul>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_availability_zone_rebalancing(mut self, input: ::std::option::Option<crate::types::AvailabilityZoneRebalancing>) -> Self {
        self.availability_zone_rebalancing = input;
        self
    }
    /// <p>Indicates whether to use Availability Zone rebalancing for the service.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-rebalancing.html">Balancing an Amazon ECS service across Availability Zones</a> in the <i> <i>Amazon Elastic Container Service Developer Guide</i> </i>.</p>
    /// <p>The default behavior of <code>AvailabilityZoneRebalancing</code> differs between create and update requests:</p>
    /// <ul>
    /// <li>
    /// <p>For create service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults the value to <code>ENABLED</code>.</p></li>
    /// <li>
    /// <p>For update service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults to the existing serviceâ€™s <code>AvailabilityZoneRebalancing</code> value. If the service never had an <code>AvailabilityZoneRebalancing</code> value set, Amazon ECS treats this as <code>DISABLED</code>.</p></li>
    /// </ul>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_availability_zone_rebalancing(&self) -> &::std::option::Option<crate::types::AvailabilityZoneRebalancing> {
        &self.availability_zone_rebalancing
    }
    /// <p>An object representing the network configuration for the service.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn network_configuration(mut self, input: crate::types::NetworkConfiguration) -> Self {
        self.network_configuration = ::std::option::Option::Some(input);
        self
    }
    /// <p>An object representing the network configuration for the service.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_network_configuration(mut self, input: ::std::option::Option<crate::types::NetworkConfiguration>) -> Self {
        self.network_configuration = input;
        self
    }
    /// <p>An object representing the network configuration for the service.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_network_configuration(&self) -> &::std::option::Option<crate::types::NetworkConfiguration> {
        &self.network_configuration
    }
    /// Appends an item to `placement_constraints`.
    ///
    /// To override the contents of this collection use [`set_placement_constraints`](Self::set_placement_constraints).
    ///
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn placement_constraints(mut self, input: crate::types::PlacementConstraint) -> Self {
        let mut v = self.placement_constraints.unwrap_or_default();
        v.push(input);
        self.placement_constraints = ::std::option::Option::Some(v);
        self
    }
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_placement_constraints(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::PlacementConstraint>>) -> Self {
        self.placement_constraints = input;
        self
    }
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_placement_constraints(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::PlacementConstraint>> {
        &self.placement_constraints
    }
    /// Appends an item to `placement_strategy`.
    ///
    /// To override the contents of this collection use [`set_placement_strategy`](Self::set_placement_strategy).
    ///
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn placement_strategy(mut self, input: crate::types::PlacementStrategy) -> Self {
        let mut v = self.placement_strategy.unwrap_or_default();
        v.push(input);
        self.placement_strategy = ::std::option::Option::Some(v);
        self
    }
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_placement_strategy(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::PlacementStrategy>>) -> Self {
        self.placement_strategy = input;
        self
    }
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_placement_strategy(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::PlacementStrategy>> {
        &self.placement_strategy
    }
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn platform_version(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.platform_version = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_platform_version(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.platform_version = input;
        self
    }
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_platform_version(&self) -> &::std::option::Option<::std::string::String> {
        &self.platform_version
    }
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    pub fn force_new_deployment(mut self, input: bool) -> Self {
        self.force_new_deployment = ::std::option::Option::Some(input);
        self
    }
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    pub fn set_force_new_deployment(mut self, input: ::std::option::Option<bool>) -> Self {
        self.force_new_deployment = input;
        self
    }
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    pub fn get_force_new_deployment(&self) -> &::std::option::Option<bool> {
        &self.force_new_deployment
    }
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing, VPC Lattice, and container health checks after a task has first started. If you don't specify a health check grace period value, the default value of <code>0</code> is used. If you don't use any of the health checks, then <code>healthCheckGracePeriodSeconds</code> is unused.</p>
    /// <p>If your service's tasks take a while to start and respond to health checks, you can specify a health check grace period of up to 2,147,483,647 seconds (about 69 years). During that time, the Amazon ECS service scheduler ignores health check status. This grace period can prevent the service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    /// <p>If your service has more running tasks than desired, unhealthy tasks in the grace period might be stopped to reach the desired count.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn health_check_grace_period_seconds(mut self, input: i32) -> Self {
        self.health_check_grace_period_seconds = ::std::option::Option::Some(input);
        self
    }
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing, VPC Lattice, and container health checks after a task has first started. If you don't specify a health check grace period value, the default value of <code>0</code> is used. If you don't use any of the health checks, then <code>healthCheckGracePeriodSeconds</code> is unused.</p>
    /// <p>If your service's tasks take a while to start and respond to health checks, you can specify a health check grace period of up to 2,147,483,647 seconds (about 69 years). During that time, the Amazon ECS service scheduler ignores health check status. This grace period can prevent the service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    /// <p>If your service has more running tasks than desired, unhealthy tasks in the grace period might be stopped to reach the desired count.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_health_check_grace_period_seconds(mut self, input: ::std::option::Option<i32>) -> Self {
        self.health_check_grace_period_seconds = input;
        self
    }
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing, VPC Lattice, and container health checks after a task has first started. If you don't specify a health check grace period value, the default value of <code>0</code> is used. If you don't use any of the health checks, then <code>healthCheckGracePeriodSeconds</code> is unused.</p>
    /// <p>If your service's tasks take a while to start and respond to health checks, you can specify a health check grace period of up to 2,147,483,647 seconds (about 69 years). During that time, the Amazon ECS service scheduler ignores health check status. This grace period can prevent the service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    /// <p>If your service has more running tasks than desired, unhealthy tasks in the grace period might be stopped to reach the desired count.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_health_check_grace_period_seconds(&self) -> &::std::option::Option<i32> {
        &self.health_check_grace_period_seconds
    }
    /// <p>The deployment controller to use for the service.</p>
    pub fn deployment_controller(mut self, input: crate::types::DeploymentController) -> Self {
        self.deployment_controller = ::std::option::Option::Some(input);
        self
    }
    /// <p>The deployment controller to use for the service.</p>
    pub fn set_deployment_controller(mut self, input: ::std::option::Option<crate::types::DeploymentController>) -> Self {
        self.deployment_controller = input;
        self
    }
    /// <p>The deployment controller to use for the service.</p>
    pub fn get_deployment_controller(&self) -> &::std::option::Option<crate::types::DeploymentController> {
        &self.deployment_controller
    }
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn enable_execute_command(mut self, input: bool) -> Self {
        self.enable_execute_command = ::std::option::Option::Some(input);
        self
    }
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_enable_execute_command(mut self, input: ::std::option::Option<bool>) -> Self {
        self.enable_execute_command = input;
        self
    }
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_enable_execute_command(&self) -> &::std::option::Option<bool> {
        &self.enable_execute_command
    }
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn enable_ecs_managed_tags(mut self, input: bool) -> Self {
        self.enable_ecs_managed_tags = ::std::option::Option::Some(input);
        self
    }
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_enable_ecs_managed_tags(mut self, input: ::std::option::Option<bool>) -> Self {
        self.enable_ecs_managed_tags = input;
        self
    }
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_enable_ecs_managed_tags(&self) -> &::std::option::Option<bool> {
        &self.enable_ecs_managed_tags
    }
    /// Appends an item to `load_balancers`.
    ///
    /// To override the contents of this collection use [`set_load_balancers`](Self::set_load_balancers).
    ///
    /// <note>
    /// <p>You must have a service-linked role when you update this property</p>
    /// </note>
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn load_balancers(mut self, input: crate::types::LoadBalancer) -> Self {
        let mut v = self.load_balancers.unwrap_or_default();
        v.push(input);
        self.load_balancers = ::std::option::Option::Some(v);
        self
    }
    /// <note>
    /// <p>You must have a service-linked role when you update this property</p>
    /// </note>
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_load_balancers(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::LoadBalancer>>) -> Self {
        self.load_balancers = input;
        self
    }
    /// <note>
    /// <p>You must have a service-linked role when you update this property</p>
    /// </note>
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_load_balancers(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::LoadBalancer>> {
        &self.load_balancers
    }
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn propagate_tags(mut self, input: crate::types::PropagateTags) -> Self {
        self.propagate_tags = ::std::option::Option::Some(input);
        self
    }
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_propagate_tags(mut self, input: ::std::option::Option<crate::types::PropagateTags>) -> Self {
        self.propagate_tags = input;
        self
    }
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_propagate_tags(&self) -> &::std::option::Option<crate::types::PropagateTags> {
        &self.propagate_tags
    }
    /// Appends an item to `service_registries`.
    ///
    /// To override the contents of this collection use [`set_service_registries`](Self::set_service_registries).
    ///
    /// <note>
    /// <p>You must have a service-linked role when you update this property.</p>
    /// <p>For more information about the role see the <code>CreateService</code> request parameter <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateService.html#ECS-CreateService-request-role"> <code>role</code> </a>.</p>
    /// </note>
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn service_registries(mut self, input: crate::types::ServiceRegistry) -> Self {
        let mut v = self.service_registries.unwrap_or_default();
        v.push(input);
        self.service_registries = ::std::option::Option::Some(v);
        self
    }
    /// <note>
    /// <p>You must have a service-linked role when you update this property.</p>
    /// <p>For more information about the role see the <code>CreateService</code> request parameter <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateService.html#ECS-CreateService-request-role"> <code>role</code> </a>.</p>
    /// </note>
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_service_registries(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::ServiceRegistry>>) -> Self {
        self.service_registries = input;
        self
    }
    /// <note>
    /// <p>You must have a service-linked role when you update this property.</p>
    /// <p>For more information about the role see the <code>CreateService</code> request parameter <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateService.html#ECS-CreateService-request-role"> <code>role</code> </a>.</p>
    /// </note>
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_service_registries(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::ServiceRegistry>> {
        &self.service_registries
    }
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn service_connect_configuration(mut self, input: crate::types::ServiceConnectConfiguration) -> Self {
        self.service_connect_configuration = ::std::option::Option::Some(input);
        self
    }
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_service_connect_configuration(mut self, input: ::std::option::Option<crate::types::ServiceConnectConfiguration>) -> Self {
        self.service_connect_configuration = input;
        self
    }
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_service_connect_configuration(&self) -> &::std::option::Option<crate::types::ServiceConnectConfiguration> {
        &self.service_connect_configuration
    }
    /// Appends an item to `volume_configurations`.
    ///
    /// To override the contents of this collection use [`set_volume_configurations`](Self::set_volume_configurations).
    ///
    /// <p>The details of the volume that was <code>configuredAtLaunch</code>. You can configure the size, volumeType, IOPS, throughput, snapshot and encryption in <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_ServiceManagedEBSVolumeConfiguration.html">ServiceManagedEBSVolumeConfiguration</a>. The <code>name</code> of the volume must match the <code>name</code> from the task definition. If set to null, no new deployment is triggered. Otherwise, if this configuration differs from the existing one, it triggers a new deployment.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn volume_configurations(mut self, input: crate::types::ServiceVolumeConfiguration) -> Self {
        let mut v = self.volume_configurations.unwrap_or_default();
        v.push(input);
        self.volume_configurations = ::std::option::Option::Some(v);
        self
    }
    /// <p>The details of the volume that was <code>configuredAtLaunch</code>. You can configure the size, volumeType, IOPS, throughput, snapshot and encryption in <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_ServiceManagedEBSVolumeConfiguration.html">ServiceManagedEBSVolumeConfiguration</a>. The <code>name</code> of the volume must match the <code>name</code> from the task definition. If set to null, no new deployment is triggered. Otherwise, if this configuration differs from the existing one, it triggers a new deployment.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_volume_configurations(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::ServiceVolumeConfiguration>>) -> Self {
        self.volume_configurations = input;
        self
    }
    /// <p>The details of the volume that was <code>configuredAtLaunch</code>. You can configure the size, volumeType, IOPS, throughput, snapshot and encryption in <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_ServiceManagedEBSVolumeConfiguration.html">ServiceManagedEBSVolumeConfiguration</a>. The <code>name</code> of the volume must match the <code>name</code> from the task definition. If set to null, no new deployment is triggered. Otherwise, if this configuration differs from the existing one, it triggers a new deployment.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_volume_configurations(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::ServiceVolumeConfiguration>> {
        &self.volume_configurations
    }
    /// Appends an item to `vpc_lattice_configurations`.
    ///
    /// To override the contents of this collection use [`set_vpc_lattice_configurations`](Self::set_vpc_lattice_configurations).
    ///
    /// <p>An object representing the VPC Lattice configuration for the service being updated.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn vpc_lattice_configurations(mut self, input: crate::types::VpcLatticeConfiguration) -> Self {
        let mut v = self.vpc_lattice_configurations.unwrap_or_default();
        v.push(input);
        self.vpc_lattice_configurations = ::std::option::Option::Some(v);
        self
    }
    /// <p>An object representing the VPC Lattice configuration for the service being updated.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_vpc_lattice_configurations(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::VpcLatticeConfiguration>>) -> Self {
        self.vpc_lattice_configurations = input;
        self
    }
    /// <p>An object representing the VPC Lattice configuration for the service being updated.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_vpc_lattice_configurations(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::VpcLatticeConfiguration>> {
        &self.vpc_lattice_configurations
    }
    /// Consumes the builder and constructs a [`UpdateServiceInput`](crate::operation::update_service::UpdateServiceInput).
    pub fn build(
        self,
    ) -> ::std::result::Result<crate::operation::update_service::UpdateServiceInput, ::aws_smithy_types::error::operation::BuildError> {
        ::std::result::Result::Ok(crate::operation::update_service::UpdateServiceInput {
            cluster: self.cluster,
            service: self.service,
            desired_count: self.desired_count,
            task_definition: self.task_definition,
            capacity_provider_strategy: self.capacity_provider_strategy,
            deployment_configuration: self.deployment_configuration,
            availability_zone_rebalancing: self.availability_zone_rebalancing,
            network_configuration: self.network_configuration,
            placement_constraints: self.placement_constraints,
            placement_strategy: self.placement_strategy,
            platform_version: self.platform_version,
            force_new_deployment: self.force_new_deployment,
            health_check_grace_period_seconds: self.health_check_grace_period_seconds,
            deployment_controller: self.deployment_controller,
            enable_execute_command: self.enable_execute_command,
            enable_ecs_managed_tags: self.enable_ecs_managed_tags,
            load_balancers: self.load_balancers,
            propagate_tags: self.propagate_tags,
            service_registries: self.service_registries,
            service_connect_configuration: self.service_connect_configuration,
            volume_configurations: self.volume_configurations,
            vpc_lattice_configurations: self.vpc_lattice_configurations,
        })
    }
}
