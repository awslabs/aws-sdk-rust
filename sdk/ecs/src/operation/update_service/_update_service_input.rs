// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct UpdateServiceInput {
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    #[doc(hidden)]
    pub cluster: std::option::Option<std::string::String>,
    /// <p>The name of the service to update.</p>
    #[doc(hidden)]
    pub service: std::option::Option<std::string::String>,
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    #[doc(hidden)]
    pub desired_count: std::option::Option<i32>,
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    #[doc(hidden)]
    pub task_definition: std::option::Option<std::string::String>,
    /// <p>The capacity provider strategy to update the service to use.</p>
    /// <p>if the service uses the default capacity provider strategy for the cluster, the service can be updated to use one or more capacity providers as opposed to the default capacity provider strategy. However, when a service is using a capacity provider strategy that's not the default capacity provider strategy, the service can't be updated to use the cluster's default capacity provider strategy.</p>
    /// <p>A capacity provider strategy consists of one or more capacity providers along with the <code>base</code> and <code>weight</code> to assign to them. A capacity provider must be associated with the cluster to be used in a capacity provider strategy. The <code>PutClusterCapacityProviders</code> API is used to associate a capacity provider with a cluster. Only capacity providers with an <code>ACTIVE</code> or <code>UPDATING</code> status can be used.</p>
    /// <p>If specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New capacity providers can be created with the <code>CreateCapacityProvider</code> API operation.</p>
    /// <p>To use a Fargate capacity provider, specify either the <code>FARGATE</code> or <code>FARGATE_SPOT</code> capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used.</p>
    /// <p>The <code>PutClusterCapacityProviders</code> API operation is used to update the list of available capacity providers for a cluster after the cluster is created.</p>
    /// <p></p>
    #[doc(hidden)]
    pub capacity_provider_strategy:
        std::option::Option<std::vec::Vec<crate::types::CapacityProviderStrategyItem>>,
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    #[doc(hidden)]
    pub deployment_configuration: std::option::Option<crate::types::DeploymentConfiguration>,
    /// <p>An object representing the network configuration for the service.</p>
    #[doc(hidden)]
    pub network_configuration: std::option::Option<crate::types::NetworkConfiguration>,
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    #[doc(hidden)]
    pub placement_constraints:
        std::option::Option<std::vec::Vec<crate::types::PlacementConstraint>>,
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    #[doc(hidden)]
    pub placement_strategy: std::option::Option<std::vec::Vec<crate::types::PlacementStrategy>>,
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    #[doc(hidden)]
    pub platform_version: std::option::Option<std::string::String>,
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    #[doc(hidden)]
    pub force_new_deployment: bool,
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started. This is only valid if your service is configured to use a load balancer. If your service's tasks take a while to start and respond to Elastic Load Balancing health checks, you can specify a health check grace period of up to 2,147,483,647 seconds. During that time, the Amazon ECS service scheduler ignores the Elastic Load Balancing health check status. This grace period can prevent the ECS service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    #[doc(hidden)]
    pub health_check_grace_period_seconds: std::option::Option<i32>,
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    #[doc(hidden)]
    pub enable_execute_command: std::option::Option<bool>,
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    #[doc(hidden)]
    pub enable_ecs_managed_tags: std::option::Option<bool>,
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>. </p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>. </p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    #[doc(hidden)]
    pub load_balancers: std::option::Option<std::vec::Vec<crate::types::LoadBalancer>>,
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    #[doc(hidden)]
    pub propagate_tags: std::option::Option<crate::types::PropagateTags>,
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    #[doc(hidden)]
    pub service_registries: std::option::Option<std::vec::Vec<crate::types::ServiceRegistry>>,
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    #[doc(hidden)]
    pub service_connect_configuration:
        std::option::Option<crate::types::ServiceConnectConfiguration>,
}
impl UpdateServiceInput {
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    pub fn cluster(&self) -> std::option::Option<&str> {
        self.cluster.as_deref()
    }
    /// <p>The name of the service to update.</p>
    pub fn service(&self) -> std::option::Option<&str> {
        self.service.as_deref()
    }
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    pub fn desired_count(&self) -> std::option::Option<i32> {
        self.desired_count
    }
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    pub fn task_definition(&self) -> std::option::Option<&str> {
        self.task_definition.as_deref()
    }
    /// <p>The capacity provider strategy to update the service to use.</p>
    /// <p>if the service uses the default capacity provider strategy for the cluster, the service can be updated to use one or more capacity providers as opposed to the default capacity provider strategy. However, when a service is using a capacity provider strategy that's not the default capacity provider strategy, the service can't be updated to use the cluster's default capacity provider strategy.</p>
    /// <p>A capacity provider strategy consists of one or more capacity providers along with the <code>base</code> and <code>weight</code> to assign to them. A capacity provider must be associated with the cluster to be used in a capacity provider strategy. The <code>PutClusterCapacityProviders</code> API is used to associate a capacity provider with a cluster. Only capacity providers with an <code>ACTIVE</code> or <code>UPDATING</code> status can be used.</p>
    /// <p>If specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New capacity providers can be created with the <code>CreateCapacityProvider</code> API operation.</p>
    /// <p>To use a Fargate capacity provider, specify either the <code>FARGATE</code> or <code>FARGATE_SPOT</code> capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used.</p>
    /// <p>The <code>PutClusterCapacityProviders</code> API operation is used to update the list of available capacity providers for a cluster after the cluster is created.</p>
    /// <p></p>
    pub fn capacity_provider_strategy(
        &self,
    ) -> std::option::Option<&[crate::types::CapacityProviderStrategyItem]> {
        self.capacity_provider_strategy.as_deref()
    }
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    pub fn deployment_configuration(
        &self,
    ) -> std::option::Option<&crate::types::DeploymentConfiguration> {
        self.deployment_configuration.as_ref()
    }
    /// <p>An object representing the network configuration for the service.</p>
    pub fn network_configuration(
        &self,
    ) -> std::option::Option<&crate::types::NetworkConfiguration> {
        self.network_configuration.as_ref()
    }
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    pub fn placement_constraints(
        &self,
    ) -> std::option::Option<&[crate::types::PlacementConstraint]> {
        self.placement_constraints.as_deref()
    }
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    pub fn placement_strategy(&self) -> std::option::Option<&[crate::types::PlacementStrategy]> {
        self.placement_strategy.as_deref()
    }
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    pub fn platform_version(&self) -> std::option::Option<&str> {
        self.platform_version.as_deref()
    }
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    pub fn force_new_deployment(&self) -> bool {
        self.force_new_deployment
    }
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started. This is only valid if your service is configured to use a load balancer. If your service's tasks take a while to start and respond to Elastic Load Balancing health checks, you can specify a health check grace period of up to 2,147,483,647 seconds. During that time, the Amazon ECS service scheduler ignores the Elastic Load Balancing health check status. This grace period can prevent the ECS service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    pub fn health_check_grace_period_seconds(&self) -> std::option::Option<i32> {
        self.health_check_grace_period_seconds
    }
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    pub fn enable_execute_command(&self) -> std::option::Option<bool> {
        self.enable_execute_command
    }
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    pub fn enable_ecs_managed_tags(&self) -> std::option::Option<bool> {
        self.enable_ecs_managed_tags
    }
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>. </p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>. </p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    pub fn load_balancers(&self) -> std::option::Option<&[crate::types::LoadBalancer]> {
        self.load_balancers.as_deref()
    }
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    pub fn propagate_tags(&self) -> std::option::Option<&crate::types::PropagateTags> {
        self.propagate_tags.as_ref()
    }
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    pub fn service_registries(&self) -> std::option::Option<&[crate::types::ServiceRegistry]> {
        self.service_registries.as_deref()
    }
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    pub fn service_connect_configuration(
        &self,
    ) -> std::option::Option<&crate::types::ServiceConnectConfiguration> {
        self.service_connect_configuration.as_ref()
    }
}
impl UpdateServiceInput {
    /// Creates a new builder-style object to manufacture [`UpdateServiceInput`](crate::operation::update_service::UpdateServiceInput).
    pub fn builder() -> crate::operation::update_service::builders::UpdateServiceInputBuilder {
        crate::operation::update_service::builders::UpdateServiceInputBuilder::default()
    }
}

/// A builder for [`UpdateServiceInput`](crate::operation::update_service::UpdateServiceInput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct UpdateServiceInputBuilder {
    pub(crate) cluster: std::option::Option<std::string::String>,
    pub(crate) service: std::option::Option<std::string::String>,
    pub(crate) desired_count: std::option::Option<i32>,
    pub(crate) task_definition: std::option::Option<std::string::String>,
    pub(crate) capacity_provider_strategy:
        std::option::Option<std::vec::Vec<crate::types::CapacityProviderStrategyItem>>,
    pub(crate) deployment_configuration: std::option::Option<crate::types::DeploymentConfiguration>,
    pub(crate) network_configuration: std::option::Option<crate::types::NetworkConfiguration>,
    pub(crate) placement_constraints:
        std::option::Option<std::vec::Vec<crate::types::PlacementConstraint>>,
    pub(crate) placement_strategy:
        std::option::Option<std::vec::Vec<crate::types::PlacementStrategy>>,
    pub(crate) platform_version: std::option::Option<std::string::String>,
    pub(crate) force_new_deployment: std::option::Option<bool>,
    pub(crate) health_check_grace_period_seconds: std::option::Option<i32>,
    pub(crate) enable_execute_command: std::option::Option<bool>,
    pub(crate) enable_ecs_managed_tags: std::option::Option<bool>,
    pub(crate) load_balancers: std::option::Option<std::vec::Vec<crate::types::LoadBalancer>>,
    pub(crate) propagate_tags: std::option::Option<crate::types::PropagateTags>,
    pub(crate) service_registries:
        std::option::Option<std::vec::Vec<crate::types::ServiceRegistry>>,
    pub(crate) service_connect_configuration:
        std::option::Option<crate::types::ServiceConnectConfiguration>,
}
impl UpdateServiceInputBuilder {
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    pub fn cluster(mut self, input: impl Into<std::string::String>) -> Self {
        self.cluster = Some(input.into());
        self
    }
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    pub fn set_cluster(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.cluster = input;
        self
    }
    /// <p>The name of the service to update.</p>
    pub fn service(mut self, input: impl Into<std::string::String>) -> Self {
        self.service = Some(input.into());
        self
    }
    /// <p>The name of the service to update.</p>
    pub fn set_service(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.service = input;
        self
    }
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    pub fn desired_count(mut self, input: i32) -> Self {
        self.desired_count = Some(input);
        self
    }
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    pub fn set_desired_count(mut self, input: std::option::Option<i32>) -> Self {
        self.desired_count = input;
        self
    }
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    pub fn task_definition(mut self, input: impl Into<std::string::String>) -> Self {
        self.task_definition = Some(input.into());
        self
    }
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    pub fn set_task_definition(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.task_definition = input;
        self
    }
    /// Appends an item to `capacity_provider_strategy`.
    ///
    /// To override the contents of this collection use [`set_capacity_provider_strategy`](Self::set_capacity_provider_strategy).
    ///
    /// <p>The capacity provider strategy to update the service to use.</p>
    /// <p>if the service uses the default capacity provider strategy for the cluster, the service can be updated to use one or more capacity providers as opposed to the default capacity provider strategy. However, when a service is using a capacity provider strategy that's not the default capacity provider strategy, the service can't be updated to use the cluster's default capacity provider strategy.</p>
    /// <p>A capacity provider strategy consists of one or more capacity providers along with the <code>base</code> and <code>weight</code> to assign to them. A capacity provider must be associated with the cluster to be used in a capacity provider strategy. The <code>PutClusterCapacityProviders</code> API is used to associate a capacity provider with a cluster. Only capacity providers with an <code>ACTIVE</code> or <code>UPDATING</code> status can be used.</p>
    /// <p>If specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New capacity providers can be created with the <code>CreateCapacityProvider</code> API operation.</p>
    /// <p>To use a Fargate capacity provider, specify either the <code>FARGATE</code> or <code>FARGATE_SPOT</code> capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used.</p>
    /// <p>The <code>PutClusterCapacityProviders</code> API operation is used to update the list of available capacity providers for a cluster after the cluster is created.</p>
    /// <p></p>
    pub fn capacity_provider_strategy(
        mut self,
        input: crate::types::CapacityProviderStrategyItem,
    ) -> Self {
        let mut v = self.capacity_provider_strategy.unwrap_or_default();
        v.push(input);
        self.capacity_provider_strategy = Some(v);
        self
    }
    /// <p>The capacity provider strategy to update the service to use.</p>
    /// <p>if the service uses the default capacity provider strategy for the cluster, the service can be updated to use one or more capacity providers as opposed to the default capacity provider strategy. However, when a service is using a capacity provider strategy that's not the default capacity provider strategy, the service can't be updated to use the cluster's default capacity provider strategy.</p>
    /// <p>A capacity provider strategy consists of one or more capacity providers along with the <code>base</code> and <code>weight</code> to assign to them. A capacity provider must be associated with the cluster to be used in a capacity provider strategy. The <code>PutClusterCapacityProviders</code> API is used to associate a capacity provider with a cluster. Only capacity providers with an <code>ACTIVE</code> or <code>UPDATING</code> status can be used.</p>
    /// <p>If specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New capacity providers can be created with the <code>CreateCapacityProvider</code> API operation.</p>
    /// <p>To use a Fargate capacity provider, specify either the <code>FARGATE</code> or <code>FARGATE_SPOT</code> capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used.</p>
    /// <p>The <code>PutClusterCapacityProviders</code> API operation is used to update the list of available capacity providers for a cluster after the cluster is created.</p>
    /// <p></p>
    pub fn set_capacity_provider_strategy(
        mut self,
        input: std::option::Option<std::vec::Vec<crate::types::CapacityProviderStrategyItem>>,
    ) -> Self {
        self.capacity_provider_strategy = input;
        self
    }
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    pub fn deployment_configuration(
        mut self,
        input: crate::types::DeploymentConfiguration,
    ) -> Self {
        self.deployment_configuration = Some(input);
        self
    }
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    pub fn set_deployment_configuration(
        mut self,
        input: std::option::Option<crate::types::DeploymentConfiguration>,
    ) -> Self {
        self.deployment_configuration = input;
        self
    }
    /// <p>An object representing the network configuration for the service.</p>
    pub fn network_configuration(mut self, input: crate::types::NetworkConfiguration) -> Self {
        self.network_configuration = Some(input);
        self
    }
    /// <p>An object representing the network configuration for the service.</p>
    pub fn set_network_configuration(
        mut self,
        input: std::option::Option<crate::types::NetworkConfiguration>,
    ) -> Self {
        self.network_configuration = input;
        self
    }
    /// Appends an item to `placement_constraints`.
    ///
    /// To override the contents of this collection use [`set_placement_constraints`](Self::set_placement_constraints).
    ///
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    pub fn placement_constraints(mut self, input: crate::types::PlacementConstraint) -> Self {
        let mut v = self.placement_constraints.unwrap_or_default();
        v.push(input);
        self.placement_constraints = Some(v);
        self
    }
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    pub fn set_placement_constraints(
        mut self,
        input: std::option::Option<std::vec::Vec<crate::types::PlacementConstraint>>,
    ) -> Self {
        self.placement_constraints = input;
        self
    }
    /// Appends an item to `placement_strategy`.
    ///
    /// To override the contents of this collection use [`set_placement_strategy`](Self::set_placement_strategy).
    ///
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    pub fn placement_strategy(mut self, input: crate::types::PlacementStrategy) -> Self {
        let mut v = self.placement_strategy.unwrap_or_default();
        v.push(input);
        self.placement_strategy = Some(v);
        self
    }
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    pub fn set_placement_strategy(
        mut self,
        input: std::option::Option<std::vec::Vec<crate::types::PlacementStrategy>>,
    ) -> Self {
        self.placement_strategy = input;
        self
    }
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    pub fn platform_version(mut self, input: impl Into<std::string::String>) -> Self {
        self.platform_version = Some(input.into());
        self
    }
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    pub fn set_platform_version(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.platform_version = input;
        self
    }
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    pub fn force_new_deployment(mut self, input: bool) -> Self {
        self.force_new_deployment = Some(input);
        self
    }
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    pub fn set_force_new_deployment(mut self, input: std::option::Option<bool>) -> Self {
        self.force_new_deployment = input;
        self
    }
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started. This is only valid if your service is configured to use a load balancer. If your service's tasks take a while to start and respond to Elastic Load Balancing health checks, you can specify a health check grace period of up to 2,147,483,647 seconds. During that time, the Amazon ECS service scheduler ignores the Elastic Load Balancing health check status. This grace period can prevent the ECS service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    pub fn health_check_grace_period_seconds(mut self, input: i32) -> Self {
        self.health_check_grace_period_seconds = Some(input);
        self
    }
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started. This is only valid if your service is configured to use a load balancer. If your service's tasks take a while to start and respond to Elastic Load Balancing health checks, you can specify a health check grace period of up to 2,147,483,647 seconds. During that time, the Amazon ECS service scheduler ignores the Elastic Load Balancing health check status. This grace period can prevent the ECS service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    pub fn set_health_check_grace_period_seconds(
        mut self,
        input: std::option::Option<i32>,
    ) -> Self {
        self.health_check_grace_period_seconds = input;
        self
    }
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    pub fn enable_execute_command(mut self, input: bool) -> Self {
        self.enable_execute_command = Some(input);
        self
    }
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    pub fn set_enable_execute_command(mut self, input: std::option::Option<bool>) -> Self {
        self.enable_execute_command = input;
        self
    }
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    pub fn enable_ecs_managed_tags(mut self, input: bool) -> Self {
        self.enable_ecs_managed_tags = Some(input);
        self
    }
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    pub fn set_enable_ecs_managed_tags(mut self, input: std::option::Option<bool>) -> Self {
        self.enable_ecs_managed_tags = input;
        self
    }
    /// Appends an item to `load_balancers`.
    ///
    /// To override the contents of this collection use [`set_load_balancers`](Self::set_load_balancers).
    ///
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>. </p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>. </p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    pub fn load_balancers(mut self, input: crate::types::LoadBalancer) -> Self {
        let mut v = self.load_balancers.unwrap_or_default();
        v.push(input);
        self.load_balancers = Some(v);
        self
    }
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>. </p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>. </p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    pub fn set_load_balancers(
        mut self,
        input: std::option::Option<std::vec::Vec<crate::types::LoadBalancer>>,
    ) -> Self {
        self.load_balancers = input;
        self
    }
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    pub fn propagate_tags(mut self, input: crate::types::PropagateTags) -> Self {
        self.propagate_tags = Some(input);
        self
    }
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    pub fn set_propagate_tags(
        mut self,
        input: std::option::Option<crate::types::PropagateTags>,
    ) -> Self {
        self.propagate_tags = input;
        self
    }
    /// Appends an item to `service_registries`.
    ///
    /// To override the contents of this collection use [`set_service_registries`](Self::set_service_registries).
    ///
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    pub fn service_registries(mut self, input: crate::types::ServiceRegistry) -> Self {
        let mut v = self.service_registries.unwrap_or_default();
        v.push(input);
        self.service_registries = Some(v);
        self
    }
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    pub fn set_service_registries(
        mut self,
        input: std::option::Option<std::vec::Vec<crate::types::ServiceRegistry>>,
    ) -> Self {
        self.service_registries = input;
        self
    }
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    pub fn service_connect_configuration(
        mut self,
        input: crate::types::ServiceConnectConfiguration,
    ) -> Self {
        self.service_connect_configuration = Some(input);
        self
    }
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    pub fn set_service_connect_configuration(
        mut self,
        input: std::option::Option<crate::types::ServiceConnectConfiguration>,
    ) -> Self {
        self.service_connect_configuration = input;
        self
    }
    /// Consumes the builder and constructs a [`UpdateServiceInput`](crate::operation::update_service::UpdateServiceInput).
    pub fn build(
        self,
    ) -> Result<
        crate::operation::update_service::UpdateServiceInput,
        aws_smithy_http::operation::error::BuildError,
    > {
        Ok(crate::operation::update_service::UpdateServiceInput {
            cluster: self.cluster,
            service: self.service,
            desired_count: self.desired_count,
            task_definition: self.task_definition,
            capacity_provider_strategy: self.capacity_provider_strategy,
            deployment_configuration: self.deployment_configuration,
            network_configuration: self.network_configuration,
            placement_constraints: self.placement_constraints,
            placement_strategy: self.placement_strategy,
            platform_version: self.platform_version,
            force_new_deployment: self.force_new_deployment.unwrap_or_default(),
            health_check_grace_period_seconds: self.health_check_grace_period_seconds,
            enable_execute_command: self.enable_execute_command,
            enable_ecs_managed_tags: self.enable_ecs_managed_tags,
            load_balancers: self.load_balancers,
            propagate_tags: self.propagate_tags,
            service_registries: self.service_registries,
            service_connect_configuration: self.service_connect_configuration,
        })
    }
}
