// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
pub use crate::operation::update_service::_update_service_output::UpdateServiceOutputBuilder;

pub use crate::operation::update_service::_update_service_input::UpdateServiceInputBuilder;

impl crate::operation::update_service::builders::UpdateServiceInputBuilder {
    /// Sends a request with this input using the given client.
    pub async fn send_with(
        self,
        client: &crate::Client,
    ) -> ::std::result::Result<
        crate::operation::update_service::UpdateServiceOutput,
        ::aws_smithy_runtime_api::client::result::SdkError<
            crate::operation::update_service::UpdateServiceError,
            ::aws_smithy_runtime_api::client::orchestrator::HttpResponse,
        >,
    > {
        let mut fluent_builder = client.update_service();
        fluent_builder.inner = self;
        fluent_builder.send().await
    }
}
/// Fluent builder constructing a request to `UpdateService`.
///
/// <p>Modifies the parameters of a service.</p><note>
/// <p>On March 21, 2024, a change was made to resolve the task definition revision before authorization. When a task definition revision is not specified, authorization will occur using the latest revision of a task definition.</p>
/// </note>
/// <p>For services using the rolling update (<code>ECS</code>) you can update the desired count, deployment configuration, network configuration, load balancers, service registries, enable ECS managed tags option, propagate tags option, task placement constraints and strategies, and task definition. When you update any of these parameters, Amazon ECS starts new tasks with the new configuration.</p>
/// <p>You can attach Amazon EBS volumes to Amazon ECS tasks by configuring the volume when starting or running a task, or when creating or updating a service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-volumes.html#ebs-volume-types">Amazon EBS volumes</a> in the <i>Amazon Elastic Container Service Developer Guide</i>. You can update your volume configurations and trigger a new deployment. <code>volumeConfigurations</code> is only supported for REPLICA service and not DAEMON service. If you leave <code>volumeConfigurations</code> <code>null</code>, it doesn't trigger a new deployment. For more information on volumes, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-volumes.html#ebs-volume-types">Amazon EBS volumes</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
/// <p>For services using the blue/green (<code>CODE_DEPLOY</code>) deployment controller, only the desired count, deployment configuration, health check grace period, task placement constraints and strategies, enable ECS managed tags option, and propagate tags can be updated using this API. If the network configuration, platform version, task definition, or load balancer need to be updated, create a new CodeDeploy deployment. For more information, see <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> in the <i>CodeDeploy API Reference</i>.</p>
/// <p>For services using an external deployment controller, you can update only the desired count, task placement constraints and strategies, health check grace period, enable ECS managed tags option, and propagate tags option, using this API. If the launch type, load balancer, network configuration, platform version, or task definition need to be updated, create a new task set For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>.</p>
/// <p>You can add to or subtract from the number of instantiations of a task definition in a service by specifying the cluster that the service is running in and a new <code>desiredCount</code> parameter.</p>
/// <p>You can attach Amazon EBS volumes to Amazon ECS tasks by configuring the volume when starting or running a task, or when creating or updating a service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-volumes.html#ebs-volume-types">Amazon EBS volumes</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
/// <p>If you have updated the container image of your application, you can create a new task definition with that image and deploy it to your service. The service scheduler uses the minimum healthy percent and maximum percent parameters (in the service's deployment configuration) to determine the deployment strategy.</p><note>
/// <p>If your updated Docker image uses the same tag as what is in the existing task definition for your service (for example, <code>my_image:latest</code>), you don't need to create a new revision of your task definition. You can update the service using the <code>forceNewDeployment</code> option. The new tasks launched by the deployment pull the current image/tag combination from your repository when they start.</p>
/// </note>
/// <p>You can also update the deployment configuration of a service. When a deployment is triggered by updating the task definition of a service, the service scheduler uses the deployment configuration parameters, <code>minimumHealthyPercent</code> and <code>maximumPercent</code>, to determine the deployment strategy.</p>
/// <ul>
/// <li>
/// <p>If <code>minimumHealthyPercent</code> is below 100%, the scheduler can ignore <code>desiredCount</code> temporarily during a deployment. For example, if <code>desiredCount</code> is four tasks, a minimum of 50% allows the scheduler to stop two existing tasks before starting two new tasks. Tasks for services that don't use a load balancer are considered healthy if they're in the <code>RUNNING</code> state. Tasks for services that use a load balancer are considered healthy if they're in the <code>RUNNING</code> state and are reported as healthy by the load balancer.</p></li>
/// <li>
/// <p>The <code>maximumPercent</code> parameter represents an upper limit on the number of running tasks during a deployment. You can use it to define the deployment batch size. For example, if <code>desiredCount</code> is four tasks, a maximum of 200% starts four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available).</p></li>
/// </ul>
/// <p>When <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_UpdateService.html">UpdateService</a> stops a task during a deployment, the equivalent of <code>docker stop</code> is issued to the containers running in the task. This results in a <code>SIGTERM</code> and a 30-second timeout. After this, <code>SIGKILL</code> is sent and the containers are forcibly stopped. If the container handles the <code>SIGTERM</code> gracefully and exits within 30 seconds from receiving it, no <code>SIGKILL</code> is sent.</p>
/// <p>When the service scheduler launches new tasks, it determines task placement in your cluster with the following logic.</p>
/// <ul>
/// <li>
/// <p>Determine which of the container instances in your cluster can support your service's task definition. For example, they have the required CPU, memory, ports, and container instance attributes.</p></li>
/// <li>
/// <p>By default, the service scheduler attempts to balance tasks across Availability Zones in this manner even though you can choose a different placement strategy.</p>
/// <ul>
/// <li>
/// <p>Sort the valid container instances by the fewest number of running tasks for this service in the same Availability Zone as the instance. For example, if zone A has one running service task and zones B and C each have zero, valid container instances in either zone B or C are considered optimal for placement.</p></li>
/// <li>
/// <p>Place the new service task on a valid container instance in an optimal Availability Zone (based on the previous steps), favoring container instances with the fewest number of running tasks for this service.</p></li>
/// </ul></li>
/// </ul>
/// <p>When the service scheduler stops running tasks, it attempts to maintain balance across the Availability Zones in your cluster using the following logic:</p>
/// <ul>
/// <li>
/// <p>Sort the container instances by the largest number of running tasks for this service in the same Availability Zone as the instance. For example, if zone A has one running service task and zones B and C each have two, container instances in either zone B or C are considered optimal for termination.</p></li>
/// <li>
/// <p>Stop the task on a container instance in an optimal Availability Zone (based on the previous steps), favoring container instances with the largest number of running tasks for this service.</p></li>
/// </ul>
#[derive(::std::clone::Clone, ::std::fmt::Debug)]
pub struct UpdateServiceFluentBuilder {
    handle: ::std::sync::Arc<crate::client::Handle>,
    inner: crate::operation::update_service::builders::UpdateServiceInputBuilder,
    config_override: ::std::option::Option<crate::config::Builder>,
}
impl
    crate::client::customize::internal::CustomizableSend<
        crate::operation::update_service::UpdateServiceOutput,
        crate::operation::update_service::UpdateServiceError,
    > for UpdateServiceFluentBuilder
{
    fn send(
        self,
        config_override: crate::config::Builder,
    ) -> crate::client::customize::internal::BoxFuture<
        crate::client::customize::internal::SendResult<
            crate::operation::update_service::UpdateServiceOutput,
            crate::operation::update_service::UpdateServiceError,
        >,
    > {
        ::std::boxed::Box::pin(async move { self.config_override(config_override).send().await })
    }
}
impl UpdateServiceFluentBuilder {
    /// Creates a new `UpdateServiceFluentBuilder`.
    pub(crate) fn new(handle: ::std::sync::Arc<crate::client::Handle>) -> Self {
        Self {
            handle,
            inner: ::std::default::Default::default(),
            config_override: ::std::option::Option::None,
        }
    }
    /// Access the UpdateService as a reference.
    pub fn as_input(&self) -> &crate::operation::update_service::builders::UpdateServiceInputBuilder {
        &self.inner
    }
    /// Sends the request and returns the response.
    ///
    /// If an error occurs, an `SdkError` will be returned with additional details that
    /// can be matched against.
    ///
    /// By default, any retryable failures will be retried twice. Retry behavior
    /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
    /// set when configuring the client.
    pub async fn send(
        self,
    ) -> ::std::result::Result<
        crate::operation::update_service::UpdateServiceOutput,
        ::aws_smithy_runtime_api::client::result::SdkError<
            crate::operation::update_service::UpdateServiceError,
            ::aws_smithy_runtime_api::client::orchestrator::HttpResponse,
        >,
    > {
        let input = self
            .inner
            .build()
            .map_err(::aws_smithy_runtime_api::client::result::SdkError::construction_failure)?;
        let runtime_plugins = crate::operation::update_service::UpdateService::operation_runtime_plugins(
            self.handle.runtime_plugins.clone(),
            &self.handle.conf,
            self.config_override,
        );
        crate::operation::update_service::UpdateService::orchestrate(&runtime_plugins, input).await
    }

    /// Consumes this builder, creating a customizable operation that can be modified before being sent.
    pub fn customize(
        self,
    ) -> crate::client::customize::CustomizableOperation<
        crate::operation::update_service::UpdateServiceOutput,
        crate::operation::update_service::UpdateServiceError,
        Self,
    > {
        crate::client::customize::CustomizableOperation::new(self)
    }
    pub(crate) fn config_override(mut self, config_override: impl ::std::convert::Into<crate::config::Builder>) -> Self {
        self.set_config_override(::std::option::Option::Some(config_override.into()));
        self
    }

    pub(crate) fn set_config_override(&mut self, config_override: ::std::option::Option<crate::config::Builder>) -> &mut Self {
        self.config_override = config_override;
        self
    }
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    /// <p>You can't change the cluster name.</p>
    pub fn cluster(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.inner = self.inner.cluster(input.into());
        self
    }
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    /// <p>You can't change the cluster name.</p>
    pub fn set_cluster(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.inner = self.inner.set_cluster(input);
        self
    }
    /// <p>The short name or full Amazon Resource Name (ARN) of the cluster that your service runs on. If you do not specify a cluster, the default cluster is assumed.</p>
    /// <p>You can't change the cluster name.</p>
    pub fn get_cluster(&self) -> &::std::option::Option<::std::string::String> {
        self.inner.get_cluster()
    }
    /// <p>The name of the service to update.</p>
    pub fn service(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.inner = self.inner.service(input.into());
        self
    }
    /// <p>The name of the service to update.</p>
    pub fn set_service(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.inner = self.inner.set_service(input);
        self
    }
    /// <p>The name of the service to update.</p>
    pub fn get_service(&self) -> &::std::option::Option<::std::string::String> {
        self.inner.get_service()
    }
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn desired_count(mut self, input: i32) -> Self {
        self.inner = self.inner.desired_count(input);
        self
    }
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_desired_count(mut self, input: ::std::option::Option<i32>) -> Self {
        self.inner = self.inner.set_desired_count(input);
        self
    }
    /// <p>The number of instantiations of the task to place and keep running in your service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_desired_count(&self) -> &::std::option::Option<i32> {
        self.inner.get_desired_count()
    }
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn task_definition(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.inner = self.inner.task_definition(input.into());
        self
    }
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_task_definition(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.inner = self.inner.set_task_definition(input);
        self
    }
    /// <p>The <code>family</code> and <code>revision</code> (<code>family:revision</code>) or full ARN of the task definition to run in your service. If a <code>revision</code> is not specified, the latest <code>ACTIVE</code> revision is used. If you modify the task definition with <code>UpdateService</code>, Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_task_definition(&self) -> &::std::option::Option<::std::string::String> {
        self.inner.get_task_definition()
    }
    ///
    /// Appends an item to `capacityProviderStrategy`.
    ///
    /// To override the contents of this collection use [`set_capacity_provider_strategy`](Self::set_capacity_provider_strategy).
    ///
    /// <p>The details of a capacity provider strategy. You can set a capacity provider when you create a cluster, run a task, or update a service.</p><note>
    /// <p>If you want to use Amazon ECS Managed Instances, you must use the <code>capacityProviderStrategy</code> request parameter.</p>
    /// </note>
    /// <p>When you use Fargate, the capacity providers are <code>FARGATE</code> or <code>FARGATE_SPOT</code>.</p>
    /// <p>When you use Amazon EC2, the capacity providers are Auto Scaling groups.</p>
    /// <p>You can change capacity providers for rolling deployments and blue/green deployments.</p>
    /// <p>The following list provides the valid transitions:</p>
    /// <ul>
    /// <li>
    /// <p>Update the Fargate launch type to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 launch type to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Fargate capacity provider to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 capacity provider to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Auto Scaling group or Fargate capacity provider back to the launch type.</p>
    /// <p>Pass an empty list in the <code>capacityProviderStrategy</code> parameter.</p></li>
    /// </ul>
    /// <p>For information about Amazon Web Services CDK considerations, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service-parameters.html">Amazon Web Services CDK considerations</a>.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn capacity_provider_strategy(mut self, input: crate::types::CapacityProviderStrategyItem) -> Self {
        self.inner = self.inner.capacity_provider_strategy(input);
        self
    }
    /// <p>The details of a capacity provider strategy. You can set a capacity provider when you create a cluster, run a task, or update a service.</p><note>
    /// <p>If you want to use Amazon ECS Managed Instances, you must use the <code>capacityProviderStrategy</code> request parameter.</p>
    /// </note>
    /// <p>When you use Fargate, the capacity providers are <code>FARGATE</code> or <code>FARGATE_SPOT</code>.</p>
    /// <p>When you use Amazon EC2, the capacity providers are Auto Scaling groups.</p>
    /// <p>You can change capacity providers for rolling deployments and blue/green deployments.</p>
    /// <p>The following list provides the valid transitions:</p>
    /// <ul>
    /// <li>
    /// <p>Update the Fargate launch type to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 launch type to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Fargate capacity provider to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 capacity provider to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Auto Scaling group or Fargate capacity provider back to the launch type.</p>
    /// <p>Pass an empty list in the <code>capacityProviderStrategy</code> parameter.</p></li>
    /// </ul>
    /// <p>For information about Amazon Web Services CDK considerations, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service-parameters.html">Amazon Web Services CDK considerations</a>.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_capacity_provider_strategy(
        mut self,
        input: ::std::option::Option<::std::vec::Vec<crate::types::CapacityProviderStrategyItem>>,
    ) -> Self {
        self.inner = self.inner.set_capacity_provider_strategy(input);
        self
    }
    /// <p>The details of a capacity provider strategy. You can set a capacity provider when you create a cluster, run a task, or update a service.</p><note>
    /// <p>If you want to use Amazon ECS Managed Instances, you must use the <code>capacityProviderStrategy</code> request parameter.</p>
    /// </note>
    /// <p>When you use Fargate, the capacity providers are <code>FARGATE</code> or <code>FARGATE_SPOT</code>.</p>
    /// <p>When you use Amazon EC2, the capacity providers are Auto Scaling groups.</p>
    /// <p>You can change capacity providers for rolling deployments and blue/green deployments.</p>
    /// <p>The following list provides the valid transitions:</p>
    /// <ul>
    /// <li>
    /// <p>Update the Fargate launch type to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 launch type to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Fargate capacity provider to an Auto Scaling group capacity provider.</p></li>
    /// <li>
    /// <p>Update the Amazon EC2 capacity provider to a Fargate capacity provider.</p></li>
    /// <li>
    /// <p>Update the Auto Scaling group or Fargate capacity provider back to the launch type.</p>
    /// <p>Pass an empty list in the <code>capacityProviderStrategy</code> parameter.</p></li>
    /// </ul>
    /// <p>For information about Amazon Web Services CDK considerations, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service-parameters.html">Amazon Web Services CDK considerations</a>.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_capacity_provider_strategy(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::CapacityProviderStrategyItem>> {
        self.inner.get_capacity_provider_strategy()
    }
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn deployment_configuration(mut self, input: crate::types::DeploymentConfiguration) -> Self {
        self.inner = self.inner.deployment_configuration(input);
        self
    }
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_deployment_configuration(mut self, input: ::std::option::Option<crate::types::DeploymentConfiguration>) -> Self {
        self.inner = self.inner.set_deployment_configuration(input);
        self
    }
    /// <p>Optional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_deployment_configuration(&self) -> &::std::option::Option<crate::types::DeploymentConfiguration> {
        self.inner.get_deployment_configuration()
    }
    /// <p>Indicates whether to use Availability Zone rebalancing for the service.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-rebalancing.html">Balancing an Amazon ECS service across Availability Zones</a> in the <i> <i>Amazon Elastic Container Service Developer Guide</i> </i>.</p>
    /// <p>The default behavior of <code>AvailabilityZoneRebalancing</code> differs between create and update requests:</p>
    /// <ul>
    /// <li>
    /// <p>For create service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults the value to <code>ENABLED</code>.</p></li>
    /// <li>
    /// <p>For update service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults to the existing service’s <code>AvailabilityZoneRebalancing</code> value. If the service never had an <code>AvailabilityZoneRebalancing</code> value set, Amazon ECS treats this as <code>DISABLED</code>.</p></li>
    /// </ul>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn availability_zone_rebalancing(mut self, input: crate::types::AvailabilityZoneRebalancing) -> Self {
        self.inner = self.inner.availability_zone_rebalancing(input);
        self
    }
    /// <p>Indicates whether to use Availability Zone rebalancing for the service.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-rebalancing.html">Balancing an Amazon ECS service across Availability Zones</a> in the <i> <i>Amazon Elastic Container Service Developer Guide</i> </i>.</p>
    /// <p>The default behavior of <code>AvailabilityZoneRebalancing</code> differs between create and update requests:</p>
    /// <ul>
    /// <li>
    /// <p>For create service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults the value to <code>ENABLED</code>.</p></li>
    /// <li>
    /// <p>For update service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults to the existing service’s <code>AvailabilityZoneRebalancing</code> value. If the service never had an <code>AvailabilityZoneRebalancing</code> value set, Amazon ECS treats this as <code>DISABLED</code>.</p></li>
    /// </ul>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_availability_zone_rebalancing(mut self, input: ::std::option::Option<crate::types::AvailabilityZoneRebalancing>) -> Self {
        self.inner = self.inner.set_availability_zone_rebalancing(input);
        self
    }
    /// <p>Indicates whether to use Availability Zone rebalancing for the service.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-rebalancing.html">Balancing an Amazon ECS service across Availability Zones</a> in the <i> <i>Amazon Elastic Container Service Developer Guide</i> </i>.</p>
    /// <p>The default behavior of <code>AvailabilityZoneRebalancing</code> differs between create and update requests:</p>
    /// <ul>
    /// <li>
    /// <p>For create service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults the value to <code>ENABLED</code>.</p></li>
    /// <li>
    /// <p>For update service requests, when no value is specified for <code>AvailabilityZoneRebalancing</code>, Amazon ECS defaults to the existing service’s <code>AvailabilityZoneRebalancing</code> value. If the service never had an <code>AvailabilityZoneRebalancing</code> value set, Amazon ECS treats this as <code>DISABLED</code>.</p></li>
    /// </ul>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_availability_zone_rebalancing(&self) -> &::std::option::Option<crate::types::AvailabilityZoneRebalancing> {
        self.inner.get_availability_zone_rebalancing()
    }
    /// <p>An object representing the network configuration for the service.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn network_configuration(mut self, input: crate::types::NetworkConfiguration) -> Self {
        self.inner = self.inner.network_configuration(input);
        self
    }
    /// <p>An object representing the network configuration for the service.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_network_configuration(mut self, input: ::std::option::Option<crate::types::NetworkConfiguration>) -> Self {
        self.inner = self.inner.set_network_configuration(input);
        self
    }
    /// <p>An object representing the network configuration for the service.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_network_configuration(&self) -> &::std::option::Option<crate::types::NetworkConfiguration> {
        self.inner.get_network_configuration()
    }
    ///
    /// Appends an item to `placementConstraints`.
    ///
    /// To override the contents of this collection use [`set_placement_constraints`](Self::set_placement_constraints).
    ///
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn placement_constraints(mut self, input: crate::types::PlacementConstraint) -> Self {
        self.inner = self.inner.placement_constraints(input);
        self
    }
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_placement_constraints(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::PlacementConstraint>>) -> Self {
        self.inner = self.inner.set_placement_constraints(input);
        self
    }
    /// <p>An array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.</p>
    /// <p>You can specify a maximum of 10 constraints for each task. This limit includes constraints in the task definition and those specified at runtime.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_placement_constraints(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::PlacementConstraint>> {
        self.inner.get_placement_constraints()
    }
    ///
    /// Appends an item to `placementStrategy`.
    ///
    /// To override the contents of this collection use [`set_placement_strategy`](Self::set_placement_strategy).
    ///
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn placement_strategy(mut self, input: crate::types::PlacementStrategy) -> Self {
        self.inner = self.inner.placement_strategy(input);
        self
    }
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_placement_strategy(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::PlacementStrategy>>) -> Self {
        self.inner = self.inner.set_placement_strategy(input);
        self
    }
    /// <p>The task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.</p>
    /// <p>You can specify a maximum of five strategy rules for each service.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_placement_strategy(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::PlacementStrategy>> {
        self.inner.get_placement_strategy()
    }
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn platform_version(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.inner = self.inner.platform_version(input.into());
        self
    }
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_platform_version(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.inner = self.inner.set_platform_version(input);
        self
    }
    /// <p>The platform version that your tasks in the service run on. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the <code>LATEST</code> platform version is used. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html">Fargate Platform Versions</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_platform_version(&self) -> &::std::option::Option<::std::string::String> {
        self.inner.get_platform_version()
    }
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    pub fn force_new_deployment(mut self, input: bool) -> Self {
        self.inner = self.inner.force_new_deployment(input);
        self
    }
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    pub fn set_force_new_deployment(mut self, input: ::std::option::Option<bool>) -> Self {
        self.inner = self.inner.set_force_new_deployment(input);
        self
    }
    /// <p>Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (<code>my_image:latest</code>) or to roll Fargate tasks onto a newer platform version.</p>
    pub fn get_force_new_deployment(&self) -> &::std::option::Option<bool> {
        self.inner.get_force_new_deployment()
    }
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing, VPC Lattice, and container health checks after a task has first started. If you don't specify a health check grace period value, the default value of <code>0</code> is used. If you don't use any of the health checks, then <code>healthCheckGracePeriodSeconds</code> is unused.</p>
    /// <p>If your service's tasks take a while to start and respond to health checks, you can specify a health check grace period of up to 2,147,483,647 seconds (about 69 years). During that time, the Amazon ECS service scheduler ignores health check status. This grace period can prevent the service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    /// <p>If your service has more running tasks than desired, unhealthy tasks in the grace period might be stopped to reach the desired count.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn health_check_grace_period_seconds(mut self, input: i32) -> Self {
        self.inner = self.inner.health_check_grace_period_seconds(input);
        self
    }
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing, VPC Lattice, and container health checks after a task has first started. If you don't specify a health check grace period value, the default value of <code>0</code> is used. If you don't use any of the health checks, then <code>healthCheckGracePeriodSeconds</code> is unused.</p>
    /// <p>If your service's tasks take a while to start and respond to health checks, you can specify a health check grace period of up to 2,147,483,647 seconds (about 69 years). During that time, the Amazon ECS service scheduler ignores health check status. This grace period can prevent the service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    /// <p>If your service has more running tasks than desired, unhealthy tasks in the grace period might be stopped to reach the desired count.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_health_check_grace_period_seconds(mut self, input: ::std::option::Option<i32>) -> Self {
        self.inner = self.inner.set_health_check_grace_period_seconds(input);
        self
    }
    /// <p>The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing, VPC Lattice, and container health checks after a task has first started. If you don't specify a health check grace period value, the default value of <code>0</code> is used. If you don't use any of the health checks, then <code>healthCheckGracePeriodSeconds</code> is unused.</p>
    /// <p>If your service's tasks take a while to start and respond to health checks, you can specify a health check grace period of up to 2,147,483,647 seconds (about 69 years). During that time, the Amazon ECS service scheduler ignores health check status. This grace period can prevent the service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.</p>
    /// <p>If your service has more running tasks than desired, unhealthy tasks in the grace period might be stopped to reach the desired count.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_health_check_grace_period_seconds(&self) -> &::std::option::Option<i32> {
        self.inner.get_health_check_grace_period_seconds()
    }
    /// <p>The deployment controller to use for the service.</p>
    pub fn deployment_controller(mut self, input: crate::types::DeploymentController) -> Self {
        self.inner = self.inner.deployment_controller(input);
        self
    }
    /// <p>The deployment controller to use for the service.</p>
    pub fn set_deployment_controller(mut self, input: ::std::option::Option<crate::types::DeploymentController>) -> Self {
        self.inner = self.inner.set_deployment_controller(input);
        self
    }
    /// <p>The deployment controller to use for the service.</p>
    pub fn get_deployment_controller(&self) -> &::std::option::Option<crate::types::DeploymentController> {
        self.inner.get_deployment_controller()
    }
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn enable_execute_command(mut self, input: bool) -> Self {
        self.inner = self.inner.enable_execute_command(input);
        self
    }
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_enable_execute_command(mut self, input: ::std::option::Option<bool>) -> Self {
        self.inner = self.inner.set_enable_execute_command(input);
        self
    }
    /// <p>If <code>true</code>, this enables execute command functionality on all task containers.</p>
    /// <p>If you do not want to override the value that was set when the service was created, you can set this to <code>null</code> when performing this action.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_enable_execute_command(&self) -> &::std::option::Option<bool> {
        self.inner.get_enable_execute_command()
    }
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn enable_ecs_managed_tags(mut self, input: bool) -> Self {
        self.inner = self.inner.enable_ecs_managed_tags(input);
        self
    }
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_enable_ecs_managed_tags(mut self, input: ::std::option::Option<bool>) -> Self {
        self.inner = self.inner.set_enable_ecs_managed_tags(input);
        self
    }
    /// <p>Determines whether to turn on Amazon ECS managed tags for the tasks in the service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html">Tagging Your Amazon ECS Resources</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_enable_ecs_managed_tags(&self) -> &::std::option::Option<bool> {
        self.inner.get_enable_ecs_managed_tags()
    }
    ///
    /// Appends an item to `loadBalancers`.
    ///
    /// To override the contents of this collection use [`set_load_balancers`](Self::set_load_balancers).
    ///
    /// <note>
    /// <p>You must have a service-linked role when you update this property</p>
    /// </note>
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn load_balancers(mut self, input: crate::types::LoadBalancer) -> Self {
        self.inner = self.inner.load_balancers(input);
        self
    }
    /// <note>
    /// <p>You must have a service-linked role when you update this property</p>
    /// </note>
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_load_balancers(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::LoadBalancer>>) -> Self {
        self.inner = self.inner.set_load_balancers(input);
        self
    }
    /// <note>
    /// <p>You must have a service-linked role when you update this property</p>
    /// </note>
    /// <p>A list of Elastic Load Balancing load balancer objects. It contains the load balancer name, the container name, and the container port to access from the load balancer. The container name is as it appears in a container definition.</p>
    /// <p>When you add, update, or remove a load balancer configuration, Amazon ECS starts new tasks with the updated Elastic Load Balancing configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>For services that use rolling updates, you can add, update, or remove Elastic Load Balancing target groups. You can update from a single target group to multiple target groups and from multiple target groups to a single target group.</p>
    /// <p>For services that use blue/green deployments, you can update Elastic Load Balancing target groups by using <code> <a href="https://docs.aws.amazon.com/codedeploy/latest/APIReference/API_CreateDeployment.html">CreateDeployment</a> </code> through CodeDeploy. Note that multiple target groups are not supported for blue/green deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>For services that use the external deployment controller, you can add, update, or remove load balancers by using <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateTaskSet.html">CreateTaskSet</a>. Note that multiple target groups are not supported for external deployments. For more information see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html">Register multiple target groups with a service</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>You can remove existing <code>loadBalancers</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_load_balancers(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::LoadBalancer>> {
        self.inner.get_load_balancers()
    }
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn propagate_tags(mut self, input: crate::types::PropagateTags) -> Self {
        self.inner = self.inner.propagate_tags(input);
        self
    }
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn set_propagate_tags(mut self, input: ::std::option::Option<crate::types::PropagateTags>) -> Self {
        self.inner = self.inner.set_propagate_tags(input);
        self
    }
    /// <p>Determines whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags aren't propagated.</p>
    /// <p>Only tasks launched after the update will reflect the update. To update the tags on all tasks, set <code>forceNewDeployment</code> to <code>true</code>, so that Amazon ECS starts new tasks with the updated tags.</p>
    /// <p>This parameter doesn't trigger a new service deployment.</p>
    pub fn get_propagate_tags(&self) -> &::std::option::Option<crate::types::PropagateTags> {
        self.inner.get_propagate_tags()
    }
    ///
    /// Appends an item to `serviceRegistries`.
    ///
    /// To override the contents of this collection use [`set_service_registries`](Self::set_service_registries).
    ///
    /// <note>
    /// <p>You must have a service-linked role when you update this property.</p>
    /// <p>For more information about the role see the <code>CreateService</code> request parameter <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateService.html#ECS-CreateService-request-role"> <code>role</code> </a>.</p>
    /// </note>
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn service_registries(mut self, input: crate::types::ServiceRegistry) -> Self {
        self.inner = self.inner.service_registries(input);
        self
    }
    /// <note>
    /// <p>You must have a service-linked role when you update this property.</p>
    /// <p>For more information about the role see the <code>CreateService</code> request parameter <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateService.html#ECS-CreateService-request-role"> <code>role</code> </a>.</p>
    /// </note>
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_service_registries(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::ServiceRegistry>>) -> Self {
        self.inner = self.inner.set_service_registries(input);
        self
    }
    /// <note>
    /// <p>You must have a service-linked role when you update this property.</p>
    /// <p>For more information about the role see the <code>CreateService</code> request parameter <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateService.html#ECS-CreateService-request-role"> <code>role</code> </a>.</p>
    /// </note>
    /// <p>The details for the service discovery registries to assign to this service. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-discovery.html">Service Discovery</a>.</p>
    /// <p>When you add, update, or remove the service registries configuration, Amazon ECS starts new tasks with the updated service registries configuration, and then stops the old tasks when the new tasks are running.</p>
    /// <p>You can remove existing <code>serviceRegistries</code> by passing an empty list.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_service_registries(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::ServiceRegistry>> {
        self.inner.get_service_registries()
    }
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn service_connect_configuration(mut self, input: crate::types::ServiceConnectConfiguration) -> Self {
        self.inner = self.inner.service_connect_configuration(input);
        self
    }
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_service_connect_configuration(mut self, input: ::std::option::Option<crate::types::ServiceConnectConfiguration>) -> Self {
        self.inner = self.inner.set_service_connect_configuration(input);
        self
    }
    /// <p>The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.</p>
    /// <p>Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html">Service Connect</a> in the <i>Amazon Elastic Container Service Developer Guide</i>.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_service_connect_configuration(&self) -> &::std::option::Option<crate::types::ServiceConnectConfiguration> {
        self.inner.get_service_connect_configuration()
    }
    ///
    /// Appends an item to `volumeConfigurations`.
    ///
    /// To override the contents of this collection use [`set_volume_configurations`](Self::set_volume_configurations).
    ///
    /// <p>The details of the volume that was <code>configuredAtLaunch</code>. You can configure the size, volumeType, IOPS, throughput, snapshot and encryption in <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_ServiceManagedEBSVolumeConfiguration.html">ServiceManagedEBSVolumeConfiguration</a>. The <code>name</code> of the volume must match the <code>name</code> from the task definition. If set to null, no new deployment is triggered. Otherwise, if this configuration differs from the existing one, it triggers a new deployment.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn volume_configurations(mut self, input: crate::types::ServiceVolumeConfiguration) -> Self {
        self.inner = self.inner.volume_configurations(input);
        self
    }
    /// <p>The details of the volume that was <code>configuredAtLaunch</code>. You can configure the size, volumeType, IOPS, throughput, snapshot and encryption in <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_ServiceManagedEBSVolumeConfiguration.html">ServiceManagedEBSVolumeConfiguration</a>. The <code>name</code> of the volume must match the <code>name</code> from the task definition. If set to null, no new deployment is triggered. Otherwise, if this configuration differs from the existing one, it triggers a new deployment.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_volume_configurations(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::ServiceVolumeConfiguration>>) -> Self {
        self.inner = self.inner.set_volume_configurations(input);
        self
    }
    /// <p>The details of the volume that was <code>configuredAtLaunch</code>. You can configure the size, volumeType, IOPS, throughput, snapshot and encryption in <a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_ServiceManagedEBSVolumeConfiguration.html">ServiceManagedEBSVolumeConfiguration</a>. The <code>name</code> of the volume must match the <code>name</code> from the task definition. If set to null, no new deployment is triggered. Otherwise, if this configuration differs from the existing one, it triggers a new deployment.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_volume_configurations(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::ServiceVolumeConfiguration>> {
        self.inner.get_volume_configurations()
    }
    ///
    /// Appends an item to `vpcLatticeConfigurations`.
    ///
    /// To override the contents of this collection use [`set_vpc_lattice_configurations`](Self::set_vpc_lattice_configurations).
    ///
    /// <p>An object representing the VPC Lattice configuration for the service being updated.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn vpc_lattice_configurations(mut self, input: crate::types::VpcLatticeConfiguration) -> Self {
        self.inner = self.inner.vpc_lattice_configurations(input);
        self
    }
    /// <p>An object representing the VPC Lattice configuration for the service being updated.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn set_vpc_lattice_configurations(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::VpcLatticeConfiguration>>) -> Self {
        self.inner = self.inner.set_vpc_lattice_configurations(input);
        self
    }
    /// <p>An object representing the VPC Lattice configuration for the service being updated.</p>
    /// <p>This parameter triggers a new service deployment.</p>
    pub fn get_vpc_lattice_configurations(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::VpcLatticeConfiguration>> {
        self.inner.get_vpc_lattice_configurations()
    }
}
