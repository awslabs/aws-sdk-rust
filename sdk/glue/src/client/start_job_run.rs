// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`StartJobRun`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`job_name(impl Into<String>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::job_name) / [`set_job_name(Option<String>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::set_job_name): <p>The name of the job definition to use.</p>
    ///   - [`job_run_id(impl Into<String>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::job_run_id) / [`set_job_run_id(Option<String>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::set_job_run_id): <p>The ID of a previous <code>JobRun</code> to retry.</p>
    ///   - [`arguments(HashMap<String, String>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::arguments) / [`set_arguments(Option<HashMap<String, String>>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::set_arguments): <p>The job arguments specifically for this run. For this job run, they replace the default arguments set in the job definition itself.</p>  <p>You can specify arguments here that your own job-execution script consumes, as well as arguments that Glue itself consumes.</p>  <p>Job arguments may be logged. Do not pass plaintext secrets as arguments. Retrieve secrets from a Glue Connection, Secrets Manager or other secret management mechanism if you intend to keep them within the Job. </p>  <p>For information about how to specify and consume your own Job arguments, see the <a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-calling.html">Calling Glue APIs in Python</a> topic in the developer guide.</p>  <p>For information about the key-value pairs that Glue consumes to set up your job, see the <a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html">Special Parameters Used by Glue</a> topic in the developer guide.</p>
    ///   - [`allocated_capacity(i32)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::allocated_capacity) / [`set_allocated_capacity(i32)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::set_allocated_capacity): <p>This field is deprecated. Use <code>MaxCapacity</code> instead.</p>  <p>The number of Glue data processing units (DPUs) to allocate to this JobRun. You can allocate a minimum of 2 DPUs; the default is 10. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the <a href="https://aws.amazon.com/glue/pricing/">Glue pricing page</a>.</p>
    ///   - [`timeout(i32)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::timeout) / [`set_timeout(Option<i32>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::set_timeout): <p>The <code>JobRun</code> timeout in minutes. This is the maximum time that a job run can consume resources before it is terminated and enters <code>TIMEOUT</code> status. This value overrides the timeout value set in the parent job.</p>  <p>Streaming jobs do not have a timeout. The default for non-streaming jobs is 2,880 minutes (48 hours).</p>
    ///   - [`max_capacity(f64)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::max_capacity) / [`set_max_capacity(Option<f64>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::set_max_capacity): <p>The number of Glue data processing units (DPUs) that can be allocated when this job runs. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the <a href="https://aws.amazon.com/glue/pricing/">Glue pricing page</a>.</p>  <p>Do not set <code>Max Capacity</code> if using <code>WorkerType</code> and <code>NumberOfWorkers</code>.</p>  <p>The value that can be allocated for <code>MaxCapacity</code> depends on whether you are running a Python shell job, or an Apache Spark ETL job:</p>  <ul>   <li> <p>When you specify a Python shell job (<code>JobCommand.Name</code>="pythonshell"), you can allocate either 0.0625 or 1 DPU. The default is 0.0625 DPU.</p> </li>   <li> <p>When you specify an Apache Spark ETL job (<code>JobCommand.Name</code>="glueetl"), you can allocate a minimum of 2 DPUs. The default is 10 DPUs. This job type cannot have a fractional DPU allocation.</p> </li>  </ul>
    ///   - [`security_configuration(impl Into<String>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::security_configuration) / [`set_security_configuration(Option<String>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::set_security_configuration): <p>The name of the <code>SecurityConfiguration</code> structure to be used with this job run.</p>
    ///   - [`notification_property(NotificationProperty)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::notification_property) / [`set_notification_property(Option<NotificationProperty>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::set_notification_property): <p>Specifies configuration properties of a job run notification.</p>
    ///   - [`worker_type(WorkerType)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::worker_type) / [`set_worker_type(Option<WorkerType>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::set_worker_type): <p>The type of predefined worker that is allocated when a job runs. Accepts a value of Standard, G.1X, G.2X, or G.025X.</p>  <ul>   <li> <p>For the <code>Standard</code> worker type, each worker provides 4 vCPU, 16 GB of memory and a 50GB disk, and 2 executors per worker.</p> </li>   <li> <p>For the <code>G.1X</code> worker type, each worker provides 4 vCPU, 16 GB of memory and a 64GB disk, and 1 executor per worker.</p> </li>   <li> <p>For the <code>G.2X</code> worker type, each worker provides 8 vCPU, 32 GB of memory and a 128GB disk, and 1 executor per worker.</p> </li>   <li> <p>For the <code>G.025X</code> worker type, each worker maps to 0.25 DPU (2 vCPU, 4 GB of memory, 64 GB disk), and provides 1 executor per worker. We recommend this worker type for low volume streaming jobs. This worker type is only available for Glue version 3.0 streaming jobs.</p> </li>  </ul>
    ///   - [`number_of_workers(i32)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::number_of_workers) / [`set_number_of_workers(Option<i32>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::set_number_of_workers): <p>The number of workers of a defined <code>workerType</code> that are allocated when a job runs.</p>
    ///   - [`execution_class(ExecutionClass)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::execution_class) / [`set_execution_class(Option<ExecutionClass>)`](crate::operation::start_job_run::builders::StartJobRunFluentBuilder::set_execution_class): <p>Indicates whether the job is run with a standard or flexible execution class. The standard execution-class is ideal for time-sensitive workloads that require fast job startup and dedicated resources.</p>  <p>The flexible execution class is appropriate for time-insensitive jobs whose start and completion times may vary. </p>  <p>Only jobs with Glue version 3.0 and above and command type <code>glueetl</code> will be allowed to set <code>ExecutionClass</code> to <code>FLEX</code>. The flexible execution class is available for Spark jobs.</p>
    /// - On success, responds with [`StartJobRunOutput`](crate::operation::start_job_run::StartJobRunOutput) with field(s):
    ///   - [`job_run_id(Option<String>)`](crate::operation::start_job_run::StartJobRunOutput::job_run_id): <p>The ID assigned to this job run.</p>
    /// - On failure, responds with [`SdkError<StartJobRunError>`](crate::operation::start_job_run::StartJobRunError)
    pub fn start_job_run(
        &self,
    ) -> crate::operation::start_job_run::builders::StartJobRunFluentBuilder {
        crate::operation::start_job_run::builders::StartJobRunFluentBuilder::new(
            self.handle.clone(),
        )
    }
}
