// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Additional options for streaming.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct KafkaStreamingSourceOptions {
    /// <p>A list of bootstrap server URLs, for example, as <code>b-1.vpc-test-2.o4q88o.c6.kafka.us-east-1.amazonaws.com:9094</code>. This option must be specified in the API call or defined in the table metadata in the Data Catalog.</p>
    #[doc(hidden)]
    pub bootstrap_servers: std::option::Option<std::string::String>,
    /// <p>The protocol used to communicate with brokers. The possible values are <code>"SSL"</code> or <code>"PLAINTEXT"</code>.</p>
    #[doc(hidden)]
    pub security_protocol: std::option::Option<std::string::String>,
    /// <p>The name of the connection.</p>
    #[doc(hidden)]
    pub connection_name: std::option::Option<std::string::String>,
    /// <p>The topic name as specified in Apache Kafka. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    #[doc(hidden)]
    pub topic_name: std::option::Option<std::string::String>,
    /// <p>The specific <code>TopicPartitions</code> to consume. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    #[doc(hidden)]
    pub assign: std::option::Option<std::string::String>,
    /// <p>A Java regex string that identifies the topic list to subscribe to. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    #[doc(hidden)]
    pub subscribe_pattern: std::option::Option<std::string::String>,
    /// <p>An optional classification.</p>
    #[doc(hidden)]
    pub classification: std::option::Option<std::string::String>,
    /// <p>Specifies the delimiter character.</p>
    #[doc(hidden)]
    pub delimiter: std::option::Option<std::string::String>,
    /// <p>The starting position in the Kafka topic to read data from. The possible values are <code>"earliest"</code> or <code>"latest"</code>. The default value is <code>"latest"</code>.</p>
    #[doc(hidden)]
    pub starting_offsets: std::option::Option<std::string::String>,
    /// <p>The end point when a batch query is ended. Possible values are either <code>"latest"</code> or a JSON string that specifies an ending offset for each <code>TopicPartition</code>.</p>
    #[doc(hidden)]
    pub ending_offsets: std::option::Option<std::string::String>,
    /// <p>The timeout in milliseconds to poll data from Kafka in Spark job executors. The default value is <code>512</code>.</p>
    #[doc(hidden)]
    pub poll_timeout_ms: std::option::Option<i64>,
    /// <p>The number of times to retry before failing to fetch Kafka offsets. The default value is <code>3</code>.</p>
    #[doc(hidden)]
    pub num_retries: std::option::Option<i32>,
    /// <p>The time in milliseconds to wait before retrying to fetch Kafka offsets. The default value is <code>10</code>.</p>
    #[doc(hidden)]
    pub retry_interval_ms: std::option::Option<i64>,
    /// <p>The rate limit on the maximum number of offsets that are processed per trigger interval. The specified total number of offsets is proportionally split across <code>topicPartitions</code> of different volumes. The default value is null, which means that the consumer reads all offsets until the known latest offset.</p>
    #[doc(hidden)]
    pub max_offsets_per_trigger: std::option::Option<i64>,
    /// <p>The desired minimum number of partitions to read from Kafka. The default value is null, which means that the number of spark partitions is equal to the number of Kafka partitions.</p>
    #[doc(hidden)]
    pub min_partitions: std::option::Option<i32>,
}
impl KafkaStreamingSourceOptions {
    /// <p>A list of bootstrap server URLs, for example, as <code>b-1.vpc-test-2.o4q88o.c6.kafka.us-east-1.amazonaws.com:9094</code>. This option must be specified in the API call or defined in the table metadata in the Data Catalog.</p>
    pub fn bootstrap_servers(&self) -> std::option::Option<&str> {
        self.bootstrap_servers.as_deref()
    }
    /// <p>The protocol used to communicate with brokers. The possible values are <code>"SSL"</code> or <code>"PLAINTEXT"</code>.</p>
    pub fn security_protocol(&self) -> std::option::Option<&str> {
        self.security_protocol.as_deref()
    }
    /// <p>The name of the connection.</p>
    pub fn connection_name(&self) -> std::option::Option<&str> {
        self.connection_name.as_deref()
    }
    /// <p>The topic name as specified in Apache Kafka. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    pub fn topic_name(&self) -> std::option::Option<&str> {
        self.topic_name.as_deref()
    }
    /// <p>The specific <code>TopicPartitions</code> to consume. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    pub fn assign(&self) -> std::option::Option<&str> {
        self.assign.as_deref()
    }
    /// <p>A Java regex string that identifies the topic list to subscribe to. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    pub fn subscribe_pattern(&self) -> std::option::Option<&str> {
        self.subscribe_pattern.as_deref()
    }
    /// <p>An optional classification.</p>
    pub fn classification(&self) -> std::option::Option<&str> {
        self.classification.as_deref()
    }
    /// <p>Specifies the delimiter character.</p>
    pub fn delimiter(&self) -> std::option::Option<&str> {
        self.delimiter.as_deref()
    }
    /// <p>The starting position in the Kafka topic to read data from. The possible values are <code>"earliest"</code> or <code>"latest"</code>. The default value is <code>"latest"</code>.</p>
    pub fn starting_offsets(&self) -> std::option::Option<&str> {
        self.starting_offsets.as_deref()
    }
    /// <p>The end point when a batch query is ended. Possible values are either <code>"latest"</code> or a JSON string that specifies an ending offset for each <code>TopicPartition</code>.</p>
    pub fn ending_offsets(&self) -> std::option::Option<&str> {
        self.ending_offsets.as_deref()
    }
    /// <p>The timeout in milliseconds to poll data from Kafka in Spark job executors. The default value is <code>512</code>.</p>
    pub fn poll_timeout_ms(&self) -> std::option::Option<i64> {
        self.poll_timeout_ms
    }
    /// <p>The number of times to retry before failing to fetch Kafka offsets. The default value is <code>3</code>.</p>
    pub fn num_retries(&self) -> std::option::Option<i32> {
        self.num_retries
    }
    /// <p>The time in milliseconds to wait before retrying to fetch Kafka offsets. The default value is <code>10</code>.</p>
    pub fn retry_interval_ms(&self) -> std::option::Option<i64> {
        self.retry_interval_ms
    }
    /// <p>The rate limit on the maximum number of offsets that are processed per trigger interval. The specified total number of offsets is proportionally split across <code>topicPartitions</code> of different volumes. The default value is null, which means that the consumer reads all offsets until the known latest offset.</p>
    pub fn max_offsets_per_trigger(&self) -> std::option::Option<i64> {
        self.max_offsets_per_trigger
    }
    /// <p>The desired minimum number of partitions to read from Kafka. The default value is null, which means that the number of spark partitions is equal to the number of Kafka partitions.</p>
    pub fn min_partitions(&self) -> std::option::Option<i32> {
        self.min_partitions
    }
}
impl KafkaStreamingSourceOptions {
    /// Creates a new builder-style object to manufacture [`KafkaStreamingSourceOptions`](crate::types::KafkaStreamingSourceOptions).
    pub fn builder() -> crate::types::builders::KafkaStreamingSourceOptionsBuilder {
        crate::types::builders::KafkaStreamingSourceOptionsBuilder::default()
    }
}

/// A builder for [`KafkaStreamingSourceOptions`](crate::types::KafkaStreamingSourceOptions).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct KafkaStreamingSourceOptionsBuilder {
    pub(crate) bootstrap_servers: std::option::Option<std::string::String>,
    pub(crate) security_protocol: std::option::Option<std::string::String>,
    pub(crate) connection_name: std::option::Option<std::string::String>,
    pub(crate) topic_name: std::option::Option<std::string::String>,
    pub(crate) assign: std::option::Option<std::string::String>,
    pub(crate) subscribe_pattern: std::option::Option<std::string::String>,
    pub(crate) classification: std::option::Option<std::string::String>,
    pub(crate) delimiter: std::option::Option<std::string::String>,
    pub(crate) starting_offsets: std::option::Option<std::string::String>,
    pub(crate) ending_offsets: std::option::Option<std::string::String>,
    pub(crate) poll_timeout_ms: std::option::Option<i64>,
    pub(crate) num_retries: std::option::Option<i32>,
    pub(crate) retry_interval_ms: std::option::Option<i64>,
    pub(crate) max_offsets_per_trigger: std::option::Option<i64>,
    pub(crate) min_partitions: std::option::Option<i32>,
}
impl KafkaStreamingSourceOptionsBuilder {
    /// <p>A list of bootstrap server URLs, for example, as <code>b-1.vpc-test-2.o4q88o.c6.kafka.us-east-1.amazonaws.com:9094</code>. This option must be specified in the API call or defined in the table metadata in the Data Catalog.</p>
    pub fn bootstrap_servers(mut self, input: impl Into<std::string::String>) -> Self {
        self.bootstrap_servers = Some(input.into());
        self
    }
    /// <p>A list of bootstrap server URLs, for example, as <code>b-1.vpc-test-2.o4q88o.c6.kafka.us-east-1.amazonaws.com:9094</code>. This option must be specified in the API call or defined in the table metadata in the Data Catalog.</p>
    pub fn set_bootstrap_servers(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.bootstrap_servers = input;
        self
    }
    /// <p>The protocol used to communicate with brokers. The possible values are <code>"SSL"</code> or <code>"PLAINTEXT"</code>.</p>
    pub fn security_protocol(mut self, input: impl Into<std::string::String>) -> Self {
        self.security_protocol = Some(input.into());
        self
    }
    /// <p>The protocol used to communicate with brokers. The possible values are <code>"SSL"</code> or <code>"PLAINTEXT"</code>.</p>
    pub fn set_security_protocol(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.security_protocol = input;
        self
    }
    /// <p>The name of the connection.</p>
    pub fn connection_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.connection_name = Some(input.into());
        self
    }
    /// <p>The name of the connection.</p>
    pub fn set_connection_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.connection_name = input;
        self
    }
    /// <p>The topic name as specified in Apache Kafka. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    pub fn topic_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.topic_name = Some(input.into());
        self
    }
    /// <p>The topic name as specified in Apache Kafka. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    pub fn set_topic_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.topic_name = input;
        self
    }
    /// <p>The specific <code>TopicPartitions</code> to consume. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    pub fn assign(mut self, input: impl Into<std::string::String>) -> Self {
        self.assign = Some(input.into());
        self
    }
    /// <p>The specific <code>TopicPartitions</code> to consume. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    pub fn set_assign(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.assign = input;
        self
    }
    /// <p>A Java regex string that identifies the topic list to subscribe to. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    pub fn subscribe_pattern(mut self, input: impl Into<std::string::String>) -> Self {
        self.subscribe_pattern = Some(input.into());
        self
    }
    /// <p>A Java regex string that identifies the topic list to subscribe to. You must specify at least one of <code>"topicName"</code>, <code>"assign"</code> or <code>"subscribePattern"</code>.</p>
    pub fn set_subscribe_pattern(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.subscribe_pattern = input;
        self
    }
    /// <p>An optional classification.</p>
    pub fn classification(mut self, input: impl Into<std::string::String>) -> Self {
        self.classification = Some(input.into());
        self
    }
    /// <p>An optional classification.</p>
    pub fn set_classification(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.classification = input;
        self
    }
    /// <p>Specifies the delimiter character.</p>
    pub fn delimiter(mut self, input: impl Into<std::string::String>) -> Self {
        self.delimiter = Some(input.into());
        self
    }
    /// <p>Specifies the delimiter character.</p>
    pub fn set_delimiter(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.delimiter = input;
        self
    }
    /// <p>The starting position in the Kafka topic to read data from. The possible values are <code>"earliest"</code> or <code>"latest"</code>. The default value is <code>"latest"</code>.</p>
    pub fn starting_offsets(mut self, input: impl Into<std::string::String>) -> Self {
        self.starting_offsets = Some(input.into());
        self
    }
    /// <p>The starting position in the Kafka topic to read data from. The possible values are <code>"earliest"</code> or <code>"latest"</code>. The default value is <code>"latest"</code>.</p>
    pub fn set_starting_offsets(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.starting_offsets = input;
        self
    }
    /// <p>The end point when a batch query is ended. Possible values are either <code>"latest"</code> or a JSON string that specifies an ending offset for each <code>TopicPartition</code>.</p>
    pub fn ending_offsets(mut self, input: impl Into<std::string::String>) -> Self {
        self.ending_offsets = Some(input.into());
        self
    }
    /// <p>The end point when a batch query is ended. Possible values are either <code>"latest"</code> or a JSON string that specifies an ending offset for each <code>TopicPartition</code>.</p>
    pub fn set_ending_offsets(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.ending_offsets = input;
        self
    }
    /// <p>The timeout in milliseconds to poll data from Kafka in Spark job executors. The default value is <code>512</code>.</p>
    pub fn poll_timeout_ms(mut self, input: i64) -> Self {
        self.poll_timeout_ms = Some(input);
        self
    }
    /// <p>The timeout in milliseconds to poll data from Kafka in Spark job executors. The default value is <code>512</code>.</p>
    pub fn set_poll_timeout_ms(mut self, input: std::option::Option<i64>) -> Self {
        self.poll_timeout_ms = input;
        self
    }
    /// <p>The number of times to retry before failing to fetch Kafka offsets. The default value is <code>3</code>.</p>
    pub fn num_retries(mut self, input: i32) -> Self {
        self.num_retries = Some(input);
        self
    }
    /// <p>The number of times to retry before failing to fetch Kafka offsets. The default value is <code>3</code>.</p>
    pub fn set_num_retries(mut self, input: std::option::Option<i32>) -> Self {
        self.num_retries = input;
        self
    }
    /// <p>The time in milliseconds to wait before retrying to fetch Kafka offsets. The default value is <code>10</code>.</p>
    pub fn retry_interval_ms(mut self, input: i64) -> Self {
        self.retry_interval_ms = Some(input);
        self
    }
    /// <p>The time in milliseconds to wait before retrying to fetch Kafka offsets. The default value is <code>10</code>.</p>
    pub fn set_retry_interval_ms(mut self, input: std::option::Option<i64>) -> Self {
        self.retry_interval_ms = input;
        self
    }
    /// <p>The rate limit on the maximum number of offsets that are processed per trigger interval. The specified total number of offsets is proportionally split across <code>topicPartitions</code> of different volumes. The default value is null, which means that the consumer reads all offsets until the known latest offset.</p>
    pub fn max_offsets_per_trigger(mut self, input: i64) -> Self {
        self.max_offsets_per_trigger = Some(input);
        self
    }
    /// <p>The rate limit on the maximum number of offsets that are processed per trigger interval. The specified total number of offsets is proportionally split across <code>topicPartitions</code> of different volumes. The default value is null, which means that the consumer reads all offsets until the known latest offset.</p>
    pub fn set_max_offsets_per_trigger(mut self, input: std::option::Option<i64>) -> Self {
        self.max_offsets_per_trigger = input;
        self
    }
    /// <p>The desired minimum number of partitions to read from Kafka. The default value is null, which means that the number of spark partitions is equal to the number of Kafka partitions.</p>
    pub fn min_partitions(mut self, input: i32) -> Self {
        self.min_partitions = Some(input);
        self
    }
    /// <p>The desired minimum number of partitions to read from Kafka. The default value is null, which means that the number of spark partitions is equal to the number of Kafka partitions.</p>
    pub fn set_min_partitions(mut self, input: std::option::Option<i32>) -> Self {
        self.min_partitions = input;
        self
    }
    /// Consumes the builder and constructs a [`KafkaStreamingSourceOptions`](crate::types::KafkaStreamingSourceOptions).
    pub fn build(self) -> crate::types::KafkaStreamingSourceOptions {
        crate::types::KafkaStreamingSourceOptions {
            bootstrap_servers: self.bootstrap_servers,
            security_protocol: self.security_protocol,
            connection_name: self.connection_name,
            topic_name: self.topic_name,
            assign: self.assign,
            subscribe_pattern: self.subscribe_pattern,
            classification: self.classification,
            delimiter: self.delimiter,
            starting_offsets: self.starting_offsets,
            ending_offsets: self.ending_offsets,
            poll_timeout_ms: self.poll_timeout_ms,
            num_retries: self.num_retries,
            retry_interval_ms: self.retry_interval_ms,
            max_offsets_per_trigger: self.max_offsets_per_trigger,
            min_partitions: self.min_partitions,
        }
    }
}
