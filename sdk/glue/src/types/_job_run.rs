// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Contains information about a job run.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct JobRun  {
    /// <p>The ID of this job run.</p>
    #[doc(hidden)]
    pub id: std::option::Option<std::string::String>,
    /// <p>The number of the attempt to run this job.</p>
    #[doc(hidden)]
    pub attempt: i32,
    /// <p>The ID of the previous run of this job. For example, the <code>JobRunId</code> specified in the <code>StartJobRun</code> action.</p>
    #[doc(hidden)]
    pub previous_run_id: std::option::Option<std::string::String>,
    /// <p>The name of the trigger that started this job run.</p>
    #[doc(hidden)]
    pub trigger_name: std::option::Option<std::string::String>,
    /// <p>The name of the job definition being used in this run.</p>
    #[doc(hidden)]
    pub job_name: std::option::Option<std::string::String>,
    /// <p>The date and time at which this job run was started.</p>
    #[doc(hidden)]
    pub started_on: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The last time that this job run was modified.</p>
    #[doc(hidden)]
    pub last_modified_on: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time that this job run completed.</p>
    #[doc(hidden)]
    pub completed_on: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The current state of the job run. For more information about the statuses of jobs that have terminated abnormally, see <a href="https://docs.aws.amazon.com/glue/latest/dg/job-run-statuses.html">Glue Job Run Statuses</a>.</p>
    #[doc(hidden)]
    pub job_run_state: std::option::Option<crate::types::JobRunState>,
    /// <p>The job arguments associated with this run. For this job run, they replace the default arguments set in the job definition itself.</p> 
    /// <p>You can specify arguments here that your own job-execution script consumes, as well as arguments that Glue itself consumes.</p> 
    /// <p>For information about how to specify and consume your own job arguments, see the <a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-calling.html">Calling Glue APIs in Python</a> topic in the developer guide.</p> 
    /// <p>For information about the key-value pairs that Glue consumes to set up your job, see the <a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html">Special Parameters Used by Glue</a> topic in the developer guide.</p>
    #[doc(hidden)]
    pub arguments: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    /// <p>An error message associated with this job run.</p>
    #[doc(hidden)]
    pub error_message: std::option::Option<std::string::String>,
    /// <p>A list of predecessors to this job run.</p>
    #[doc(hidden)]
    pub predecessor_runs: std::option::Option<std::vec::Vec<crate::types::Predecessor>>,
    /// <p>This field is deprecated. Use <code>MaxCapacity</code> instead.</p> 
    /// <p>The number of Glue data processing units (DPUs) allocated to this JobRun. From 2 to 100 DPUs can be allocated; the default is 10. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the <a href="https://aws.amazon.com/glue/pricing/">Glue pricing page</a>.</p>
    #[deprecated(note = "This property is deprecated, use MaxCapacity instead.")]
    #[doc(hidden)]
    pub allocated_capacity: i32,
    /// <p>The amount of time (in seconds) that the job run consumed resources.</p>
    #[doc(hidden)]
    pub execution_time: i32,
    /// <p>The <code>JobRun</code> timeout in minutes. This is the maximum time that a job run can consume resources before it is terminated and enters <code>TIMEOUT</code> status. This value overrides the timeout value set in the parent job.</p> 
    /// <p>Streaming jobs do not have a timeout. The default for non-streaming jobs is 2,880 minutes (48 hours).</p>
    #[doc(hidden)]
    pub timeout: std::option::Option<i32>,
    /// <p>The number of Glue data processing units (DPUs) that can be allocated when this job runs. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the <a href="https://aws.amazon.com/glue/pricing/">Glue pricing page</a>.</p> 
    /// <p>Do not set <code>Max Capacity</code> if using <code>WorkerType</code> and <code>NumberOfWorkers</code>.</p> 
    /// <p>The value that can be allocated for <code>MaxCapacity</code> depends on whether you are running a Python shell job or an Apache Spark ETL job:</p> 
    /// <ul> 
    /// <li> <p>When you specify a Python shell job (<code>JobCommand.Name</code>="pythonshell"), you can allocate either 0.0625 or 1 DPU. The default is 0.0625 DPU.</p> </li> 
    /// <li> <p>When you specify an Apache Spark ETL job (<code>JobCommand.Name</code>="glueetl"), you can allocate a minimum of 2 DPUs. The default is 10 DPUs. This job type cannot have a fractional DPU allocation.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub max_capacity: std::option::Option<f64>,
    /// <p>The type of predefined worker that is allocated when a job runs. Accepts a value of Standard, G.1X, G.2X, or G.025X.</p> 
    /// <ul> 
    /// <li> <p>For the <code>Standard</code> worker type, each worker provides 4 vCPU, 16 GB of memory and a 50GB disk, and 2 executors per worker.</p> </li> 
    /// <li> <p>For the <code>G.1X</code> worker type, each worker provides 4 vCPU, 16 GB of memory and a 64GB disk, and 1 executor per worker.</p> </li> 
    /// <li> <p>For the <code>G.2X</code> worker type, each worker provides 8 vCPU, 32 GB of memory and a 128GB disk, and 1 executor per worker.</p> </li> 
    /// <li> <p>For the <code>G.025X</code> worker type, each worker maps to 0.25 DPU (2 vCPU, 4 GB of memory, 64 GB disk), and provides 1 executor per worker. We recommend this worker type for low volume streaming jobs. This worker type is only available for Glue version 3.0 streaming jobs.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub worker_type: std::option::Option<crate::types::WorkerType>,
    /// <p>The number of workers of a defined <code>workerType</code> that are allocated when a job runs.</p>
    #[doc(hidden)]
    pub number_of_workers: std::option::Option<i32>,
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used with this job run.</p>
    #[doc(hidden)]
    pub security_configuration: std::option::Option<std::string::String>,
    /// <p>The name of the log group for secure logging that can be server-side encrypted in Amazon CloudWatch using KMS. This name can be <code>/aws-glue/jobs/</code>, in which case the default encryption is <code>NONE</code>. If you add a role name and <code>SecurityConfiguration</code> name (in other words, <code>/aws-glue/jobs-yourRoleName-yourSecurityConfigurationName/</code>), then that security configuration is used to encrypt the log group.</p>
    #[doc(hidden)]
    pub log_group_name: std::option::Option<std::string::String>,
    /// <p>Specifies configuration properties of a job run notification.</p>
    #[doc(hidden)]
    pub notification_property: std::option::Option<crate::types::NotificationProperty>,
    /// <p>Glue version determines the versions of Apache Spark and Python that Glue supports. The Python version indicates the version supported for jobs of type Spark. </p> 
    /// <p>For more information about the available Glue versions and corresponding Spark and Python versions, see <a href="https://docs.aws.amazon.com/glue/latest/dg/add-job.html">Glue version</a> in the developer guide.</p> 
    /// <p>Jobs that are created without specifying a Glue version default to Glue 0.9.</p>
    #[doc(hidden)]
    pub glue_version: std::option::Option<std::string::String>,
    /// <p>This field populates only for Auto Scaling job runs, and represents the total time each executor ran during the lifecycle of a job run in seconds, multiplied by a DPU factor (1 for <code>G.1X</code>, 2 for <code>G.2X</code>, or 0.25 for <code>G.025X</code> workers). This value may be different than the <code>executionEngineRuntime</code> * <code>MaxCapacity</code> as in the case of Auto Scaling jobs, as the number of executors running at a given time may be less than the <code>MaxCapacity</code>. Therefore, it is possible that the value of <code>DPUSeconds</code> is less than <code>executionEngineRuntime</code> * <code>MaxCapacity</code>.</p>
    #[doc(hidden)]
    pub dpu_seconds: std::option::Option<f64>,
    /// <p>Indicates whether the job is run with a standard or flexible execution class. The standard execution-class is ideal for time-sensitive workloads that require fast job startup and dedicated resources.</p> 
    /// <p>The flexible execution class is appropriate for time-insensitive jobs whose start and completion times may vary. </p> 
    /// <p>Only jobs with Glue version 3.0 and above and command type <code>glueetl</code> will be allowed to set <code>ExecutionClass</code> to <code>FLEX</code>. The flexible execution class is available for Spark jobs.</p>
    #[doc(hidden)]
    pub execution_class: std::option::Option<crate::types::ExecutionClass>,
}
impl JobRun {
    /// <p>The ID of this job run.</p>
    pub fn id(&self) -> std::option::Option<& str> {
        self.id.as_deref()
    }
    /// <p>The number of the attempt to run this job.</p>
    pub fn attempt(&self) -> i32 {
        self.attempt
    }
    /// <p>The ID of the previous run of this job. For example, the <code>JobRunId</code> specified in the <code>StartJobRun</code> action.</p>
    pub fn previous_run_id(&self) -> std::option::Option<& str> {
        self.previous_run_id.as_deref()
    }
    /// <p>The name of the trigger that started this job run.</p>
    pub fn trigger_name(&self) -> std::option::Option<& str> {
        self.trigger_name.as_deref()
    }
    /// <p>The name of the job definition being used in this run.</p>
    pub fn job_name(&self) -> std::option::Option<& str> {
        self.job_name.as_deref()
    }
    /// <p>The date and time at which this job run was started.</p>
    pub fn started_on(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.started_on.as_ref()
    }
    /// <p>The last time that this job run was modified.</p>
    pub fn last_modified_on(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.last_modified_on.as_ref()
    }
    /// <p>The date and time that this job run completed.</p>
    pub fn completed_on(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.completed_on.as_ref()
    }
    /// <p>The current state of the job run. For more information about the statuses of jobs that have terminated abnormally, see <a href="https://docs.aws.amazon.com/glue/latest/dg/job-run-statuses.html">Glue Job Run Statuses</a>.</p>
    pub fn job_run_state(&self) -> std::option::Option<& crate::types::JobRunState> {
        self.job_run_state.as_ref()
    }
    /// <p>The job arguments associated with this run. For this job run, they replace the default arguments set in the job definition itself.</p> 
    /// <p>You can specify arguments here that your own job-execution script consumes, as well as arguments that Glue itself consumes.</p> 
    /// <p>For information about how to specify and consume your own job arguments, see the <a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-calling.html">Calling Glue APIs in Python</a> topic in the developer guide.</p> 
    /// <p>For information about the key-value pairs that Glue consumes to set up your job, see the <a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html">Special Parameters Used by Glue</a> topic in the developer guide.</p>
    pub fn arguments(&self) -> std::option::Option<& std::collections::HashMap<std::string::String, std::string::String>> {
        self.arguments.as_ref()
    }
    /// <p>An error message associated with this job run.</p>
    pub fn error_message(&self) -> std::option::Option<& str> {
        self.error_message.as_deref()
    }
    /// <p>A list of predecessors to this job run.</p>
    pub fn predecessor_runs(&self) -> std::option::Option<& [crate::types::Predecessor]> {
        self.predecessor_runs.as_deref()
    }
    /// <p>This field is deprecated. Use <code>MaxCapacity</code> instead.</p> 
    /// <p>The number of Glue data processing units (DPUs) allocated to this JobRun. From 2 to 100 DPUs can be allocated; the default is 10. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the <a href="https://aws.amazon.com/glue/pricing/">Glue pricing page</a>.</p>
    #[deprecated(note = "This property is deprecated, use MaxCapacity instead.")]
    pub fn allocated_capacity(&self) -> i32 {
        self.allocated_capacity
    }
    /// <p>The amount of time (in seconds) that the job run consumed resources.</p>
    pub fn execution_time(&self) -> i32 {
        self.execution_time
    }
    /// <p>The <code>JobRun</code> timeout in minutes. This is the maximum time that a job run can consume resources before it is terminated and enters <code>TIMEOUT</code> status. This value overrides the timeout value set in the parent job.</p> 
    /// <p>Streaming jobs do not have a timeout. The default for non-streaming jobs is 2,880 minutes (48 hours).</p>
    pub fn timeout(&self) -> std::option::Option<i32> {
        self.timeout
    }
    /// <p>The number of Glue data processing units (DPUs) that can be allocated when this job runs. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the <a href="https://aws.amazon.com/glue/pricing/">Glue pricing page</a>.</p> 
    /// <p>Do not set <code>Max Capacity</code> if using <code>WorkerType</code> and <code>NumberOfWorkers</code>.</p> 
    /// <p>The value that can be allocated for <code>MaxCapacity</code> depends on whether you are running a Python shell job or an Apache Spark ETL job:</p> 
    /// <ul> 
    /// <li> <p>When you specify a Python shell job (<code>JobCommand.Name</code>="pythonshell"), you can allocate either 0.0625 or 1 DPU. The default is 0.0625 DPU.</p> </li> 
    /// <li> <p>When you specify an Apache Spark ETL job (<code>JobCommand.Name</code>="glueetl"), you can allocate a minimum of 2 DPUs. The default is 10 DPUs. This job type cannot have a fractional DPU allocation.</p> </li> 
    /// </ul>
    pub fn max_capacity(&self) -> std::option::Option<f64> {
        self.max_capacity
    }
    /// <p>The type of predefined worker that is allocated when a job runs. Accepts a value of Standard, G.1X, G.2X, or G.025X.</p> 
    /// <ul> 
    /// <li> <p>For the <code>Standard</code> worker type, each worker provides 4 vCPU, 16 GB of memory and a 50GB disk, and 2 executors per worker.</p> </li> 
    /// <li> <p>For the <code>G.1X</code> worker type, each worker provides 4 vCPU, 16 GB of memory and a 64GB disk, and 1 executor per worker.</p> </li> 
    /// <li> <p>For the <code>G.2X</code> worker type, each worker provides 8 vCPU, 32 GB of memory and a 128GB disk, and 1 executor per worker.</p> </li> 
    /// <li> <p>For the <code>G.025X</code> worker type, each worker maps to 0.25 DPU (2 vCPU, 4 GB of memory, 64 GB disk), and provides 1 executor per worker. We recommend this worker type for low volume streaming jobs. This worker type is only available for Glue version 3.0 streaming jobs.</p> </li> 
    /// </ul>
    pub fn worker_type(&self) -> std::option::Option<& crate::types::WorkerType> {
        self.worker_type.as_ref()
    }
    /// <p>The number of workers of a defined <code>workerType</code> that are allocated when a job runs.</p>
    pub fn number_of_workers(&self) -> std::option::Option<i32> {
        self.number_of_workers
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used with this job run.</p>
    pub fn security_configuration(&self) -> std::option::Option<& str> {
        self.security_configuration.as_deref()
    }
    /// <p>The name of the log group for secure logging that can be server-side encrypted in Amazon CloudWatch using KMS. This name can be <code>/aws-glue/jobs/</code>, in which case the default encryption is <code>NONE</code>. If you add a role name and <code>SecurityConfiguration</code> name (in other words, <code>/aws-glue/jobs-yourRoleName-yourSecurityConfigurationName/</code>), then that security configuration is used to encrypt the log group.</p>
    pub fn log_group_name(&self) -> std::option::Option<& str> {
        self.log_group_name.as_deref()
    }
    /// <p>Specifies configuration properties of a job run notification.</p>
    pub fn notification_property(&self) -> std::option::Option<& crate::types::NotificationProperty> {
        self.notification_property.as_ref()
    }
    /// <p>Glue version determines the versions of Apache Spark and Python that Glue supports. The Python version indicates the version supported for jobs of type Spark. </p> 
    /// <p>For more information about the available Glue versions and corresponding Spark and Python versions, see <a href="https://docs.aws.amazon.com/glue/latest/dg/add-job.html">Glue version</a> in the developer guide.</p> 
    /// <p>Jobs that are created without specifying a Glue version default to Glue 0.9.</p>
    pub fn glue_version(&self) -> std::option::Option<& str> {
        self.glue_version.as_deref()
    }
    /// <p>This field populates only for Auto Scaling job runs, and represents the total time each executor ran during the lifecycle of a job run in seconds, multiplied by a DPU factor (1 for <code>G.1X</code>, 2 for <code>G.2X</code>, or 0.25 for <code>G.025X</code> workers). This value may be different than the <code>executionEngineRuntime</code> * <code>MaxCapacity</code> as in the case of Auto Scaling jobs, as the number of executors running at a given time may be less than the <code>MaxCapacity</code>. Therefore, it is possible that the value of <code>DPUSeconds</code> is less than <code>executionEngineRuntime</code> * <code>MaxCapacity</code>.</p>
    pub fn dpu_seconds(&self) -> std::option::Option<f64> {
        self.dpu_seconds
    }
    /// <p>Indicates whether the job is run with a standard or flexible execution class. The standard execution-class is ideal for time-sensitive workloads that require fast job startup and dedicated resources.</p> 
    /// <p>The flexible execution class is appropriate for time-insensitive jobs whose start and completion times may vary. </p> 
    /// <p>Only jobs with Glue version 3.0 and above and command type <code>glueetl</code> will be allowed to set <code>ExecutionClass</code> to <code>FLEX</code>. The flexible execution class is available for Spark jobs.</p>
    pub fn execution_class(&self) -> std::option::Option<& crate::types::ExecutionClass> {
        self.execution_class.as_ref()
    }
}
impl JobRun {
    /// Creates a new builder-style object to manufacture [`JobRun`](crate::types::JobRun).
    pub fn builder() -> crate::types::builders::JobRunBuilder {
        crate::types::builders::JobRunBuilder::default()
    }
}

/// A builder for [`JobRun`](crate::types::JobRun).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct JobRunBuilder {
    pub(crate) id: std::option::Option<std::string::String>,
    pub(crate) attempt: std::option::Option<i32>,
    pub(crate) previous_run_id: std::option::Option<std::string::String>,
    pub(crate) trigger_name: std::option::Option<std::string::String>,
    pub(crate) job_name: std::option::Option<std::string::String>,
    pub(crate) started_on: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) last_modified_on: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) completed_on: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) job_run_state: std::option::Option<crate::types::JobRunState>,
    pub(crate) arguments: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    pub(crate) error_message: std::option::Option<std::string::String>,
    pub(crate) predecessor_runs: std::option::Option<std::vec::Vec<crate::types::Predecessor>>,
    pub(crate) allocated_capacity: std::option::Option<i32>,
    pub(crate) execution_time: std::option::Option<i32>,
    pub(crate) timeout: std::option::Option<i32>,
    pub(crate) max_capacity: std::option::Option<f64>,
    pub(crate) worker_type: std::option::Option<crate::types::WorkerType>,
    pub(crate) number_of_workers: std::option::Option<i32>,
    pub(crate) security_configuration: std::option::Option<std::string::String>,
    pub(crate) log_group_name: std::option::Option<std::string::String>,
    pub(crate) notification_property: std::option::Option<crate::types::NotificationProperty>,
    pub(crate) glue_version: std::option::Option<std::string::String>,
    pub(crate) dpu_seconds: std::option::Option<f64>,
    pub(crate) execution_class: std::option::Option<crate::types::ExecutionClass>,
}
impl JobRunBuilder {
    /// <p>The ID of this job run.</p>
    pub fn id(mut self, input: impl Into<std::string::String>) -> Self {
        self.id = Some(input.into());
        self
    }
    /// <p>The ID of this job run.</p>
    pub fn set_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.id = input; self
    }
    /// <p>The number of the attempt to run this job.</p>
    pub fn attempt(mut self, input: i32) -> Self {
        self.attempt = Some(input);
        self
    }
    /// <p>The number of the attempt to run this job.</p>
    pub fn set_attempt(mut self, input: std::option::Option<i32>) -> Self {
        self.attempt = input; self
    }
    /// <p>The ID of the previous run of this job. For example, the <code>JobRunId</code> specified in the <code>StartJobRun</code> action.</p>
    pub fn previous_run_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.previous_run_id = Some(input.into());
        self
    }
    /// <p>The ID of the previous run of this job. For example, the <code>JobRunId</code> specified in the <code>StartJobRun</code> action.</p>
    pub fn set_previous_run_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.previous_run_id = input; self
    }
    /// <p>The name of the trigger that started this job run.</p>
    pub fn trigger_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.trigger_name = Some(input.into());
        self
    }
    /// <p>The name of the trigger that started this job run.</p>
    pub fn set_trigger_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.trigger_name = input; self
    }
    /// <p>The name of the job definition being used in this run.</p>
    pub fn job_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.job_name = Some(input.into());
        self
    }
    /// <p>The name of the job definition being used in this run.</p>
    pub fn set_job_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.job_name = input; self
    }
    /// <p>The date and time at which this job run was started.</p>
    pub fn started_on(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.started_on = Some(input);
        self
    }
    /// <p>The date and time at which this job run was started.</p>
    pub fn set_started_on(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.started_on = input; self
    }
    /// <p>The last time that this job run was modified.</p>
    pub fn last_modified_on(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.last_modified_on = Some(input);
        self
    }
    /// <p>The last time that this job run was modified.</p>
    pub fn set_last_modified_on(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.last_modified_on = input; self
    }
    /// <p>The date and time that this job run completed.</p>
    pub fn completed_on(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.completed_on = Some(input);
        self
    }
    /// <p>The date and time that this job run completed.</p>
    pub fn set_completed_on(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.completed_on = input; self
    }
    /// <p>The current state of the job run. For more information about the statuses of jobs that have terminated abnormally, see <a href="https://docs.aws.amazon.com/glue/latest/dg/job-run-statuses.html">Glue Job Run Statuses</a>.</p>
    pub fn job_run_state(mut self, input: crate::types::JobRunState) -> Self {
        self.job_run_state = Some(input);
        self
    }
    /// <p>The current state of the job run. For more information about the statuses of jobs that have terminated abnormally, see <a href="https://docs.aws.amazon.com/glue/latest/dg/job-run-statuses.html">Glue Job Run Statuses</a>.</p>
    pub fn set_job_run_state(mut self, input: std::option::Option<crate::types::JobRunState>) -> Self {
        self.job_run_state = input; self
    }
    /// Adds a key-value pair to `arguments`.
    ///
    /// To override the contents of this collection use [`set_arguments`](Self::set_arguments).
    ///
    /// <p>The job arguments associated with this run. For this job run, they replace the default arguments set in the job definition itself.</p> 
    /// <p>You can specify arguments here that your own job-execution script consumes, as well as arguments that Glue itself consumes.</p> 
    /// <p>For information about how to specify and consume your own job arguments, see the <a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-calling.html">Calling Glue APIs in Python</a> topic in the developer guide.</p> 
    /// <p>For information about the key-value pairs that Glue consumes to set up your job, see the <a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html">Special Parameters Used by Glue</a> topic in the developer guide.</p>
    pub fn arguments(mut self, k: impl Into<std::string::String>, v: impl Into<std::string::String>) -> Self {
        let mut hash_map = self.arguments.unwrap_or_default();
                        hash_map.insert(k.into(), v.into());
                        self.arguments = Some(hash_map);
                        self
    }
    /// <p>The job arguments associated with this run. For this job run, they replace the default arguments set in the job definition itself.</p> 
    /// <p>You can specify arguments here that your own job-execution script consumes, as well as arguments that Glue itself consumes.</p> 
    /// <p>For information about how to specify and consume your own job arguments, see the <a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-calling.html">Calling Glue APIs in Python</a> topic in the developer guide.</p> 
    /// <p>For information about the key-value pairs that Glue consumes to set up your job, see the <a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html">Special Parameters Used by Glue</a> topic in the developer guide.</p>
    pub fn set_arguments(mut self, input: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>) -> Self {
        self.arguments = input; self
    }
    /// <p>An error message associated with this job run.</p>
    pub fn error_message(mut self, input: impl Into<std::string::String>) -> Self {
        self.error_message = Some(input.into());
        self
    }
    /// <p>An error message associated with this job run.</p>
    pub fn set_error_message(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.error_message = input; self
    }
    /// Appends an item to `predecessor_runs`.
    ///
    /// To override the contents of this collection use [`set_predecessor_runs`](Self::set_predecessor_runs).
    ///
    /// <p>A list of predecessors to this job run.</p>
    pub fn predecessor_runs(mut self, input: crate::types::Predecessor) -> Self {
        let mut v = self.predecessor_runs.unwrap_or_default();
                        v.push(input);
                        self.predecessor_runs = Some(v);
                        self
    }
    /// <p>A list of predecessors to this job run.</p>
    pub fn set_predecessor_runs(mut self, input: std::option::Option<std::vec::Vec<crate::types::Predecessor>>) -> Self {
        self.predecessor_runs = input; self
    }
    /// <p>This field is deprecated. Use <code>MaxCapacity</code> instead.</p> 
    /// <p>The number of Glue data processing units (DPUs) allocated to this JobRun. From 2 to 100 DPUs can be allocated; the default is 10. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the <a href="https://aws.amazon.com/glue/pricing/">Glue pricing page</a>.</p>
    #[deprecated(note = "This property is deprecated, use MaxCapacity instead.")]
    pub fn allocated_capacity(mut self, input: i32) -> Self {
        self.allocated_capacity = Some(input);
        self
    }
    /// <p>This field is deprecated. Use <code>MaxCapacity</code> instead.</p> 
    /// <p>The number of Glue data processing units (DPUs) allocated to this JobRun. From 2 to 100 DPUs can be allocated; the default is 10. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the <a href="https://aws.amazon.com/glue/pricing/">Glue pricing page</a>.</p>
    #[deprecated(note = "This property is deprecated, use MaxCapacity instead.")]
    pub fn set_allocated_capacity(mut self, input: std::option::Option<i32>) -> Self {
        self.allocated_capacity = input; self
    }
    /// <p>The amount of time (in seconds) that the job run consumed resources.</p>
    pub fn execution_time(mut self, input: i32) -> Self {
        self.execution_time = Some(input);
        self
    }
    /// <p>The amount of time (in seconds) that the job run consumed resources.</p>
    pub fn set_execution_time(mut self, input: std::option::Option<i32>) -> Self {
        self.execution_time = input; self
    }
    /// <p>The <code>JobRun</code> timeout in minutes. This is the maximum time that a job run can consume resources before it is terminated and enters <code>TIMEOUT</code> status. This value overrides the timeout value set in the parent job.</p> 
    /// <p>Streaming jobs do not have a timeout. The default for non-streaming jobs is 2,880 minutes (48 hours).</p>
    pub fn timeout(mut self, input: i32) -> Self {
        self.timeout = Some(input);
        self
    }
    /// <p>The <code>JobRun</code> timeout in minutes. This is the maximum time that a job run can consume resources before it is terminated and enters <code>TIMEOUT</code> status. This value overrides the timeout value set in the parent job.</p> 
    /// <p>Streaming jobs do not have a timeout. The default for non-streaming jobs is 2,880 minutes (48 hours).</p>
    pub fn set_timeout(mut self, input: std::option::Option<i32>) -> Self {
        self.timeout = input; self
    }
    /// <p>The number of Glue data processing units (DPUs) that can be allocated when this job runs. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the <a href="https://aws.amazon.com/glue/pricing/">Glue pricing page</a>.</p> 
    /// <p>Do not set <code>Max Capacity</code> if using <code>WorkerType</code> and <code>NumberOfWorkers</code>.</p> 
    /// <p>The value that can be allocated for <code>MaxCapacity</code> depends on whether you are running a Python shell job or an Apache Spark ETL job:</p> 
    /// <ul> 
    /// <li> <p>When you specify a Python shell job (<code>JobCommand.Name</code>="pythonshell"), you can allocate either 0.0625 or 1 DPU. The default is 0.0625 DPU.</p> </li> 
    /// <li> <p>When you specify an Apache Spark ETL job (<code>JobCommand.Name</code>="glueetl"), you can allocate a minimum of 2 DPUs. The default is 10 DPUs. This job type cannot have a fractional DPU allocation.</p> </li> 
    /// </ul>
    pub fn max_capacity(mut self, input: f64) -> Self {
        self.max_capacity = Some(input);
        self
    }
    /// <p>The number of Glue data processing units (DPUs) that can be allocated when this job runs. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the <a href="https://aws.amazon.com/glue/pricing/">Glue pricing page</a>.</p> 
    /// <p>Do not set <code>Max Capacity</code> if using <code>WorkerType</code> and <code>NumberOfWorkers</code>.</p> 
    /// <p>The value that can be allocated for <code>MaxCapacity</code> depends on whether you are running a Python shell job or an Apache Spark ETL job:</p> 
    /// <ul> 
    /// <li> <p>When you specify a Python shell job (<code>JobCommand.Name</code>="pythonshell"), you can allocate either 0.0625 or 1 DPU. The default is 0.0625 DPU.</p> </li> 
    /// <li> <p>When you specify an Apache Spark ETL job (<code>JobCommand.Name</code>="glueetl"), you can allocate a minimum of 2 DPUs. The default is 10 DPUs. This job type cannot have a fractional DPU allocation.</p> </li> 
    /// </ul>
    pub fn set_max_capacity(mut self, input: std::option::Option<f64>) -> Self {
        self.max_capacity = input; self
    }
    /// <p>The type of predefined worker that is allocated when a job runs. Accepts a value of Standard, G.1X, G.2X, or G.025X.</p> 
    /// <ul> 
    /// <li> <p>For the <code>Standard</code> worker type, each worker provides 4 vCPU, 16 GB of memory and a 50GB disk, and 2 executors per worker.</p> </li> 
    /// <li> <p>For the <code>G.1X</code> worker type, each worker provides 4 vCPU, 16 GB of memory and a 64GB disk, and 1 executor per worker.</p> </li> 
    /// <li> <p>For the <code>G.2X</code> worker type, each worker provides 8 vCPU, 32 GB of memory and a 128GB disk, and 1 executor per worker.</p> </li> 
    /// <li> <p>For the <code>G.025X</code> worker type, each worker maps to 0.25 DPU (2 vCPU, 4 GB of memory, 64 GB disk), and provides 1 executor per worker. We recommend this worker type for low volume streaming jobs. This worker type is only available for Glue version 3.0 streaming jobs.</p> </li> 
    /// </ul>
    pub fn worker_type(mut self, input: crate::types::WorkerType) -> Self {
        self.worker_type = Some(input);
        self
    }
    /// <p>The type of predefined worker that is allocated when a job runs. Accepts a value of Standard, G.1X, G.2X, or G.025X.</p> 
    /// <ul> 
    /// <li> <p>For the <code>Standard</code> worker type, each worker provides 4 vCPU, 16 GB of memory and a 50GB disk, and 2 executors per worker.</p> </li> 
    /// <li> <p>For the <code>G.1X</code> worker type, each worker provides 4 vCPU, 16 GB of memory and a 64GB disk, and 1 executor per worker.</p> </li> 
    /// <li> <p>For the <code>G.2X</code> worker type, each worker provides 8 vCPU, 32 GB of memory and a 128GB disk, and 1 executor per worker.</p> </li> 
    /// <li> <p>For the <code>G.025X</code> worker type, each worker maps to 0.25 DPU (2 vCPU, 4 GB of memory, 64 GB disk), and provides 1 executor per worker. We recommend this worker type for low volume streaming jobs. This worker type is only available for Glue version 3.0 streaming jobs.</p> </li> 
    /// </ul>
    pub fn set_worker_type(mut self, input: std::option::Option<crate::types::WorkerType>) -> Self {
        self.worker_type = input; self
    }
    /// <p>The number of workers of a defined <code>workerType</code> that are allocated when a job runs.</p>
    pub fn number_of_workers(mut self, input: i32) -> Self {
        self.number_of_workers = Some(input);
        self
    }
    /// <p>The number of workers of a defined <code>workerType</code> that are allocated when a job runs.</p>
    pub fn set_number_of_workers(mut self, input: std::option::Option<i32>) -> Self {
        self.number_of_workers = input; self
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used with this job run.</p>
    pub fn security_configuration(mut self, input: impl Into<std::string::String>) -> Self {
        self.security_configuration = Some(input.into());
        self
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used with this job run.</p>
    pub fn set_security_configuration(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.security_configuration = input; self
    }
    /// <p>The name of the log group for secure logging that can be server-side encrypted in Amazon CloudWatch using KMS. This name can be <code>/aws-glue/jobs/</code>, in which case the default encryption is <code>NONE</code>. If you add a role name and <code>SecurityConfiguration</code> name (in other words, <code>/aws-glue/jobs-yourRoleName-yourSecurityConfigurationName/</code>), then that security configuration is used to encrypt the log group.</p>
    pub fn log_group_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.log_group_name = Some(input.into());
        self
    }
    /// <p>The name of the log group for secure logging that can be server-side encrypted in Amazon CloudWatch using KMS. This name can be <code>/aws-glue/jobs/</code>, in which case the default encryption is <code>NONE</code>. If you add a role name and <code>SecurityConfiguration</code> name (in other words, <code>/aws-glue/jobs-yourRoleName-yourSecurityConfigurationName/</code>), then that security configuration is used to encrypt the log group.</p>
    pub fn set_log_group_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.log_group_name = input; self
    }
    /// <p>Specifies configuration properties of a job run notification.</p>
    pub fn notification_property(mut self, input: crate::types::NotificationProperty) -> Self {
        self.notification_property = Some(input);
        self
    }
    /// <p>Specifies configuration properties of a job run notification.</p>
    pub fn set_notification_property(mut self, input: std::option::Option<crate::types::NotificationProperty>) -> Self {
        self.notification_property = input; self
    }
    /// <p>Glue version determines the versions of Apache Spark and Python that Glue supports. The Python version indicates the version supported for jobs of type Spark. </p> 
    /// <p>For more information about the available Glue versions and corresponding Spark and Python versions, see <a href="https://docs.aws.amazon.com/glue/latest/dg/add-job.html">Glue version</a> in the developer guide.</p> 
    /// <p>Jobs that are created without specifying a Glue version default to Glue 0.9.</p>
    pub fn glue_version(mut self, input: impl Into<std::string::String>) -> Self {
        self.glue_version = Some(input.into());
        self
    }
    /// <p>Glue version determines the versions of Apache Spark and Python that Glue supports. The Python version indicates the version supported for jobs of type Spark. </p> 
    /// <p>For more information about the available Glue versions and corresponding Spark and Python versions, see <a href="https://docs.aws.amazon.com/glue/latest/dg/add-job.html">Glue version</a> in the developer guide.</p> 
    /// <p>Jobs that are created without specifying a Glue version default to Glue 0.9.</p>
    pub fn set_glue_version(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.glue_version = input; self
    }
    /// <p>This field populates only for Auto Scaling job runs, and represents the total time each executor ran during the lifecycle of a job run in seconds, multiplied by a DPU factor (1 for <code>G.1X</code>, 2 for <code>G.2X</code>, or 0.25 for <code>G.025X</code> workers). This value may be different than the <code>executionEngineRuntime</code> * <code>MaxCapacity</code> as in the case of Auto Scaling jobs, as the number of executors running at a given time may be less than the <code>MaxCapacity</code>. Therefore, it is possible that the value of <code>DPUSeconds</code> is less than <code>executionEngineRuntime</code> * <code>MaxCapacity</code>.</p>
    pub fn dpu_seconds(mut self, input: f64) -> Self {
        self.dpu_seconds = Some(input);
        self
    }
    /// <p>This field populates only for Auto Scaling job runs, and represents the total time each executor ran during the lifecycle of a job run in seconds, multiplied by a DPU factor (1 for <code>G.1X</code>, 2 for <code>G.2X</code>, or 0.25 for <code>G.025X</code> workers). This value may be different than the <code>executionEngineRuntime</code> * <code>MaxCapacity</code> as in the case of Auto Scaling jobs, as the number of executors running at a given time may be less than the <code>MaxCapacity</code>. Therefore, it is possible that the value of <code>DPUSeconds</code> is less than <code>executionEngineRuntime</code> * <code>MaxCapacity</code>.</p>
    pub fn set_dpu_seconds(mut self, input: std::option::Option<f64>) -> Self {
        self.dpu_seconds = input; self
    }
    /// <p>Indicates whether the job is run with a standard or flexible execution class. The standard execution-class is ideal for time-sensitive workloads that require fast job startup and dedicated resources.</p> 
    /// <p>The flexible execution class is appropriate for time-insensitive jobs whose start and completion times may vary. </p> 
    /// <p>Only jobs with Glue version 3.0 and above and command type <code>glueetl</code> will be allowed to set <code>ExecutionClass</code> to <code>FLEX</code>. The flexible execution class is available for Spark jobs.</p>
    pub fn execution_class(mut self, input: crate::types::ExecutionClass) -> Self {
        self.execution_class = Some(input);
        self
    }
    /// <p>Indicates whether the job is run with a standard or flexible execution class. The standard execution-class is ideal for time-sensitive workloads that require fast job startup and dedicated resources.</p> 
    /// <p>The flexible execution class is appropriate for time-insensitive jobs whose start and completion times may vary. </p> 
    /// <p>Only jobs with Glue version 3.0 and above and command type <code>glueetl</code> will be allowed to set <code>ExecutionClass</code> to <code>FLEX</code>. The flexible execution class is available for Spark jobs.</p>
    pub fn set_execution_class(mut self, input: std::option::Option<crate::types::ExecutionClass>) -> Self {
        self.execution_class = input; self
    }
    /// Consumes the builder and constructs a [`JobRun`](crate::types::JobRun).
    pub fn build(self) -> crate::types::JobRun {
        crate::types::JobRun {
            id: self.id
            ,
            attempt: self.attempt
                .unwrap_or_default()
            ,
            previous_run_id: self.previous_run_id
            ,
            trigger_name: self.trigger_name
            ,
            job_name: self.job_name
            ,
            started_on: self.started_on
            ,
            last_modified_on: self.last_modified_on
            ,
            completed_on: self.completed_on
            ,
            job_run_state: self.job_run_state
            ,
            arguments: self.arguments
            ,
            error_message: self.error_message
            ,
            predecessor_runs: self.predecessor_runs
            ,
            allocated_capacity: self.allocated_capacity
                .unwrap_or_default()
            ,
            execution_time: self.execution_time
                .unwrap_or_default()
            ,
            timeout: self.timeout
            ,
            max_capacity: self.max_capacity
            ,
            worker_type: self.worker_type
            ,
            number_of_workers: self.number_of_workers
            ,
            security_configuration: self.security_configuration
            ,
            log_group_name: self.log_group_name
            ,
            notification_property: self.notification_property
            ,
            glue_version: self.glue_version
            ,
            dpu_seconds: self.dpu_seconds
            ,
            execution_class: self.execution_class
            ,
        }
    }
}

