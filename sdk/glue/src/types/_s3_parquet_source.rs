// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Specifies an Apache Parquet data store stored in Amazon S3.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct S3ParquetSource {
    /// <p>The name of the data store.</p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
    /// <p>A list of the Amazon S3 paths to read from.</p>
    #[doc(hidden)]
    pub paths: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>Specifies how the data is compressed. This is generally not necessary if the data has a standard file extension. Possible values are <code>"gzip"</code> and <code>"bzip"</code>).</p>
    #[doc(hidden)]
    pub compression_type: std::option::Option<crate::types::ParquetCompressionType>,
    /// <p>A string containing a JSON list of Unix-style glob patterns to exclude. For example, "[\"**.pdf\"]" excludes all PDF files. </p>
    #[doc(hidden)]
    pub exclusions: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>The target group size in bytes. The default is computed based on the input data size and the size of your cluster. When there are fewer than 50,000 input files, <code>"groupFiles"</code> must be set to <code>"inPartition"</code> for this to take effect.</p>
    #[doc(hidden)]
    pub group_size: std::option::Option<std::string::String>,
    /// <p>Grouping files is turned on by default when the input contains more than 50,000 files. To turn on grouping with fewer than 50,000 files, set this parameter to "inPartition". To disable grouping when there are more than 50,000 files, set this parameter to <code>"none"</code>.</p>
    #[doc(hidden)]
    pub group_files: std::option::Option<std::string::String>,
    /// <p>If set to true, recursively reads files in all subdirectories under the specified paths.</p>
    #[doc(hidden)]
    pub recurse: std::option::Option<bool>,
    /// <p>This option controls the duration in milliseconds after which the s3 listing is likely to be consistent. Files with modification timestamps falling within the last maxBand milliseconds are tracked specially when using JobBookmarks to account for Amazon S3 eventual consistency. Most users don't need to set this option. The default is 900000 milliseconds, or 15 minutes.</p>
    #[doc(hidden)]
    pub max_band: std::option::Option<i32>,
    /// <p>This option specifies the maximum number of files to save from the last maxBand seconds. If this number is exceeded, extra files are skipped and only processed in the next job run.</p>
    #[doc(hidden)]
    pub max_files_in_band: std::option::Option<i32>,
    /// <p>Specifies additional connection options.</p>
    #[doc(hidden)]
    pub additional_options: std::option::Option<crate::types::S3DirectSourceAdditionalOptions>,
    /// <p>Specifies the data schema for the S3 Parquet source.</p>
    #[doc(hidden)]
    pub output_schemas: std::option::Option<std::vec::Vec<crate::types::GlueSchema>>,
}
impl S3ParquetSource {
    /// <p>The name of the data store.</p>
    pub fn name(&self) -> std::option::Option<&str> {
        self.name.as_deref()
    }
    /// <p>A list of the Amazon S3 paths to read from.</p>
    pub fn paths(&self) -> std::option::Option<&[std::string::String]> {
        self.paths.as_deref()
    }
    /// <p>Specifies how the data is compressed. This is generally not necessary if the data has a standard file extension. Possible values are <code>"gzip"</code> and <code>"bzip"</code>).</p>
    pub fn compression_type(&self) -> std::option::Option<&crate::types::ParquetCompressionType> {
        self.compression_type.as_ref()
    }
    /// <p>A string containing a JSON list of Unix-style glob patterns to exclude. For example, "[\"**.pdf\"]" excludes all PDF files. </p>
    pub fn exclusions(&self) -> std::option::Option<&[std::string::String]> {
        self.exclusions.as_deref()
    }
    /// <p>The target group size in bytes. The default is computed based on the input data size and the size of your cluster. When there are fewer than 50,000 input files, <code>"groupFiles"</code> must be set to <code>"inPartition"</code> for this to take effect.</p>
    pub fn group_size(&self) -> std::option::Option<&str> {
        self.group_size.as_deref()
    }
    /// <p>Grouping files is turned on by default when the input contains more than 50,000 files. To turn on grouping with fewer than 50,000 files, set this parameter to "inPartition". To disable grouping when there are more than 50,000 files, set this parameter to <code>"none"</code>.</p>
    pub fn group_files(&self) -> std::option::Option<&str> {
        self.group_files.as_deref()
    }
    /// <p>If set to true, recursively reads files in all subdirectories under the specified paths.</p>
    pub fn recurse(&self) -> std::option::Option<bool> {
        self.recurse
    }
    /// <p>This option controls the duration in milliseconds after which the s3 listing is likely to be consistent. Files with modification timestamps falling within the last maxBand milliseconds are tracked specially when using JobBookmarks to account for Amazon S3 eventual consistency. Most users don't need to set this option. The default is 900000 milliseconds, or 15 minutes.</p>
    pub fn max_band(&self) -> std::option::Option<i32> {
        self.max_band
    }
    /// <p>This option specifies the maximum number of files to save from the last maxBand seconds. If this number is exceeded, extra files are skipped and only processed in the next job run.</p>
    pub fn max_files_in_band(&self) -> std::option::Option<i32> {
        self.max_files_in_band
    }
    /// <p>Specifies additional connection options.</p>
    pub fn additional_options(
        &self,
    ) -> std::option::Option<&crate::types::S3DirectSourceAdditionalOptions> {
        self.additional_options.as_ref()
    }
    /// <p>Specifies the data schema for the S3 Parquet source.</p>
    pub fn output_schemas(&self) -> std::option::Option<&[crate::types::GlueSchema]> {
        self.output_schemas.as_deref()
    }
}
impl S3ParquetSource {
    /// Creates a new builder-style object to manufacture [`S3ParquetSource`](crate::types::S3ParquetSource).
    pub fn builder() -> crate::types::builders::S3ParquetSourceBuilder {
        crate::types::builders::S3ParquetSourceBuilder::default()
    }
}

/// A builder for [`S3ParquetSource`](crate::types::S3ParquetSource).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct S3ParquetSourceBuilder {
    pub(crate) name: std::option::Option<std::string::String>,
    pub(crate) paths: std::option::Option<std::vec::Vec<std::string::String>>,
    pub(crate) compression_type: std::option::Option<crate::types::ParquetCompressionType>,
    pub(crate) exclusions: std::option::Option<std::vec::Vec<std::string::String>>,
    pub(crate) group_size: std::option::Option<std::string::String>,
    pub(crate) group_files: std::option::Option<std::string::String>,
    pub(crate) recurse: std::option::Option<bool>,
    pub(crate) max_band: std::option::Option<i32>,
    pub(crate) max_files_in_band: std::option::Option<i32>,
    pub(crate) additional_options:
        std::option::Option<crate::types::S3DirectSourceAdditionalOptions>,
    pub(crate) output_schemas: std::option::Option<std::vec::Vec<crate::types::GlueSchema>>,
}
impl S3ParquetSourceBuilder {
    /// <p>The name of the data store.</p>
    pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
        self.name = Some(input.into());
        self
    }
    /// <p>The name of the data store.</p>
    pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.name = input;
        self
    }
    /// Appends an item to `paths`.
    ///
    /// To override the contents of this collection use [`set_paths`](Self::set_paths).
    ///
    /// <p>A list of the Amazon S3 paths to read from.</p>
    pub fn paths(mut self, input: impl Into<std::string::String>) -> Self {
        let mut v = self.paths.unwrap_or_default();
        v.push(input.into());
        self.paths = Some(v);
        self
    }
    /// <p>A list of the Amazon S3 paths to read from.</p>
    pub fn set_paths(
        mut self,
        input: std::option::Option<std::vec::Vec<std::string::String>>,
    ) -> Self {
        self.paths = input;
        self
    }
    /// <p>Specifies how the data is compressed. This is generally not necessary if the data has a standard file extension. Possible values are <code>"gzip"</code> and <code>"bzip"</code>).</p>
    pub fn compression_type(mut self, input: crate::types::ParquetCompressionType) -> Self {
        self.compression_type = Some(input);
        self
    }
    /// <p>Specifies how the data is compressed. This is generally not necessary if the data has a standard file extension. Possible values are <code>"gzip"</code> and <code>"bzip"</code>).</p>
    pub fn set_compression_type(
        mut self,
        input: std::option::Option<crate::types::ParquetCompressionType>,
    ) -> Self {
        self.compression_type = input;
        self
    }
    /// Appends an item to `exclusions`.
    ///
    /// To override the contents of this collection use [`set_exclusions`](Self::set_exclusions).
    ///
    /// <p>A string containing a JSON list of Unix-style glob patterns to exclude. For example, "[\"**.pdf\"]" excludes all PDF files. </p>
    pub fn exclusions(mut self, input: impl Into<std::string::String>) -> Self {
        let mut v = self.exclusions.unwrap_or_default();
        v.push(input.into());
        self.exclusions = Some(v);
        self
    }
    /// <p>A string containing a JSON list of Unix-style glob patterns to exclude. For example, "[\"**.pdf\"]" excludes all PDF files. </p>
    pub fn set_exclusions(
        mut self,
        input: std::option::Option<std::vec::Vec<std::string::String>>,
    ) -> Self {
        self.exclusions = input;
        self
    }
    /// <p>The target group size in bytes. The default is computed based on the input data size and the size of your cluster. When there are fewer than 50,000 input files, <code>"groupFiles"</code> must be set to <code>"inPartition"</code> for this to take effect.</p>
    pub fn group_size(mut self, input: impl Into<std::string::String>) -> Self {
        self.group_size = Some(input.into());
        self
    }
    /// <p>The target group size in bytes. The default is computed based on the input data size and the size of your cluster. When there are fewer than 50,000 input files, <code>"groupFiles"</code> must be set to <code>"inPartition"</code> for this to take effect.</p>
    pub fn set_group_size(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.group_size = input;
        self
    }
    /// <p>Grouping files is turned on by default when the input contains more than 50,000 files. To turn on grouping with fewer than 50,000 files, set this parameter to "inPartition". To disable grouping when there are more than 50,000 files, set this parameter to <code>"none"</code>.</p>
    pub fn group_files(mut self, input: impl Into<std::string::String>) -> Self {
        self.group_files = Some(input.into());
        self
    }
    /// <p>Grouping files is turned on by default when the input contains more than 50,000 files. To turn on grouping with fewer than 50,000 files, set this parameter to "inPartition". To disable grouping when there are more than 50,000 files, set this parameter to <code>"none"</code>.</p>
    pub fn set_group_files(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.group_files = input;
        self
    }
    /// <p>If set to true, recursively reads files in all subdirectories under the specified paths.</p>
    pub fn recurse(mut self, input: bool) -> Self {
        self.recurse = Some(input);
        self
    }
    /// <p>If set to true, recursively reads files in all subdirectories under the specified paths.</p>
    pub fn set_recurse(mut self, input: std::option::Option<bool>) -> Self {
        self.recurse = input;
        self
    }
    /// <p>This option controls the duration in milliseconds after which the s3 listing is likely to be consistent. Files with modification timestamps falling within the last maxBand milliseconds are tracked specially when using JobBookmarks to account for Amazon S3 eventual consistency. Most users don't need to set this option. The default is 900000 milliseconds, or 15 minutes.</p>
    pub fn max_band(mut self, input: i32) -> Self {
        self.max_band = Some(input);
        self
    }
    /// <p>This option controls the duration in milliseconds after which the s3 listing is likely to be consistent. Files with modification timestamps falling within the last maxBand milliseconds are tracked specially when using JobBookmarks to account for Amazon S3 eventual consistency. Most users don't need to set this option. The default is 900000 milliseconds, or 15 minutes.</p>
    pub fn set_max_band(mut self, input: std::option::Option<i32>) -> Self {
        self.max_band = input;
        self
    }
    /// <p>This option specifies the maximum number of files to save from the last maxBand seconds. If this number is exceeded, extra files are skipped and only processed in the next job run.</p>
    pub fn max_files_in_band(mut self, input: i32) -> Self {
        self.max_files_in_band = Some(input);
        self
    }
    /// <p>This option specifies the maximum number of files to save from the last maxBand seconds. If this number is exceeded, extra files are skipped and only processed in the next job run.</p>
    pub fn set_max_files_in_band(mut self, input: std::option::Option<i32>) -> Self {
        self.max_files_in_band = input;
        self
    }
    /// <p>Specifies additional connection options.</p>
    pub fn additional_options(
        mut self,
        input: crate::types::S3DirectSourceAdditionalOptions,
    ) -> Self {
        self.additional_options = Some(input);
        self
    }
    /// <p>Specifies additional connection options.</p>
    pub fn set_additional_options(
        mut self,
        input: std::option::Option<crate::types::S3DirectSourceAdditionalOptions>,
    ) -> Self {
        self.additional_options = input;
        self
    }
    /// Appends an item to `output_schemas`.
    ///
    /// To override the contents of this collection use [`set_output_schemas`](Self::set_output_schemas).
    ///
    /// <p>Specifies the data schema for the S3 Parquet source.</p>
    pub fn output_schemas(mut self, input: crate::types::GlueSchema) -> Self {
        let mut v = self.output_schemas.unwrap_or_default();
        v.push(input);
        self.output_schemas = Some(v);
        self
    }
    /// <p>Specifies the data schema for the S3 Parquet source.</p>
    pub fn set_output_schemas(
        mut self,
        input: std::option::Option<std::vec::Vec<crate::types::GlueSchema>>,
    ) -> Self {
        self.output_schemas = input;
        self
    }
    /// Consumes the builder and constructs a [`S3ParquetSource`](crate::types::S3ParquetSource).
    pub fn build(self) -> crate::types::S3ParquetSource {
        crate::types::S3ParquetSource {
            name: self.name,
            paths: self.paths,
            compression_type: self.compression_type,
            exclusions: self.exclusions,
            group_size: self.group_size,
            group_files: self.group_files,
            recurse: self.recurse,
            max_band: self.max_band,
            max_files_in_band: self.max_files_in_band,
            additional_options: self.additional_options,
            output_schemas: self.output_schemas,
        }
    }
}
