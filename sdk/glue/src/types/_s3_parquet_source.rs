// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Specifies an Apache Parquet data store stored in Amazon S3.</p>
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct S3ParquetSource {
    /// <p>The name of the data store.</p>
    pub name: ::std::string::String,
    /// <p>A list of the Amazon S3 paths to read from.</p>
    pub paths: ::std::vec::Vec<::std::string::String>,
    /// <p>Specifies how the data is compressed. This is generally not necessary if the data has a standard file extension. Possible values are <code>"gzip"</code> and <code>"bzip"</code>).</p>
    pub compression_type: ::std::option::Option<crate::types::ParquetCompressionType>,
    /// <p>A string containing a JSON list of Unix-style glob patterns to exclude. For example, "[\"**.pdf\"]" excludes all PDF files. </p>
    pub exclusions: ::std::option::Option<::std::vec::Vec<::std::string::String>>,
    /// <p>The target group size in bytes. The default is computed based on the input data size and the size of your cluster. When there are fewer than 50,000 input files, <code>"groupFiles"</code> must be set to <code>"inPartition"</code> for this to take effect.</p>
    pub group_size: ::std::option::Option<::std::string::String>,
    /// <p>Grouping files is turned on by default when the input contains more than 50,000 files. To turn on grouping with fewer than 50,000 files, set this parameter to "inPartition". To disable grouping when there are more than 50,000 files, set this parameter to <code>"none"</code>.</p>
    pub group_files: ::std::option::Option<::std::string::String>,
    /// <p>If set to true, recursively reads files in all subdirectories under the specified paths.</p>
    pub recurse: ::std::option::Option<bool>,
    /// <p>This option controls the duration in milliseconds after which the s3 listing is likely to be consistent. Files with modification timestamps falling within the last maxBand milliseconds are tracked specially when using JobBookmarks to account for Amazon S3 eventual consistency. Most users don't need to set this option. The default is 900000 milliseconds, or 15 minutes.</p>
    pub max_band: ::std::option::Option<i32>,
    /// <p>This option specifies the maximum number of files to save from the last maxBand seconds. If this number is exceeded, extra files are skipped and only processed in the next job run.</p>
    pub max_files_in_band: ::std::option::Option<i32>,
    /// <p>Specifies additional connection options.</p>
    pub additional_options: ::std::option::Option<crate::types::S3DirectSourceAdditionalOptions>,
    /// <p>Specifies the data schema for the S3 Parquet source.</p>
    pub output_schemas: ::std::option::Option<::std::vec::Vec<crate::types::GlueSchema>>,
}
impl S3ParquetSource {
    /// <p>The name of the data store.</p>
    pub fn name(&self) -> &str {
        use std::ops::Deref;
        self.name.deref()
    }
    /// <p>A list of the Amazon S3 paths to read from.</p>
    pub fn paths(&self) -> &[::std::string::String] {
        use std::ops::Deref;
        self.paths.deref()
    }
    /// <p>Specifies how the data is compressed. This is generally not necessary if the data has a standard file extension. Possible values are <code>"gzip"</code> and <code>"bzip"</code>).</p>
    pub fn compression_type(&self) -> ::std::option::Option<&crate::types::ParquetCompressionType> {
        self.compression_type.as_ref()
    }
    /// <p>A string containing a JSON list of Unix-style glob patterns to exclude. For example, "[\"**.pdf\"]" excludes all PDF files. </p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.exclusions.is_none()`.
    pub fn exclusions(&self) -> &[::std::string::String] {
        self.exclusions.as_deref().unwrap_or_default()
    }
    /// <p>The target group size in bytes. The default is computed based on the input data size and the size of your cluster. When there are fewer than 50,000 input files, <code>"groupFiles"</code> must be set to <code>"inPartition"</code> for this to take effect.</p>
    pub fn group_size(&self) -> ::std::option::Option<&str> {
        self.group_size.as_deref()
    }
    /// <p>Grouping files is turned on by default when the input contains more than 50,000 files. To turn on grouping with fewer than 50,000 files, set this parameter to "inPartition". To disable grouping when there are more than 50,000 files, set this parameter to <code>"none"</code>.</p>
    pub fn group_files(&self) -> ::std::option::Option<&str> {
        self.group_files.as_deref()
    }
    /// <p>If set to true, recursively reads files in all subdirectories under the specified paths.</p>
    pub fn recurse(&self) -> ::std::option::Option<bool> {
        self.recurse
    }
    /// <p>This option controls the duration in milliseconds after which the s3 listing is likely to be consistent. Files with modification timestamps falling within the last maxBand milliseconds are tracked specially when using JobBookmarks to account for Amazon S3 eventual consistency. Most users don't need to set this option. The default is 900000 milliseconds, or 15 minutes.</p>
    pub fn max_band(&self) -> ::std::option::Option<i32> {
        self.max_band
    }
    /// <p>This option specifies the maximum number of files to save from the last maxBand seconds. If this number is exceeded, extra files are skipped and only processed in the next job run.</p>
    pub fn max_files_in_band(&self) -> ::std::option::Option<i32> {
        self.max_files_in_band
    }
    /// <p>Specifies additional connection options.</p>
    pub fn additional_options(&self) -> ::std::option::Option<&crate::types::S3DirectSourceAdditionalOptions> {
        self.additional_options.as_ref()
    }
    /// <p>Specifies the data schema for the S3 Parquet source.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.output_schemas.is_none()`.
    pub fn output_schemas(&self) -> &[crate::types::GlueSchema] {
        self.output_schemas.as_deref().unwrap_or_default()
    }
}
impl S3ParquetSource {
    /// Creates a new builder-style object to manufacture [`S3ParquetSource`](crate::types::S3ParquetSource).
    pub fn builder() -> crate::types::builders::S3ParquetSourceBuilder {
        crate::types::builders::S3ParquetSourceBuilder::default()
    }
}

/// A builder for [`S3ParquetSource`](crate::types::S3ParquetSource).
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
pub struct S3ParquetSourceBuilder {
    pub(crate) name: ::std::option::Option<::std::string::String>,
    pub(crate) paths: ::std::option::Option<::std::vec::Vec<::std::string::String>>,
    pub(crate) compression_type: ::std::option::Option<crate::types::ParquetCompressionType>,
    pub(crate) exclusions: ::std::option::Option<::std::vec::Vec<::std::string::String>>,
    pub(crate) group_size: ::std::option::Option<::std::string::String>,
    pub(crate) group_files: ::std::option::Option<::std::string::String>,
    pub(crate) recurse: ::std::option::Option<bool>,
    pub(crate) max_band: ::std::option::Option<i32>,
    pub(crate) max_files_in_band: ::std::option::Option<i32>,
    pub(crate) additional_options: ::std::option::Option<crate::types::S3DirectSourceAdditionalOptions>,
    pub(crate) output_schemas: ::std::option::Option<::std::vec::Vec<crate::types::GlueSchema>>,
}
impl S3ParquetSourceBuilder {
    /// <p>The name of the data store.</p>
    /// This field is required.
    pub fn name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The name of the data store.</p>
    pub fn set_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.name = input;
        self
    }
    /// <p>The name of the data store.</p>
    pub fn get_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.name
    }
    /// Appends an item to `paths`.
    ///
    /// To override the contents of this collection use [`set_paths`](Self::set_paths).
    ///
    /// <p>A list of the Amazon S3 paths to read from.</p>
    pub fn paths(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        let mut v = self.paths.unwrap_or_default();
        v.push(input.into());
        self.paths = ::std::option::Option::Some(v);
        self
    }
    /// <p>A list of the Amazon S3 paths to read from.</p>
    pub fn set_paths(mut self, input: ::std::option::Option<::std::vec::Vec<::std::string::String>>) -> Self {
        self.paths = input;
        self
    }
    /// <p>A list of the Amazon S3 paths to read from.</p>
    pub fn get_paths(&self) -> &::std::option::Option<::std::vec::Vec<::std::string::String>> {
        &self.paths
    }
    /// <p>Specifies how the data is compressed. This is generally not necessary if the data has a standard file extension. Possible values are <code>"gzip"</code> and <code>"bzip"</code>).</p>
    pub fn compression_type(mut self, input: crate::types::ParquetCompressionType) -> Self {
        self.compression_type = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specifies how the data is compressed. This is generally not necessary if the data has a standard file extension. Possible values are <code>"gzip"</code> and <code>"bzip"</code>).</p>
    pub fn set_compression_type(mut self, input: ::std::option::Option<crate::types::ParquetCompressionType>) -> Self {
        self.compression_type = input;
        self
    }
    /// <p>Specifies how the data is compressed. This is generally not necessary if the data has a standard file extension. Possible values are <code>"gzip"</code> and <code>"bzip"</code>).</p>
    pub fn get_compression_type(&self) -> &::std::option::Option<crate::types::ParquetCompressionType> {
        &self.compression_type
    }
    /// Appends an item to `exclusions`.
    ///
    /// To override the contents of this collection use [`set_exclusions`](Self::set_exclusions).
    ///
    /// <p>A string containing a JSON list of Unix-style glob patterns to exclude. For example, "[\"**.pdf\"]" excludes all PDF files. </p>
    pub fn exclusions(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        let mut v = self.exclusions.unwrap_or_default();
        v.push(input.into());
        self.exclusions = ::std::option::Option::Some(v);
        self
    }
    /// <p>A string containing a JSON list of Unix-style glob patterns to exclude. For example, "[\"**.pdf\"]" excludes all PDF files. </p>
    pub fn set_exclusions(mut self, input: ::std::option::Option<::std::vec::Vec<::std::string::String>>) -> Self {
        self.exclusions = input;
        self
    }
    /// <p>A string containing a JSON list of Unix-style glob patterns to exclude. For example, "[\"**.pdf\"]" excludes all PDF files. </p>
    pub fn get_exclusions(&self) -> &::std::option::Option<::std::vec::Vec<::std::string::String>> {
        &self.exclusions
    }
    /// <p>The target group size in bytes. The default is computed based on the input data size and the size of your cluster. When there are fewer than 50,000 input files, <code>"groupFiles"</code> must be set to <code>"inPartition"</code> for this to take effect.</p>
    pub fn group_size(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.group_size = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The target group size in bytes. The default is computed based on the input data size and the size of your cluster. When there are fewer than 50,000 input files, <code>"groupFiles"</code> must be set to <code>"inPartition"</code> for this to take effect.</p>
    pub fn set_group_size(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.group_size = input;
        self
    }
    /// <p>The target group size in bytes. The default is computed based on the input data size and the size of your cluster. When there are fewer than 50,000 input files, <code>"groupFiles"</code> must be set to <code>"inPartition"</code> for this to take effect.</p>
    pub fn get_group_size(&self) -> &::std::option::Option<::std::string::String> {
        &self.group_size
    }
    /// <p>Grouping files is turned on by default when the input contains more than 50,000 files. To turn on grouping with fewer than 50,000 files, set this parameter to "inPartition". To disable grouping when there are more than 50,000 files, set this parameter to <code>"none"</code>.</p>
    pub fn group_files(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.group_files = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Grouping files is turned on by default when the input contains more than 50,000 files. To turn on grouping with fewer than 50,000 files, set this parameter to "inPartition". To disable grouping when there are more than 50,000 files, set this parameter to <code>"none"</code>.</p>
    pub fn set_group_files(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.group_files = input;
        self
    }
    /// <p>Grouping files is turned on by default when the input contains more than 50,000 files. To turn on grouping with fewer than 50,000 files, set this parameter to "inPartition". To disable grouping when there are more than 50,000 files, set this parameter to <code>"none"</code>.</p>
    pub fn get_group_files(&self) -> &::std::option::Option<::std::string::String> {
        &self.group_files
    }
    /// <p>If set to true, recursively reads files in all subdirectories under the specified paths.</p>
    pub fn recurse(mut self, input: bool) -> Self {
        self.recurse = ::std::option::Option::Some(input);
        self
    }
    /// <p>If set to true, recursively reads files in all subdirectories under the specified paths.</p>
    pub fn set_recurse(mut self, input: ::std::option::Option<bool>) -> Self {
        self.recurse = input;
        self
    }
    /// <p>If set to true, recursively reads files in all subdirectories under the specified paths.</p>
    pub fn get_recurse(&self) -> &::std::option::Option<bool> {
        &self.recurse
    }
    /// <p>This option controls the duration in milliseconds after which the s3 listing is likely to be consistent. Files with modification timestamps falling within the last maxBand milliseconds are tracked specially when using JobBookmarks to account for Amazon S3 eventual consistency. Most users don't need to set this option. The default is 900000 milliseconds, or 15 minutes.</p>
    pub fn max_band(mut self, input: i32) -> Self {
        self.max_band = ::std::option::Option::Some(input);
        self
    }
    /// <p>This option controls the duration in milliseconds after which the s3 listing is likely to be consistent. Files with modification timestamps falling within the last maxBand milliseconds are tracked specially when using JobBookmarks to account for Amazon S3 eventual consistency. Most users don't need to set this option. The default is 900000 milliseconds, or 15 minutes.</p>
    pub fn set_max_band(mut self, input: ::std::option::Option<i32>) -> Self {
        self.max_band = input;
        self
    }
    /// <p>This option controls the duration in milliseconds after which the s3 listing is likely to be consistent. Files with modification timestamps falling within the last maxBand milliseconds are tracked specially when using JobBookmarks to account for Amazon S3 eventual consistency. Most users don't need to set this option. The default is 900000 milliseconds, or 15 minutes.</p>
    pub fn get_max_band(&self) -> &::std::option::Option<i32> {
        &self.max_band
    }
    /// <p>This option specifies the maximum number of files to save from the last maxBand seconds. If this number is exceeded, extra files are skipped and only processed in the next job run.</p>
    pub fn max_files_in_band(mut self, input: i32) -> Self {
        self.max_files_in_band = ::std::option::Option::Some(input);
        self
    }
    /// <p>This option specifies the maximum number of files to save from the last maxBand seconds. If this number is exceeded, extra files are skipped and only processed in the next job run.</p>
    pub fn set_max_files_in_band(mut self, input: ::std::option::Option<i32>) -> Self {
        self.max_files_in_band = input;
        self
    }
    /// <p>This option specifies the maximum number of files to save from the last maxBand seconds. If this number is exceeded, extra files are skipped and only processed in the next job run.</p>
    pub fn get_max_files_in_band(&self) -> &::std::option::Option<i32> {
        &self.max_files_in_band
    }
    /// <p>Specifies additional connection options.</p>
    pub fn additional_options(mut self, input: crate::types::S3DirectSourceAdditionalOptions) -> Self {
        self.additional_options = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specifies additional connection options.</p>
    pub fn set_additional_options(mut self, input: ::std::option::Option<crate::types::S3DirectSourceAdditionalOptions>) -> Self {
        self.additional_options = input;
        self
    }
    /// <p>Specifies additional connection options.</p>
    pub fn get_additional_options(&self) -> &::std::option::Option<crate::types::S3DirectSourceAdditionalOptions> {
        &self.additional_options
    }
    /// Appends an item to `output_schemas`.
    ///
    /// To override the contents of this collection use [`set_output_schemas`](Self::set_output_schemas).
    ///
    /// <p>Specifies the data schema for the S3 Parquet source.</p>
    pub fn output_schemas(mut self, input: crate::types::GlueSchema) -> Self {
        let mut v = self.output_schemas.unwrap_or_default();
        v.push(input);
        self.output_schemas = ::std::option::Option::Some(v);
        self
    }
    /// <p>Specifies the data schema for the S3 Parquet source.</p>
    pub fn set_output_schemas(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::GlueSchema>>) -> Self {
        self.output_schemas = input;
        self
    }
    /// <p>Specifies the data schema for the S3 Parquet source.</p>
    pub fn get_output_schemas(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::GlueSchema>> {
        &self.output_schemas
    }
    /// Consumes the builder and constructs a [`S3ParquetSource`](crate::types::S3ParquetSource).
    /// This method will fail if any of the following fields are not set:
    /// - [`name`](crate::types::builders::S3ParquetSourceBuilder::name)
    /// - [`paths`](crate::types::builders::S3ParquetSourceBuilder::paths)
    pub fn build(self) -> ::std::result::Result<crate::types::S3ParquetSource, ::aws_smithy_types::error::operation::BuildError> {
        ::std::result::Result::Ok(crate::types::S3ParquetSource {
            name: self.name.ok_or_else(|| {
                ::aws_smithy_types::error::operation::BuildError::missing_field(
                    "name",
                    "name was not specified but it is required when building S3ParquetSource",
                )
            })?,
            paths: self.paths.ok_or_else(|| {
                ::aws_smithy_types::error::operation::BuildError::missing_field(
                    "paths",
                    "paths was not specified but it is required when building S3ParquetSource",
                )
            })?,
            compression_type: self.compression_type,
            exclusions: self.exclusions,
            group_size: self.group_size,
            group_files: self.group_files,
            recurse: self.recurse,
            max_band: self.max_band,
            max_files_in_band: self.max_files_in_band,
            additional_options: self.additional_options,
            output_schemas: self.output_schemas,
        })
    }
}
