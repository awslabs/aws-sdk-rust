// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Contains details for a table optimizer run.</p>
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct TableOptimizerRun {
    /// <p>An event type representing the status of the table optimizer run.</p>
    pub event_type: ::std::option::Option<crate::types::TableOptimizerEventType>,
    /// <p>Represents the epoch timestamp at which the compaction job was started within Lake Formation.</p>
    pub start_timestamp: ::std::option::Option<::aws_smithy_types::DateTime>,
    /// <p>Represents the epoch timestamp at which the compaction job ended.</p>
    pub end_timestamp: ::std::option::Option<::aws_smithy_types::DateTime>,
    /// <p>A <code>RunMetrics</code> object containing metrics for the optimizer run.</p>
    /// <p>This member is deprecated. See the individual metric members for compaction, retention, and orphan file deletion.</p>
    #[deprecated(note = "Metrics has been replaced by optimizer type specific metrics such as IcebergCompactionMetrics")]
    pub metrics: ::std::option::Option<crate::types::RunMetrics>,
    /// <p>An error that occured during the optimizer run.</p>
    pub error: ::std::option::Option<::std::string::String>,
    /// <p>A <code>CompactionMetrics</code> object containing metrics for the optimizer run.</p>
    pub compaction_metrics: ::std::option::Option<crate::types::CompactionMetrics>,
    /// <p>The strategy used for the compaction run. Indicates which algorithm was applied to determine how files were selected and combined during the compaction process. Valid values are:</p>
    /// <ul>
    /// <li>
    /// <p><code>binpack</code>: Combines small files into larger files, typically targeting sizes over 100MB, while applying any pending deletes. This is the recommended compaction strategy for most use cases.</p></li>
    /// <li>
    /// <p><code>sort</code>: Organizes data based on specified columns which are sorted hierarchically during compaction, improving query performance for filtered operations. This strategy is recommended when your queries frequently filter on specific columns. To use this strategy, you must first define a sort order in your Iceberg table properties using the <code>sort_order</code> table property.</p></li>
    /// <li>
    /// <p><code>z-order</code>: Optimizes data organization by blending multiple attributes into a single scalar value that can be used for sorting, allowing efficient querying across multiple dimensions. This strategy is recommended when you need to query data across multiple dimensions simultaneously. To use this strategy, you must first define a sort order in your Iceberg table properties using the <code>sort_order</code> table property.</p></li>
    /// </ul>
    pub compaction_strategy: ::std::option::Option<crate::types::CompactionStrategy>,
    /// <p>A <code>RetentionMetrics</code> object containing metrics for the optimizer run.</p>
    pub retention_metrics: ::std::option::Option<crate::types::RetentionMetrics>,
    /// <p>An <code>OrphanFileDeletionMetrics</code> object containing metrics for the optimizer run.</p>
    pub orphan_file_deletion_metrics: ::std::option::Option<crate::types::OrphanFileDeletionMetrics>,
}
impl TableOptimizerRun {
    /// <p>An event type representing the status of the table optimizer run.</p>
    pub fn event_type(&self) -> ::std::option::Option<&crate::types::TableOptimizerEventType> {
        self.event_type.as_ref()
    }
    /// <p>Represents the epoch timestamp at which the compaction job was started within Lake Formation.</p>
    pub fn start_timestamp(&self) -> ::std::option::Option<&::aws_smithy_types::DateTime> {
        self.start_timestamp.as_ref()
    }
    /// <p>Represents the epoch timestamp at which the compaction job ended.</p>
    pub fn end_timestamp(&self) -> ::std::option::Option<&::aws_smithy_types::DateTime> {
        self.end_timestamp.as_ref()
    }
    /// <p>A <code>RunMetrics</code> object containing metrics for the optimizer run.</p>
    /// <p>This member is deprecated. See the individual metric members for compaction, retention, and orphan file deletion.</p>
    #[deprecated(note = "Metrics has been replaced by optimizer type specific metrics such as IcebergCompactionMetrics")]
    pub fn metrics(&self) -> ::std::option::Option<&crate::types::RunMetrics> {
        self.metrics.as_ref()
    }
    /// <p>An error that occured during the optimizer run.</p>
    pub fn error(&self) -> ::std::option::Option<&str> {
        self.error.as_deref()
    }
    /// <p>A <code>CompactionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn compaction_metrics(&self) -> ::std::option::Option<&crate::types::CompactionMetrics> {
        self.compaction_metrics.as_ref()
    }
    /// <p>The strategy used for the compaction run. Indicates which algorithm was applied to determine how files were selected and combined during the compaction process. Valid values are:</p>
    /// <ul>
    /// <li>
    /// <p><code>binpack</code>: Combines small files into larger files, typically targeting sizes over 100MB, while applying any pending deletes. This is the recommended compaction strategy for most use cases.</p></li>
    /// <li>
    /// <p><code>sort</code>: Organizes data based on specified columns which are sorted hierarchically during compaction, improving query performance for filtered operations. This strategy is recommended when your queries frequently filter on specific columns. To use this strategy, you must first define a sort order in your Iceberg table properties using the <code>sort_order</code> table property.</p></li>
    /// <li>
    /// <p><code>z-order</code>: Optimizes data organization by blending multiple attributes into a single scalar value that can be used for sorting, allowing efficient querying across multiple dimensions. This strategy is recommended when you need to query data across multiple dimensions simultaneously. To use this strategy, you must first define a sort order in your Iceberg table properties using the <code>sort_order</code> table property.</p></li>
    /// </ul>
    pub fn compaction_strategy(&self) -> ::std::option::Option<&crate::types::CompactionStrategy> {
        self.compaction_strategy.as_ref()
    }
    /// <p>A <code>RetentionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn retention_metrics(&self) -> ::std::option::Option<&crate::types::RetentionMetrics> {
        self.retention_metrics.as_ref()
    }
    /// <p>An <code>OrphanFileDeletionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn orphan_file_deletion_metrics(&self) -> ::std::option::Option<&crate::types::OrphanFileDeletionMetrics> {
        self.orphan_file_deletion_metrics.as_ref()
    }
}
impl TableOptimizerRun {
    /// Creates a new builder-style object to manufacture [`TableOptimizerRun`](crate::types::TableOptimizerRun).
    pub fn builder() -> crate::types::builders::TableOptimizerRunBuilder {
        crate::types::builders::TableOptimizerRunBuilder::default()
    }
}

/// A builder for [`TableOptimizerRun`](crate::types::TableOptimizerRun).
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
#[non_exhaustive]
pub struct TableOptimizerRunBuilder {
    pub(crate) event_type: ::std::option::Option<crate::types::TableOptimizerEventType>,
    pub(crate) start_timestamp: ::std::option::Option<::aws_smithy_types::DateTime>,
    pub(crate) end_timestamp: ::std::option::Option<::aws_smithy_types::DateTime>,
    pub(crate) metrics: ::std::option::Option<crate::types::RunMetrics>,
    pub(crate) error: ::std::option::Option<::std::string::String>,
    pub(crate) compaction_metrics: ::std::option::Option<crate::types::CompactionMetrics>,
    pub(crate) compaction_strategy: ::std::option::Option<crate::types::CompactionStrategy>,
    pub(crate) retention_metrics: ::std::option::Option<crate::types::RetentionMetrics>,
    pub(crate) orphan_file_deletion_metrics: ::std::option::Option<crate::types::OrphanFileDeletionMetrics>,
}
impl TableOptimizerRunBuilder {
    /// <p>An event type representing the status of the table optimizer run.</p>
    pub fn event_type(mut self, input: crate::types::TableOptimizerEventType) -> Self {
        self.event_type = ::std::option::Option::Some(input);
        self
    }
    /// <p>An event type representing the status of the table optimizer run.</p>
    pub fn set_event_type(mut self, input: ::std::option::Option<crate::types::TableOptimizerEventType>) -> Self {
        self.event_type = input;
        self
    }
    /// <p>An event type representing the status of the table optimizer run.</p>
    pub fn get_event_type(&self) -> &::std::option::Option<crate::types::TableOptimizerEventType> {
        &self.event_type
    }
    /// <p>Represents the epoch timestamp at which the compaction job was started within Lake Formation.</p>
    pub fn start_timestamp(mut self, input: ::aws_smithy_types::DateTime) -> Self {
        self.start_timestamp = ::std::option::Option::Some(input);
        self
    }
    /// <p>Represents the epoch timestamp at which the compaction job was started within Lake Formation.</p>
    pub fn set_start_timestamp(mut self, input: ::std::option::Option<::aws_smithy_types::DateTime>) -> Self {
        self.start_timestamp = input;
        self
    }
    /// <p>Represents the epoch timestamp at which the compaction job was started within Lake Formation.</p>
    pub fn get_start_timestamp(&self) -> &::std::option::Option<::aws_smithy_types::DateTime> {
        &self.start_timestamp
    }
    /// <p>Represents the epoch timestamp at which the compaction job ended.</p>
    pub fn end_timestamp(mut self, input: ::aws_smithy_types::DateTime) -> Self {
        self.end_timestamp = ::std::option::Option::Some(input);
        self
    }
    /// <p>Represents the epoch timestamp at which the compaction job ended.</p>
    pub fn set_end_timestamp(mut self, input: ::std::option::Option<::aws_smithy_types::DateTime>) -> Self {
        self.end_timestamp = input;
        self
    }
    /// <p>Represents the epoch timestamp at which the compaction job ended.</p>
    pub fn get_end_timestamp(&self) -> &::std::option::Option<::aws_smithy_types::DateTime> {
        &self.end_timestamp
    }
    /// <p>A <code>RunMetrics</code> object containing metrics for the optimizer run.</p>
    /// <p>This member is deprecated. See the individual metric members for compaction, retention, and orphan file deletion.</p>
    #[deprecated(note = "Metrics has been replaced by optimizer type specific metrics such as IcebergCompactionMetrics")]
    pub fn metrics(mut self, input: crate::types::RunMetrics) -> Self {
        self.metrics = ::std::option::Option::Some(input);
        self
    }
    /// <p>A <code>RunMetrics</code> object containing metrics for the optimizer run.</p>
    /// <p>This member is deprecated. See the individual metric members for compaction, retention, and orphan file deletion.</p>
    #[deprecated(note = "Metrics has been replaced by optimizer type specific metrics such as IcebergCompactionMetrics")]
    pub fn set_metrics(mut self, input: ::std::option::Option<crate::types::RunMetrics>) -> Self {
        self.metrics = input;
        self
    }
    /// <p>A <code>RunMetrics</code> object containing metrics for the optimizer run.</p>
    /// <p>This member is deprecated. See the individual metric members for compaction, retention, and orphan file deletion.</p>
    #[deprecated(note = "Metrics has been replaced by optimizer type specific metrics such as IcebergCompactionMetrics")]
    pub fn get_metrics(&self) -> &::std::option::Option<crate::types::RunMetrics> {
        &self.metrics
    }
    /// <p>An error that occured during the optimizer run.</p>
    pub fn error(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.error = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>An error that occured during the optimizer run.</p>
    pub fn set_error(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.error = input;
        self
    }
    /// <p>An error that occured during the optimizer run.</p>
    pub fn get_error(&self) -> &::std::option::Option<::std::string::String> {
        &self.error
    }
    /// <p>A <code>CompactionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn compaction_metrics(mut self, input: crate::types::CompactionMetrics) -> Self {
        self.compaction_metrics = ::std::option::Option::Some(input);
        self
    }
    /// <p>A <code>CompactionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn set_compaction_metrics(mut self, input: ::std::option::Option<crate::types::CompactionMetrics>) -> Self {
        self.compaction_metrics = input;
        self
    }
    /// <p>A <code>CompactionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn get_compaction_metrics(&self) -> &::std::option::Option<crate::types::CompactionMetrics> {
        &self.compaction_metrics
    }
    /// <p>The strategy used for the compaction run. Indicates which algorithm was applied to determine how files were selected and combined during the compaction process. Valid values are:</p>
    /// <ul>
    /// <li>
    /// <p><code>binpack</code>: Combines small files into larger files, typically targeting sizes over 100MB, while applying any pending deletes. This is the recommended compaction strategy for most use cases.</p></li>
    /// <li>
    /// <p><code>sort</code>: Organizes data based on specified columns which are sorted hierarchically during compaction, improving query performance for filtered operations. This strategy is recommended when your queries frequently filter on specific columns. To use this strategy, you must first define a sort order in your Iceberg table properties using the <code>sort_order</code> table property.</p></li>
    /// <li>
    /// <p><code>z-order</code>: Optimizes data organization by blending multiple attributes into a single scalar value that can be used for sorting, allowing efficient querying across multiple dimensions. This strategy is recommended when you need to query data across multiple dimensions simultaneously. To use this strategy, you must first define a sort order in your Iceberg table properties using the <code>sort_order</code> table property.</p></li>
    /// </ul>
    pub fn compaction_strategy(mut self, input: crate::types::CompactionStrategy) -> Self {
        self.compaction_strategy = ::std::option::Option::Some(input);
        self
    }
    /// <p>The strategy used for the compaction run. Indicates which algorithm was applied to determine how files were selected and combined during the compaction process. Valid values are:</p>
    /// <ul>
    /// <li>
    /// <p><code>binpack</code>: Combines small files into larger files, typically targeting sizes over 100MB, while applying any pending deletes. This is the recommended compaction strategy for most use cases.</p></li>
    /// <li>
    /// <p><code>sort</code>: Organizes data based on specified columns which are sorted hierarchically during compaction, improving query performance for filtered operations. This strategy is recommended when your queries frequently filter on specific columns. To use this strategy, you must first define a sort order in your Iceberg table properties using the <code>sort_order</code> table property.</p></li>
    /// <li>
    /// <p><code>z-order</code>: Optimizes data organization by blending multiple attributes into a single scalar value that can be used for sorting, allowing efficient querying across multiple dimensions. This strategy is recommended when you need to query data across multiple dimensions simultaneously. To use this strategy, you must first define a sort order in your Iceberg table properties using the <code>sort_order</code> table property.</p></li>
    /// </ul>
    pub fn set_compaction_strategy(mut self, input: ::std::option::Option<crate::types::CompactionStrategy>) -> Self {
        self.compaction_strategy = input;
        self
    }
    /// <p>The strategy used for the compaction run. Indicates which algorithm was applied to determine how files were selected and combined during the compaction process. Valid values are:</p>
    /// <ul>
    /// <li>
    /// <p><code>binpack</code>: Combines small files into larger files, typically targeting sizes over 100MB, while applying any pending deletes. This is the recommended compaction strategy for most use cases.</p></li>
    /// <li>
    /// <p><code>sort</code>: Organizes data based on specified columns which are sorted hierarchically during compaction, improving query performance for filtered operations. This strategy is recommended when your queries frequently filter on specific columns. To use this strategy, you must first define a sort order in your Iceberg table properties using the <code>sort_order</code> table property.</p></li>
    /// <li>
    /// <p><code>z-order</code>: Optimizes data organization by blending multiple attributes into a single scalar value that can be used for sorting, allowing efficient querying across multiple dimensions. This strategy is recommended when you need to query data across multiple dimensions simultaneously. To use this strategy, you must first define a sort order in your Iceberg table properties using the <code>sort_order</code> table property.</p></li>
    /// </ul>
    pub fn get_compaction_strategy(&self) -> &::std::option::Option<crate::types::CompactionStrategy> {
        &self.compaction_strategy
    }
    /// <p>A <code>RetentionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn retention_metrics(mut self, input: crate::types::RetentionMetrics) -> Self {
        self.retention_metrics = ::std::option::Option::Some(input);
        self
    }
    /// <p>A <code>RetentionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn set_retention_metrics(mut self, input: ::std::option::Option<crate::types::RetentionMetrics>) -> Self {
        self.retention_metrics = input;
        self
    }
    /// <p>A <code>RetentionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn get_retention_metrics(&self) -> &::std::option::Option<crate::types::RetentionMetrics> {
        &self.retention_metrics
    }
    /// <p>An <code>OrphanFileDeletionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn orphan_file_deletion_metrics(mut self, input: crate::types::OrphanFileDeletionMetrics) -> Self {
        self.orphan_file_deletion_metrics = ::std::option::Option::Some(input);
        self
    }
    /// <p>An <code>OrphanFileDeletionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn set_orphan_file_deletion_metrics(mut self, input: ::std::option::Option<crate::types::OrphanFileDeletionMetrics>) -> Self {
        self.orphan_file_deletion_metrics = input;
        self
    }
    /// <p>An <code>OrphanFileDeletionMetrics</code> object containing metrics for the optimizer run.</p>
    pub fn get_orphan_file_deletion_metrics(&self) -> &::std::option::Option<crate::types::OrphanFileDeletionMetrics> {
        &self.orphan_file_deletion_metrics
    }
    /// Consumes the builder and constructs a [`TableOptimizerRun`](crate::types::TableOptimizerRun).
    pub fn build(self) -> crate::types::TableOptimizerRun {
        crate::types::TableOptimizerRun {
            event_type: self.event_type,
            start_timestamp: self.start_timestamp,
            end_timestamp: self.end_timestamp,
            metrics: self.metrics,
            error: self.error,
            compaction_metrics: self.compaction_metrics,
            compaction_strategy: self.compaction_strategy,
            retention_metrics: self.retention_metrics,
            orphan_file_deletion_metrics: self.orphan_file_deletion_metrics,
        }
    }
}
