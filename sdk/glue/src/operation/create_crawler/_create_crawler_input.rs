// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct CreateCrawlerInput  {
    /// <p>Name of the new crawler.</p>
    pub name: ::std::option::Option<::std::string::String>,
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to access customer resources.</p>
    pub role: ::std::option::Option<::std::string::String>,
    /// <p>The Glue database where results are written, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    pub database_name: ::std::option::Option<::std::string::String>,
    /// <p>A description of the new crawler.</p>
    pub description: ::std::option::Option<::std::string::String>,
    /// <p>A list of collection of targets to crawl.</p>
    pub targets: ::std::option::Option<crate::types::CrawlerTargets>,
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    pub schedule: ::std::option::Option<::std::string::String>,
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    pub classifiers: ::std::option::Option<::std::vec::Vec::<::std::string::String>>,
    /// <p>The table prefix used for catalog tables that are created.</p>
    pub table_prefix: ::std::option::Option<::std::string::String>,
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    pub schema_change_policy: ::std::option::Option<crate::types::SchemaChangePolicy>,
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    pub recrawl_policy: ::std::option::Option<crate::types::RecrawlPolicy>,
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    pub lineage_configuration: ::std::option::Option<crate::types::LineageConfiguration>,
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    pub lake_formation_configuration: ::std::option::Option<crate::types::LakeFormationConfiguration>,
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    pub configuration: ::std::option::Option<::std::string::String>,
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    pub crawler_security_configuration: ::std::option::Option<::std::string::String>,
    /// <p>The tags to use with this crawler request. You may use tags to limit access to the crawler. For more information about tags in Glue, see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html">Amazon Web Services Tags in Glue</a> in the developer guide.</p>
    pub tags: ::std::option::Option<::std::collections::HashMap::<::std::string::String, ::std::string::String>>,
}
impl  CreateCrawlerInput  {
    /// <p>Name of the new crawler.</p>
    pub fn name(&self) -> ::std::option::Option<& str> {
        self.name.as_deref()
    }
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to access customer resources.</p>
    pub fn role(&self) -> ::std::option::Option<& str> {
        self.role.as_deref()
    }
    /// <p>The Glue database where results are written, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    pub fn database_name(&self) -> ::std::option::Option<& str> {
        self.database_name.as_deref()
    }
    /// <p>A description of the new crawler.</p>
    pub fn description(&self) -> ::std::option::Option<& str> {
        self.description.as_deref()
    }
    /// <p>A list of collection of targets to crawl.</p>
    pub fn targets(&self) -> ::std::option::Option<& crate::types::CrawlerTargets> {
        self.targets.as_ref()
    }
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    pub fn schedule(&self) -> ::std::option::Option<& str> {
        self.schedule.as_deref()
    }
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    /// 
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.classifiers.is_none()`.
    pub fn classifiers(&self) -> & [::std::string::String] {
        self.classifiers.as_deref()
        .unwrap_or_default()
    }
    /// <p>The table prefix used for catalog tables that are created.</p>
    pub fn table_prefix(&self) -> ::std::option::Option<& str> {
        self.table_prefix.as_deref()
    }
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    pub fn schema_change_policy(&self) -> ::std::option::Option<& crate::types::SchemaChangePolicy> {
        self.schema_change_policy.as_ref()
    }
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    pub fn recrawl_policy(&self) -> ::std::option::Option<& crate::types::RecrawlPolicy> {
        self.recrawl_policy.as_ref()
    }
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    pub fn lineage_configuration(&self) -> ::std::option::Option<& crate::types::LineageConfiguration> {
        self.lineage_configuration.as_ref()
    }
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    pub fn lake_formation_configuration(&self) -> ::std::option::Option<& crate::types::LakeFormationConfiguration> {
        self.lake_formation_configuration.as_ref()
    }
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    pub fn configuration(&self) -> ::std::option::Option<& str> {
        self.configuration.as_deref()
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    pub fn crawler_security_configuration(&self) -> ::std::option::Option<& str> {
        self.crawler_security_configuration.as_deref()
    }
    /// <p>The tags to use with this crawler request. You may use tags to limit access to the crawler. For more information about tags in Glue, see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html">Amazon Web Services Tags in Glue</a> in the developer guide.</p>
    pub fn tags(&self) -> ::std::option::Option<& ::std::collections::HashMap::<::std::string::String, ::std::string::String>> {
        self.tags.as_ref()
    }
}
impl CreateCrawlerInput {
    /// Creates a new builder-style object to manufacture [`CreateCrawlerInput`](crate::operation::create_crawler::CreateCrawlerInput).
    pub fn builder() -> crate::operation::create_crawler::builders::CreateCrawlerInputBuilder {
        crate::operation::create_crawler::builders::CreateCrawlerInputBuilder::default()
    }
}

/// A builder for [`CreateCrawlerInput`](crate::operation::create_crawler::CreateCrawlerInput).
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
pub struct CreateCrawlerInputBuilder {
    pub(crate) name: ::std::option::Option<::std::string::String>,
    pub(crate) role: ::std::option::Option<::std::string::String>,
    pub(crate) database_name: ::std::option::Option<::std::string::String>,
    pub(crate) description: ::std::option::Option<::std::string::String>,
    pub(crate) targets: ::std::option::Option<crate::types::CrawlerTargets>,
    pub(crate) schedule: ::std::option::Option<::std::string::String>,
    pub(crate) classifiers: ::std::option::Option<::std::vec::Vec::<::std::string::String>>,
    pub(crate) table_prefix: ::std::option::Option<::std::string::String>,
    pub(crate) schema_change_policy: ::std::option::Option<crate::types::SchemaChangePolicy>,
    pub(crate) recrawl_policy: ::std::option::Option<crate::types::RecrawlPolicy>,
    pub(crate) lineage_configuration: ::std::option::Option<crate::types::LineageConfiguration>,
    pub(crate) lake_formation_configuration: ::std::option::Option<crate::types::LakeFormationConfiguration>,
    pub(crate) configuration: ::std::option::Option<::std::string::String>,
    pub(crate) crawler_security_configuration: ::std::option::Option<::std::string::String>,
    pub(crate) tags: ::std::option::Option<::std::collections::HashMap::<::std::string::String, ::std::string::String>>,
}
impl CreateCrawlerInputBuilder {
    /// <p>Name of the new crawler.</p>
    /// This field is required.
    pub fn name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Name of the new crawler.</p>
    pub fn set_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.name = input; self
    }
    /// <p>Name of the new crawler.</p>
    pub fn get_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.name
    }
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to access customer resources.</p>
    /// This field is required.
    pub fn role(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.role = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to access customer resources.</p>
    pub fn set_role(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.role = input; self
    }
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to access customer resources.</p>
    pub fn get_role(&self) -> &::std::option::Option<::std::string::String> {
        &self.role
    }
    /// <p>The Glue database where results are written, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    pub fn database_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.database_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The Glue database where results are written, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    pub fn set_database_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.database_name = input; self
    }
    /// <p>The Glue database where results are written, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    pub fn get_database_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.database_name
    }
    /// <p>A description of the new crawler.</p>
    pub fn description(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.description = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>A description of the new crawler.</p>
    pub fn set_description(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.description = input; self
    }
    /// <p>A description of the new crawler.</p>
    pub fn get_description(&self) -> &::std::option::Option<::std::string::String> {
        &self.description
    }
    /// <p>A list of collection of targets to crawl.</p>
    /// This field is required.
    pub fn targets(mut self, input: crate::types::CrawlerTargets) -> Self {
        self.targets = ::std::option::Option::Some(input);
        self
    }
    /// <p>A list of collection of targets to crawl.</p>
    pub fn set_targets(mut self, input: ::std::option::Option<crate::types::CrawlerTargets>) -> Self {
        self.targets = input; self
    }
    /// <p>A list of collection of targets to crawl.</p>
    pub fn get_targets(&self) -> &::std::option::Option<crate::types::CrawlerTargets> {
        &self.targets
    }
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    pub fn schedule(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.schedule = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    pub fn set_schedule(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.schedule = input; self
    }
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    pub fn get_schedule(&self) -> &::std::option::Option<::std::string::String> {
        &self.schedule
    }
    /// Appends an item to `classifiers`.
    ///
    /// To override the contents of this collection use [`set_classifiers`](Self::set_classifiers).
    ///
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    pub fn classifiers(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        let mut v = self.classifiers.unwrap_or_default();
                        v.push(input.into());
                        self.classifiers = ::std::option::Option::Some(v);
                        self
    }
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    pub fn set_classifiers(mut self, input: ::std::option::Option<::std::vec::Vec::<::std::string::String>>) -> Self {
        self.classifiers = input; self
    }
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    pub fn get_classifiers(&self) -> &::std::option::Option<::std::vec::Vec::<::std::string::String>> {
        &self.classifiers
    }
    /// <p>The table prefix used for catalog tables that are created.</p>
    pub fn table_prefix(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.table_prefix = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The table prefix used for catalog tables that are created.</p>
    pub fn set_table_prefix(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.table_prefix = input; self
    }
    /// <p>The table prefix used for catalog tables that are created.</p>
    pub fn get_table_prefix(&self) -> &::std::option::Option<::std::string::String> {
        &self.table_prefix
    }
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    pub fn schema_change_policy(mut self, input: crate::types::SchemaChangePolicy) -> Self {
        self.schema_change_policy = ::std::option::Option::Some(input);
        self
    }
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    pub fn set_schema_change_policy(mut self, input: ::std::option::Option<crate::types::SchemaChangePolicy>) -> Self {
        self.schema_change_policy = input; self
    }
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    pub fn get_schema_change_policy(&self) -> &::std::option::Option<crate::types::SchemaChangePolicy> {
        &self.schema_change_policy
    }
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    pub fn recrawl_policy(mut self, input: crate::types::RecrawlPolicy) -> Self {
        self.recrawl_policy = ::std::option::Option::Some(input);
        self
    }
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    pub fn set_recrawl_policy(mut self, input: ::std::option::Option<crate::types::RecrawlPolicy>) -> Self {
        self.recrawl_policy = input; self
    }
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    pub fn get_recrawl_policy(&self) -> &::std::option::Option<crate::types::RecrawlPolicy> {
        &self.recrawl_policy
    }
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    pub fn lineage_configuration(mut self, input: crate::types::LineageConfiguration) -> Self {
        self.lineage_configuration = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    pub fn set_lineage_configuration(mut self, input: ::std::option::Option<crate::types::LineageConfiguration>) -> Self {
        self.lineage_configuration = input; self
    }
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    pub fn get_lineage_configuration(&self) -> &::std::option::Option<crate::types::LineageConfiguration> {
        &self.lineage_configuration
    }
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    pub fn lake_formation_configuration(mut self, input: crate::types::LakeFormationConfiguration) -> Self {
        self.lake_formation_configuration = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    pub fn set_lake_formation_configuration(mut self, input: ::std::option::Option<crate::types::LakeFormationConfiguration>) -> Self {
        self.lake_formation_configuration = input; self
    }
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    pub fn get_lake_formation_configuration(&self) -> &::std::option::Option<crate::types::LakeFormationConfiguration> {
        &self.lake_formation_configuration
    }
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    pub fn configuration(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.configuration = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    pub fn set_configuration(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.configuration = input; self
    }
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    pub fn get_configuration(&self) -> &::std::option::Option<::std::string::String> {
        &self.configuration
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    pub fn crawler_security_configuration(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.crawler_security_configuration = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    pub fn set_crawler_security_configuration(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.crawler_security_configuration = input; self
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    pub fn get_crawler_security_configuration(&self) -> &::std::option::Option<::std::string::String> {
        &self.crawler_security_configuration
    }
    /// Adds a key-value pair to `tags`.
    ///
    /// To override the contents of this collection use [`set_tags`](Self::set_tags).
    ///
    /// <p>The tags to use with this crawler request. You may use tags to limit access to the crawler. For more information about tags in Glue, see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html">Amazon Web Services Tags in Glue</a> in the developer guide.</p>
    pub fn tags(mut self, k: impl ::std::convert::Into<::std::string::String>, v: impl ::std::convert::Into<::std::string::String>) -> Self {
        let mut hash_map = self.tags.unwrap_or_default();
                        hash_map.insert(k.into(), v.into());
                        self.tags = ::std::option::Option::Some(hash_map);
                        self
    }
    /// <p>The tags to use with this crawler request. You may use tags to limit access to the crawler. For more information about tags in Glue, see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html">Amazon Web Services Tags in Glue</a> in the developer guide.</p>
    pub fn set_tags(mut self, input: ::std::option::Option<::std::collections::HashMap::<::std::string::String, ::std::string::String>>) -> Self {
        self.tags = input; self
    }
    /// <p>The tags to use with this crawler request. You may use tags to limit access to the crawler. For more information about tags in Glue, see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html">Amazon Web Services Tags in Glue</a> in the developer guide.</p>
    pub fn get_tags(&self) -> &::std::option::Option<::std::collections::HashMap::<::std::string::String, ::std::string::String>> {
        &self.tags
    }
    /// Consumes the builder and constructs a [`CreateCrawlerInput`](crate::operation::create_crawler::CreateCrawlerInput).
    pub fn build(self) -> ::std::result::Result<crate::operation::create_crawler::CreateCrawlerInput, ::aws_smithy_types::error::operation::BuildError> {
        ::std::result::Result::Ok(
            crate::operation::create_crawler::CreateCrawlerInput {
                name: self.name
                ,
                role: self.role
                ,
                database_name: self.database_name
                ,
                description: self.description
                ,
                targets: self.targets
                ,
                schedule: self.schedule
                ,
                classifiers: self.classifiers
                ,
                table_prefix: self.table_prefix
                ,
                schema_change_policy: self.schema_change_policy
                ,
                recrawl_policy: self.recrawl_policy
                ,
                lineage_configuration: self.lineage_configuration
                ,
                lake_formation_configuration: self.lake_formation_configuration
                ,
                configuration: self.configuration
                ,
                crawler_security_configuration: self.crawler_security_configuration
                ,
                tags: self.tags
                ,
            }
        )
    }
}

