// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateCrawlerInput  {
    /// <p>Name of the new crawler.</p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to access customer resources.</p>
    #[doc(hidden)]
    pub role: std::option::Option<std::string::String>,
    /// <p>The Glue database where results are written, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    #[doc(hidden)]
    pub database_name: std::option::Option<std::string::String>,
    /// <p>A description of the new crawler.</p>
    #[doc(hidden)]
    pub description: std::option::Option<std::string::String>,
    /// <p>A list of collection of targets to crawl.</p>
    #[doc(hidden)]
    pub targets: std::option::Option<crate::types::CrawlerTargets>,
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    #[doc(hidden)]
    pub schedule: std::option::Option<std::string::String>,
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    #[doc(hidden)]
    pub classifiers: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>The table prefix used for catalog tables that are created.</p>
    #[doc(hidden)]
    pub table_prefix: std::option::Option<std::string::String>,
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    #[doc(hidden)]
    pub schema_change_policy: std::option::Option<crate::types::SchemaChangePolicy>,
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    #[doc(hidden)]
    pub recrawl_policy: std::option::Option<crate::types::RecrawlPolicy>,
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    #[doc(hidden)]
    pub lineage_configuration: std::option::Option<crate::types::LineageConfiguration>,
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    #[doc(hidden)]
    pub lake_formation_configuration: std::option::Option<crate::types::LakeFormationConfiguration>,
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    #[doc(hidden)]
    pub configuration: std::option::Option<std::string::String>,
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    #[doc(hidden)]
    pub crawler_security_configuration: std::option::Option<std::string::String>,
    /// <p>The tags to use with this crawler request. You may use tags to limit access to the crawler. For more information about tags in Glue, see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html">Amazon Web Services Tags in Glue</a> in the developer guide.</p>
    #[doc(hidden)]
    pub tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
}
impl CreateCrawlerInput {
    /// <p>Name of the new crawler.</p>
    pub fn name(&self) -> std::option::Option<& str> {
        self.name.as_deref()
    }
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to access customer resources.</p>
    pub fn role(&self) -> std::option::Option<& str> {
        self.role.as_deref()
    }
    /// <p>The Glue database where results are written, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    pub fn database_name(&self) -> std::option::Option<& str> {
        self.database_name.as_deref()
    }
    /// <p>A description of the new crawler.</p>
    pub fn description(&self) -> std::option::Option<& str> {
        self.description.as_deref()
    }
    /// <p>A list of collection of targets to crawl.</p>
    pub fn targets(&self) -> std::option::Option<& crate::types::CrawlerTargets> {
        self.targets.as_ref()
    }
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    pub fn schedule(&self) -> std::option::Option<& str> {
        self.schedule.as_deref()
    }
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    pub fn classifiers(&self) -> std::option::Option<& [std::string::String]> {
        self.classifiers.as_deref()
    }
    /// <p>The table prefix used for catalog tables that are created.</p>
    pub fn table_prefix(&self) -> std::option::Option<& str> {
        self.table_prefix.as_deref()
    }
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    pub fn schema_change_policy(&self) -> std::option::Option<& crate::types::SchemaChangePolicy> {
        self.schema_change_policy.as_ref()
    }
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    pub fn recrawl_policy(&self) -> std::option::Option<& crate::types::RecrawlPolicy> {
        self.recrawl_policy.as_ref()
    }
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    pub fn lineage_configuration(&self) -> std::option::Option<& crate::types::LineageConfiguration> {
        self.lineage_configuration.as_ref()
    }
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    pub fn lake_formation_configuration(&self) -> std::option::Option<& crate::types::LakeFormationConfiguration> {
        self.lake_formation_configuration.as_ref()
    }
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    pub fn configuration(&self) -> std::option::Option<& str> {
        self.configuration.as_deref()
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    pub fn crawler_security_configuration(&self) -> std::option::Option<& str> {
        self.crawler_security_configuration.as_deref()
    }
    /// <p>The tags to use with this crawler request. You may use tags to limit access to the crawler. For more information about tags in Glue, see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html">Amazon Web Services Tags in Glue</a> in the developer guide.</p>
    pub fn tags(&self) -> std::option::Option<& std::collections::HashMap<std::string::String, std::string::String>> {
        self.tags.as_ref()
    }
}
impl CreateCrawlerInput {
    /// Creates a new builder-style object to manufacture [`CreateCrawlerInput`](crate::operation::create_crawler::CreateCrawlerInput).
    pub fn builder() -> crate::operation::create_crawler::builders::CreateCrawlerInputBuilder {
        crate::operation::create_crawler::builders::CreateCrawlerInputBuilder::default()
    }
}

/// A builder for [`CreateCrawlerInput`](crate::operation::create_crawler::CreateCrawlerInput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct CreateCrawlerInputBuilder {
    pub(crate) name: std::option::Option<std::string::String>,
    pub(crate) role: std::option::Option<std::string::String>,
    pub(crate) database_name: std::option::Option<std::string::String>,
    pub(crate) description: std::option::Option<std::string::String>,
    pub(crate) targets: std::option::Option<crate::types::CrawlerTargets>,
    pub(crate) schedule: std::option::Option<std::string::String>,
    pub(crate) classifiers: std::option::Option<std::vec::Vec<std::string::String>>,
    pub(crate) table_prefix: std::option::Option<std::string::String>,
    pub(crate) schema_change_policy: std::option::Option<crate::types::SchemaChangePolicy>,
    pub(crate) recrawl_policy: std::option::Option<crate::types::RecrawlPolicy>,
    pub(crate) lineage_configuration: std::option::Option<crate::types::LineageConfiguration>,
    pub(crate) lake_formation_configuration: std::option::Option<crate::types::LakeFormationConfiguration>,
    pub(crate) configuration: std::option::Option<std::string::String>,
    pub(crate) crawler_security_configuration: std::option::Option<std::string::String>,
    pub(crate) tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
}
impl CreateCrawlerInputBuilder {
    /// <p>Name of the new crawler.</p>
    pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
        self.name = Some(input.into());
        self
    }
    /// <p>Name of the new crawler.</p>
    pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.name = input; self
    }
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to access customer resources.</p>
    pub fn role(mut self, input: impl Into<std::string::String>) -> Self {
        self.role = Some(input.into());
        self
    }
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to access customer resources.</p>
    pub fn set_role(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.role = input; self
    }
    /// <p>The Glue database where results are written, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    pub fn database_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.database_name = Some(input.into());
        self
    }
    /// <p>The Glue database where results are written, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    pub fn set_database_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.database_name = input; self
    }
    /// <p>A description of the new crawler.</p>
    pub fn description(mut self, input: impl Into<std::string::String>) -> Self {
        self.description = Some(input.into());
        self
    }
    /// <p>A description of the new crawler.</p>
    pub fn set_description(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.description = input; self
    }
    /// <p>A list of collection of targets to crawl.</p>
    pub fn targets(mut self, input: crate::types::CrawlerTargets) -> Self {
        self.targets = Some(input);
        self
    }
    /// <p>A list of collection of targets to crawl.</p>
    pub fn set_targets(mut self, input: std::option::Option<crate::types::CrawlerTargets>) -> Self {
        self.targets = input; self
    }
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    pub fn schedule(mut self, input: impl Into<std::string::String>) -> Self {
        self.schedule = Some(input.into());
        self
    }
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    pub fn set_schedule(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.schedule = input; self
    }
    /// Appends an item to `classifiers`.
    ///
    /// To override the contents of this collection use [`set_classifiers`](Self::set_classifiers).
    ///
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    pub fn classifiers(mut self, input: impl Into<std::string::String>) -> Self {
        let mut v = self.classifiers.unwrap_or_default();
                        v.push(input.into());
                        self.classifiers = Some(v);
                        self
    }
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    pub fn set_classifiers(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
        self.classifiers = input; self
    }
    /// <p>The table prefix used for catalog tables that are created.</p>
    pub fn table_prefix(mut self, input: impl Into<std::string::String>) -> Self {
        self.table_prefix = Some(input.into());
        self
    }
    /// <p>The table prefix used for catalog tables that are created.</p>
    pub fn set_table_prefix(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.table_prefix = input; self
    }
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    pub fn schema_change_policy(mut self, input: crate::types::SchemaChangePolicy) -> Self {
        self.schema_change_policy = Some(input);
        self
    }
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    pub fn set_schema_change_policy(mut self, input: std::option::Option<crate::types::SchemaChangePolicy>) -> Self {
        self.schema_change_policy = input; self
    }
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    pub fn recrawl_policy(mut self, input: crate::types::RecrawlPolicy) -> Self {
        self.recrawl_policy = Some(input);
        self
    }
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    pub fn set_recrawl_policy(mut self, input: std::option::Option<crate::types::RecrawlPolicy>) -> Self {
        self.recrawl_policy = input; self
    }
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    pub fn lineage_configuration(mut self, input: crate::types::LineageConfiguration) -> Self {
        self.lineage_configuration = Some(input);
        self
    }
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    pub fn set_lineage_configuration(mut self, input: std::option::Option<crate::types::LineageConfiguration>) -> Self {
        self.lineage_configuration = input; self
    }
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    pub fn lake_formation_configuration(mut self, input: crate::types::LakeFormationConfiguration) -> Self {
        self.lake_formation_configuration = Some(input);
        self
    }
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    pub fn set_lake_formation_configuration(mut self, input: std::option::Option<crate::types::LakeFormationConfiguration>) -> Self {
        self.lake_formation_configuration = input; self
    }
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    pub fn configuration(mut self, input: impl Into<std::string::String>) -> Self {
        self.configuration = Some(input.into());
        self
    }
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    pub fn set_configuration(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.configuration = input; self
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    pub fn crawler_security_configuration(mut self, input: impl Into<std::string::String>) -> Self {
        self.crawler_security_configuration = Some(input.into());
        self
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    pub fn set_crawler_security_configuration(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.crawler_security_configuration = input; self
    }
    /// Adds a key-value pair to `tags`.
    ///
    /// To override the contents of this collection use [`set_tags`](Self::set_tags).
    ///
    /// <p>The tags to use with this crawler request. You may use tags to limit access to the crawler. For more information about tags in Glue, see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html">Amazon Web Services Tags in Glue</a> in the developer guide.</p>
    pub fn tags(mut self, k: impl Into<std::string::String>, v: impl Into<std::string::String>) -> Self {
        let mut hash_map = self.tags.unwrap_or_default();
                        hash_map.insert(k.into(), v.into());
                        self.tags = Some(hash_map);
                        self
    }
    /// <p>The tags to use with this crawler request. You may use tags to limit access to the crawler. For more information about tags in Glue, see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html">Amazon Web Services Tags in Glue</a> in the developer guide.</p>
    pub fn set_tags(mut self, input: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>) -> Self {
        self.tags = input; self
    }
    /// Consumes the builder and constructs a [`CreateCrawlerInput`](crate::operation::create_crawler::CreateCrawlerInput).
    pub fn build(self) -> Result<crate::operation::create_crawler::CreateCrawlerInput, aws_smithy_http::operation::error::BuildError> {
        Ok(
            crate::operation::create_crawler::CreateCrawlerInput {
                name: self.name
                ,
                role: self.role
                ,
                database_name: self.database_name
                ,
                description: self.description
                ,
                targets: self.targets
                ,
                schedule: self.schedule
                ,
                classifiers: self.classifiers
                ,
                table_prefix: self.table_prefix
                ,
                schema_change_policy: self.schema_change_policy
                ,
                recrawl_policy: self.recrawl_policy
                ,
                lineage_configuration: self.lineage_configuration
                ,
                lake_formation_configuration: self.lake_formation_configuration
                ,
                configuration: self.configuration
                ,
                crawler_security_configuration: self.crawler_security_configuration
                ,
                tags: self.tags
                ,
            }
        )
    }
}

