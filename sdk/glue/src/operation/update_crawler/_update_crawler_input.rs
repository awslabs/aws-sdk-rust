// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct UpdateCrawlerInput {
    /// <p>Name of the new crawler.</p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role that is used by the new crawler to access customer resources.</p>
    #[doc(hidden)]
    pub role: std::option::Option<std::string::String>,
    /// <p>The Glue database where results are stored, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    #[doc(hidden)]
    pub database_name: std::option::Option<std::string::String>,
    /// <p>A description of the new crawler.</p>
    #[doc(hidden)]
    pub description: std::option::Option<std::string::String>,
    /// <p>A list of targets to crawl.</p>
    #[doc(hidden)]
    pub targets: std::option::Option<crate::types::CrawlerTargets>,
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    #[doc(hidden)]
    pub schedule: std::option::Option<std::string::String>,
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    #[doc(hidden)]
    pub classifiers: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>The table prefix used for catalog tables that are created.</p>
    #[doc(hidden)]
    pub table_prefix: std::option::Option<std::string::String>,
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    #[doc(hidden)]
    pub schema_change_policy: std::option::Option<crate::types::SchemaChangePolicy>,
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    #[doc(hidden)]
    pub recrawl_policy: std::option::Option<crate::types::RecrawlPolicy>,
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    #[doc(hidden)]
    pub lineage_configuration: std::option::Option<crate::types::LineageConfiguration>,
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    #[doc(hidden)]
    pub lake_formation_configuration: std::option::Option<crate::types::LakeFormationConfiguration>,
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    #[doc(hidden)]
    pub configuration: std::option::Option<std::string::String>,
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    #[doc(hidden)]
    pub crawler_security_configuration: std::option::Option<std::string::String>,
}
impl UpdateCrawlerInput {
    /// <p>Name of the new crawler.</p>
    pub fn name(&self) -> std::option::Option<&str> {
        self.name.as_deref()
    }
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role that is used by the new crawler to access customer resources.</p>
    pub fn role(&self) -> std::option::Option<&str> {
        self.role.as_deref()
    }
    /// <p>The Glue database where results are stored, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    pub fn database_name(&self) -> std::option::Option<&str> {
        self.database_name.as_deref()
    }
    /// <p>A description of the new crawler.</p>
    pub fn description(&self) -> std::option::Option<&str> {
        self.description.as_deref()
    }
    /// <p>A list of targets to crawl.</p>
    pub fn targets(&self) -> std::option::Option<&crate::types::CrawlerTargets> {
        self.targets.as_ref()
    }
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    pub fn schedule(&self) -> std::option::Option<&str> {
        self.schedule.as_deref()
    }
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    pub fn classifiers(&self) -> std::option::Option<&[std::string::String]> {
        self.classifiers.as_deref()
    }
    /// <p>The table prefix used for catalog tables that are created.</p>
    pub fn table_prefix(&self) -> std::option::Option<&str> {
        self.table_prefix.as_deref()
    }
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    pub fn schema_change_policy(&self) -> std::option::Option<&crate::types::SchemaChangePolicy> {
        self.schema_change_policy.as_ref()
    }
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    pub fn recrawl_policy(&self) -> std::option::Option<&crate::types::RecrawlPolicy> {
        self.recrawl_policy.as_ref()
    }
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    pub fn lineage_configuration(
        &self,
    ) -> std::option::Option<&crate::types::LineageConfiguration> {
        self.lineage_configuration.as_ref()
    }
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    pub fn lake_formation_configuration(
        &self,
    ) -> std::option::Option<&crate::types::LakeFormationConfiguration> {
        self.lake_formation_configuration.as_ref()
    }
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    pub fn configuration(&self) -> std::option::Option<&str> {
        self.configuration.as_deref()
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    pub fn crawler_security_configuration(&self) -> std::option::Option<&str> {
        self.crawler_security_configuration.as_deref()
    }
}
impl UpdateCrawlerInput {
    /// Creates a new builder-style object to manufacture [`UpdateCrawlerInput`](crate::operation::update_crawler::UpdateCrawlerInput).
    pub fn builder() -> crate::operation::update_crawler::builders::UpdateCrawlerInputBuilder {
        crate::operation::update_crawler::builders::UpdateCrawlerInputBuilder::default()
    }
}

/// A builder for [`UpdateCrawlerInput`](crate::operation::update_crawler::UpdateCrawlerInput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct UpdateCrawlerInputBuilder {
    pub(crate) name: std::option::Option<std::string::String>,
    pub(crate) role: std::option::Option<std::string::String>,
    pub(crate) database_name: std::option::Option<std::string::String>,
    pub(crate) description: std::option::Option<std::string::String>,
    pub(crate) targets: std::option::Option<crate::types::CrawlerTargets>,
    pub(crate) schedule: std::option::Option<std::string::String>,
    pub(crate) classifiers: std::option::Option<std::vec::Vec<std::string::String>>,
    pub(crate) table_prefix: std::option::Option<std::string::String>,
    pub(crate) schema_change_policy: std::option::Option<crate::types::SchemaChangePolicy>,
    pub(crate) recrawl_policy: std::option::Option<crate::types::RecrawlPolicy>,
    pub(crate) lineage_configuration: std::option::Option<crate::types::LineageConfiguration>,
    pub(crate) lake_formation_configuration:
        std::option::Option<crate::types::LakeFormationConfiguration>,
    pub(crate) configuration: std::option::Option<std::string::String>,
    pub(crate) crawler_security_configuration: std::option::Option<std::string::String>,
}
impl UpdateCrawlerInputBuilder {
    /// <p>Name of the new crawler.</p>
    pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
        self.name = Some(input.into());
        self
    }
    /// <p>Name of the new crawler.</p>
    pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.name = input;
        self
    }
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role that is used by the new crawler to access customer resources.</p>
    pub fn role(mut self, input: impl Into<std::string::String>) -> Self {
        self.role = Some(input.into());
        self
    }
    /// <p>The IAM role or Amazon Resource Name (ARN) of an IAM role that is used by the new crawler to access customer resources.</p>
    pub fn set_role(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.role = input;
        self
    }
    /// <p>The Glue database where results are stored, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    pub fn database_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.database_name = Some(input.into());
        self
    }
    /// <p>The Glue database where results are stored, such as: <code>arn:aws:daylight:us-east-1::database/sometable/*</code>.</p>
    pub fn set_database_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.database_name = input;
        self
    }
    /// <p>A description of the new crawler.</p>
    pub fn description(mut self, input: impl Into<std::string::String>) -> Self {
        self.description = Some(input.into());
        self
    }
    /// <p>A description of the new crawler.</p>
    pub fn set_description(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.description = input;
        self
    }
    /// <p>A list of targets to crawl.</p>
    pub fn targets(mut self, input: crate::types::CrawlerTargets) -> Self {
        self.targets = Some(input);
        self
    }
    /// <p>A list of targets to crawl.</p>
    pub fn set_targets(mut self, input: std::option::Option<crate::types::CrawlerTargets>) -> Self {
        self.targets = input;
        self
    }
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    pub fn schedule(mut self, input: impl Into<std::string::String>) -> Self {
        self.schedule = Some(input.into());
        self
    }
    /// <p>A <code>cron</code> expression used to specify the schedule (see <a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a>. For example, to run something every day at 12:15 UTC, you would specify: <code>cron(15 12 * * ? *)</code>.</p>
    pub fn set_schedule(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.schedule = input;
        self
    }
    /// Appends an item to `classifiers`.
    ///
    /// To override the contents of this collection use [`set_classifiers`](Self::set_classifiers).
    ///
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    pub fn classifiers(mut self, input: impl Into<std::string::String>) -> Self {
        let mut v = self.classifiers.unwrap_or_default();
        v.push(input.into());
        self.classifiers = Some(v);
        self
    }
    /// <p>A list of custom classifiers that the user has registered. By default, all built-in classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.</p>
    pub fn set_classifiers(
        mut self,
        input: std::option::Option<std::vec::Vec<std::string::String>>,
    ) -> Self {
        self.classifiers = input;
        self
    }
    /// <p>The table prefix used for catalog tables that are created.</p>
    pub fn table_prefix(mut self, input: impl Into<std::string::String>) -> Self {
        self.table_prefix = Some(input.into());
        self
    }
    /// <p>The table prefix used for catalog tables that are created.</p>
    pub fn set_table_prefix(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.table_prefix = input;
        self
    }
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    pub fn schema_change_policy(mut self, input: crate::types::SchemaChangePolicy) -> Self {
        self.schema_change_policy = Some(input);
        self
    }
    /// <p>The policy for the crawler's update and deletion behavior.</p>
    pub fn set_schema_change_policy(
        mut self,
        input: std::option::Option<crate::types::SchemaChangePolicy>,
    ) -> Self {
        self.schema_change_policy = input;
        self
    }
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    pub fn recrawl_policy(mut self, input: crate::types::RecrawlPolicy) -> Self {
        self.recrawl_policy = Some(input);
        self
    }
    /// <p>A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.</p>
    pub fn set_recrawl_policy(
        mut self,
        input: std::option::Option<crate::types::RecrawlPolicy>,
    ) -> Self {
        self.recrawl_policy = input;
        self
    }
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    pub fn lineage_configuration(mut self, input: crate::types::LineageConfiguration) -> Self {
        self.lineage_configuration = Some(input);
        self
    }
    /// <p>Specifies data lineage configuration settings for the crawler.</p>
    pub fn set_lineage_configuration(
        mut self,
        input: std::option::Option<crate::types::LineageConfiguration>,
    ) -> Self {
        self.lineage_configuration = input;
        self
    }
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    pub fn lake_formation_configuration(
        mut self,
        input: crate::types::LakeFormationConfiguration,
    ) -> Self {
        self.lake_formation_configuration = Some(input);
        self
    }
    /// <p>Specifies Lake Formation configuration settings for the crawler.</p>
    pub fn set_lake_formation_configuration(
        mut self,
        input: std::option::Option<crate::types::LakeFormationConfiguration>,
    ) -> Self {
        self.lake_formation_configuration = input;
        self
    }
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    pub fn configuration(mut self, input: impl Into<std::string::String>) -> Self {
        self.configuration = Some(input.into());
        self
    }
    /// <p>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Setting crawler configuration options</a>.</p>
    pub fn set_configuration(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.configuration = input;
        self
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    pub fn crawler_security_configuration(mut self, input: impl Into<std::string::String>) -> Self {
        self.crawler_security_configuration = Some(input.into());
        self
    }
    /// <p>The name of the <code>SecurityConfiguration</code> structure to be used by this crawler.</p>
    pub fn set_crawler_security_configuration(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.crawler_security_configuration = input;
        self
    }
    /// Consumes the builder and constructs a [`UpdateCrawlerInput`](crate::operation::update_crawler::UpdateCrawlerInput).
    pub fn build(
        self,
    ) -> Result<
        crate::operation::update_crawler::UpdateCrawlerInput,
        aws_smithy_http::operation::error::BuildError,
    > {
        Ok(crate::operation::update_crawler::UpdateCrawlerInput {
            name: self.name,
            role: self.role,
            database_name: self.database_name,
            description: self.description,
            targets: self.targets,
            schedule: self.schedule,
            classifiers: self.classifiers,
            table_prefix: self.table_prefix,
            schema_change_policy: self.schema_change_policy,
            recrawl_policy: self.recrawl_policy,
            lineage_configuration: self.lineage_configuration,
            lake_formation_configuration: self.lake_formation_configuration,
            configuration: self.configuration,
            crawler_security_configuration: self.crawler_security_configuration,
        })
    }
}
