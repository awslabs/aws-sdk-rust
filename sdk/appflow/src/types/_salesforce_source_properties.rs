// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p> The properties that are applied when Salesforce is being used as a source. </p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct SalesforceSourceProperties  {
    /// <p> The object specified in the Salesforce flow source. </p>
    #[doc(hidden)]
    pub object: std::option::Option<std::string::String>,
    /// <p> The flag that enables dynamic fetching of new (recently added) fields in the Salesforce objects while running a flow. </p>
    #[doc(hidden)]
    pub enable_dynamic_field_update: bool,
    /// <p> Indicates whether Amazon AppFlow includes deleted files in the flow run. </p>
    #[doc(hidden)]
    pub include_deleted_records: bool,
    /// <p>Specifies which Salesforce API is used by Amazon AppFlow when your flow transfers data from Salesforce.</p> 
    /// <dl> 
    /// <dt>
    /// AUTOMATIC
    /// </dt> 
    /// <dd> 
    /// <p>The default. Amazon AppFlow selects which API to use based on the number of records that your flow transfers from Salesforce. If your flow transfers fewer than 1,000,000 records, Amazon AppFlow uses Salesforce REST API. If your flow transfers 1,000,000 records or more, Amazon AppFlow uses Salesforce Bulk API 2.0.</p> 
    /// <p>Each of these Salesforce APIs structures data differently. If Amazon AppFlow selects the API automatically, be aware that, for recurring flows, the data output might vary from one flow run to the next. For example, if a flow runs daily, it might use REST API on one day to transfer 900,000 records, and it might use Bulk API 2.0 on the next day to transfer 1,100,000 records. For each of these flow runs, the respective Salesforce API formats the data differently. Some of the differences include how dates are formatted and null values are represented. Also, Bulk API 2.0 doesn't transfer Salesforce compound fields.</p> 
    /// <p>By choosing this option, you optimize flow performance for both small and large data transfers, but the tradeoff is inconsistent formatting in the output.</p> 
    /// </dd> 
    /// <dt>
    /// BULKV2
    /// </dt> 
    /// <dd> 
    /// <p>Amazon AppFlow uses only Salesforce Bulk API 2.0. This API runs asynchronous data transfers, and it's optimal for large sets of data. By choosing this option, you ensure that your flow writes consistent output, but you optimize performance only for large data transfers.</p> 
    /// <p>Note that Bulk API 2.0 does not transfer Salesforce compound fields.</p> 
    /// </dd> 
    /// <dt>
    /// REST_SYNC
    /// </dt> 
    /// <dd> 
    /// <p>Amazon AppFlow uses only Salesforce REST API. By choosing this option, you ensure that your flow writes consistent output, but you decrease performance for large data transfers that are better suited for Bulk API 2.0. In some cases, if your flow attempts to transfer a vary large set of data, it might fail wituh a timed out error.</p> 
    /// </dd> 
    /// </dl>
    #[doc(hidden)]
    pub data_transfer_api: std::option::Option<crate::types::SalesforceDataTransferApi>,
}
impl SalesforceSourceProperties {
    /// <p> The object specified in the Salesforce flow source. </p>
    pub fn object(&self) -> std::option::Option<& str> {
        self.object.as_deref()
    }
    /// <p> The flag that enables dynamic fetching of new (recently added) fields in the Salesforce objects while running a flow. </p>
    pub fn enable_dynamic_field_update(&self) -> bool {
        self.enable_dynamic_field_update
    }
    /// <p> Indicates whether Amazon AppFlow includes deleted files in the flow run. </p>
    pub fn include_deleted_records(&self) -> bool {
        self.include_deleted_records
    }
    /// <p>Specifies which Salesforce API is used by Amazon AppFlow when your flow transfers data from Salesforce.</p> 
    /// <dl> 
    /// <dt>
    /// AUTOMATIC
    /// </dt> 
    /// <dd> 
    /// <p>The default. Amazon AppFlow selects which API to use based on the number of records that your flow transfers from Salesforce. If your flow transfers fewer than 1,000,000 records, Amazon AppFlow uses Salesforce REST API. If your flow transfers 1,000,000 records or more, Amazon AppFlow uses Salesforce Bulk API 2.0.</p> 
    /// <p>Each of these Salesforce APIs structures data differently. If Amazon AppFlow selects the API automatically, be aware that, for recurring flows, the data output might vary from one flow run to the next. For example, if a flow runs daily, it might use REST API on one day to transfer 900,000 records, and it might use Bulk API 2.0 on the next day to transfer 1,100,000 records. For each of these flow runs, the respective Salesforce API formats the data differently. Some of the differences include how dates are formatted and null values are represented. Also, Bulk API 2.0 doesn't transfer Salesforce compound fields.</p> 
    /// <p>By choosing this option, you optimize flow performance for both small and large data transfers, but the tradeoff is inconsistent formatting in the output.</p> 
    /// </dd> 
    /// <dt>
    /// BULKV2
    /// </dt> 
    /// <dd> 
    /// <p>Amazon AppFlow uses only Salesforce Bulk API 2.0. This API runs asynchronous data transfers, and it's optimal for large sets of data. By choosing this option, you ensure that your flow writes consistent output, but you optimize performance only for large data transfers.</p> 
    /// <p>Note that Bulk API 2.0 does not transfer Salesforce compound fields.</p> 
    /// </dd> 
    /// <dt>
    /// REST_SYNC
    /// </dt> 
    /// <dd> 
    /// <p>Amazon AppFlow uses only Salesforce REST API. By choosing this option, you ensure that your flow writes consistent output, but you decrease performance for large data transfers that are better suited for Bulk API 2.0. In some cases, if your flow attempts to transfer a vary large set of data, it might fail wituh a timed out error.</p> 
    /// </dd> 
    /// </dl>
    pub fn data_transfer_api(&self) -> std::option::Option<& crate::types::SalesforceDataTransferApi> {
        self.data_transfer_api.as_ref()
    }
}
impl SalesforceSourceProperties {
    /// Creates a new builder-style object to manufacture [`SalesforceSourceProperties`](crate::types::SalesforceSourceProperties).
    pub fn builder() -> crate::types::builders::SalesforceSourcePropertiesBuilder {
        crate::types::builders::SalesforceSourcePropertiesBuilder::default()
    }
}

/// A builder for [`SalesforceSourceProperties`](crate::types::SalesforceSourceProperties).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct SalesforceSourcePropertiesBuilder {
    pub(crate) object: std::option::Option<std::string::String>,
    pub(crate) enable_dynamic_field_update: std::option::Option<bool>,
    pub(crate) include_deleted_records: std::option::Option<bool>,
    pub(crate) data_transfer_api: std::option::Option<crate::types::SalesforceDataTransferApi>,
}
impl SalesforceSourcePropertiesBuilder {
    /// <p> The object specified in the Salesforce flow source. </p>
    pub fn object(mut self, input: impl Into<std::string::String>) -> Self {
        self.object = Some(input.into());
        self
    }
    /// <p> The object specified in the Salesforce flow source. </p>
    pub fn set_object(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.object = input; self
    }
    /// <p> The flag that enables dynamic fetching of new (recently added) fields in the Salesforce objects while running a flow. </p>
    pub fn enable_dynamic_field_update(mut self, input: bool) -> Self {
        self.enable_dynamic_field_update = Some(input);
        self
    }
    /// <p> The flag that enables dynamic fetching of new (recently added) fields in the Salesforce objects while running a flow. </p>
    pub fn set_enable_dynamic_field_update(mut self, input: std::option::Option<bool>) -> Self {
        self.enable_dynamic_field_update = input; self
    }
    /// <p> Indicates whether Amazon AppFlow includes deleted files in the flow run. </p>
    pub fn include_deleted_records(mut self, input: bool) -> Self {
        self.include_deleted_records = Some(input);
        self
    }
    /// <p> Indicates whether Amazon AppFlow includes deleted files in the flow run. </p>
    pub fn set_include_deleted_records(mut self, input: std::option::Option<bool>) -> Self {
        self.include_deleted_records = input; self
    }
    /// <p>Specifies which Salesforce API is used by Amazon AppFlow when your flow transfers data from Salesforce.</p> 
    /// <dl> 
    /// <dt>
    /// AUTOMATIC
    /// </dt> 
    /// <dd> 
    /// <p>The default. Amazon AppFlow selects which API to use based on the number of records that your flow transfers from Salesforce. If your flow transfers fewer than 1,000,000 records, Amazon AppFlow uses Salesforce REST API. If your flow transfers 1,000,000 records or more, Amazon AppFlow uses Salesforce Bulk API 2.0.</p> 
    /// <p>Each of these Salesforce APIs structures data differently. If Amazon AppFlow selects the API automatically, be aware that, for recurring flows, the data output might vary from one flow run to the next. For example, if a flow runs daily, it might use REST API on one day to transfer 900,000 records, and it might use Bulk API 2.0 on the next day to transfer 1,100,000 records. For each of these flow runs, the respective Salesforce API formats the data differently. Some of the differences include how dates are formatted and null values are represented. Also, Bulk API 2.0 doesn't transfer Salesforce compound fields.</p> 
    /// <p>By choosing this option, you optimize flow performance for both small and large data transfers, but the tradeoff is inconsistent formatting in the output.</p> 
    /// </dd> 
    /// <dt>
    /// BULKV2
    /// </dt> 
    /// <dd> 
    /// <p>Amazon AppFlow uses only Salesforce Bulk API 2.0. This API runs asynchronous data transfers, and it's optimal for large sets of data. By choosing this option, you ensure that your flow writes consistent output, but you optimize performance only for large data transfers.</p> 
    /// <p>Note that Bulk API 2.0 does not transfer Salesforce compound fields.</p> 
    /// </dd> 
    /// <dt>
    /// REST_SYNC
    /// </dt> 
    /// <dd> 
    /// <p>Amazon AppFlow uses only Salesforce REST API. By choosing this option, you ensure that your flow writes consistent output, but you decrease performance for large data transfers that are better suited for Bulk API 2.0. In some cases, if your flow attempts to transfer a vary large set of data, it might fail wituh a timed out error.</p> 
    /// </dd> 
    /// </dl>
    pub fn data_transfer_api(mut self, input: crate::types::SalesforceDataTransferApi) -> Self {
        self.data_transfer_api = Some(input);
        self
    }
    /// <p>Specifies which Salesforce API is used by Amazon AppFlow when your flow transfers data from Salesforce.</p> 
    /// <dl> 
    /// <dt>
    /// AUTOMATIC
    /// </dt> 
    /// <dd> 
    /// <p>The default. Amazon AppFlow selects which API to use based on the number of records that your flow transfers from Salesforce. If your flow transfers fewer than 1,000,000 records, Amazon AppFlow uses Salesforce REST API. If your flow transfers 1,000,000 records or more, Amazon AppFlow uses Salesforce Bulk API 2.0.</p> 
    /// <p>Each of these Salesforce APIs structures data differently. If Amazon AppFlow selects the API automatically, be aware that, for recurring flows, the data output might vary from one flow run to the next. For example, if a flow runs daily, it might use REST API on one day to transfer 900,000 records, and it might use Bulk API 2.0 on the next day to transfer 1,100,000 records. For each of these flow runs, the respective Salesforce API formats the data differently. Some of the differences include how dates are formatted and null values are represented. Also, Bulk API 2.0 doesn't transfer Salesforce compound fields.</p> 
    /// <p>By choosing this option, you optimize flow performance for both small and large data transfers, but the tradeoff is inconsistent formatting in the output.</p> 
    /// </dd> 
    /// <dt>
    /// BULKV2
    /// </dt> 
    /// <dd> 
    /// <p>Amazon AppFlow uses only Salesforce Bulk API 2.0. This API runs asynchronous data transfers, and it's optimal for large sets of data. By choosing this option, you ensure that your flow writes consistent output, but you optimize performance only for large data transfers.</p> 
    /// <p>Note that Bulk API 2.0 does not transfer Salesforce compound fields.</p> 
    /// </dd> 
    /// <dt>
    /// REST_SYNC
    /// </dt> 
    /// <dd> 
    /// <p>Amazon AppFlow uses only Salesforce REST API. By choosing this option, you ensure that your flow writes consistent output, but you decrease performance for large data transfers that are better suited for Bulk API 2.0. In some cases, if your flow attempts to transfer a vary large set of data, it might fail wituh a timed out error.</p> 
    /// </dd> 
    /// </dl>
    pub fn set_data_transfer_api(mut self, input: std::option::Option<crate::types::SalesforceDataTransferApi>) -> Self {
        self.data_transfer_api = input; self
    }
    /// Consumes the builder and constructs a [`SalesforceSourceProperties`](crate::types::SalesforceSourceProperties).
    pub fn build(self) -> crate::types::SalesforceSourceProperties {
        crate::types::SalesforceSourceProperties {
            object: self.object
            ,
            enable_dynamic_field_update: self.enable_dynamic_field_update
                .unwrap_or_default()
            ,
            include_deleted_records: self.include_deleted_records
                .unwrap_or_default()
            ,
            data_transfer_api: self.data_transfer_api
            ,
        }
    }
}

