// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
pub use crate::operation::split_shard::_split_shard_output::SplitShardOutputBuilder;

pub use crate::operation::split_shard::_split_shard_input::SplitShardInputBuilder;

/// Fluent builder constructing a request to `SplitShard`.
/// 
/// <p>Splits a shard into two new shards in the Kinesis data stream, to increase the stream's capacity to ingest and transport data. <code>SplitShard</code> is called when there is a need to increase the overall capacity of a stream because of an expected increase in the volume of data records being ingested. This API is only supported for the data streams with the provisioned capacity mode.</p> <note> 
/// <p>When invoking this API, it is recommended you use the <code>StreamARN</code> input parameter rather than the <code>StreamName</code> input parameter.</p> 
/// </note> 
/// <p>You can also use <code>SplitShard</code> when a shard appears to be approaching its maximum utilization; for example, the producers sending data into the specific shard are suddenly sending more than previously anticipated. You can also call <code>SplitShard</code> to increase stream capacity, so that more Kinesis Data Streams applications can simultaneously read data from the stream for real-time processing. </p> 
/// <p>You must specify the shard to be split and the new hash key, which is the position in the shard where the shard gets split in two. In many cases, the new hash key might be the average of the beginning and ending hash key, but it can be any hash key value in the range being mapped into the shard. For more information, see <a href="https://docs.aws.amazon.com/kinesis/latest/dev/kinesis-using-sdk-java-resharding-split.html">Split a Shard</a> in the <i>Amazon Kinesis Data Streams Developer Guide</i>.</p> 
/// <p>You can use <code>DescribeStreamSummary</code> and the <code>ListShards</code> APIs to determine the shard ID and hash key values for the <code>ShardToSplit</code> and <code>NewStartingHashKey</code> parameters that are specified in the <code>SplitShard</code> request.</p> 
/// <p> <code>SplitShard</code> is an asynchronous operation. Upon receiving a <code>SplitShard</code> request, Kinesis Data Streams immediately returns a response and sets the stream status to <code>UPDATING</code>. After the operation is completed, Kinesis Data Streams sets the stream status to <code>ACTIVE</code>. Read and write operations continue to work while the stream is in the <code>UPDATING</code> state. </p> 
/// <p>You can use <code>DescribeStreamSummary</code> to check the status of the stream, which is returned in <code>StreamStatus</code>. If the stream is in the <code>ACTIVE</code> state, you can call <code>SplitShard</code>. </p> 
/// <p>If the specified stream does not exist, <code>DescribeStreamSummary</code> returns a <code>ResourceNotFoundException</code>. If you try to create more shards than are authorized for your account, you receive a <code>LimitExceededException</code>. </p> 
/// <p>For the default shard limit for an Amazon Web Services account, see <a href="https://docs.aws.amazon.com/kinesis/latest/dev/service-sizes-and-limits.html">Kinesis Data Streams Limits</a> in the <i>Amazon Kinesis Data Streams Developer Guide</i>. To increase this limit, <a href="https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html">contact Amazon Web Services Support</a>.</p> 
/// <p>If you try to operate on too many streams simultaneously using <code>CreateStream</code>, <code>DeleteStream</code>, <code>MergeShards</code>, and/or <code>SplitShard</code>, you receive a <code>LimitExceededException</code>. </p> 
/// <p> <code>SplitShard</code> has a limit of five transactions per second per account.</p>
#[derive(std::clone::Clone, std::fmt::Debug)]
pub struct SplitShardFluentBuilder {
                handle: std::sync::Arc<crate::client::Handle>,
                inner: crate::operation::split_shard::builders::SplitShardInputBuilder
            }
impl SplitShardFluentBuilder  {
    /// Creates a new `SplitShard`.
                    pub(crate) fn new(handle: std::sync::Arc<crate::client::Handle>) -> Self {
                        Self { handle, inner: Default::default() }
                    }
    
                    /// Consume this builder, creating a customizable operation that can be modified before being
                    /// sent. The operation's inner [http::Request] can be modified as well.
                    pub async fn customize(self) -> std::result::Result<
                        crate::client::customize::CustomizableOperation<crate::operation::split_shard::SplitShard, aws_http::retry::AwsResponseRetryClassifier,>,
                        aws_smithy_http::result::SdkError<crate::operation::split_shard::SplitShardError>
                    >  {
                        let handle = self.handle.clone();
                        let operation = self.inner.build().map_err(aws_smithy_http::result::SdkError::construction_failure)?
                            .make_operation(&handle.conf)
                            .await
                            .map_err(aws_smithy_http::result::SdkError::construction_failure)?;
                        Ok(crate::client::customize::CustomizableOperation { handle, operation })
                    }
    
                    /// Sends the request and returns the response.
                    ///
                    /// If an error occurs, an `SdkError` will be returned with additional details that
                    /// can be matched against.
                    ///
                    /// By default, any retryable failures will be retried twice. Retry behavior
                    /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
                    /// set when configuring the client.
                    pub async fn send(self) -> std::result::Result<crate::operation::split_shard::SplitShardOutput, aws_smithy_http::result::SdkError<crate::operation::split_shard::SplitShardError>>
                     {
                        let op = self.inner.build().map_err(aws_smithy_http::result::SdkError::construction_failure)?
                            .make_operation(&self.handle.conf)
                            .await
                            .map_err(aws_smithy_http::result::SdkError::construction_failure)?;
                        self.handle.client.call(op).await
                    }
    /// <p>The name of the stream for the shard split.</p>
    pub fn stream_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.stream_name(input.into());
        self
    }
    /// <p>The name of the stream for the shard split.</p>
    pub fn set_stream_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_stream_name(input);
        self
    }
    /// <p>The shard ID of the shard to split.</p>
    pub fn shard_to_split(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.shard_to_split(input.into());
        self
    }
    /// <p>The shard ID of the shard to split.</p>
    pub fn set_shard_to_split(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_shard_to_split(input);
        self
    }
    /// <p>A hash key value for the starting hash key of one of the child shards created by the split. The hash key range for a given shard constitutes a set of ordered contiguous positive integers. The value for <code>NewStartingHashKey</code> must be in the range of hash keys being mapped into the shard. The <code>NewStartingHashKey</code> hash key value and all higher hash key values in hash key range are distributed to one of the child shards. All the lower hash key values in the range are distributed to the other child shard.</p>
    pub fn new_starting_hash_key(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.new_starting_hash_key(input.into());
        self
    }
    /// <p>A hash key value for the starting hash key of one of the child shards created by the split. The hash key range for a given shard constitutes a set of ordered contiguous positive integers. The value for <code>NewStartingHashKey</code> must be in the range of hash keys being mapped into the shard. The <code>NewStartingHashKey</code> hash key value and all higher hash key values in hash key range are distributed to one of the child shards. All the lower hash key values in the range are distributed to the other child shard.</p>
    pub fn set_new_starting_hash_key(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_new_starting_hash_key(input);
        self
    }
    /// <p>The ARN of the stream.</p>
    pub fn stream_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.stream_arn(input.into());
        self
    }
    /// <p>The ARN of the stream.</p>
    pub fn set_stream_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_stream_arn(input);
        self
    }
}

