// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateAutoScalingConfigurationInput {
    /// <p>A name for the auto scaling configuration. When you use it for the first time in an Amazon Web Services Region, App Runner creates revision number <code>1</code> of this name. When you use the same name in subsequent calls, App Runner creates incremental revisions of the configuration.</p> <note>
    /// <p>The name <code>DefaultConfiguration</code> is reserved (it's the configuration that App Runner uses if you don't provide a custome one). You can't use it to create a new auto scaling configuration, and you can't create a revision of it.</p>
    /// <p>When you want to use your own auto scaling configuration for your App Runner service, <i>create a configuration with a different name</i>, and then provide it when you create or update your service.</p>
    /// </note>
    #[doc(hidden)]
    pub auto_scaling_configuration_name: std::option::Option<std::string::String>,
    /// <p>The maximum number of concurrent requests that you want an instance to process. If the number of concurrent requests exceeds this limit, App Runner scales up your service.</p>
    /// <p>Default: <code>100</code> </p>
    #[doc(hidden)]
    pub max_concurrency: std::option::Option<i32>,
    /// <p>The minimum number of instances that App Runner provisions for your service. The service always has at least <code>MinSize</code> provisioned instances. Some of them actively serve traffic. The rest of them (provisioned and inactive instances) are a cost-effective compute capacity reserve and are ready to be quickly activated. You pay for memory usage of all the provisioned instances. You pay for CPU usage of only the active subset.</p>
    /// <p>App Runner temporarily doubles the number of provisioned instances during deployments, to maintain the same capacity for both old and new code.</p>
    /// <p>Default: <code>1</code> </p>
    #[doc(hidden)]
    pub min_size: std::option::Option<i32>,
    /// <p>The maximum number of instances that your service scales up to. At most <code>MaxSize</code> instances actively serve traffic for your service.</p>
    /// <p>Default: <code>25</code> </p>
    #[doc(hidden)]
    pub max_size: std::option::Option<i32>,
    /// <p>A list of metadata items that you can associate with your auto scaling configuration resource. A tag is a key-value pair.</p>
    #[doc(hidden)]
    pub tags: std::option::Option<std::vec::Vec<crate::types::Tag>>,
}
impl CreateAutoScalingConfigurationInput {
    /// <p>A name for the auto scaling configuration. When you use it for the first time in an Amazon Web Services Region, App Runner creates revision number <code>1</code> of this name. When you use the same name in subsequent calls, App Runner creates incremental revisions of the configuration.</p> <note>
    /// <p>The name <code>DefaultConfiguration</code> is reserved (it's the configuration that App Runner uses if you don't provide a custome one). You can't use it to create a new auto scaling configuration, and you can't create a revision of it.</p>
    /// <p>When you want to use your own auto scaling configuration for your App Runner service, <i>create a configuration with a different name</i>, and then provide it when you create or update your service.</p>
    /// </note>
    pub fn auto_scaling_configuration_name(&self) -> std::option::Option<&str> {
        self.auto_scaling_configuration_name.as_deref()
    }
    /// <p>The maximum number of concurrent requests that you want an instance to process. If the number of concurrent requests exceeds this limit, App Runner scales up your service.</p>
    /// <p>Default: <code>100</code> </p>
    pub fn max_concurrency(&self) -> std::option::Option<i32> {
        self.max_concurrency
    }
    /// <p>The minimum number of instances that App Runner provisions for your service. The service always has at least <code>MinSize</code> provisioned instances. Some of them actively serve traffic. The rest of them (provisioned and inactive instances) are a cost-effective compute capacity reserve and are ready to be quickly activated. You pay for memory usage of all the provisioned instances. You pay for CPU usage of only the active subset.</p>
    /// <p>App Runner temporarily doubles the number of provisioned instances during deployments, to maintain the same capacity for both old and new code.</p>
    /// <p>Default: <code>1</code> </p>
    pub fn min_size(&self) -> std::option::Option<i32> {
        self.min_size
    }
    /// <p>The maximum number of instances that your service scales up to. At most <code>MaxSize</code> instances actively serve traffic for your service.</p>
    /// <p>Default: <code>25</code> </p>
    pub fn max_size(&self) -> std::option::Option<i32> {
        self.max_size
    }
    /// <p>A list of metadata items that you can associate with your auto scaling configuration resource. A tag is a key-value pair.</p>
    pub fn tags(&self) -> std::option::Option<&[crate::types::Tag]> {
        self.tags.as_deref()
    }
}
impl CreateAutoScalingConfigurationInput {
    /// Creates a new builder-style object to manufacture [`CreateAutoScalingConfigurationInput`](crate::operation::create_auto_scaling_configuration::CreateAutoScalingConfigurationInput).
    pub fn builder() -> crate::operation::create_auto_scaling_configuration::builders::CreateAutoScalingConfigurationInputBuilder{
        crate::operation::create_auto_scaling_configuration::builders::CreateAutoScalingConfigurationInputBuilder::default()
    }
}

/// A builder for [`CreateAutoScalingConfigurationInput`](crate::operation::create_auto_scaling_configuration::CreateAutoScalingConfigurationInput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct CreateAutoScalingConfigurationInputBuilder {
    pub(crate) auto_scaling_configuration_name: std::option::Option<std::string::String>,
    pub(crate) max_concurrency: std::option::Option<i32>,
    pub(crate) min_size: std::option::Option<i32>,
    pub(crate) max_size: std::option::Option<i32>,
    pub(crate) tags: std::option::Option<std::vec::Vec<crate::types::Tag>>,
}
impl CreateAutoScalingConfigurationInputBuilder {
    /// <p>A name for the auto scaling configuration. When you use it for the first time in an Amazon Web Services Region, App Runner creates revision number <code>1</code> of this name. When you use the same name in subsequent calls, App Runner creates incremental revisions of the configuration.</p> <note>
    /// <p>The name <code>DefaultConfiguration</code> is reserved (it's the configuration that App Runner uses if you don't provide a custome one). You can't use it to create a new auto scaling configuration, and you can't create a revision of it.</p>
    /// <p>When you want to use your own auto scaling configuration for your App Runner service, <i>create a configuration with a different name</i>, and then provide it when you create or update your service.</p>
    /// </note>
    pub fn auto_scaling_configuration_name(
        mut self,
        input: impl Into<std::string::String>,
    ) -> Self {
        self.auto_scaling_configuration_name = Some(input.into());
        self
    }
    /// <p>A name for the auto scaling configuration. When you use it for the first time in an Amazon Web Services Region, App Runner creates revision number <code>1</code> of this name. When you use the same name in subsequent calls, App Runner creates incremental revisions of the configuration.</p> <note>
    /// <p>The name <code>DefaultConfiguration</code> is reserved (it's the configuration that App Runner uses if you don't provide a custome one). You can't use it to create a new auto scaling configuration, and you can't create a revision of it.</p>
    /// <p>When you want to use your own auto scaling configuration for your App Runner service, <i>create a configuration with a different name</i>, and then provide it when you create or update your service.</p>
    /// </note>
    pub fn set_auto_scaling_configuration_name(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.auto_scaling_configuration_name = input;
        self
    }
    /// <p>The maximum number of concurrent requests that you want an instance to process. If the number of concurrent requests exceeds this limit, App Runner scales up your service.</p>
    /// <p>Default: <code>100</code> </p>
    pub fn max_concurrency(mut self, input: i32) -> Self {
        self.max_concurrency = Some(input);
        self
    }
    /// <p>The maximum number of concurrent requests that you want an instance to process. If the number of concurrent requests exceeds this limit, App Runner scales up your service.</p>
    /// <p>Default: <code>100</code> </p>
    pub fn set_max_concurrency(mut self, input: std::option::Option<i32>) -> Self {
        self.max_concurrency = input;
        self
    }
    /// <p>The minimum number of instances that App Runner provisions for your service. The service always has at least <code>MinSize</code> provisioned instances. Some of them actively serve traffic. The rest of them (provisioned and inactive instances) are a cost-effective compute capacity reserve and are ready to be quickly activated. You pay for memory usage of all the provisioned instances. You pay for CPU usage of only the active subset.</p>
    /// <p>App Runner temporarily doubles the number of provisioned instances during deployments, to maintain the same capacity for both old and new code.</p>
    /// <p>Default: <code>1</code> </p>
    pub fn min_size(mut self, input: i32) -> Self {
        self.min_size = Some(input);
        self
    }
    /// <p>The minimum number of instances that App Runner provisions for your service. The service always has at least <code>MinSize</code> provisioned instances. Some of them actively serve traffic. The rest of them (provisioned and inactive instances) are a cost-effective compute capacity reserve and are ready to be quickly activated. You pay for memory usage of all the provisioned instances. You pay for CPU usage of only the active subset.</p>
    /// <p>App Runner temporarily doubles the number of provisioned instances during deployments, to maintain the same capacity for both old and new code.</p>
    /// <p>Default: <code>1</code> </p>
    pub fn set_min_size(mut self, input: std::option::Option<i32>) -> Self {
        self.min_size = input;
        self
    }
    /// <p>The maximum number of instances that your service scales up to. At most <code>MaxSize</code> instances actively serve traffic for your service.</p>
    /// <p>Default: <code>25</code> </p>
    pub fn max_size(mut self, input: i32) -> Self {
        self.max_size = Some(input);
        self
    }
    /// <p>The maximum number of instances that your service scales up to. At most <code>MaxSize</code> instances actively serve traffic for your service.</p>
    /// <p>Default: <code>25</code> </p>
    pub fn set_max_size(mut self, input: std::option::Option<i32>) -> Self {
        self.max_size = input;
        self
    }
    /// Appends an item to `tags`.
    ///
    /// To override the contents of this collection use [`set_tags`](Self::set_tags).
    ///
    /// <p>A list of metadata items that you can associate with your auto scaling configuration resource. A tag is a key-value pair.</p>
    pub fn tags(mut self, input: crate::types::Tag) -> Self {
        let mut v = self.tags.unwrap_or_default();
        v.push(input);
        self.tags = Some(v);
        self
    }
    /// <p>A list of metadata items that you can associate with your auto scaling configuration resource. A tag is a key-value pair.</p>
    pub fn set_tags(
        mut self,
        input: std::option::Option<std::vec::Vec<crate::types::Tag>>,
    ) -> Self {
        self.tags = input;
        self
    }
    /// Consumes the builder and constructs a [`CreateAutoScalingConfigurationInput`](crate::operation::create_auto_scaling_configuration::CreateAutoScalingConfigurationInput).
    pub fn build(
        self,
    ) -> Result<
        crate::operation::create_auto_scaling_configuration::CreateAutoScalingConfigurationInput,
        aws_smithy_http::operation::error::BuildError,
    > {
        Ok(
            crate::operation::create_auto_scaling_configuration::CreateAutoScalingConfigurationInput {
                auto_scaling_configuration_name: self.auto_scaling_configuration_name
                ,
                max_concurrency: self.max_concurrency
                ,
                min_size: self.min_size
                ,
                max_size: self.max_size
                ,
                tags: self.tags
                ,
            }
        )
    }
}
