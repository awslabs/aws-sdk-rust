// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Describes an App Runner automatic scaling configuration resource.</p> 
/// <p>A higher <code>MinSize</code> increases the spread of your App Runner service over more Availability Zones in the Amazon Web Services Region. The tradeoff is a higher minimal cost.</p> 
/// <p>A lower <code>MaxSize</code> controls your cost. The tradeoff is lower responsiveness during peak demand.</p> 
/// <p>Multiple revisions of a configuration might have the same <code>AutoScalingConfigurationName</code> and different <code>AutoScalingConfigurationRevision</code> values.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct AutoScalingConfiguration  {
    /// <p>The Amazon Resource Name (ARN) of this auto scaling configuration.</p>
    #[doc(hidden)]
    pub auto_scaling_configuration_arn: std::option::Option<std::string::String>,
    /// <p>The customer-provided auto scaling configuration name. It can be used in multiple revisions of a configuration.</p>
    #[doc(hidden)]
    pub auto_scaling_configuration_name: std::option::Option<std::string::String>,
    /// <p>The revision of this auto scaling configuration. It's unique among all the active configurations (<code>"Status": "ACTIVE"</code>) that share the same <code>AutoScalingConfigurationName</code>.</p>
    #[doc(hidden)]
    pub auto_scaling_configuration_revision: i32,
    /// <p>It's set to <code>true</code> for the configuration with the highest <code>Revision</code> among all configurations that share the same <code>AutoScalingConfigurationName</code>. It's set to <code>false</code> otherwise.</p>
    #[doc(hidden)]
    pub latest: bool,
    /// <p>The current state of the auto scaling configuration. If the status of a configuration revision is <code>INACTIVE</code>, it was deleted and can't be used. Inactive configuration revisions are permanently removed some time after they are deleted.</p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::types::AutoScalingConfigurationStatus>,
    /// <p>The maximum number of concurrent requests that an instance processes. If the number of concurrent requests exceeds this limit, App Runner scales the service up.</p>
    #[doc(hidden)]
    pub max_concurrency: i32,
    /// <p>The minimum number of instances that App Runner provisions for a service. The service always has at least <code>MinSize</code> provisioned instances. Some of them actively serve traffic. The rest of them (provisioned and inactive instances) are a cost-effective compute capacity reserve and are ready to be quickly activated. You pay for memory usage of all the provisioned instances. You pay for CPU usage of only the active subset.</p> 
    /// <p>App Runner temporarily doubles the number of provisioned instances during deployments, to maintain the same capacity for both old and new code.</p>
    #[doc(hidden)]
    pub min_size: i32,
    /// <p>The maximum number of instances that a service scales up to. At most <code>MaxSize</code> instances actively serve traffic for your service.</p>
    #[doc(hidden)]
    pub max_size: i32,
    /// <p>The time when the auto scaling configuration was created. It's in Unix time stamp format.</p>
    #[doc(hidden)]
    pub created_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The time when the auto scaling configuration was deleted. It's in Unix time stamp format.</p>
    #[doc(hidden)]
    pub deleted_at: std::option::Option<aws_smithy_types::DateTime>,
}
impl AutoScalingConfiguration {
    /// <p>The Amazon Resource Name (ARN) of this auto scaling configuration.</p>
    pub fn auto_scaling_configuration_arn(&self) -> std::option::Option<& str> {
        self.auto_scaling_configuration_arn.as_deref()
    }
    /// <p>The customer-provided auto scaling configuration name. It can be used in multiple revisions of a configuration.</p>
    pub fn auto_scaling_configuration_name(&self) -> std::option::Option<& str> {
        self.auto_scaling_configuration_name.as_deref()
    }
    /// <p>The revision of this auto scaling configuration. It's unique among all the active configurations (<code>"Status": "ACTIVE"</code>) that share the same <code>AutoScalingConfigurationName</code>.</p>
    pub fn auto_scaling_configuration_revision(&self) -> i32 {
        self.auto_scaling_configuration_revision
    }
    /// <p>It's set to <code>true</code> for the configuration with the highest <code>Revision</code> among all configurations that share the same <code>AutoScalingConfigurationName</code>. It's set to <code>false</code> otherwise.</p>
    pub fn latest(&self) -> bool {
        self.latest
    }
    /// <p>The current state of the auto scaling configuration. If the status of a configuration revision is <code>INACTIVE</code>, it was deleted and can't be used. Inactive configuration revisions are permanently removed some time after they are deleted.</p>
    pub fn status(&self) -> std::option::Option<& crate::types::AutoScalingConfigurationStatus> {
        self.status.as_ref()
    }
    /// <p>The maximum number of concurrent requests that an instance processes. If the number of concurrent requests exceeds this limit, App Runner scales the service up.</p>
    pub fn max_concurrency(&self) -> i32 {
        self.max_concurrency
    }
    /// <p>The minimum number of instances that App Runner provisions for a service. The service always has at least <code>MinSize</code> provisioned instances. Some of them actively serve traffic. The rest of them (provisioned and inactive instances) are a cost-effective compute capacity reserve and are ready to be quickly activated. You pay for memory usage of all the provisioned instances. You pay for CPU usage of only the active subset.</p> 
    /// <p>App Runner temporarily doubles the number of provisioned instances during deployments, to maintain the same capacity for both old and new code.</p>
    pub fn min_size(&self) -> i32 {
        self.min_size
    }
    /// <p>The maximum number of instances that a service scales up to. At most <code>MaxSize</code> instances actively serve traffic for your service.</p>
    pub fn max_size(&self) -> i32 {
        self.max_size
    }
    /// <p>The time when the auto scaling configuration was created. It's in Unix time stamp format.</p>
    pub fn created_at(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.created_at.as_ref()
    }
    /// <p>The time when the auto scaling configuration was deleted. It's in Unix time stamp format.</p>
    pub fn deleted_at(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.deleted_at.as_ref()
    }
}
impl AutoScalingConfiguration {
    /// Creates a new builder-style object to manufacture [`AutoScalingConfiguration`](crate::types::AutoScalingConfiguration).
    pub fn builder() -> crate::types::builders::AutoScalingConfigurationBuilder {
        crate::types::builders::AutoScalingConfigurationBuilder::default()
    }
}

/// A builder for [`AutoScalingConfiguration`](crate::types::AutoScalingConfiguration).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct AutoScalingConfigurationBuilder {
    pub(crate) auto_scaling_configuration_arn: std::option::Option<std::string::String>,
    pub(crate) auto_scaling_configuration_name: std::option::Option<std::string::String>,
    pub(crate) auto_scaling_configuration_revision: std::option::Option<i32>,
    pub(crate) latest: std::option::Option<bool>,
    pub(crate) status: std::option::Option<crate::types::AutoScalingConfigurationStatus>,
    pub(crate) max_concurrency: std::option::Option<i32>,
    pub(crate) min_size: std::option::Option<i32>,
    pub(crate) max_size: std::option::Option<i32>,
    pub(crate) created_at: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) deleted_at: std::option::Option<aws_smithy_types::DateTime>,
}
impl AutoScalingConfigurationBuilder {
    /// <p>The Amazon Resource Name (ARN) of this auto scaling configuration.</p>
    pub fn auto_scaling_configuration_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.auto_scaling_configuration_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of this auto scaling configuration.</p>
    pub fn set_auto_scaling_configuration_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.auto_scaling_configuration_arn = input; self
    }
    /// <p>The customer-provided auto scaling configuration name. It can be used in multiple revisions of a configuration.</p>
    pub fn auto_scaling_configuration_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.auto_scaling_configuration_name = Some(input.into());
        self
    }
    /// <p>The customer-provided auto scaling configuration name. It can be used in multiple revisions of a configuration.</p>
    pub fn set_auto_scaling_configuration_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.auto_scaling_configuration_name = input; self
    }
    /// <p>The revision of this auto scaling configuration. It's unique among all the active configurations (<code>"Status": "ACTIVE"</code>) that share the same <code>AutoScalingConfigurationName</code>.</p>
    pub fn auto_scaling_configuration_revision(mut self, input: i32) -> Self {
        self.auto_scaling_configuration_revision = Some(input);
        self
    }
    /// <p>The revision of this auto scaling configuration. It's unique among all the active configurations (<code>"Status": "ACTIVE"</code>) that share the same <code>AutoScalingConfigurationName</code>.</p>
    pub fn set_auto_scaling_configuration_revision(mut self, input: std::option::Option<i32>) -> Self {
        self.auto_scaling_configuration_revision = input; self
    }
    /// <p>It's set to <code>true</code> for the configuration with the highest <code>Revision</code> among all configurations that share the same <code>AutoScalingConfigurationName</code>. It's set to <code>false</code> otherwise.</p>
    pub fn latest(mut self, input: bool) -> Self {
        self.latest = Some(input);
        self
    }
    /// <p>It's set to <code>true</code> for the configuration with the highest <code>Revision</code> among all configurations that share the same <code>AutoScalingConfigurationName</code>. It's set to <code>false</code> otherwise.</p>
    pub fn set_latest(mut self, input: std::option::Option<bool>) -> Self {
        self.latest = input; self
    }
    /// <p>The current state of the auto scaling configuration. If the status of a configuration revision is <code>INACTIVE</code>, it was deleted and can't be used. Inactive configuration revisions are permanently removed some time after they are deleted.</p>
    pub fn status(mut self, input: crate::types::AutoScalingConfigurationStatus) -> Self {
        self.status = Some(input);
        self
    }
    /// <p>The current state of the auto scaling configuration. If the status of a configuration revision is <code>INACTIVE</code>, it was deleted and can't be used. Inactive configuration revisions are permanently removed some time after they are deleted.</p>
    pub fn set_status(mut self, input: std::option::Option<crate::types::AutoScalingConfigurationStatus>) -> Self {
        self.status = input; self
    }
    /// <p>The maximum number of concurrent requests that an instance processes. If the number of concurrent requests exceeds this limit, App Runner scales the service up.</p>
    pub fn max_concurrency(mut self, input: i32) -> Self {
        self.max_concurrency = Some(input);
        self
    }
    /// <p>The maximum number of concurrent requests that an instance processes. If the number of concurrent requests exceeds this limit, App Runner scales the service up.</p>
    pub fn set_max_concurrency(mut self, input: std::option::Option<i32>) -> Self {
        self.max_concurrency = input; self
    }
    /// <p>The minimum number of instances that App Runner provisions for a service. The service always has at least <code>MinSize</code> provisioned instances. Some of them actively serve traffic. The rest of them (provisioned and inactive instances) are a cost-effective compute capacity reserve and are ready to be quickly activated. You pay for memory usage of all the provisioned instances. You pay for CPU usage of only the active subset.</p> 
    /// <p>App Runner temporarily doubles the number of provisioned instances during deployments, to maintain the same capacity for both old and new code.</p>
    pub fn min_size(mut self, input: i32) -> Self {
        self.min_size = Some(input);
        self
    }
    /// <p>The minimum number of instances that App Runner provisions for a service. The service always has at least <code>MinSize</code> provisioned instances. Some of them actively serve traffic. The rest of them (provisioned and inactive instances) are a cost-effective compute capacity reserve and are ready to be quickly activated. You pay for memory usage of all the provisioned instances. You pay for CPU usage of only the active subset.</p> 
    /// <p>App Runner temporarily doubles the number of provisioned instances during deployments, to maintain the same capacity for both old and new code.</p>
    pub fn set_min_size(mut self, input: std::option::Option<i32>) -> Self {
        self.min_size = input; self
    }
    /// <p>The maximum number of instances that a service scales up to. At most <code>MaxSize</code> instances actively serve traffic for your service.</p>
    pub fn max_size(mut self, input: i32) -> Self {
        self.max_size = Some(input);
        self
    }
    /// <p>The maximum number of instances that a service scales up to. At most <code>MaxSize</code> instances actively serve traffic for your service.</p>
    pub fn set_max_size(mut self, input: std::option::Option<i32>) -> Self {
        self.max_size = input; self
    }
    /// <p>The time when the auto scaling configuration was created. It's in Unix time stamp format.</p>
    pub fn created_at(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.created_at = Some(input);
        self
    }
    /// <p>The time when the auto scaling configuration was created. It's in Unix time stamp format.</p>
    pub fn set_created_at(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.created_at = input; self
    }
    /// <p>The time when the auto scaling configuration was deleted. It's in Unix time stamp format.</p>
    pub fn deleted_at(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.deleted_at = Some(input);
        self
    }
    /// <p>The time when the auto scaling configuration was deleted. It's in Unix time stamp format.</p>
    pub fn set_deleted_at(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.deleted_at = input; self
    }
    /// Consumes the builder and constructs a [`AutoScalingConfiguration`](crate::types::AutoScalingConfiguration).
    pub fn build(self) -> crate::types::AutoScalingConfiguration {
        crate::types::AutoScalingConfiguration {
            auto_scaling_configuration_arn: self.auto_scaling_configuration_arn
            ,
            auto_scaling_configuration_name: self.auto_scaling_configuration_name
            ,
            auto_scaling_configuration_revision: self.auto_scaling_configuration_revision
                .unwrap_or_default()
            ,
            latest: self.latest
                .unwrap_or_default()
            ,
            status: self.status
            ,
            max_concurrency: self.max_concurrency
                .unwrap_or_default()
            ,
            min_size: self.min_size
                .unwrap_or_default()
            ,
            max_size: self.max_size
                .unwrap_or_default()
            ,
            created_at: self.created_at
            ,
            deleted_at: self.deleted_at
            ,
        }
    }
}

