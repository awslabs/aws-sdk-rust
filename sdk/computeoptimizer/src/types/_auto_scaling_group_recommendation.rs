// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Describes an Auto Scaling group recommendation.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct AutoScalingGroupRecommendation  {
    /// <p>The Amazon Web Services account ID of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub account_id: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub auto_scaling_group_arn: std::option::Option<std::string::String>,
    /// <p>The name of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub auto_scaling_group_name: std::option::Option<std::string::String>,
    /// <p>The finding classification of the Auto Scaling group.</p> 
    /// <p>Findings for Auto Scaling groups include:</p> 
    /// <ul> 
    /// <li> <p> <b> <code>NotOptimized</code> </b>—An Auto Scaling group is considered not optimized when Compute Optimizer identifies a recommendation that can provide better performance for your workload.</p> </li> 
    /// <li> <p> <b> <code>Optimized</code> </b>—An Auto Scaling group is considered optimized when Compute Optimizer determines that the group is correctly provisioned to run your workload based on the chosen instance type. For optimized resources, Compute Optimizer might recommend a new generation instance type.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub finding: std::option::Option<crate::types::Finding>,
    /// <p>An array of objects that describe the utilization metrics of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub utilization_metrics: std::option::Option<std::vec::Vec<crate::types::UtilizationMetric>>,
    /// <p>The number of days for which utilization metrics were analyzed for the Auto Scaling group.</p>
    #[doc(hidden)]
    pub look_back_period_in_days: f64,
    /// <p>An array of objects that describe the current configuration of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub current_configuration: std::option::Option<crate::types::AutoScalingGroupConfiguration>,
    /// <p>An array of objects that describe the recommendation options for the Auto Scaling group.</p>
    #[doc(hidden)]
    pub recommendation_options: std::option::Option<std::vec::Vec<crate::types::AutoScalingGroupRecommendationOption>>,
    /// <p>The timestamp of when the Auto Scaling group recommendation was last generated.</p>
    #[doc(hidden)]
    pub last_refresh_timestamp: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The risk of the current Auto Scaling group not meeting the performance needs of its workloads. The higher the risk, the more likely the current Auto Scaling group configuration has insufficient capacity and cannot meet workload requirements.</p>
    #[doc(hidden)]
    pub current_performance_risk: std::option::Option<crate::types::CurrentPerformanceRisk>,
    /// <p>An object that describes the effective recommendation preferences for the Auto Scaling group.</p>
    #[doc(hidden)]
    pub effective_recommendation_preferences: std::option::Option<crate::types::EffectiveRecommendationPreferences>,
    /// <p>The applications that might be running on the instances in the Auto Scaling group as inferred by Compute Optimizer.</p> 
    /// <p>Compute Optimizer can infer if one of the following applications might be running on the instances:</p> 
    /// <ul> 
    /// <li> <p> <code>AmazonEmr</code> - Infers that Amazon EMR might be running on the instances.</p> </li> 
    /// <li> <p> <code>ApacheCassandra</code> - Infers that Apache Cassandra might be running on the instances.</p> </li> 
    /// <li> <p> <code>ApacheHadoop</code> - Infers that Apache Hadoop might be running on the instances.</p> </li> 
    /// <li> <p> <code>Memcached</code> - Infers that Memcached might be running on the instances.</p> </li> 
    /// <li> <p> <code>NGINX</code> - Infers that NGINX might be running on the instances.</p> </li> 
    /// <li> <p> <code>PostgreSql</code> - Infers that PostgreSQL might be running on the instances.</p> </li> 
    /// <li> <p> <code>Redis</code> - Infers that Redis might be running on the instances.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub inferred_workload_types: std::option::Option<std::vec::Vec<crate::types::InferredWorkloadType>>,
}
impl AutoScalingGroupRecommendation {
    /// <p>The Amazon Web Services account ID of the Auto Scaling group.</p>
    pub fn account_id(&self) -> std::option::Option<& str> {
        self.account_id.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
    pub fn auto_scaling_group_arn(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_arn.as_deref()
    }
    /// <p>The name of the Auto Scaling group.</p>
    pub fn auto_scaling_group_name(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_name.as_deref()
    }
    /// <p>The finding classification of the Auto Scaling group.</p> 
    /// <p>Findings for Auto Scaling groups include:</p> 
    /// <ul> 
    /// <li> <p> <b> <code>NotOptimized</code> </b>—An Auto Scaling group is considered not optimized when Compute Optimizer identifies a recommendation that can provide better performance for your workload.</p> </li> 
    /// <li> <p> <b> <code>Optimized</code> </b>—An Auto Scaling group is considered optimized when Compute Optimizer determines that the group is correctly provisioned to run your workload based on the chosen instance type. For optimized resources, Compute Optimizer might recommend a new generation instance type.</p> </li> 
    /// </ul>
    pub fn finding(&self) -> std::option::Option<& crate::types::Finding> {
        self.finding.as_ref()
    }
    /// <p>An array of objects that describe the utilization metrics of the Auto Scaling group.</p>
    pub fn utilization_metrics(&self) -> std::option::Option<& [crate::types::UtilizationMetric]> {
        self.utilization_metrics.as_deref()
    }
    /// <p>The number of days for which utilization metrics were analyzed for the Auto Scaling group.</p>
    pub fn look_back_period_in_days(&self) -> f64 {
        self.look_back_period_in_days
    }
    /// <p>An array of objects that describe the current configuration of the Auto Scaling group.</p>
    pub fn current_configuration(&self) -> std::option::Option<& crate::types::AutoScalingGroupConfiguration> {
        self.current_configuration.as_ref()
    }
    /// <p>An array of objects that describe the recommendation options for the Auto Scaling group.</p>
    pub fn recommendation_options(&self) -> std::option::Option<& [crate::types::AutoScalingGroupRecommendationOption]> {
        self.recommendation_options.as_deref()
    }
    /// <p>The timestamp of when the Auto Scaling group recommendation was last generated.</p>
    pub fn last_refresh_timestamp(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.last_refresh_timestamp.as_ref()
    }
    /// <p>The risk of the current Auto Scaling group not meeting the performance needs of its workloads. The higher the risk, the more likely the current Auto Scaling group configuration has insufficient capacity and cannot meet workload requirements.</p>
    pub fn current_performance_risk(&self) -> std::option::Option<& crate::types::CurrentPerformanceRisk> {
        self.current_performance_risk.as_ref()
    }
    /// <p>An object that describes the effective recommendation preferences for the Auto Scaling group.</p>
    pub fn effective_recommendation_preferences(&self) -> std::option::Option<& crate::types::EffectiveRecommendationPreferences> {
        self.effective_recommendation_preferences.as_ref()
    }
    /// <p>The applications that might be running on the instances in the Auto Scaling group as inferred by Compute Optimizer.</p> 
    /// <p>Compute Optimizer can infer if one of the following applications might be running on the instances:</p> 
    /// <ul> 
    /// <li> <p> <code>AmazonEmr</code> - Infers that Amazon EMR might be running on the instances.</p> </li> 
    /// <li> <p> <code>ApacheCassandra</code> - Infers that Apache Cassandra might be running on the instances.</p> </li> 
    /// <li> <p> <code>ApacheHadoop</code> - Infers that Apache Hadoop might be running on the instances.</p> </li> 
    /// <li> <p> <code>Memcached</code> - Infers that Memcached might be running on the instances.</p> </li> 
    /// <li> <p> <code>NGINX</code> - Infers that NGINX might be running on the instances.</p> </li> 
    /// <li> <p> <code>PostgreSql</code> - Infers that PostgreSQL might be running on the instances.</p> </li> 
    /// <li> <p> <code>Redis</code> - Infers that Redis might be running on the instances.</p> </li> 
    /// </ul>
    pub fn inferred_workload_types(&self) -> std::option::Option<& [crate::types::InferredWorkloadType]> {
        self.inferred_workload_types.as_deref()
    }
}
impl AutoScalingGroupRecommendation {
    /// Creates a new builder-style object to manufacture [`AutoScalingGroupRecommendation`](crate::types::AutoScalingGroupRecommendation).
    pub fn builder() -> crate::types::builders::AutoScalingGroupRecommendationBuilder {
        crate::types::builders::AutoScalingGroupRecommendationBuilder::default()
    }
}

/// A builder for [`AutoScalingGroupRecommendation`](crate::types::AutoScalingGroupRecommendation).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct AutoScalingGroupRecommendationBuilder {
    pub(crate) account_id: std::option::Option<std::string::String>,
    pub(crate) auto_scaling_group_arn: std::option::Option<std::string::String>,
    pub(crate) auto_scaling_group_name: std::option::Option<std::string::String>,
    pub(crate) finding: std::option::Option<crate::types::Finding>,
    pub(crate) utilization_metrics: std::option::Option<std::vec::Vec<crate::types::UtilizationMetric>>,
    pub(crate) look_back_period_in_days: std::option::Option<f64>,
    pub(crate) current_configuration: std::option::Option<crate::types::AutoScalingGroupConfiguration>,
    pub(crate) recommendation_options: std::option::Option<std::vec::Vec<crate::types::AutoScalingGroupRecommendationOption>>,
    pub(crate) last_refresh_timestamp: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) current_performance_risk: std::option::Option<crate::types::CurrentPerformanceRisk>,
    pub(crate) effective_recommendation_preferences: std::option::Option<crate::types::EffectiveRecommendationPreferences>,
    pub(crate) inferred_workload_types: std::option::Option<std::vec::Vec<crate::types::InferredWorkloadType>>,
}
impl AutoScalingGroupRecommendationBuilder {
    /// <p>The Amazon Web Services account ID of the Auto Scaling group.</p>
    pub fn account_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.account_id = Some(input.into());
        self
    }
    /// <p>The Amazon Web Services account ID of the Auto Scaling group.</p>
    pub fn set_account_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.account_id = input; self
    }
    /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
    pub fn auto_scaling_group_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.auto_scaling_group_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
    pub fn set_auto_scaling_group_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.auto_scaling_group_arn = input; self
    }
    /// <p>The name of the Auto Scaling group.</p>
    pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.auto_scaling_group_name = Some(input.into());
        self
    }
    /// <p>The name of the Auto Scaling group.</p>
    pub fn set_auto_scaling_group_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.auto_scaling_group_name = input; self
    }
    /// <p>The finding classification of the Auto Scaling group.</p> 
    /// <p>Findings for Auto Scaling groups include:</p> 
    /// <ul> 
    /// <li> <p> <b> <code>NotOptimized</code> </b>—An Auto Scaling group is considered not optimized when Compute Optimizer identifies a recommendation that can provide better performance for your workload.</p> </li> 
    /// <li> <p> <b> <code>Optimized</code> </b>—An Auto Scaling group is considered optimized when Compute Optimizer determines that the group is correctly provisioned to run your workload based on the chosen instance type. For optimized resources, Compute Optimizer might recommend a new generation instance type.</p> </li> 
    /// </ul>
    pub fn finding(mut self, input: crate::types::Finding) -> Self {
        self.finding = Some(input);
        self
    }
    /// <p>The finding classification of the Auto Scaling group.</p> 
    /// <p>Findings for Auto Scaling groups include:</p> 
    /// <ul> 
    /// <li> <p> <b> <code>NotOptimized</code> </b>—An Auto Scaling group is considered not optimized when Compute Optimizer identifies a recommendation that can provide better performance for your workload.</p> </li> 
    /// <li> <p> <b> <code>Optimized</code> </b>—An Auto Scaling group is considered optimized when Compute Optimizer determines that the group is correctly provisioned to run your workload based on the chosen instance type. For optimized resources, Compute Optimizer might recommend a new generation instance type.</p> </li> 
    /// </ul>
    pub fn set_finding(mut self, input: std::option::Option<crate::types::Finding>) -> Self {
        self.finding = input; self
    }
    /// Appends an item to `utilization_metrics`.
    ///
    /// To override the contents of this collection use [`set_utilization_metrics`](Self::set_utilization_metrics).
    ///
    /// <p>An array of objects that describe the utilization metrics of the Auto Scaling group.</p>
    pub fn utilization_metrics(mut self, input: crate::types::UtilizationMetric) -> Self {
        let mut v = self.utilization_metrics.unwrap_or_default();
                        v.push(input);
                        self.utilization_metrics = Some(v);
                        self
    }
    /// <p>An array of objects that describe the utilization metrics of the Auto Scaling group.</p>
    pub fn set_utilization_metrics(mut self, input: std::option::Option<std::vec::Vec<crate::types::UtilizationMetric>>) -> Self {
        self.utilization_metrics = input; self
    }
    /// <p>The number of days for which utilization metrics were analyzed for the Auto Scaling group.</p>
    pub fn look_back_period_in_days(mut self, input: f64) -> Self {
        self.look_back_period_in_days = Some(input);
        self
    }
    /// <p>The number of days for which utilization metrics were analyzed for the Auto Scaling group.</p>
    pub fn set_look_back_period_in_days(mut self, input: std::option::Option<f64>) -> Self {
        self.look_back_period_in_days = input; self
    }
    /// <p>An array of objects that describe the current configuration of the Auto Scaling group.</p>
    pub fn current_configuration(mut self, input: crate::types::AutoScalingGroupConfiguration) -> Self {
        self.current_configuration = Some(input);
        self
    }
    /// <p>An array of objects that describe the current configuration of the Auto Scaling group.</p>
    pub fn set_current_configuration(mut self, input: std::option::Option<crate::types::AutoScalingGroupConfiguration>) -> Self {
        self.current_configuration = input; self
    }
    /// Appends an item to `recommendation_options`.
    ///
    /// To override the contents of this collection use [`set_recommendation_options`](Self::set_recommendation_options).
    ///
    /// <p>An array of objects that describe the recommendation options for the Auto Scaling group.</p>
    pub fn recommendation_options(mut self, input: crate::types::AutoScalingGroupRecommendationOption) -> Self {
        let mut v = self.recommendation_options.unwrap_or_default();
                        v.push(input);
                        self.recommendation_options = Some(v);
                        self
    }
    /// <p>An array of objects that describe the recommendation options for the Auto Scaling group.</p>
    pub fn set_recommendation_options(mut self, input: std::option::Option<std::vec::Vec<crate::types::AutoScalingGroupRecommendationOption>>) -> Self {
        self.recommendation_options = input; self
    }
    /// <p>The timestamp of when the Auto Scaling group recommendation was last generated.</p>
    pub fn last_refresh_timestamp(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.last_refresh_timestamp = Some(input);
        self
    }
    /// <p>The timestamp of when the Auto Scaling group recommendation was last generated.</p>
    pub fn set_last_refresh_timestamp(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.last_refresh_timestamp = input; self
    }
    /// <p>The risk of the current Auto Scaling group not meeting the performance needs of its workloads. The higher the risk, the more likely the current Auto Scaling group configuration has insufficient capacity and cannot meet workload requirements.</p>
    pub fn current_performance_risk(mut self, input: crate::types::CurrentPerformanceRisk) -> Self {
        self.current_performance_risk = Some(input);
        self
    }
    /// <p>The risk of the current Auto Scaling group not meeting the performance needs of its workloads. The higher the risk, the more likely the current Auto Scaling group configuration has insufficient capacity and cannot meet workload requirements.</p>
    pub fn set_current_performance_risk(mut self, input: std::option::Option<crate::types::CurrentPerformanceRisk>) -> Self {
        self.current_performance_risk = input; self
    }
    /// <p>An object that describes the effective recommendation preferences for the Auto Scaling group.</p>
    pub fn effective_recommendation_preferences(mut self, input: crate::types::EffectiveRecommendationPreferences) -> Self {
        self.effective_recommendation_preferences = Some(input);
        self
    }
    /// <p>An object that describes the effective recommendation preferences for the Auto Scaling group.</p>
    pub fn set_effective_recommendation_preferences(mut self, input: std::option::Option<crate::types::EffectiveRecommendationPreferences>) -> Self {
        self.effective_recommendation_preferences = input; self
    }
    /// Appends an item to `inferred_workload_types`.
    ///
    /// To override the contents of this collection use [`set_inferred_workload_types`](Self::set_inferred_workload_types).
    ///
    /// <p>The applications that might be running on the instances in the Auto Scaling group as inferred by Compute Optimizer.</p> 
    /// <p>Compute Optimizer can infer if one of the following applications might be running on the instances:</p> 
    /// <ul> 
    /// <li> <p> <code>AmazonEmr</code> - Infers that Amazon EMR might be running on the instances.</p> </li> 
    /// <li> <p> <code>ApacheCassandra</code> - Infers that Apache Cassandra might be running on the instances.</p> </li> 
    /// <li> <p> <code>ApacheHadoop</code> - Infers that Apache Hadoop might be running on the instances.</p> </li> 
    /// <li> <p> <code>Memcached</code> - Infers that Memcached might be running on the instances.</p> </li> 
    /// <li> <p> <code>NGINX</code> - Infers that NGINX might be running on the instances.</p> </li> 
    /// <li> <p> <code>PostgreSql</code> - Infers that PostgreSQL might be running on the instances.</p> </li> 
    /// <li> <p> <code>Redis</code> - Infers that Redis might be running on the instances.</p> </li> 
    /// </ul>
    pub fn inferred_workload_types(mut self, input: crate::types::InferredWorkloadType) -> Self {
        let mut v = self.inferred_workload_types.unwrap_or_default();
                        v.push(input);
                        self.inferred_workload_types = Some(v);
                        self
    }
    /// <p>The applications that might be running on the instances in the Auto Scaling group as inferred by Compute Optimizer.</p> 
    /// <p>Compute Optimizer can infer if one of the following applications might be running on the instances:</p> 
    /// <ul> 
    /// <li> <p> <code>AmazonEmr</code> - Infers that Amazon EMR might be running on the instances.</p> </li> 
    /// <li> <p> <code>ApacheCassandra</code> - Infers that Apache Cassandra might be running on the instances.</p> </li> 
    /// <li> <p> <code>ApacheHadoop</code> - Infers that Apache Hadoop might be running on the instances.</p> </li> 
    /// <li> <p> <code>Memcached</code> - Infers that Memcached might be running on the instances.</p> </li> 
    /// <li> <p> <code>NGINX</code> - Infers that NGINX might be running on the instances.</p> </li> 
    /// <li> <p> <code>PostgreSql</code> - Infers that PostgreSQL might be running on the instances.</p> </li> 
    /// <li> <p> <code>Redis</code> - Infers that Redis might be running on the instances.</p> </li> 
    /// </ul>
    pub fn set_inferred_workload_types(mut self, input: std::option::Option<std::vec::Vec<crate::types::InferredWorkloadType>>) -> Self {
        self.inferred_workload_types = input; self
    }
    /// Consumes the builder and constructs a [`AutoScalingGroupRecommendation`](crate::types::AutoScalingGroupRecommendation).
    pub fn build(self) -> crate::types::AutoScalingGroupRecommendation {
        crate::types::AutoScalingGroupRecommendation {
            account_id: self.account_id
            ,
            auto_scaling_group_arn: self.auto_scaling_group_arn
            ,
            auto_scaling_group_name: self.auto_scaling_group_name
            ,
            finding: self.finding
            ,
            utilization_metrics: self.utilization_metrics
            ,
            look_back_period_in_days: self.look_back_period_in_days
                .unwrap_or_default()
            ,
            current_configuration: self.current_configuration
            ,
            recommendation_options: self.recommendation_options
            ,
            last_refresh_timestamp: self.last_refresh_timestamp
            ,
            current_performance_risk: self.current_performance_risk
            ,
            effective_recommendation_preferences: self.effective_recommendation_preferences
            ,
            inferred_workload_types: self.inferred_workload_types
            ,
        }
    }
}

