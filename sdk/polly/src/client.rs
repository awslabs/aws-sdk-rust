// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[derive(std::fmt::Debug)]
pub(crate) struct Handle<C = aws_hyper::DynConnector> {
    client: aws_hyper::Client<C>,
    conf: crate::Config,
}

#[derive(Clone, std::fmt::Debug)]
pub struct Client<C = aws_hyper::DynConnector> {
    handle: std::sync::Arc<Handle<C>>,
}
impl<C> Client<C> {
    pub fn from_conf_conn(conf: crate::Config, conn: C) -> Self {
        let client = aws_hyper::Client::new(conn);
        Self {
            handle: std::sync::Arc::new(Handle { client, conf }),
        }
    }

    pub fn conf(&self) -> &crate::Config {
        &self.handle.conf
    }
}
impl Client {
    #[cfg(any(feature = "rustls", feature = "native-tls"))]
    pub fn from_env() -> Self {
        Self::from_conf(crate::Config::builder().build())
    }

    #[cfg(any(feature = "rustls", feature = "native-tls"))]
    pub fn from_conf(conf: crate::Config) -> Self {
        let client = aws_hyper::Client::https();
        Self {
            handle: std::sync::Arc::new(Handle { client, conf }),
        }
    }
}
impl<C> Client<C>
where
    C: aws_hyper::SmithyConnector,
{
    pub fn delete_lexicon(&self) -> fluent_builders::DeleteLexicon<C> {
        fluent_builders::DeleteLexicon::new(self.handle.clone())
    }
    pub fn describe_voices(&self) -> fluent_builders::DescribeVoices<C> {
        fluent_builders::DescribeVoices::new(self.handle.clone())
    }
    pub fn get_lexicon(&self) -> fluent_builders::GetLexicon<C> {
        fluent_builders::GetLexicon::new(self.handle.clone())
    }
    pub fn get_speech_synthesis_task(&self) -> fluent_builders::GetSpeechSynthesisTask<C> {
        fluent_builders::GetSpeechSynthesisTask::new(self.handle.clone())
    }
    pub fn list_lexicons(&self) -> fluent_builders::ListLexicons<C> {
        fluent_builders::ListLexicons::new(self.handle.clone())
    }
    pub fn list_speech_synthesis_tasks(&self) -> fluent_builders::ListSpeechSynthesisTasks<C> {
        fluent_builders::ListSpeechSynthesisTasks::new(self.handle.clone())
    }
    pub fn put_lexicon(&self) -> fluent_builders::PutLexicon<C> {
        fluent_builders::PutLexicon::new(self.handle.clone())
    }
    pub fn start_speech_synthesis_task(&self) -> fluent_builders::StartSpeechSynthesisTask<C> {
        fluent_builders::StartSpeechSynthesisTask::new(self.handle.clone())
    }
    pub fn synthesize_speech(&self) -> fluent_builders::SynthesizeSpeech<C> {
        fluent_builders::SynthesizeSpeech::new(self.handle.clone())
    }
}
pub mod fluent_builders {
    #[derive(std::fmt::Debug)]
    pub struct DeleteLexicon<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::delete_lexicon_input::Builder,
    }
    impl<C> DeleteLexicon<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteLexiconOutput,
            smithy_http::result::SdkError<crate::error::DeleteLexiconError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the lexicon to delete. Must be an existing lexicon in the region.</p>
        pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.name(input);
            self
        }
        pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_name(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct DescribeVoices<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::describe_voices_input::Builder,
    }
    impl<C> DescribeVoices<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeVoicesOutput,
            smithy_http::result::SdkError<crate::error::DescribeVoicesError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>Specifies the engine (<code>standard</code> or <code>neural</code>) used by Amazon Polly
        /// when processing input text for speech synthesis. </p>
        pub fn engine(mut self, input: crate::model::Engine) -> Self {
            self.inner = self.inner.engine(input);
            self
        }
        pub fn set_engine(mut self, input: std::option::Option<crate::model::Engine>) -> Self {
            self.inner = self.inner.set_engine(input);
            self
        }
        /// <p> The language identification tag (ISO 639 code for the language name-ISO 3166 country
        /// code) for filtering the list of voices returned. If you don't specify this optional parameter,
        /// all available voices are returned. </p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.inner = self.inner.language_code(input);
            self
        }
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.inner = self.inner.set_language_code(input);
            self
        }
        /// <p>Boolean value indicating whether to return any bilingual voices that use the specified
        /// language as an additional language. For instance, if you request all languages that use US
        /// English (es-US), and there is an Italian voice that speaks both Italian (it-IT) and US
        /// English, that voice will be included if you specify <code>yes</code> but not if you specify
        /// <code>no</code>.</p>
        pub fn include_additional_language_codes(mut self, input: bool) -> Self {
            self.inner = self.inner.include_additional_language_codes(input);
            self
        }
        pub fn set_include_additional_language_codes(
            mut self,
            input: std::option::Option<bool>,
        ) -> Self {
            self.inner = self.inner.set_include_additional_language_codes(input);
            self
        }
        /// <p>An opaque pagination token returned from the previous <code>DescribeVoices</code>
        /// operation. If present, this indicates where to continue the listing.</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input);
            self
        }
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct GetLexicon<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::get_lexicon_input::Builder,
    }
    impl<C> GetLexicon<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::GetLexiconOutput,
            smithy_http::result::SdkError<crate::error::GetLexiconError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>Name of the lexicon.</p>
        pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.name(input);
            self
        }
        pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_name(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct GetSpeechSynthesisTask<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::get_speech_synthesis_task_input::Builder,
    }
    impl<C> GetSpeechSynthesisTask<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::GetSpeechSynthesisTaskOutput,
            smithy_http::result::SdkError<crate::error::GetSpeechSynthesisTaskError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The Amazon Polly generated identifier for a speech synthesis task.</p>
        pub fn task_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.task_id(input);
            self
        }
        pub fn set_task_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_task_id(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct ListLexicons<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::list_lexicons_input::Builder,
    }
    impl<C> ListLexicons<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListLexiconsOutput,
            smithy_http::result::SdkError<crate::error::ListLexiconsError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>An opaque pagination token returned from previous <code>ListLexicons</code> operation.
        /// If present, indicates where to continue the list of lexicons.</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input);
            self
        }
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct ListSpeechSynthesisTasks<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::list_speech_synthesis_tasks_input::Builder,
    }
    impl<C> ListSpeechSynthesisTasks<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListSpeechSynthesisTasksOutput,
            smithy_http::result::SdkError<crate::error::ListSpeechSynthesisTasksError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>Maximum number of speech synthesis tasks returned in a List operation.</p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.inner = self.inner.max_results(input);
            self
        }
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_results(input);
            self
        }
        /// <p>The pagination token to use in the next request to continue the listing of speech
        /// synthesis tasks. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input);
            self
        }
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>Status of the speech synthesis tasks returned in a List operation</p>
        pub fn status(mut self, input: crate::model::TaskStatus) -> Self {
            self.inner = self.inner.status(input);
            self
        }
        pub fn set_status(mut self, input: std::option::Option<crate::model::TaskStatus>) -> Self {
            self.inner = self.inner.set_status(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct PutLexicon<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::put_lexicon_input::Builder,
    }
    impl<C> PutLexicon<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::PutLexiconOutput,
            smithy_http::result::SdkError<crate::error::PutLexiconError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>Name of the lexicon. The name must follow the regular express format [0-9A-Za-z]{1,20}.
        /// That is, the name is a case-sensitive alphanumeric string up to 20 characters long. </p>
        pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.name(input);
            self
        }
        pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_name(input);
            self
        }
        /// <p>Content of the PLS lexicon as string data.</p>
        pub fn content(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.content(input);
            self
        }
        pub fn set_content(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_content(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct StartSpeechSynthesisTask<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::start_speech_synthesis_task_input::Builder,
    }
    impl<C> StartSpeechSynthesisTask<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::StartSpeechSynthesisTaskOutput,
            smithy_http::result::SdkError<crate::error::StartSpeechSynthesisTaskError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>Specifies the engine (<code>standard</code> or <code>neural</code>) for Amazon Polly to
        /// use when processing input text for speech synthesis. Using a voice that is not supported for
        /// the engine selected will result in an error.</p>
        pub fn engine(mut self, input: crate::model::Engine) -> Self {
            self.inner = self.inner.engine(input);
            self
        }
        pub fn set_engine(mut self, input: std::option::Option<crate::model::Engine>) -> Self {
            self.inner = self.inner.set_engine(input);
            self
        }
        /// <p>Optional language code for the Speech Synthesis request. This is only necessary if using a
        /// bilingual voice, such as Aditi, which can be used for either Indian English (en-IN) or Hindi
        /// (hi-IN). </p>
        /// <p>If a bilingual voice is used and no language code is specified, Amazon Polly will use the
        /// default language of the bilingual voice. The default language for any voice is the one
        /// returned by the <a href="https://docs.aws.amazon.com/polly/latest/dg/API_DescribeVoices.html">DescribeVoices</a> operation for the <code>LanguageCode</code> parameter. For example,
        /// if no language code is specified, Aditi will use Indian English rather than Hindi.</p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.inner = self.inner.language_code(input);
            self
        }
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.inner = self.inner.set_language_code(input);
            self
        }
        /// <p>List of one or more pronunciation lexicon names you want the service to apply during
        /// synthesis. Lexicons are applied only if the language of the lexicon is the same as the
        /// language of the voice. </p>
        pub fn lexicon_names(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.lexicon_names(inp);
            self
        }
        pub fn set_lexicon_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_lexicon_names(input);
            self
        }
        /// <p>The format in which the returned output will be encoded. For audio stream, this will be
        /// mp3, ogg_vorbis, or pcm. For speech marks, this will be json. </p>
        pub fn output_format(mut self, input: crate::model::OutputFormat) -> Self {
            self.inner = self.inner.output_format(input);
            self
        }
        pub fn set_output_format(
            mut self,
            input: std::option::Option<crate::model::OutputFormat>,
        ) -> Self {
            self.inner = self.inner.set_output_format(input);
            self
        }
        /// <p>Amazon S3 bucket name to which the output file will be saved.</p>
        pub fn output_s3_bucket_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.output_s3_bucket_name(input);
            self
        }
        pub fn set_output_s3_bucket_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_output_s3_bucket_name(input);
            self
        }
        /// <p>The Amazon S3 key prefix for the output speech file.</p>
        pub fn output_s3_key_prefix(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.output_s3_key_prefix(input);
            self
        }
        pub fn set_output_s3_key_prefix(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_output_s3_key_prefix(input);
            self
        }
        /// <p>The audio frequency specified in Hz.</p>
        /// <p>The valid values for mp3 and ogg_vorbis are "8000", "16000", "22050", and "24000". The
        /// default value for standard voices is "22050". The default value for neural voices is
        /// "24000".</p>
        /// <p>Valid values for pcm are "8000" and "16000" The default value is "16000". </p>
        pub fn sample_rate(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.sample_rate(input);
            self
        }
        pub fn set_sample_rate(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_sample_rate(input);
            self
        }
        /// <p>ARN for the SNS topic optionally used for providing status notification for a speech
        /// synthesis task.</p>
        pub fn sns_topic_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.sns_topic_arn(input);
            self
        }
        pub fn set_sns_topic_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_sns_topic_arn(input);
            self
        }
        /// <p>The type of speech marks returned for the input text.</p>
        pub fn speech_mark_types(mut self, inp: impl Into<crate::model::SpeechMarkType>) -> Self {
            self.inner = self.inner.speech_mark_types(inp);
            self
        }
        pub fn set_speech_mark_types(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::SpeechMarkType>>,
        ) -> Self {
            self.inner = self.inner.set_speech_mark_types(input);
            self
        }
        /// <p>The input text to synthesize. If you specify ssml as the TextType, follow the SSML format
        /// for the input text. </p>
        pub fn text(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.text(input);
            self
        }
        pub fn set_text(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_text(input);
            self
        }
        /// <p>Specifies whether the input text is plain text or SSML. The default value is plain text.
        /// </p>
        pub fn text_type(mut self, input: crate::model::TextType) -> Self {
            self.inner = self.inner.text_type(input);
            self
        }
        pub fn set_text_type(mut self, input: std::option::Option<crate::model::TextType>) -> Self {
            self.inner = self.inner.set_text_type(input);
            self
        }
        /// <p>Voice ID to use for the synthesis. </p>
        pub fn voice_id(mut self, input: crate::model::VoiceId) -> Self {
            self.inner = self.inner.voice_id(input);
            self
        }
        pub fn set_voice_id(mut self, input: std::option::Option<crate::model::VoiceId>) -> Self {
            self.inner = self.inner.set_voice_id(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct SynthesizeSpeech<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::synthesize_speech_input::Builder,
    }
    impl<C> SynthesizeSpeech<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::SynthesizeSpeechOutput,
            smithy_http::result::SdkError<crate::error::SynthesizeSpeechError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>Specifies the engine (<code>standard</code> or <code>neural</code>) for Amazon Polly to
        /// use when processing input text for speech synthesis. For information on Amazon Polly voices and which voices are available in standard-only, NTTS-only, and
        /// both standard and NTTS formats, see <a href="https://docs.aws.amazon.com/polly/latest/dg/voicelist.html">Available Voices</a>.</p>
        /// <p>
        /// <b>NTTS-only voices</b>
        /// </p>
        /// <p>When using NTTS-only voices such as Kevin (en-US), this parameter is required and must be
        /// set to <code>neural</code>. If the engine is not specified, or is set to <code>standard</code>,
        /// this will result in an error. </p>
        /// <p>Type: String</p>
        /// <p>Valid Values: <code>standard</code>  |  <code>neural</code>
        /// </p>
        /// <p>Required: Yes</p>
        /// <p>
        /// <b>Standard voices</b>
        /// </p>
        /// <p>For standard voices, this is not required; the engine parameter defaults to
        /// <code>standard</code>. If the engine is not specified, or is set to <code>standard</code> and
        /// an NTTS-only voice is selected, this will result in an error. </p>
        pub fn engine(mut self, input: crate::model::Engine) -> Self {
            self.inner = self.inner.engine(input);
            self
        }
        pub fn set_engine(mut self, input: std::option::Option<crate::model::Engine>) -> Self {
            self.inner = self.inner.set_engine(input);
            self
        }
        /// <p>Optional language code for the Synthesize Speech request. This is only necessary if using
        /// a bilingual voice, such as Aditi, which can be used for either Indian English (en-IN) or Hindi
        /// (hi-IN). </p>
        /// <p>If a bilingual voice is used and no language code is specified, Amazon Polly will use the
        /// default language of the bilingual voice. The default language for any voice is the one
        /// returned by the <a href="https://docs.aws.amazon.com/polly/latest/dg/API_DescribeVoices.html">DescribeVoices</a> operation for the <code>LanguageCode</code> parameter. For example,
        /// if no language code is specified, Aditi will use Indian English rather than Hindi.</p>
        pub fn language_code(mut self, input: crate::model::LanguageCode) -> Self {
            self.inner = self.inner.language_code(input);
            self
        }
        pub fn set_language_code(
            mut self,
            input: std::option::Option<crate::model::LanguageCode>,
        ) -> Self {
            self.inner = self.inner.set_language_code(input);
            self
        }
        /// <p>List of one or more pronunciation lexicon names you want the service to apply during
        /// synthesis. Lexicons are applied only if the language of the lexicon is the same as the
        /// language of the voice. For information about storing lexicons, see <a href="https://docs.aws.amazon.com/polly/latest/dg/API_PutLexicon.html">PutLexicon</a>.</p>
        pub fn lexicon_names(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.lexicon_names(inp);
            self
        }
        pub fn set_lexicon_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_lexicon_names(input);
            self
        }
        /// <p> The format in which the returned output will be encoded. For audio stream, this will
        /// be mp3, ogg_vorbis, or pcm. For speech marks, this will be json. </p>
        /// <p>When pcm is used, the content returned is audio/pcm in a signed 16-bit, 1 channel
        /// (mono), little-endian format. </p>
        pub fn output_format(mut self, input: crate::model::OutputFormat) -> Self {
            self.inner = self.inner.output_format(input);
            self
        }
        pub fn set_output_format(
            mut self,
            input: std::option::Option<crate::model::OutputFormat>,
        ) -> Self {
            self.inner = self.inner.set_output_format(input);
            self
        }
        /// <p>The audio frequency specified in Hz.</p>
        /// <p>The valid values for mp3 and ogg_vorbis are "8000", "16000", "22050", and "24000". The
        /// default value for standard voices is "22050". The default value for neural voices is
        /// "24000".</p>
        /// <p>Valid values for pcm are "8000" and "16000" The default value is "16000". </p>
        pub fn sample_rate(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.sample_rate(input);
            self
        }
        pub fn set_sample_rate(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_sample_rate(input);
            self
        }
        /// <p>The type of speech marks returned for the input text.</p>
        pub fn speech_mark_types(mut self, inp: impl Into<crate::model::SpeechMarkType>) -> Self {
            self.inner = self.inner.speech_mark_types(inp);
            self
        }
        pub fn set_speech_mark_types(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::SpeechMarkType>>,
        ) -> Self {
            self.inner = self.inner.set_speech_mark_types(input);
            self
        }
        /// <p> Input text to synthesize. If you specify <code>ssml</code> as the
        /// <code>TextType</code>, follow the SSML format for the input text. </p>
        pub fn text(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.text(input);
            self
        }
        pub fn set_text(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_text(input);
            self
        }
        /// <p> Specifies whether the input text is plain text or SSML. The default value is plain
        /// text. For more information, see <a href="https://docs.aws.amazon.com/polly/latest/dg/ssml.html">Using SSML</a>.</p>
        pub fn text_type(mut self, input: crate::model::TextType) -> Self {
            self.inner = self.inner.text_type(input);
            self
        }
        pub fn set_text_type(mut self, input: std::option::Option<crate::model::TextType>) -> Self {
            self.inner = self.inner.set_text_type(input);
            self
        }
        /// <p> Voice ID to use for the synthesis. You can get a list of available voice IDs by
        /// calling the <a href="https://docs.aws.amazon.com/polly/latest/dg/API_DescribeVoices.html">DescribeVoices</a> operation. </p>
        pub fn voice_id(mut self, input: crate::model::VoiceId) -> Self {
            self.inner = self.inner.voice_id(input);
            self
        }
        pub fn set_voice_id(mut self, input: std::option::Option<crate::model::VoiceId>) -> Self {
            self.inner = self.inner.set_voice_id(input);
            self
        }
    }
}
