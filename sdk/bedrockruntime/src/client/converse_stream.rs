// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`ConverseStream`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`model_id(impl Into<String>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::model_id) / [`set_model_id(Option<String>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_model_id):<br>required: **true**<br><p>Specifies the model or throughput with which to run inference, or the prompt resource to use in inference. The value depends on the resource that you use:</p> <ul>  <li>   <p>If you use a base model, specify the model ID or its ARN. For a list of model IDs for base models, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html#model-ids-arns">Amazon Bedrock base model IDs (on-demand throughput)</a> in the Amazon Bedrock User Guide.</p></li>  <li>   <p>If you use an inference profile, specify the inference profile ID or its ARN. For a list of inference profile IDs, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference-support.html">Supported Regions and models for cross-region inference</a> in the Amazon Bedrock User Guide.</p></li>  <li>   <p>If you use a provisioned model, specify the ARN of the Provisioned Throughput. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/prov-thru-use.html">Run inference using a Provisioned Throughput</a> in the Amazon Bedrock User Guide.</p></li>  <li>   <p>If you use a custom model, first purchase Provisioned Throughput for it. Then specify the ARN of the resulting provisioned model. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-use.html">Use a custom model in Amazon Bedrock</a> in the Amazon Bedrock User Guide.</p></li>  <li>   <p>To include a prompt that was defined in <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-management.html">Prompt management</a>, specify the ARN of the prompt version to use.</p></li> </ul> <p>The Converse API doesn't support <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html">imported models</a>.</p><br>
    ///   - [`messages(Message)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::messages) / [`set_messages(Option<Vec::<Message>>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_messages):<br>required: **false**<br><p>The messages that you want to send to the model.</p><br>
    ///   - [`system(SystemContentBlock)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::system) / [`set_system(Option<Vec::<SystemContentBlock>>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_system):<br>required: **false**<br><p>A prompt that provides instructions or context to the model about the task it should perform, or the persona it should adopt during the conversation.</p><br>
    ///   - [`inference_config(InferenceConfiguration)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::inference_config) / [`set_inference_config(Option<InferenceConfiguration>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_inference_config):<br>required: **false**<br><p>Inference parameters to pass to the model. <code>Converse</code> and <code>ConverseStream</code> support a base set of inference parameters. If you need to pass additional parameters that the model supports, use the <code>additionalModelRequestFields</code> request field.</p><br>
    ///   - [`tool_config(ToolConfiguration)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::tool_config) / [`set_tool_config(Option<ToolConfiguration>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_tool_config):<br>required: **false**<br><p>Configuration information for the tools that the model can use when generating a response.</p> <p>For information about models that support streaming tool use, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features">Supported models and model features</a>.</p><br>
    ///   - [`guardrail_config(GuardrailStreamConfiguration)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::guardrail_config) / [`set_guardrail_config(Option<GuardrailStreamConfiguration>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_guardrail_config):<br>required: **false**<br><p>Configuration information for a guardrail that you want to use in the request. If you include <code>guardContent</code> blocks in the <code>content</code> field in the <code>messages</code> field, the guardrail operates only on those messages. If you include no <code>guardContent</code> blocks, the guardrail operates on all messages in the request body and in any included prompt resource.</p><br>
    ///   - [`additional_model_request_fields(Document)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::additional_model_request_fields) / [`set_additional_model_request_fields(Option<Document>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_additional_model_request_fields):<br>required: **false**<br><p>Additional inference parameters that the model supports, beyond the base set of inference parameters that <code>Converse</code> and <code>ConverseStream</code> support in the <code>inferenceConfig</code> field. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Model parameters</a>.</p><br>
    ///   - [`prompt_variables(impl Into<String>, PromptVariableValues)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::prompt_variables) / [`set_prompt_variables(Option<HashMap::<String, PromptVariableValues>>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_prompt_variables):<br>required: **false**<br><p>Contains a map of variables in a prompt from Prompt management to objects containing the values to fill in for them when running model invocation. This field is ignored if you don't specify a prompt resource in the <code>modelId</code> field.</p><br>
    ///   - [`additional_model_response_field_paths(impl Into<String>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::additional_model_response_field_paths) / [`set_additional_model_response_field_paths(Option<Vec::<String>>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_additional_model_response_field_paths):<br>required: **false**<br><p>Additional model parameters field paths to return in the response. <code>Converse</code> and <code>ConverseStream</code> return the requested fields as a JSON Pointer object in the <code>additionalModelResponseFields</code> field. The following is example JSON for <code>additionalModelResponseFieldPaths</code>.</p> <p><code>\[ "/stop_sequence" \]</code></p> <p>For information about the JSON Pointer syntax, see the <a href="https://datatracker.ietf.org/doc/html/rfc6901">Internet Engineering Task Force (IETF)</a> documentation.</p> <p><code>Converse</code> and <code>ConverseStream</code> reject an empty JSON Pointer or incorrectly structured JSON Pointer with a <code>400</code> error code. if the JSON Pointer is valid, but the requested field is not in the model response, it is ignored by <code>Converse</code>.</p><br>
    ///   - [`request_metadata(impl Into<String>, impl Into<String>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::request_metadata) / [`set_request_metadata(Option<HashMap::<String, String>>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_request_metadata):<br>required: **false**<br><p>Key-value pairs that you can use to filter invocation logs.</p><br>
    ///   - [`performance_config(PerformanceConfiguration)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::performance_config) / [`set_performance_config(Option<PerformanceConfiguration>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_performance_config):<br>required: **false**<br><p>Model performance settings for the request.</p><br>
    ///   - [`service_tier(ServiceTier)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::service_tier) / [`set_service_tier(Option<ServiceTier>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_service_tier):<br>required: **false**<br><p>Specifies the processing tier configuration used for serving the request.</p><br>
    ///   - [`output_config(OutputConfig)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::output_config) / [`set_output_config(Option<OutputConfig>)`](crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::set_output_config):<br>required: **false**<br><p>Output configuration for a model response.</p><br>
    /// - On success, responds with [`ConverseStreamOutput`](crate::operation::converse_stream::ConverseStreamOutput) with field(s):
    ///   - [`stream(EventReceiver<ConverseStreamOutput, ConverseStreamOutputError>)`](crate::operation::converse_stream::ConverseStreamOutput::stream): <p>The output stream that the model generated.</p>
    /// - On failure, responds with [`SdkError<ConverseStreamError>`](crate::operation::converse_stream::ConverseStreamError)
    pub fn converse_stream(&self) -> crate::operation::converse_stream::builders::ConverseStreamFluentBuilder {
        crate::operation::converse_stream::builders::ConverseStreamFluentBuilder::new(self.handle.clone())
    }
}
