// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct StartMlDataProcessingJobInput  {
    /// <p>A unique identifier for the new job. The default is an autogenerated UUID.</p>
    pub id: ::std::option::Option<::std::string::String>,
    /// <p>The job ID of a completed data processing job run on an earlier version of the data.</p>
    pub previous_data_processing_job_id: ::std::option::Option<::std::string::String>,
    /// <p>The URI of the Amazon S3 location where you want SageMaker to download the data needed to run the data processing job.</p>
    pub input_data_s3_location: ::std::option::Option<::std::string::String>,
    /// <p>The URI of the Amazon S3 location where you want SageMaker to save the results of a data processing job.</p>
    pub processed_data_s3_location: ::std::option::Option<::std::string::String>,
    /// <p>The ARN of an IAM role for SageMaker execution. This must be listed in your DB cluster parameter group or an error will occur.</p>
    pub sagemaker_iam_role_arn: ::std::option::Option<::std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of an IAM role that SageMaker can assume to perform tasks on your behalf. This must be listed in your DB cluster parameter group or an error will occur.</p>
    pub neptune_iam_role_arn: ::std::option::Option<::std::string::String>,
    /// <p>The type of ML instance used during data processing. Its memory should be large enough to hold the processed dataset. The default is the smallest ml.r5 type whose memory is ten times larger than the size of the exported graph data on disk.</p>
    pub processing_instance_type: ::std::option::Option<::std::string::String>,
    /// <p>The disk volume size of the processing instance. Both input data and processed data are stored on disk, so the volume size must be large enough to hold both data sets. The default is 0. If not specified or 0, Neptune ML chooses the volume size automatically based on the data size.</p>
    pub processing_instance_volume_size_in_gb: ::std::option::Option<i32>,
    /// <p>Timeout in seconds for the data processing job. The default is 86,400 (1 day).</p>
    pub processing_time_out_in_seconds: ::std::option::Option<i32>,
    /// <p>One of the two model types that Neptune ML currently supports: heterogeneous graph models (<code>heterogeneous</code>), and knowledge graph (<code>kge</code>). The default is none. If not specified, Neptune ML chooses the model type automatically based on the data.</p>
    pub model_type: ::std::option::Option<::std::string::String>,
    /// <p>A data specification file that describes how to load the exported graph data for training. The file is automatically generated by the Neptune export toolkit. The default is <code>training-data-configuration.json</code>.</p>
    pub config_file_name: ::std::option::Option<::std::string::String>,
    /// <p>The IDs of the subnets in the Neptune VPC. The default is None.</p>
    pub subnets: ::std::option::Option<::std::vec::Vec::<::std::string::String>>,
    /// <p>The VPC security group IDs. The default is None.</p>
    pub security_group_ids: ::std::option::Option<::std::vec::Vec::<::std::string::String>>,
    /// <p>The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instances that run the training job. The default is None.</p>
    pub volume_encryption_kms_key: ::std::option::Option<::std::string::String>,
    /// <p>The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt the output of the processing job. The default is none.</p>
    pub s3_output_encryption_kms_key: ::std::option::Option<::std::string::String>,
}
impl  StartMlDataProcessingJobInput  {
    /// <p>A unique identifier for the new job. The default is an autogenerated UUID.</p>
    pub fn id(&self) -> ::std::option::Option<& str> {
        self.id.as_deref()
    }
    /// <p>The job ID of a completed data processing job run on an earlier version of the data.</p>
    pub fn previous_data_processing_job_id(&self) -> ::std::option::Option<& str> {
        self.previous_data_processing_job_id.as_deref()
    }
    /// <p>The URI of the Amazon S3 location where you want SageMaker to download the data needed to run the data processing job.</p>
    pub fn input_data_s3_location(&self) -> ::std::option::Option<& str> {
        self.input_data_s3_location.as_deref()
    }
    /// <p>The URI of the Amazon S3 location where you want SageMaker to save the results of a data processing job.</p>
    pub fn processed_data_s3_location(&self) -> ::std::option::Option<& str> {
        self.processed_data_s3_location.as_deref()
    }
    /// <p>The ARN of an IAM role for SageMaker execution. This must be listed in your DB cluster parameter group or an error will occur.</p>
    pub fn sagemaker_iam_role_arn(&self) -> ::std::option::Option<& str> {
        self.sagemaker_iam_role_arn.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role that SageMaker can assume to perform tasks on your behalf. This must be listed in your DB cluster parameter group or an error will occur.</p>
    pub fn neptune_iam_role_arn(&self) -> ::std::option::Option<& str> {
        self.neptune_iam_role_arn.as_deref()
    }
    /// <p>The type of ML instance used during data processing. Its memory should be large enough to hold the processed dataset. The default is the smallest ml.r5 type whose memory is ten times larger than the size of the exported graph data on disk.</p>
    pub fn processing_instance_type(&self) -> ::std::option::Option<& str> {
        self.processing_instance_type.as_deref()
    }
    /// <p>The disk volume size of the processing instance. Both input data and processed data are stored on disk, so the volume size must be large enough to hold both data sets. The default is 0. If not specified or 0, Neptune ML chooses the volume size automatically based on the data size.</p>
    pub fn processing_instance_volume_size_in_gb(&self) -> ::std::option::Option<i32> {
        self.processing_instance_volume_size_in_gb
    }
    /// <p>Timeout in seconds for the data processing job. The default is 86,400 (1 day).</p>
    pub fn processing_time_out_in_seconds(&self) -> ::std::option::Option<i32> {
        self.processing_time_out_in_seconds
    }
    /// <p>One of the two model types that Neptune ML currently supports: heterogeneous graph models (<code>heterogeneous</code>), and knowledge graph (<code>kge</code>). The default is none. If not specified, Neptune ML chooses the model type automatically based on the data.</p>
    pub fn model_type(&self) -> ::std::option::Option<& str> {
        self.model_type.as_deref()
    }
    /// <p>A data specification file that describes how to load the exported graph data for training. The file is automatically generated by the Neptune export toolkit. The default is <code>training-data-configuration.json</code>.</p>
    pub fn config_file_name(&self) -> ::std::option::Option<& str> {
        self.config_file_name.as_deref()
    }
    /// <p>The IDs of the subnets in the Neptune VPC. The default is None.</p>
    /// 
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.subnets.is_none()`.
    pub fn subnets(&self) -> & [::std::string::String] {
        self.subnets.as_deref()
        .unwrap_or_default()
    }
    /// <p>The VPC security group IDs. The default is None.</p>
    /// 
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.security_group_ids.is_none()`.
    pub fn security_group_ids(&self) -> & [::std::string::String] {
        self.security_group_ids.as_deref()
        .unwrap_or_default()
    }
    /// <p>The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instances that run the training job. The default is None.</p>
    pub fn volume_encryption_kms_key(&self) -> ::std::option::Option<& str> {
        self.volume_encryption_kms_key.as_deref()
    }
    /// <p>The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt the output of the processing job. The default is none.</p>
    pub fn s3_output_encryption_kms_key(&self) -> ::std::option::Option<& str> {
        self.s3_output_encryption_kms_key.as_deref()
    }
}
impl StartMlDataProcessingJobInput {
    /// Creates a new builder-style object to manufacture [`StartMlDataProcessingJobInput`](crate::operation::start_ml_data_processing_job::StartMlDataProcessingJobInput).
    pub fn builder() -> crate::operation::start_ml_data_processing_job::builders::StartMlDataProcessingJobInputBuilder {
        crate::operation::start_ml_data_processing_job::builders::StartMlDataProcessingJobInputBuilder::default()
    }
}

/// A builder for [`StartMlDataProcessingJobInput`](crate::operation::start_ml_data_processing_job::StartMlDataProcessingJobInput).
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
pub struct StartMlDataProcessingJobInputBuilder {
    pub(crate) id: ::std::option::Option<::std::string::String>,
    pub(crate) previous_data_processing_job_id: ::std::option::Option<::std::string::String>,
    pub(crate) input_data_s3_location: ::std::option::Option<::std::string::String>,
    pub(crate) processed_data_s3_location: ::std::option::Option<::std::string::String>,
    pub(crate) sagemaker_iam_role_arn: ::std::option::Option<::std::string::String>,
    pub(crate) neptune_iam_role_arn: ::std::option::Option<::std::string::String>,
    pub(crate) processing_instance_type: ::std::option::Option<::std::string::String>,
    pub(crate) processing_instance_volume_size_in_gb: ::std::option::Option<i32>,
    pub(crate) processing_time_out_in_seconds: ::std::option::Option<i32>,
    pub(crate) model_type: ::std::option::Option<::std::string::String>,
    pub(crate) config_file_name: ::std::option::Option<::std::string::String>,
    pub(crate) subnets: ::std::option::Option<::std::vec::Vec::<::std::string::String>>,
    pub(crate) security_group_ids: ::std::option::Option<::std::vec::Vec::<::std::string::String>>,
    pub(crate) volume_encryption_kms_key: ::std::option::Option<::std::string::String>,
    pub(crate) s3_output_encryption_kms_key: ::std::option::Option<::std::string::String>,
}
impl StartMlDataProcessingJobInputBuilder {
    /// <p>A unique identifier for the new job. The default is an autogenerated UUID.</p>
    pub fn id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>A unique identifier for the new job. The default is an autogenerated UUID.</p>
    pub fn set_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.id = input; self
    }
    /// <p>A unique identifier for the new job. The default is an autogenerated UUID.</p>
    pub fn get_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.id
    }
    /// <p>The job ID of a completed data processing job run on an earlier version of the data.</p>
    pub fn previous_data_processing_job_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.previous_data_processing_job_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The job ID of a completed data processing job run on an earlier version of the data.</p>
    pub fn set_previous_data_processing_job_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.previous_data_processing_job_id = input; self
    }
    /// <p>The job ID of a completed data processing job run on an earlier version of the data.</p>
    pub fn get_previous_data_processing_job_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.previous_data_processing_job_id
    }
    /// <p>The URI of the Amazon S3 location where you want SageMaker to download the data needed to run the data processing job.</p>
    /// This field is required.
    pub fn input_data_s3_location(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.input_data_s3_location = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The URI of the Amazon S3 location where you want SageMaker to download the data needed to run the data processing job.</p>
    pub fn set_input_data_s3_location(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.input_data_s3_location = input; self
    }
    /// <p>The URI of the Amazon S3 location where you want SageMaker to download the data needed to run the data processing job.</p>
    pub fn get_input_data_s3_location(&self) -> &::std::option::Option<::std::string::String> {
        &self.input_data_s3_location
    }
    /// <p>The URI of the Amazon S3 location where you want SageMaker to save the results of a data processing job.</p>
    /// This field is required.
    pub fn processed_data_s3_location(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.processed_data_s3_location = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The URI of the Amazon S3 location where you want SageMaker to save the results of a data processing job.</p>
    pub fn set_processed_data_s3_location(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.processed_data_s3_location = input; self
    }
    /// <p>The URI of the Amazon S3 location where you want SageMaker to save the results of a data processing job.</p>
    pub fn get_processed_data_s3_location(&self) -> &::std::option::Option<::std::string::String> {
        &self.processed_data_s3_location
    }
    /// <p>The ARN of an IAM role for SageMaker execution. This must be listed in your DB cluster parameter group or an error will occur.</p>
    pub fn sagemaker_iam_role_arn(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.sagemaker_iam_role_arn = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The ARN of an IAM role for SageMaker execution. This must be listed in your DB cluster parameter group or an error will occur.</p>
    pub fn set_sagemaker_iam_role_arn(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.sagemaker_iam_role_arn = input; self
    }
    /// <p>The ARN of an IAM role for SageMaker execution. This must be listed in your DB cluster parameter group or an error will occur.</p>
    pub fn get_sagemaker_iam_role_arn(&self) -> &::std::option::Option<::std::string::String> {
        &self.sagemaker_iam_role_arn
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role that SageMaker can assume to perform tasks on your behalf. This must be listed in your DB cluster parameter group or an error will occur.</p>
    pub fn neptune_iam_role_arn(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.neptune_iam_role_arn = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role that SageMaker can assume to perform tasks on your behalf. This must be listed in your DB cluster parameter group or an error will occur.</p>
    pub fn set_neptune_iam_role_arn(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.neptune_iam_role_arn = input; self
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role that SageMaker can assume to perform tasks on your behalf. This must be listed in your DB cluster parameter group or an error will occur.</p>
    pub fn get_neptune_iam_role_arn(&self) -> &::std::option::Option<::std::string::String> {
        &self.neptune_iam_role_arn
    }
    /// <p>The type of ML instance used during data processing. Its memory should be large enough to hold the processed dataset. The default is the smallest ml.r5 type whose memory is ten times larger than the size of the exported graph data on disk.</p>
    pub fn processing_instance_type(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.processing_instance_type = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The type of ML instance used during data processing. Its memory should be large enough to hold the processed dataset. The default is the smallest ml.r5 type whose memory is ten times larger than the size of the exported graph data on disk.</p>
    pub fn set_processing_instance_type(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.processing_instance_type = input; self
    }
    /// <p>The type of ML instance used during data processing. Its memory should be large enough to hold the processed dataset. The default is the smallest ml.r5 type whose memory is ten times larger than the size of the exported graph data on disk.</p>
    pub fn get_processing_instance_type(&self) -> &::std::option::Option<::std::string::String> {
        &self.processing_instance_type
    }
    /// <p>The disk volume size of the processing instance. Both input data and processed data are stored on disk, so the volume size must be large enough to hold both data sets. The default is 0. If not specified or 0, Neptune ML chooses the volume size automatically based on the data size.</p>
    pub fn processing_instance_volume_size_in_gb(mut self, input: i32) -> Self {
        self.processing_instance_volume_size_in_gb = ::std::option::Option::Some(input);
        self
    }
    /// <p>The disk volume size of the processing instance. Both input data and processed data are stored on disk, so the volume size must be large enough to hold both data sets. The default is 0. If not specified or 0, Neptune ML chooses the volume size automatically based on the data size.</p>
    pub fn set_processing_instance_volume_size_in_gb(mut self, input: ::std::option::Option<i32>) -> Self {
        self.processing_instance_volume_size_in_gb = input; self
    }
    /// <p>The disk volume size of the processing instance. Both input data and processed data are stored on disk, so the volume size must be large enough to hold both data sets. The default is 0. If not specified or 0, Neptune ML chooses the volume size automatically based on the data size.</p>
    pub fn get_processing_instance_volume_size_in_gb(&self) -> &::std::option::Option<i32> {
        &self.processing_instance_volume_size_in_gb
    }
    /// <p>Timeout in seconds for the data processing job. The default is 86,400 (1 day).</p>
    pub fn processing_time_out_in_seconds(mut self, input: i32) -> Self {
        self.processing_time_out_in_seconds = ::std::option::Option::Some(input);
        self
    }
    /// <p>Timeout in seconds for the data processing job. The default is 86,400 (1 day).</p>
    pub fn set_processing_time_out_in_seconds(mut self, input: ::std::option::Option<i32>) -> Self {
        self.processing_time_out_in_seconds = input; self
    }
    /// <p>Timeout in seconds for the data processing job. The default is 86,400 (1 day).</p>
    pub fn get_processing_time_out_in_seconds(&self) -> &::std::option::Option<i32> {
        &self.processing_time_out_in_seconds
    }
    /// <p>One of the two model types that Neptune ML currently supports: heterogeneous graph models (<code>heterogeneous</code>), and knowledge graph (<code>kge</code>). The default is none. If not specified, Neptune ML chooses the model type automatically based on the data.</p>
    pub fn model_type(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.model_type = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>One of the two model types that Neptune ML currently supports: heterogeneous graph models (<code>heterogeneous</code>), and knowledge graph (<code>kge</code>). The default is none. If not specified, Neptune ML chooses the model type automatically based on the data.</p>
    pub fn set_model_type(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.model_type = input; self
    }
    /// <p>One of the two model types that Neptune ML currently supports: heterogeneous graph models (<code>heterogeneous</code>), and knowledge graph (<code>kge</code>). The default is none. If not specified, Neptune ML chooses the model type automatically based on the data.</p>
    pub fn get_model_type(&self) -> &::std::option::Option<::std::string::String> {
        &self.model_type
    }
    /// <p>A data specification file that describes how to load the exported graph data for training. The file is automatically generated by the Neptune export toolkit. The default is <code>training-data-configuration.json</code>.</p>
    pub fn config_file_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.config_file_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>A data specification file that describes how to load the exported graph data for training. The file is automatically generated by the Neptune export toolkit. The default is <code>training-data-configuration.json</code>.</p>
    pub fn set_config_file_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.config_file_name = input; self
    }
    /// <p>A data specification file that describes how to load the exported graph data for training. The file is automatically generated by the Neptune export toolkit. The default is <code>training-data-configuration.json</code>.</p>
    pub fn get_config_file_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.config_file_name
    }
    /// Appends an item to `subnets`.
    ///
    /// To override the contents of this collection use [`set_subnets`](Self::set_subnets).
    ///
    /// <p>The IDs of the subnets in the Neptune VPC. The default is None.</p>
    pub fn subnets(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        let mut v = self.subnets.unwrap_or_default();
                        v.push(input.into());
                        self.subnets = ::std::option::Option::Some(v);
                        self
    }
    /// <p>The IDs of the subnets in the Neptune VPC. The default is None.</p>
    pub fn set_subnets(mut self, input: ::std::option::Option<::std::vec::Vec::<::std::string::String>>) -> Self {
        self.subnets = input; self
    }
    /// <p>The IDs of the subnets in the Neptune VPC. The default is None.</p>
    pub fn get_subnets(&self) -> &::std::option::Option<::std::vec::Vec::<::std::string::String>> {
        &self.subnets
    }
    /// Appends an item to `security_group_ids`.
    ///
    /// To override the contents of this collection use [`set_security_group_ids`](Self::set_security_group_ids).
    ///
    /// <p>The VPC security group IDs. The default is None.</p>
    pub fn security_group_ids(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        let mut v = self.security_group_ids.unwrap_or_default();
                        v.push(input.into());
                        self.security_group_ids = ::std::option::Option::Some(v);
                        self
    }
    /// <p>The VPC security group IDs. The default is None.</p>
    pub fn set_security_group_ids(mut self, input: ::std::option::Option<::std::vec::Vec::<::std::string::String>>) -> Self {
        self.security_group_ids = input; self
    }
    /// <p>The VPC security group IDs. The default is None.</p>
    pub fn get_security_group_ids(&self) -> &::std::option::Option<::std::vec::Vec::<::std::string::String>> {
        &self.security_group_ids
    }
    /// <p>The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instances that run the training job. The default is None.</p>
    pub fn volume_encryption_kms_key(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.volume_encryption_kms_key = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instances that run the training job. The default is None.</p>
    pub fn set_volume_encryption_kms_key(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.volume_encryption_kms_key = input; self
    }
    /// <p>The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instances that run the training job. The default is None.</p>
    pub fn get_volume_encryption_kms_key(&self) -> &::std::option::Option<::std::string::String> {
        &self.volume_encryption_kms_key
    }
    /// <p>The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt the output of the processing job. The default is none.</p>
    pub fn s3_output_encryption_kms_key(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.s3_output_encryption_kms_key = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt the output of the processing job. The default is none.</p>
    pub fn set_s3_output_encryption_kms_key(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.s3_output_encryption_kms_key = input; self
    }
    /// <p>The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt the output of the processing job. The default is none.</p>
    pub fn get_s3_output_encryption_kms_key(&self) -> &::std::option::Option<::std::string::String> {
        &self.s3_output_encryption_kms_key
    }
    /// Consumes the builder and constructs a [`StartMlDataProcessingJobInput`](crate::operation::start_ml_data_processing_job::StartMlDataProcessingJobInput).
    pub fn build(self) -> ::std::result::Result<crate::operation::start_ml_data_processing_job::StartMlDataProcessingJobInput, ::aws_smithy_types::error::operation::BuildError> {
        ::std::result::Result::Ok(
            crate::operation::start_ml_data_processing_job::StartMlDataProcessingJobInput {
                id: self.id
                ,
                previous_data_processing_job_id: self.previous_data_processing_job_id
                ,
                input_data_s3_location: self.input_data_s3_location
                ,
                processed_data_s3_location: self.processed_data_s3_location
                ,
                sagemaker_iam_role_arn: self.sagemaker_iam_role_arn
                ,
                neptune_iam_role_arn: self.neptune_iam_role_arn
                ,
                processing_instance_type: self.processing_instance_type
                ,
                processing_instance_volume_size_in_gb: self.processing_instance_volume_size_in_gb
                ,
                processing_time_out_in_seconds: self.processing_time_out_in_seconds
                ,
                model_type: self.model_type
                ,
                config_file_name: self.config_file_name
                ,
                subnets: self.subnets
                ,
                security_group_ids: self.security_group_ids
                ,
                volume_encryption_kms_key: self.volume_encryption_kms_key
                ,
                s3_output_encryption_kms_key: self.s3_output_encryption_kms_key
                ,
            }
        )
    }
}

