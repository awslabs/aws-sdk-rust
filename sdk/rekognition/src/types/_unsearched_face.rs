// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Face details inferred from the image but not used for search. The response attribute contains reasons for why a face wasn't used for Search. </p>
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct UnsearchedFace {
    /// <p>Structure containing attributes of the face that the algorithm detected.</p>
    /// <p>A <code>FaceDetail</code> object contains either the default facial attributes or all facial attributes. The default attributes are <code>BoundingBox</code>, <code>Confidence</code>, <code>Landmarks</code>, <code>Pose</code>, and <code>Quality</code>.</p>
    /// <p> <code>GetFaceDetection</code> is the only Amazon Rekognition Video stored video operation that can return a <code>FaceDetail</code> object with all attributes. To specify which attributes to return, use the <code>FaceAttributes</code> input parameter for <code>StartFaceDetection</code>. The following Amazon Rekognition Video operations return only the default attributes. The corresponding Start operations don't have a <code>FaceAttributes</code> input parameter:</p>
    /// <ul>
    /// <li> <p>GetCelebrityRecognition</p> </li>
    /// <li> <p>GetPersonTracking</p> </li>
    /// <li> <p>GetFaceSearch</p> </li>
    /// </ul>
    /// <p>The Amazon Rekognition Image <code>DetectFaces</code> and <code>IndexFaces</code> operations can return all facial attributes. To specify which attributes to return, use the <code>Attributes</code> input parameter for <code>DetectFaces</code>. For <code>IndexFaces</code>, use the <code>DetectAttributes</code> input parameter.</p>
    pub face_details: ::std::option::Option<crate::types::FaceDetail>,
    /// <p> Reasons why a face wasn't used for Search. </p>
    pub reasons: ::std::option::Option<::std::vec::Vec<crate::types::UnsearchedFaceReason>>,
}
impl UnsearchedFace {
    /// <p>Structure containing attributes of the face that the algorithm detected.</p>
    /// <p>A <code>FaceDetail</code> object contains either the default facial attributes or all facial attributes. The default attributes are <code>BoundingBox</code>, <code>Confidence</code>, <code>Landmarks</code>, <code>Pose</code>, and <code>Quality</code>.</p>
    /// <p> <code>GetFaceDetection</code> is the only Amazon Rekognition Video stored video operation that can return a <code>FaceDetail</code> object with all attributes. To specify which attributes to return, use the <code>FaceAttributes</code> input parameter for <code>StartFaceDetection</code>. The following Amazon Rekognition Video operations return only the default attributes. The corresponding Start operations don't have a <code>FaceAttributes</code> input parameter:</p>
    /// <ul>
    /// <li> <p>GetCelebrityRecognition</p> </li>
    /// <li> <p>GetPersonTracking</p> </li>
    /// <li> <p>GetFaceSearch</p> </li>
    /// </ul>
    /// <p>The Amazon Rekognition Image <code>DetectFaces</code> and <code>IndexFaces</code> operations can return all facial attributes. To specify which attributes to return, use the <code>Attributes</code> input parameter for <code>DetectFaces</code>. For <code>IndexFaces</code>, use the <code>DetectAttributes</code> input parameter.</p>
    pub fn face_details(&self) -> ::std::option::Option<&crate::types::FaceDetail> {
        self.face_details.as_ref()
    }
    /// <p> Reasons why a face wasn't used for Search. </p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.reasons.is_none()`.
    pub fn reasons(&self) -> &[crate::types::UnsearchedFaceReason] {
        self.reasons.as_deref().unwrap_or_default()
    }
}
impl UnsearchedFace {
    /// Creates a new builder-style object to manufacture [`UnsearchedFace`](crate::types::UnsearchedFace).
    pub fn builder() -> crate::types::builders::UnsearchedFaceBuilder {
        crate::types::builders::UnsearchedFaceBuilder::default()
    }
}

/// A builder for [`UnsearchedFace`](crate::types::UnsearchedFace).
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
pub struct UnsearchedFaceBuilder {
    pub(crate) face_details: ::std::option::Option<crate::types::FaceDetail>,
    pub(crate) reasons: ::std::option::Option<::std::vec::Vec<crate::types::UnsearchedFaceReason>>,
}
impl UnsearchedFaceBuilder {
    /// <p>Structure containing attributes of the face that the algorithm detected.</p>
    /// <p>A <code>FaceDetail</code> object contains either the default facial attributes or all facial attributes. The default attributes are <code>BoundingBox</code>, <code>Confidence</code>, <code>Landmarks</code>, <code>Pose</code>, and <code>Quality</code>.</p>
    /// <p> <code>GetFaceDetection</code> is the only Amazon Rekognition Video stored video operation that can return a <code>FaceDetail</code> object with all attributes. To specify which attributes to return, use the <code>FaceAttributes</code> input parameter for <code>StartFaceDetection</code>. The following Amazon Rekognition Video operations return only the default attributes. The corresponding Start operations don't have a <code>FaceAttributes</code> input parameter:</p>
    /// <ul>
    /// <li> <p>GetCelebrityRecognition</p> </li>
    /// <li> <p>GetPersonTracking</p> </li>
    /// <li> <p>GetFaceSearch</p> </li>
    /// </ul>
    /// <p>The Amazon Rekognition Image <code>DetectFaces</code> and <code>IndexFaces</code> operations can return all facial attributes. To specify which attributes to return, use the <code>Attributes</code> input parameter for <code>DetectFaces</code>. For <code>IndexFaces</code>, use the <code>DetectAttributes</code> input parameter.</p>
    pub fn face_details(mut self, input: crate::types::FaceDetail) -> Self {
        self.face_details = ::std::option::Option::Some(input);
        self
    }
    /// <p>Structure containing attributes of the face that the algorithm detected.</p>
    /// <p>A <code>FaceDetail</code> object contains either the default facial attributes or all facial attributes. The default attributes are <code>BoundingBox</code>, <code>Confidence</code>, <code>Landmarks</code>, <code>Pose</code>, and <code>Quality</code>.</p>
    /// <p> <code>GetFaceDetection</code> is the only Amazon Rekognition Video stored video operation that can return a <code>FaceDetail</code> object with all attributes. To specify which attributes to return, use the <code>FaceAttributes</code> input parameter for <code>StartFaceDetection</code>. The following Amazon Rekognition Video operations return only the default attributes. The corresponding Start operations don't have a <code>FaceAttributes</code> input parameter:</p>
    /// <ul>
    /// <li> <p>GetCelebrityRecognition</p> </li>
    /// <li> <p>GetPersonTracking</p> </li>
    /// <li> <p>GetFaceSearch</p> </li>
    /// </ul>
    /// <p>The Amazon Rekognition Image <code>DetectFaces</code> and <code>IndexFaces</code> operations can return all facial attributes. To specify which attributes to return, use the <code>Attributes</code> input parameter for <code>DetectFaces</code>. For <code>IndexFaces</code>, use the <code>DetectAttributes</code> input parameter.</p>
    pub fn set_face_details(mut self, input: ::std::option::Option<crate::types::FaceDetail>) -> Self {
        self.face_details = input;
        self
    }
    /// <p>Structure containing attributes of the face that the algorithm detected.</p>
    /// <p>A <code>FaceDetail</code> object contains either the default facial attributes or all facial attributes. The default attributes are <code>BoundingBox</code>, <code>Confidence</code>, <code>Landmarks</code>, <code>Pose</code>, and <code>Quality</code>.</p>
    /// <p> <code>GetFaceDetection</code> is the only Amazon Rekognition Video stored video operation that can return a <code>FaceDetail</code> object with all attributes. To specify which attributes to return, use the <code>FaceAttributes</code> input parameter for <code>StartFaceDetection</code>. The following Amazon Rekognition Video operations return only the default attributes. The corresponding Start operations don't have a <code>FaceAttributes</code> input parameter:</p>
    /// <ul>
    /// <li> <p>GetCelebrityRecognition</p> </li>
    /// <li> <p>GetPersonTracking</p> </li>
    /// <li> <p>GetFaceSearch</p> </li>
    /// </ul>
    /// <p>The Amazon Rekognition Image <code>DetectFaces</code> and <code>IndexFaces</code> operations can return all facial attributes. To specify which attributes to return, use the <code>Attributes</code> input parameter for <code>DetectFaces</code>. For <code>IndexFaces</code>, use the <code>DetectAttributes</code> input parameter.</p>
    pub fn get_face_details(&self) -> &::std::option::Option<crate::types::FaceDetail> {
        &self.face_details
    }
    /// Appends an item to `reasons`.
    ///
    /// To override the contents of this collection use [`set_reasons`](Self::set_reasons).
    ///
    /// <p> Reasons why a face wasn't used for Search. </p>
    pub fn reasons(mut self, input: crate::types::UnsearchedFaceReason) -> Self {
        let mut v = self.reasons.unwrap_or_default();
        v.push(input);
        self.reasons = ::std::option::Option::Some(v);
        self
    }
    /// <p> Reasons why a face wasn't used for Search. </p>
    pub fn set_reasons(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::UnsearchedFaceReason>>) -> Self {
        self.reasons = input;
        self
    }
    /// <p> Reasons why a face wasn't used for Search. </p>
    pub fn get_reasons(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::UnsearchedFaceReason>> {
        &self.reasons
    }
    /// Consumes the builder and constructs a [`UnsearchedFace`](crate::types::UnsearchedFace).
    pub fn build(self) -> crate::types::UnsearchedFace {
        crate::types::UnsearchedFace {
            face_details: self.face_details,
            reasons: self.reasons,
        }
    }
}
