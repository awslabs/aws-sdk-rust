// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeStreamProcessorOutput {
    /// <p>Name of the stream processor. </p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
    /// <p>ARN of the stream processor.</p>
    #[doc(hidden)]
    pub stream_processor_arn: std::option::Option<std::string::String>,
    /// <p>Current status of the stream processor.</p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::types::StreamProcessorStatus>,
    /// <p>Detailed status message about the stream processor.</p>
    #[doc(hidden)]
    pub status_message: std::option::Option<std::string::String>,
    /// <p>Date and time the stream processor was created</p>
    #[doc(hidden)]
    pub creation_timestamp: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The time, in Unix format, the stream processor was last updated. For example, when the stream processor moves from a running state to a failed state, or when the user starts or stops the stream processor.</p>
    #[doc(hidden)]
    pub last_update_timestamp: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Kinesis video stream that provides the source streaming video.</p>
    #[doc(hidden)]
    pub input: std::option::Option<crate::types::StreamProcessorInput>,
    /// <p>Kinesis data stream to which Amazon Rekognition Video puts the analysis results.</p>
    #[doc(hidden)]
    pub output: std::option::Option<crate::types::StreamProcessorOutput>,
    /// <p>ARN of the IAM role that allows access to the stream processor.</p>
    #[doc(hidden)]
    pub role_arn: std::option::Option<std::string::String>,
    /// <p>Input parameters used in a streaming video analyzed by a stream processor. You can use <code>FaceSearch</code> to recognize faces in a streaming video, or you can use <code>ConnectedHome</code> to detect labels.</p>
    #[doc(hidden)]
    pub settings: std::option::Option<crate::types::StreamProcessorSettings>,
    /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the object detection results and completion status of a video analysis operation.</p>
    /// <p>Amazon Rekognition publishes a notification the first time an object of interest or a person is detected in the video stream. For example, if Amazon Rekognition detects a person at second 2, a pet at second 4, and a person again at second 5, Amazon Rekognition sends 2 object class detected notifications, one for a person at second 2 and one for a pet at second 4.</p>
    /// <p>Amazon Rekognition also publishes an an end-of-session notification with a summary when the stream processing session is complete.</p>
    #[doc(hidden)]
    pub notification_channel: std::option::Option<crate::types::StreamProcessorNotificationChannel>,
    /// <p> The identifier for your AWS Key Management Service key (AWS KMS key). This is an optional parameter for label detection stream processors. </p>
    #[doc(hidden)]
    pub kms_key_id: std::option::Option<std::string::String>,
    /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. This is an optional parameter for label detection stream processors. </p>
    #[doc(hidden)]
    pub regions_of_interest: std::option::Option<std::vec::Vec<crate::types::RegionOfInterest>>,
    /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
    #[doc(hidden)]
    pub data_sharing_preference:
        std::option::Option<crate::types::StreamProcessorDataSharingPreference>,
    _request_id: Option<String>,
}
impl DescribeStreamProcessorOutput {
    /// <p>Name of the stream processor. </p>
    pub fn name(&self) -> std::option::Option<&str> {
        self.name.as_deref()
    }
    /// <p>ARN of the stream processor.</p>
    pub fn stream_processor_arn(&self) -> std::option::Option<&str> {
        self.stream_processor_arn.as_deref()
    }
    /// <p>Current status of the stream processor.</p>
    pub fn status(&self) -> std::option::Option<&crate::types::StreamProcessorStatus> {
        self.status.as_ref()
    }
    /// <p>Detailed status message about the stream processor.</p>
    pub fn status_message(&self) -> std::option::Option<&str> {
        self.status_message.as_deref()
    }
    /// <p>Date and time the stream processor was created</p>
    pub fn creation_timestamp(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.creation_timestamp.as_ref()
    }
    /// <p>The time, in Unix format, the stream processor was last updated. For example, when the stream processor moves from a running state to a failed state, or when the user starts or stops the stream processor.</p>
    pub fn last_update_timestamp(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.last_update_timestamp.as_ref()
    }
    /// <p>Kinesis video stream that provides the source streaming video.</p>
    pub fn input(&self) -> std::option::Option<&crate::types::StreamProcessorInput> {
        self.input.as_ref()
    }
    /// <p>Kinesis data stream to which Amazon Rekognition Video puts the analysis results.</p>
    pub fn output(&self) -> std::option::Option<&crate::types::StreamProcessorOutput> {
        self.output.as_ref()
    }
    /// <p>ARN of the IAM role that allows access to the stream processor.</p>
    pub fn role_arn(&self) -> std::option::Option<&str> {
        self.role_arn.as_deref()
    }
    /// <p>Input parameters used in a streaming video analyzed by a stream processor. You can use <code>FaceSearch</code> to recognize faces in a streaming video, or you can use <code>ConnectedHome</code> to detect labels.</p>
    pub fn settings(&self) -> std::option::Option<&crate::types::StreamProcessorSettings> {
        self.settings.as_ref()
    }
    /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the object detection results and completion status of a video analysis operation.</p>
    /// <p>Amazon Rekognition publishes a notification the first time an object of interest or a person is detected in the video stream. For example, if Amazon Rekognition detects a person at second 2, a pet at second 4, and a person again at second 5, Amazon Rekognition sends 2 object class detected notifications, one for a person at second 2 and one for a pet at second 4.</p>
    /// <p>Amazon Rekognition also publishes an an end-of-session notification with a summary when the stream processing session is complete.</p>
    pub fn notification_channel(
        &self,
    ) -> std::option::Option<&crate::types::StreamProcessorNotificationChannel> {
        self.notification_channel.as_ref()
    }
    /// <p> The identifier for your AWS Key Management Service key (AWS KMS key). This is an optional parameter for label detection stream processors. </p>
    pub fn kms_key_id(&self) -> std::option::Option<&str> {
        self.kms_key_id.as_deref()
    }
    /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. This is an optional parameter for label detection stream processors. </p>
    pub fn regions_of_interest(&self) -> std::option::Option<&[crate::types::RegionOfInterest]> {
        self.regions_of_interest.as_deref()
    }
    /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
    pub fn data_sharing_preference(
        &self,
    ) -> std::option::Option<&crate::types::StreamProcessorDataSharingPreference> {
        self.data_sharing_preference.as_ref()
    }
}
impl aws_http::request_id::RequestId for DescribeStreamProcessorOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
impl DescribeStreamProcessorOutput {
    /// Creates a new builder-style object to manufacture [`DescribeStreamProcessorOutput`](crate::operation::describe_stream_processor::DescribeStreamProcessorOutput).
    pub fn builder(
    ) -> crate::operation::describe_stream_processor::builders::DescribeStreamProcessorOutputBuilder
    {
        crate::operation::describe_stream_processor::builders::DescribeStreamProcessorOutputBuilder::default()
    }
}

/// A builder for [`DescribeStreamProcessorOutput`](crate::operation::describe_stream_processor::DescribeStreamProcessorOutput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct DescribeStreamProcessorOutputBuilder {
    pub(crate) name: std::option::Option<std::string::String>,
    pub(crate) stream_processor_arn: std::option::Option<std::string::String>,
    pub(crate) status: std::option::Option<crate::types::StreamProcessorStatus>,
    pub(crate) status_message: std::option::Option<std::string::String>,
    pub(crate) creation_timestamp: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) last_update_timestamp: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) input: std::option::Option<crate::types::StreamProcessorInput>,
    pub(crate) output: std::option::Option<crate::types::StreamProcessorOutput>,
    pub(crate) role_arn: std::option::Option<std::string::String>,
    pub(crate) settings: std::option::Option<crate::types::StreamProcessorSettings>,
    pub(crate) notification_channel:
        std::option::Option<crate::types::StreamProcessorNotificationChannel>,
    pub(crate) kms_key_id: std::option::Option<std::string::String>,
    pub(crate) regions_of_interest:
        std::option::Option<std::vec::Vec<crate::types::RegionOfInterest>>,
    pub(crate) data_sharing_preference:
        std::option::Option<crate::types::StreamProcessorDataSharingPreference>,
    _request_id: Option<String>,
}
impl DescribeStreamProcessorOutputBuilder {
    /// <p>Name of the stream processor. </p>
    pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
        self.name = Some(input.into());
        self
    }
    /// <p>Name of the stream processor. </p>
    pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.name = input;
        self
    }
    /// <p>ARN of the stream processor.</p>
    pub fn stream_processor_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.stream_processor_arn = Some(input.into());
        self
    }
    /// <p>ARN of the stream processor.</p>
    pub fn set_stream_processor_arn(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.stream_processor_arn = input;
        self
    }
    /// <p>Current status of the stream processor.</p>
    pub fn status(mut self, input: crate::types::StreamProcessorStatus) -> Self {
        self.status = Some(input);
        self
    }
    /// <p>Current status of the stream processor.</p>
    pub fn set_status(
        mut self,
        input: std::option::Option<crate::types::StreamProcessorStatus>,
    ) -> Self {
        self.status = input;
        self
    }
    /// <p>Detailed status message about the stream processor.</p>
    pub fn status_message(mut self, input: impl Into<std::string::String>) -> Self {
        self.status_message = Some(input.into());
        self
    }
    /// <p>Detailed status message about the stream processor.</p>
    pub fn set_status_message(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.status_message = input;
        self
    }
    /// <p>Date and time the stream processor was created</p>
    pub fn creation_timestamp(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.creation_timestamp = Some(input);
        self
    }
    /// <p>Date and time the stream processor was created</p>
    pub fn set_creation_timestamp(
        mut self,
        input: std::option::Option<aws_smithy_types::DateTime>,
    ) -> Self {
        self.creation_timestamp = input;
        self
    }
    /// <p>The time, in Unix format, the stream processor was last updated. For example, when the stream processor moves from a running state to a failed state, or when the user starts or stops the stream processor.</p>
    pub fn last_update_timestamp(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.last_update_timestamp = Some(input);
        self
    }
    /// <p>The time, in Unix format, the stream processor was last updated. For example, when the stream processor moves from a running state to a failed state, or when the user starts or stops the stream processor.</p>
    pub fn set_last_update_timestamp(
        mut self,
        input: std::option::Option<aws_smithy_types::DateTime>,
    ) -> Self {
        self.last_update_timestamp = input;
        self
    }
    /// <p>Kinesis video stream that provides the source streaming video.</p>
    pub fn input(mut self, input: crate::types::StreamProcessorInput) -> Self {
        self.input = Some(input);
        self
    }
    /// <p>Kinesis video stream that provides the source streaming video.</p>
    pub fn set_input(
        mut self,
        input: std::option::Option<crate::types::StreamProcessorInput>,
    ) -> Self {
        self.input = input;
        self
    }
    /// <p>Kinesis data stream to which Amazon Rekognition Video puts the analysis results.</p>
    pub fn output(mut self, input: crate::types::StreamProcessorOutput) -> Self {
        self.output = Some(input);
        self
    }
    /// <p>Kinesis data stream to which Amazon Rekognition Video puts the analysis results.</p>
    pub fn set_output(
        mut self,
        input: std::option::Option<crate::types::StreamProcessorOutput>,
    ) -> Self {
        self.output = input;
        self
    }
    /// <p>ARN of the IAM role that allows access to the stream processor.</p>
    pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.role_arn = Some(input.into());
        self
    }
    /// <p>ARN of the IAM role that allows access to the stream processor.</p>
    pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.role_arn = input;
        self
    }
    /// <p>Input parameters used in a streaming video analyzed by a stream processor. You can use <code>FaceSearch</code> to recognize faces in a streaming video, or you can use <code>ConnectedHome</code> to detect labels.</p>
    pub fn settings(mut self, input: crate::types::StreamProcessorSettings) -> Self {
        self.settings = Some(input);
        self
    }
    /// <p>Input parameters used in a streaming video analyzed by a stream processor. You can use <code>FaceSearch</code> to recognize faces in a streaming video, or you can use <code>ConnectedHome</code> to detect labels.</p>
    pub fn set_settings(
        mut self,
        input: std::option::Option<crate::types::StreamProcessorSettings>,
    ) -> Self {
        self.settings = input;
        self
    }
    /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the object detection results and completion status of a video analysis operation.</p>
    /// <p>Amazon Rekognition publishes a notification the first time an object of interest or a person is detected in the video stream. For example, if Amazon Rekognition detects a person at second 2, a pet at second 4, and a person again at second 5, Amazon Rekognition sends 2 object class detected notifications, one for a person at second 2 and one for a pet at second 4.</p>
    /// <p>Amazon Rekognition also publishes an an end-of-session notification with a summary when the stream processing session is complete.</p>
    pub fn notification_channel(
        mut self,
        input: crate::types::StreamProcessorNotificationChannel,
    ) -> Self {
        self.notification_channel = Some(input);
        self
    }
    /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the object detection results and completion status of a video analysis operation.</p>
    /// <p>Amazon Rekognition publishes a notification the first time an object of interest or a person is detected in the video stream. For example, if Amazon Rekognition detects a person at second 2, a pet at second 4, and a person again at second 5, Amazon Rekognition sends 2 object class detected notifications, one for a person at second 2 and one for a pet at second 4.</p>
    /// <p>Amazon Rekognition also publishes an an end-of-session notification with a summary when the stream processing session is complete.</p>
    pub fn set_notification_channel(
        mut self,
        input: std::option::Option<crate::types::StreamProcessorNotificationChannel>,
    ) -> Self {
        self.notification_channel = input;
        self
    }
    /// <p> The identifier for your AWS Key Management Service key (AWS KMS key). This is an optional parameter for label detection stream processors. </p>
    pub fn kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.kms_key_id = Some(input.into());
        self
    }
    /// <p> The identifier for your AWS Key Management Service key (AWS KMS key). This is an optional parameter for label detection stream processors. </p>
    pub fn set_kms_key_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.kms_key_id = input;
        self
    }
    /// Appends an item to `regions_of_interest`.
    ///
    /// To override the contents of this collection use [`set_regions_of_interest`](Self::set_regions_of_interest).
    ///
    /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. This is an optional parameter for label detection stream processors. </p>
    pub fn regions_of_interest(mut self, input: crate::types::RegionOfInterest) -> Self {
        let mut v = self.regions_of_interest.unwrap_or_default();
        v.push(input);
        self.regions_of_interest = Some(v);
        self
    }
    /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. This is an optional parameter for label detection stream processors. </p>
    pub fn set_regions_of_interest(
        mut self,
        input: std::option::Option<std::vec::Vec<crate::types::RegionOfInterest>>,
    ) -> Self {
        self.regions_of_interest = input;
        self
    }
    /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
    pub fn data_sharing_preference(
        mut self,
        input: crate::types::StreamProcessorDataSharingPreference,
    ) -> Self {
        self.data_sharing_preference = Some(input);
        self
    }
    /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
    pub fn set_data_sharing_preference(
        mut self,
        input: std::option::Option<crate::types::StreamProcessorDataSharingPreference>,
    ) -> Self {
        self.data_sharing_preference = input;
        self
    }
    pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
        self._request_id = Some(request_id.into());
        self
    }

    pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
        self._request_id = request_id;
        self
    }
    /// Consumes the builder and constructs a [`DescribeStreamProcessorOutput`](crate::operation::describe_stream_processor::DescribeStreamProcessorOutput).
    pub fn build(
        self,
    ) -> crate::operation::describe_stream_processor::DescribeStreamProcessorOutput {
        crate::operation::describe_stream_processor::DescribeStreamProcessorOutput {
            name: self.name,
            stream_processor_arn: self.stream_processor_arn,
            status: self.status,
            status_message: self.status_message,
            creation_timestamp: self.creation_timestamp,
            last_update_timestamp: self.last_update_timestamp,
            input: self.input,
            output: self.output,
            role_arn: self.role_arn,
            settings: self.settings,
            notification_channel: self.notification_channel,
            kms_key_id: self.kms_key_id,
            regions_of_interest: self.regions_of_interest,
            data_sharing_preference: self.data_sharing_preference,
            _request_id: self._request_id,
        }
    }
}
