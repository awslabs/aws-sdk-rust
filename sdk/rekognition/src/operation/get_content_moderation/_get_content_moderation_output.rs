// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct GetContentModerationOutput {
    /// <p>The current status of the content moderation analysis job.</p>
    pub job_status: ::std::option::Option<crate::types::VideoJobStatus>,
    /// <p>If the job fails, <code>StatusMessage</code> provides a descriptive error message.</p>
    pub status_message: ::std::option::Option<::std::string::String>,
    /// <p>Information about a video that Amazon Rekognition analyzed. <code>Videometadata</code> is returned in every page of paginated responses from <code>GetContentModeration</code>.</p>
    pub video_metadata: ::std::option::Option<crate::types::VideoMetadata>,
    /// <p>The detected inappropriate, unwanted, or offensive content moderation labels and the time(s) they were detected.</p>
    pub moderation_labels: ::std::option::Option<::std::vec::Vec<crate::types::ContentModerationDetection>>,
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of content moderation labels.</p>
    pub next_token: ::std::option::Option<::std::string::String>,
    /// <p>Version number of the moderation detection model that was used to detect inappropriate, unwanted, or offensive content.</p>
    pub moderation_model_version: ::std::option::Option<::std::string::String>,
    /// <p>Job identifier for the content moderation operation for which you want to obtain results. The job identifer is returned by an initial call to StartContentModeration.</p>
    pub job_id: ::std::option::Option<::std::string::String>,
    /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
    pub video: ::std::option::Option<crate::types::Video>,
    /// <p>A job identifier specified in the call to StartContentModeration and returned in the job completion notification sent to your Amazon Simple Notification Service topic.</p>
    pub job_tag: ::std::option::Option<::std::string::String>,
    /// <p>Information about the paramters used when getting a response. Includes information on aggregation and sorting methods.</p>
    pub get_request_metadata: ::std::option::Option<crate::types::GetContentModerationRequestMetadata>,
    _request_id: Option<String>,
}
impl GetContentModerationOutput {
    /// <p>The current status of the content moderation analysis job.</p>
    pub fn job_status(&self) -> ::std::option::Option<&crate::types::VideoJobStatus> {
        self.job_status.as_ref()
    }
    /// <p>If the job fails, <code>StatusMessage</code> provides a descriptive error message.</p>
    pub fn status_message(&self) -> ::std::option::Option<&str> {
        self.status_message.as_deref()
    }
    /// <p>Information about a video that Amazon Rekognition analyzed. <code>Videometadata</code> is returned in every page of paginated responses from <code>GetContentModeration</code>.</p>
    pub fn video_metadata(&self) -> ::std::option::Option<&crate::types::VideoMetadata> {
        self.video_metadata.as_ref()
    }
    /// <p>The detected inappropriate, unwanted, or offensive content moderation labels and the time(s) they were detected.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.moderation_labels.is_none()`.
    pub fn moderation_labels(&self) -> &[crate::types::ContentModerationDetection] {
        self.moderation_labels.as_deref().unwrap_or_default()
    }
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of content moderation labels.</p>
    pub fn next_token(&self) -> ::std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Version number of the moderation detection model that was used to detect inappropriate, unwanted, or offensive content.</p>
    pub fn moderation_model_version(&self) -> ::std::option::Option<&str> {
        self.moderation_model_version.as_deref()
    }
    /// <p>Job identifier for the content moderation operation for which you want to obtain results. The job identifer is returned by an initial call to StartContentModeration.</p>
    pub fn job_id(&self) -> ::std::option::Option<&str> {
        self.job_id.as_deref()
    }
    /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
    pub fn video(&self) -> ::std::option::Option<&crate::types::Video> {
        self.video.as_ref()
    }
    /// <p>A job identifier specified in the call to StartContentModeration and returned in the job completion notification sent to your Amazon Simple Notification Service topic.</p>
    pub fn job_tag(&self) -> ::std::option::Option<&str> {
        self.job_tag.as_deref()
    }
    /// <p>Information about the paramters used when getting a response. Includes information on aggregation and sorting methods.</p>
    pub fn get_request_metadata(&self) -> ::std::option::Option<&crate::types::GetContentModerationRequestMetadata> {
        self.get_request_metadata.as_ref()
    }
}
impl ::aws_types::request_id::RequestId for GetContentModerationOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
impl GetContentModerationOutput {
    /// Creates a new builder-style object to manufacture [`GetContentModerationOutput`](crate::operation::get_content_moderation::GetContentModerationOutput).
    pub fn builder() -> crate::operation::get_content_moderation::builders::GetContentModerationOutputBuilder {
        crate::operation::get_content_moderation::builders::GetContentModerationOutputBuilder::default()
    }
}

/// A builder for [`GetContentModerationOutput`](crate::operation::get_content_moderation::GetContentModerationOutput).
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
pub struct GetContentModerationOutputBuilder {
    pub(crate) job_status: ::std::option::Option<crate::types::VideoJobStatus>,
    pub(crate) status_message: ::std::option::Option<::std::string::String>,
    pub(crate) video_metadata: ::std::option::Option<crate::types::VideoMetadata>,
    pub(crate) moderation_labels: ::std::option::Option<::std::vec::Vec<crate::types::ContentModerationDetection>>,
    pub(crate) next_token: ::std::option::Option<::std::string::String>,
    pub(crate) moderation_model_version: ::std::option::Option<::std::string::String>,
    pub(crate) job_id: ::std::option::Option<::std::string::String>,
    pub(crate) video: ::std::option::Option<crate::types::Video>,
    pub(crate) job_tag: ::std::option::Option<::std::string::String>,
    pub(crate) get_request_metadata: ::std::option::Option<crate::types::GetContentModerationRequestMetadata>,
    _request_id: Option<String>,
}
impl GetContentModerationOutputBuilder {
    /// <p>The current status of the content moderation analysis job.</p>
    pub fn job_status(mut self, input: crate::types::VideoJobStatus) -> Self {
        self.job_status = ::std::option::Option::Some(input);
        self
    }
    /// <p>The current status of the content moderation analysis job.</p>
    pub fn set_job_status(mut self, input: ::std::option::Option<crate::types::VideoJobStatus>) -> Self {
        self.job_status = input;
        self
    }
    /// <p>The current status of the content moderation analysis job.</p>
    pub fn get_job_status(&self) -> &::std::option::Option<crate::types::VideoJobStatus> {
        &self.job_status
    }
    /// <p>If the job fails, <code>StatusMessage</code> provides a descriptive error message.</p>
    pub fn status_message(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.status_message = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>If the job fails, <code>StatusMessage</code> provides a descriptive error message.</p>
    pub fn set_status_message(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.status_message = input;
        self
    }
    /// <p>If the job fails, <code>StatusMessage</code> provides a descriptive error message.</p>
    pub fn get_status_message(&self) -> &::std::option::Option<::std::string::String> {
        &self.status_message
    }
    /// <p>Information about a video that Amazon Rekognition analyzed. <code>Videometadata</code> is returned in every page of paginated responses from <code>GetContentModeration</code>.</p>
    pub fn video_metadata(mut self, input: crate::types::VideoMetadata) -> Self {
        self.video_metadata = ::std::option::Option::Some(input);
        self
    }
    /// <p>Information about a video that Amazon Rekognition analyzed. <code>Videometadata</code> is returned in every page of paginated responses from <code>GetContentModeration</code>.</p>
    pub fn set_video_metadata(mut self, input: ::std::option::Option<crate::types::VideoMetadata>) -> Self {
        self.video_metadata = input;
        self
    }
    /// <p>Information about a video that Amazon Rekognition analyzed. <code>Videometadata</code> is returned in every page of paginated responses from <code>GetContentModeration</code>.</p>
    pub fn get_video_metadata(&self) -> &::std::option::Option<crate::types::VideoMetadata> {
        &self.video_metadata
    }
    /// Appends an item to `moderation_labels`.
    ///
    /// To override the contents of this collection use [`set_moderation_labels`](Self::set_moderation_labels).
    ///
    /// <p>The detected inappropriate, unwanted, or offensive content moderation labels and the time(s) they were detected.</p>
    pub fn moderation_labels(mut self, input: crate::types::ContentModerationDetection) -> Self {
        let mut v = self.moderation_labels.unwrap_or_default();
        v.push(input);
        self.moderation_labels = ::std::option::Option::Some(v);
        self
    }
    /// <p>The detected inappropriate, unwanted, or offensive content moderation labels and the time(s) they were detected.</p>
    pub fn set_moderation_labels(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::ContentModerationDetection>>) -> Self {
        self.moderation_labels = input;
        self
    }
    /// <p>The detected inappropriate, unwanted, or offensive content moderation labels and the time(s) they were detected.</p>
    pub fn get_moderation_labels(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::ContentModerationDetection>> {
        &self.moderation_labels
    }
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of content moderation labels.</p>
    pub fn next_token(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.next_token = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of content moderation labels.</p>
    pub fn set_next_token(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.next_token = input;
        self
    }
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of content moderation labels.</p>
    pub fn get_next_token(&self) -> &::std::option::Option<::std::string::String> {
        &self.next_token
    }
    /// <p>Version number of the moderation detection model that was used to detect inappropriate, unwanted, or offensive content.</p>
    pub fn moderation_model_version(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.moderation_model_version = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Version number of the moderation detection model that was used to detect inappropriate, unwanted, or offensive content.</p>
    pub fn set_moderation_model_version(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.moderation_model_version = input;
        self
    }
    /// <p>Version number of the moderation detection model that was used to detect inappropriate, unwanted, or offensive content.</p>
    pub fn get_moderation_model_version(&self) -> &::std::option::Option<::std::string::String> {
        &self.moderation_model_version
    }
    /// <p>Job identifier for the content moderation operation for which you want to obtain results. The job identifer is returned by an initial call to StartContentModeration.</p>
    pub fn job_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.job_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>Job identifier for the content moderation operation for which you want to obtain results. The job identifer is returned by an initial call to StartContentModeration.</p>
    pub fn set_job_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.job_id = input;
        self
    }
    /// <p>Job identifier for the content moderation operation for which you want to obtain results. The job identifer is returned by an initial call to StartContentModeration.</p>
    pub fn get_job_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.job_id
    }
    /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
    pub fn video(mut self, input: crate::types::Video) -> Self {
        self.video = ::std::option::Option::Some(input);
        self
    }
    /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
    pub fn set_video(mut self, input: ::std::option::Option<crate::types::Video>) -> Self {
        self.video = input;
        self
    }
    /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
    pub fn get_video(&self) -> &::std::option::Option<crate::types::Video> {
        &self.video
    }
    /// <p>A job identifier specified in the call to StartContentModeration and returned in the job completion notification sent to your Amazon Simple Notification Service topic.</p>
    pub fn job_tag(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.job_tag = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>A job identifier specified in the call to StartContentModeration and returned in the job completion notification sent to your Amazon Simple Notification Service topic.</p>
    pub fn set_job_tag(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.job_tag = input;
        self
    }
    /// <p>A job identifier specified in the call to StartContentModeration and returned in the job completion notification sent to your Amazon Simple Notification Service topic.</p>
    pub fn get_job_tag(&self) -> &::std::option::Option<::std::string::String> {
        &self.job_tag
    }
    /// <p>Information about the paramters used when getting a response. Includes information on aggregation and sorting methods.</p>
    pub fn get_request_metadata(mut self, input: crate::types::GetContentModerationRequestMetadata) -> Self {
        self.get_request_metadata = ::std::option::Option::Some(input);
        self
    }
    /// <p>Information about the paramters used when getting a response. Includes information on aggregation and sorting methods.</p>
    pub fn set_get_request_metadata(mut self, input: ::std::option::Option<crate::types::GetContentModerationRequestMetadata>) -> Self {
        self.get_request_metadata = input;
        self
    }
    /// <p>Information about the paramters used when getting a response. Includes information on aggregation and sorting methods.</p>
    pub fn get_get_request_metadata(&self) -> &::std::option::Option<crate::types::GetContentModerationRequestMetadata> {
        &self.get_request_metadata
    }
    pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
        self._request_id = Some(request_id.into());
        self
    }

    pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
        self._request_id = request_id;
        self
    }
    /// Consumes the builder and constructs a [`GetContentModerationOutput`](crate::operation::get_content_moderation::GetContentModerationOutput).
    pub fn build(self) -> crate::operation::get_content_moderation::GetContentModerationOutput {
        crate::operation::get_content_moderation::GetContentModerationOutput {
            job_status: self.job_status,
            status_message: self.status_message,
            video_metadata: self.video_metadata,
            moderation_labels: self.moderation_labels,
            next_token: self.next_token,
            moderation_model_version: self.moderation_model_version,
            job_id: self.job_id,
            video: self.video,
            job_tag: self.job_tag,
            get_request_metadata: self.get_request_metadata,
            _request_id: self._request_id,
        }
    }
}
