// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DetectCustomLabelsInput  {
    /// <p>The ARN of the model version that you want to use.</p>
    #[doc(hidden)]
    pub project_version_arn: std::option::Option<std::string::String>,
    /// <p>Provides the input image either as bytes or an S3 object.</p> 
    /// <p>You pass image bytes to an Amazon Rekognition API operation by using the <code>Bytes</code> property. For example, you would use the <code>Bytes</code> property to pass an image loaded from a local file system. Image bytes passed by using the <code>Bytes</code> property must be base64-encoded. Your code may not need to encode image bytes if you are using an AWS SDK to call Amazon Rekognition API operations. </p> 
    /// <p>For more information, see Analyzing an Image Loaded from a Local File System in the Amazon Rekognition Developer Guide.</p> 
    /// <p> You pass images stored in an S3 bucket to an Amazon Rekognition API operation by using the <code>S3Object</code> property. Images stored in an S3 bucket do not need to be base64-encoded.</p> 
    /// <p>The region for the S3 bucket containing the S3 object must match the region you use for Amazon Rekognition operations.</p> 
    /// <p>If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes using the Bytes property is not supported. You must first upload the image to an Amazon S3 bucket and then call the operation using the S3Object property.</p> 
    /// <p>For Amazon Rekognition to process an S3 object, the user must have permission to access the S3 object. For more information, see How Amazon Rekognition works with IAM in the Amazon Rekognition Developer Guide. </p>
    #[doc(hidden)]
    pub image: std::option::Option<crate::types::Image>,
    /// <p>Maximum number of results you want the service to return in the response. The service returns the specified number of highest confidence labels ranked from highest confidence to lowest.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>Specifies the minimum confidence level for the labels to return. <code>DetectCustomLabels</code> doesn't return any labels with a confidence value that's lower than this specified value. If you specify a value of 0, <code>DetectCustomLabels</code> returns all labels, regardless of the assumed threshold applied to each label. If you don't specify a value for <code>MinConfidence</code>, <code>DetectCustomLabels</code> returns labels based on the assumed threshold of each label.</p>
    #[doc(hidden)]
    pub min_confidence: std::option::Option<f32>,
}
impl DetectCustomLabelsInput {
    /// <p>The ARN of the model version that you want to use.</p>
    pub fn project_version_arn(&self) -> std::option::Option<& str> {
        self.project_version_arn.as_deref()
    }
    /// <p>Provides the input image either as bytes or an S3 object.</p> 
    /// <p>You pass image bytes to an Amazon Rekognition API operation by using the <code>Bytes</code> property. For example, you would use the <code>Bytes</code> property to pass an image loaded from a local file system. Image bytes passed by using the <code>Bytes</code> property must be base64-encoded. Your code may not need to encode image bytes if you are using an AWS SDK to call Amazon Rekognition API operations. </p> 
    /// <p>For more information, see Analyzing an Image Loaded from a Local File System in the Amazon Rekognition Developer Guide.</p> 
    /// <p> You pass images stored in an S3 bucket to an Amazon Rekognition API operation by using the <code>S3Object</code> property. Images stored in an S3 bucket do not need to be base64-encoded.</p> 
    /// <p>The region for the S3 bucket containing the S3 object must match the region you use for Amazon Rekognition operations.</p> 
    /// <p>If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes using the Bytes property is not supported. You must first upload the image to an Amazon S3 bucket and then call the operation using the S3Object property.</p> 
    /// <p>For Amazon Rekognition to process an S3 object, the user must have permission to access the S3 object. For more information, see How Amazon Rekognition works with IAM in the Amazon Rekognition Developer Guide. </p>
    pub fn image(&self) -> std::option::Option<& crate::types::Image> {
        self.image.as_ref()
    }
    /// <p>Maximum number of results you want the service to return in the response. The service returns the specified number of highest confidence labels ranked from highest confidence to lowest.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>Specifies the minimum confidence level for the labels to return. <code>DetectCustomLabels</code> doesn't return any labels with a confidence value that's lower than this specified value. If you specify a value of 0, <code>DetectCustomLabels</code> returns all labels, regardless of the assumed threshold applied to each label. If you don't specify a value for <code>MinConfidence</code>, <code>DetectCustomLabels</code> returns labels based on the assumed threshold of each label.</p>
    pub fn min_confidence(&self) -> std::option::Option<f32> {
        self.min_confidence
    }
}
impl DetectCustomLabelsInput {
    /// Creates a new builder-style object to manufacture [`DetectCustomLabelsInput`](crate::operation::detect_custom_labels::DetectCustomLabelsInput).
    pub fn builder() -> crate::operation::detect_custom_labels::builders::DetectCustomLabelsInputBuilder {
        crate::operation::detect_custom_labels::builders::DetectCustomLabelsInputBuilder::default()
    }
}

/// A builder for [`DetectCustomLabelsInput`](crate::operation::detect_custom_labels::DetectCustomLabelsInput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct DetectCustomLabelsInputBuilder {
    pub(crate) project_version_arn: std::option::Option<std::string::String>,
    pub(crate) image: std::option::Option<crate::types::Image>,
    pub(crate) max_results: std::option::Option<i32>,
    pub(crate) min_confidence: std::option::Option<f32>,
}
impl DetectCustomLabelsInputBuilder {
    /// <p>The ARN of the model version that you want to use.</p>
    pub fn project_version_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.project_version_arn = Some(input.into());
        self
    }
    /// <p>The ARN of the model version that you want to use.</p>
    pub fn set_project_version_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.project_version_arn = input; self
    }
    /// <p>Provides the input image either as bytes or an S3 object.</p> 
    /// <p>You pass image bytes to an Amazon Rekognition API operation by using the <code>Bytes</code> property. For example, you would use the <code>Bytes</code> property to pass an image loaded from a local file system. Image bytes passed by using the <code>Bytes</code> property must be base64-encoded. Your code may not need to encode image bytes if you are using an AWS SDK to call Amazon Rekognition API operations. </p> 
    /// <p>For more information, see Analyzing an Image Loaded from a Local File System in the Amazon Rekognition Developer Guide.</p> 
    /// <p> You pass images stored in an S3 bucket to an Amazon Rekognition API operation by using the <code>S3Object</code> property. Images stored in an S3 bucket do not need to be base64-encoded.</p> 
    /// <p>The region for the S3 bucket containing the S3 object must match the region you use for Amazon Rekognition operations.</p> 
    /// <p>If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes using the Bytes property is not supported. You must first upload the image to an Amazon S3 bucket and then call the operation using the S3Object property.</p> 
    /// <p>For Amazon Rekognition to process an S3 object, the user must have permission to access the S3 object. For more information, see How Amazon Rekognition works with IAM in the Amazon Rekognition Developer Guide. </p>
    pub fn image(mut self, input: crate::types::Image) -> Self {
        self.image = Some(input);
        self
    }
    /// <p>Provides the input image either as bytes or an S3 object.</p> 
    /// <p>You pass image bytes to an Amazon Rekognition API operation by using the <code>Bytes</code> property. For example, you would use the <code>Bytes</code> property to pass an image loaded from a local file system. Image bytes passed by using the <code>Bytes</code> property must be base64-encoded. Your code may not need to encode image bytes if you are using an AWS SDK to call Amazon Rekognition API operations. </p> 
    /// <p>For more information, see Analyzing an Image Loaded from a Local File System in the Amazon Rekognition Developer Guide.</p> 
    /// <p> You pass images stored in an S3 bucket to an Amazon Rekognition API operation by using the <code>S3Object</code> property. Images stored in an S3 bucket do not need to be base64-encoded.</p> 
    /// <p>The region for the S3 bucket containing the S3 object must match the region you use for Amazon Rekognition operations.</p> 
    /// <p>If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes using the Bytes property is not supported. You must first upload the image to an Amazon S3 bucket and then call the operation using the S3Object property.</p> 
    /// <p>For Amazon Rekognition to process an S3 object, the user must have permission to access the S3 object. For more information, see How Amazon Rekognition works with IAM in the Amazon Rekognition Developer Guide. </p>
    pub fn set_image(mut self, input: std::option::Option<crate::types::Image>) -> Self {
        self.image = input; self
    }
    /// <p>Maximum number of results you want the service to return in the response. The service returns the specified number of highest confidence labels ranked from highest confidence to lowest.</p>
    pub fn max_results(mut self, input: i32) -> Self {
        self.max_results = Some(input);
        self
    }
    /// <p>Maximum number of results you want the service to return in the response. The service returns the specified number of highest confidence labels ranked from highest confidence to lowest.</p>
    pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
        self.max_results = input; self
    }
    /// <p>Specifies the minimum confidence level for the labels to return. <code>DetectCustomLabels</code> doesn't return any labels with a confidence value that's lower than this specified value. If you specify a value of 0, <code>DetectCustomLabels</code> returns all labels, regardless of the assumed threshold applied to each label. If you don't specify a value for <code>MinConfidence</code>, <code>DetectCustomLabels</code> returns labels based on the assumed threshold of each label.</p>
    pub fn min_confidence(mut self, input: f32) -> Self {
        self.min_confidence = Some(input);
        self
    }
    /// <p>Specifies the minimum confidence level for the labels to return. <code>DetectCustomLabels</code> doesn't return any labels with a confidence value that's lower than this specified value. If you specify a value of 0, <code>DetectCustomLabels</code> returns all labels, regardless of the assumed threshold applied to each label. If you don't specify a value for <code>MinConfidence</code>, <code>DetectCustomLabels</code> returns labels based on the assumed threshold of each label.</p>
    pub fn set_min_confidence(mut self, input: std::option::Option<f32>) -> Self {
        self.min_confidence = input; self
    }
    /// Consumes the builder and constructs a [`DetectCustomLabelsInput`](crate::operation::detect_custom_labels::DetectCustomLabelsInput).
    pub fn build(self) -> Result<crate::operation::detect_custom_labels::DetectCustomLabelsInput, aws_smithy_http::operation::error::BuildError> {
        Ok(
            crate::operation::detect_custom_labels::DetectCustomLabelsInput {
                project_version_arn: self.project_version_arn
                ,
                image: self.image
                ,
                max_results: self.max_results
                ,
                min_confidence: self.min_confidence
                ,
            }
        )
    }
}

