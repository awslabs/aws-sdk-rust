// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct GetSegmentDetectionInput {
    /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartSegmentDetection</code>.</p>
    #[doc(hidden)]
    pub job_id: std::option::Option<std::string::String>,
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of text.</p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
}
impl GetSegmentDetectionInput {
    /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartSegmentDetection</code>.</p>
    pub fn job_id(&self) -> std::option::Option<&str> {
        self.job_id.as_deref()
    }
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of text.</p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
}
impl GetSegmentDetectionInput {
    /// Creates a new builder-style object to manufacture [`GetSegmentDetectionInput`](crate::operation::get_segment_detection::GetSegmentDetectionInput).
    pub fn builder(
    ) -> crate::operation::get_segment_detection::builders::GetSegmentDetectionInputBuilder {
        crate::operation::get_segment_detection::builders::GetSegmentDetectionInputBuilder::default(
        )
    }
}

/// A builder for [`GetSegmentDetectionInput`](crate::operation::get_segment_detection::GetSegmentDetectionInput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct GetSegmentDetectionInputBuilder {
    pub(crate) job_id: std::option::Option<std::string::String>,
    pub(crate) max_results: std::option::Option<i32>,
    pub(crate) next_token: std::option::Option<std::string::String>,
}
impl GetSegmentDetectionInputBuilder {
    /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartSegmentDetection</code>.</p>
    pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.job_id = Some(input.into());
        self
    }
    /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartSegmentDetection</code>.</p>
    pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.job_id = input;
        self
    }
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
    pub fn max_results(mut self, input: i32) -> Self {
        self.max_results = Some(input);
        self
    }
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
    pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
        self.max_results = input;
        self
    }
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of text.</p>
    pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
        self.next_token = Some(input.into());
        self
    }
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of text.</p>
    pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.next_token = input;
        self
    }
    /// Consumes the builder and constructs a [`GetSegmentDetectionInput`](crate::operation::get_segment_detection::GetSegmentDetectionInput).
    pub fn build(
        self,
    ) -> Result<
        crate::operation::get_segment_detection::GetSegmentDetectionInput,
        aws_smithy_http::operation::error::BuildError,
    > {
        Ok(
            crate::operation::get_segment_detection::GetSegmentDetectionInput {
                job_id: self.job_id,
                max_results: self.max_results,
                next_token: self.next_token,
            },
        )
    }
}
