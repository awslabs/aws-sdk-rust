// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DetectLabelsInput  {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. Images stored in an S3 Bucket do not need to be base64-encoded.</p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    #[doc(hidden)]
    pub image: std::option::Option<crate::types::Image>,
    /// <p>Maximum number of labels you want the service to return in the response. The service returns the specified number of highest confidence labels. </p>
    #[doc(hidden)]
    pub max_labels: std::option::Option<i32>,
    /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with confidence lower than this specified value.</p> 
    /// <p>If <code>MinConfidence</code> is not specified, the operation returns labels with a confidence values greater than or equal to 55 percent.</p>
    #[doc(hidden)]
    pub min_confidence: std::option::Option<f32>,
    /// <p>A list of the types of analysis to perform. Specifying GENERAL_LABELS uses the label detection feature, while specifying IMAGE_PROPERTIES returns information regarding image color and quality. If no option is specified GENERAL_LABELS is used by default.</p>
    #[doc(hidden)]
    pub features: std::option::Option<std::vec::Vec<crate::types::DetectLabelsFeatureName>>,
    /// <p>A list of the filters to be applied to returned detected labels and image properties. Specified filters can be inclusive, exclusive, or a combination of both. Filters can be used for individual labels or label categories. The exact label names or label categories must be supplied. For a full list of labels and label categories, see LINK HERE.</p>
    #[doc(hidden)]
    pub settings: std::option::Option<crate::types::DetectLabelsSettings>,
}
impl DetectLabelsInput {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. Images stored in an S3 Bucket do not need to be base64-encoded.</p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn image(&self) -> std::option::Option<& crate::types::Image> {
        self.image.as_ref()
    }
    /// <p>Maximum number of labels you want the service to return in the response. The service returns the specified number of highest confidence labels. </p>
    pub fn max_labels(&self) -> std::option::Option<i32> {
        self.max_labels
    }
    /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with confidence lower than this specified value.</p> 
    /// <p>If <code>MinConfidence</code> is not specified, the operation returns labels with a confidence values greater than or equal to 55 percent.</p>
    pub fn min_confidence(&self) -> std::option::Option<f32> {
        self.min_confidence
    }
    /// <p>A list of the types of analysis to perform. Specifying GENERAL_LABELS uses the label detection feature, while specifying IMAGE_PROPERTIES returns information regarding image color and quality. If no option is specified GENERAL_LABELS is used by default.</p>
    pub fn features(&self) -> std::option::Option<& [crate::types::DetectLabelsFeatureName]> {
        self.features.as_deref()
    }
    /// <p>A list of the filters to be applied to returned detected labels and image properties. Specified filters can be inclusive, exclusive, or a combination of both. Filters can be used for individual labels or label categories. The exact label names or label categories must be supplied. For a full list of labels and label categories, see LINK HERE.</p>
    pub fn settings(&self) -> std::option::Option<& crate::types::DetectLabelsSettings> {
        self.settings.as_ref()
    }
}
impl DetectLabelsInput {
    /// Creates a new builder-style object to manufacture [`DetectLabelsInput`](crate::operation::detect_labels::DetectLabelsInput).
    pub fn builder() -> crate::operation::detect_labels::builders::DetectLabelsInputBuilder {
        crate::operation::detect_labels::builders::DetectLabelsInputBuilder::default()
    }
}

/// A builder for [`DetectLabelsInput`](crate::operation::detect_labels::DetectLabelsInput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct DetectLabelsInputBuilder {
    pub(crate) image: std::option::Option<crate::types::Image>,
    pub(crate) max_labels: std::option::Option<i32>,
    pub(crate) min_confidence: std::option::Option<f32>,
    pub(crate) features: std::option::Option<std::vec::Vec<crate::types::DetectLabelsFeatureName>>,
    pub(crate) settings: std::option::Option<crate::types::DetectLabelsSettings>,
}
impl DetectLabelsInputBuilder {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. Images stored in an S3 Bucket do not need to be base64-encoded.</p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn image(mut self, input: crate::types::Image) -> Self {
        self.image = Some(input);
        self
    }
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. Images stored in an S3 Bucket do not need to be base64-encoded.</p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn set_image(mut self, input: std::option::Option<crate::types::Image>) -> Self {
        self.image = input; self
    }
    /// <p>Maximum number of labels you want the service to return in the response. The service returns the specified number of highest confidence labels. </p>
    pub fn max_labels(mut self, input: i32) -> Self {
        self.max_labels = Some(input);
        self
    }
    /// <p>Maximum number of labels you want the service to return in the response. The service returns the specified number of highest confidence labels. </p>
    pub fn set_max_labels(mut self, input: std::option::Option<i32>) -> Self {
        self.max_labels = input; self
    }
    /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with confidence lower than this specified value.</p> 
    /// <p>If <code>MinConfidence</code> is not specified, the operation returns labels with a confidence values greater than or equal to 55 percent.</p>
    pub fn min_confidence(mut self, input: f32) -> Self {
        self.min_confidence = Some(input);
        self
    }
    /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with confidence lower than this specified value.</p> 
    /// <p>If <code>MinConfidence</code> is not specified, the operation returns labels with a confidence values greater than or equal to 55 percent.</p>
    pub fn set_min_confidence(mut self, input: std::option::Option<f32>) -> Self {
        self.min_confidence = input; self
    }
    /// Appends an item to `features`.
    ///
    /// To override the contents of this collection use [`set_features`](Self::set_features).
    ///
    /// <p>A list of the types of analysis to perform. Specifying GENERAL_LABELS uses the label detection feature, while specifying IMAGE_PROPERTIES returns information regarding image color and quality. If no option is specified GENERAL_LABELS is used by default.</p>
    pub fn features(mut self, input: crate::types::DetectLabelsFeatureName) -> Self {
        let mut v = self.features.unwrap_or_default();
                        v.push(input);
                        self.features = Some(v);
                        self
    }
    /// <p>A list of the types of analysis to perform. Specifying GENERAL_LABELS uses the label detection feature, while specifying IMAGE_PROPERTIES returns information regarding image color and quality. If no option is specified GENERAL_LABELS is used by default.</p>
    pub fn set_features(mut self, input: std::option::Option<std::vec::Vec<crate::types::DetectLabelsFeatureName>>) -> Self {
        self.features = input; self
    }
    /// <p>A list of the filters to be applied to returned detected labels and image properties. Specified filters can be inclusive, exclusive, or a combination of both. Filters can be used for individual labels or label categories. The exact label names or label categories must be supplied. For a full list of labels and label categories, see LINK HERE.</p>
    pub fn settings(mut self, input: crate::types::DetectLabelsSettings) -> Self {
        self.settings = Some(input);
        self
    }
    /// <p>A list of the filters to be applied to returned detected labels and image properties. Specified filters can be inclusive, exclusive, or a combination of both. Filters can be used for individual labels or label categories. The exact label names or label categories must be supplied. For a full list of labels and label categories, see LINK HERE.</p>
    pub fn set_settings(mut self, input: std::option::Option<crate::types::DetectLabelsSettings>) -> Self {
        self.settings = input; self
    }
    /// Consumes the builder and constructs a [`DetectLabelsInput`](crate::operation::detect_labels::DetectLabelsInput).
    pub fn build(self) -> Result<crate::operation::detect_labels::DetectLabelsInput, aws_smithy_http::operation::error::BuildError> {
        Ok(
            crate::operation::detect_labels::DetectLabelsInput {
                image: self.image
                ,
                max_labels: self.max_labels
                ,
                min_confidence: self.min_confidence
                ,
                features: self.features
                ,
                settings: self.settings
                ,
            }
        )
    }
}

