// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct GetLabelDetectionOutput  {
    /// <p>The current status of the label detection job.</p>
    #[doc(hidden)]
    pub job_status: std::option::Option<crate::types::VideoJobStatus>,
    /// <p>If the job fails, <code>StatusMessage</code> provides a descriptive error message.</p>
    #[doc(hidden)]
    pub status_message: std::option::Option<std::string::String>,
    /// <p>Information about a video that Amazon Rekognition Video analyzed. <code>Videometadata</code> is returned in every page of paginated responses from a Amazon Rekognition video operation.</p>
    #[doc(hidden)]
    pub video_metadata: std::option::Option<crate::types::VideoMetadata>,
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of labels.</p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>An array of labels detected in the video. Each element contains the detected label and the time, in milliseconds from the start of the video, that the label was detected. </p>
    #[doc(hidden)]
    pub labels: std::option::Option<std::vec::Vec<crate::types::LabelDetection>>,
    /// <p>Version number of the label detection model that was used to detect labels.</p>
    #[doc(hidden)]
    pub label_model_version: std::option::Option<std::string::String>,
    _request_id: Option<String>,
}
impl GetLabelDetectionOutput {
    /// <p>The current status of the label detection job.</p>
    pub fn job_status(&self) -> std::option::Option<& crate::types::VideoJobStatus> {
        self.job_status.as_ref()
    }
    /// <p>If the job fails, <code>StatusMessage</code> provides a descriptive error message.</p>
    pub fn status_message(&self) -> std::option::Option<& str> {
        self.status_message.as_deref()
    }
    /// <p>Information about a video that Amazon Rekognition Video analyzed. <code>Videometadata</code> is returned in every page of paginated responses from a Amazon Rekognition video operation.</p>
    pub fn video_metadata(&self) -> std::option::Option<& crate::types::VideoMetadata> {
        self.video_metadata.as_ref()
    }
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of labels.</p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>An array of labels detected in the video. Each element contains the detected label and the time, in milliseconds from the start of the video, that the label was detected. </p>
    pub fn labels(&self) -> std::option::Option<& [crate::types::LabelDetection]> {
        self.labels.as_deref()
    }
    /// <p>Version number of the label detection model that was used to detect labels.</p>
    pub fn label_model_version(&self) -> std::option::Option<& str> {
        self.label_model_version.as_deref()
    }
}
impl aws_http::request_id::RequestId for GetLabelDetectionOutput {
                                fn request_id(&self) -> Option<&str> {
                                    self._request_id.as_deref()
                                }
                            }
impl GetLabelDetectionOutput {
    /// Creates a new builder-style object to manufacture [`GetLabelDetectionOutput`](crate::operation::get_label_detection::GetLabelDetectionOutput).
    pub fn builder() -> crate::operation::get_label_detection::builders::GetLabelDetectionOutputBuilder {
        crate::operation::get_label_detection::builders::GetLabelDetectionOutputBuilder::default()
    }
}

/// A builder for [`GetLabelDetectionOutput`](crate::operation::get_label_detection::GetLabelDetectionOutput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct GetLabelDetectionOutputBuilder {
    pub(crate) job_status: std::option::Option<crate::types::VideoJobStatus>,
    pub(crate) status_message: std::option::Option<std::string::String>,
    pub(crate) video_metadata: std::option::Option<crate::types::VideoMetadata>,
    pub(crate) next_token: std::option::Option<std::string::String>,
    pub(crate) labels: std::option::Option<std::vec::Vec<crate::types::LabelDetection>>,
    pub(crate) label_model_version: std::option::Option<std::string::String>,
    _request_id: Option<String>,
}
impl GetLabelDetectionOutputBuilder {
    /// <p>The current status of the label detection job.</p>
    pub fn job_status(mut self, input: crate::types::VideoJobStatus) -> Self {
        self.job_status = Some(input);
        self
    }
    /// <p>The current status of the label detection job.</p>
    pub fn set_job_status(mut self, input: std::option::Option<crate::types::VideoJobStatus>) -> Self {
        self.job_status = input; self
    }
    /// <p>If the job fails, <code>StatusMessage</code> provides a descriptive error message.</p>
    pub fn status_message(mut self, input: impl Into<std::string::String>) -> Self {
        self.status_message = Some(input.into());
        self
    }
    /// <p>If the job fails, <code>StatusMessage</code> provides a descriptive error message.</p>
    pub fn set_status_message(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.status_message = input; self
    }
    /// <p>Information about a video that Amazon Rekognition Video analyzed. <code>Videometadata</code> is returned in every page of paginated responses from a Amazon Rekognition video operation.</p>
    pub fn video_metadata(mut self, input: crate::types::VideoMetadata) -> Self {
        self.video_metadata = Some(input);
        self
    }
    /// <p>Information about a video that Amazon Rekognition Video analyzed. <code>Videometadata</code> is returned in every page of paginated responses from a Amazon Rekognition video operation.</p>
    pub fn set_video_metadata(mut self, input: std::option::Option<crate::types::VideoMetadata>) -> Self {
        self.video_metadata = input; self
    }
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of labels.</p>
    pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
        self.next_token = Some(input.into());
        self
    }
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of labels.</p>
    pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.next_token = input; self
    }
    /// Appends an item to `labels`.
    ///
    /// To override the contents of this collection use [`set_labels`](Self::set_labels).
    ///
    /// <p>An array of labels detected in the video. Each element contains the detected label and the time, in milliseconds from the start of the video, that the label was detected. </p>
    pub fn labels(mut self, input: crate::types::LabelDetection) -> Self {
        let mut v = self.labels.unwrap_or_default();
                        v.push(input);
                        self.labels = Some(v);
                        self
    }
    /// <p>An array of labels detected in the video. Each element contains the detected label and the time, in milliseconds from the start of the video, that the label was detected. </p>
    pub fn set_labels(mut self, input: std::option::Option<std::vec::Vec<crate::types::LabelDetection>>) -> Self {
        self.labels = input; self
    }
    /// <p>Version number of the label detection model that was used to detect labels.</p>
    pub fn label_model_version(mut self, input: impl Into<std::string::String>) -> Self {
        self.label_model_version = Some(input.into());
        self
    }
    /// <p>Version number of the label detection model that was used to detect labels.</p>
    pub fn set_label_model_version(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.label_model_version = input; self
    }
    pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
                                    self._request_id = Some(request_id.into());
                                    self
                                }
    
                                pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
                                    self._request_id = request_id;
                                    self
                                }
    /// Consumes the builder and constructs a [`GetLabelDetectionOutput`](crate::operation::get_label_detection::GetLabelDetectionOutput).
    pub fn build(self) -> crate::operation::get_label_detection::GetLabelDetectionOutput {
        crate::operation::get_label_detection::GetLabelDetectionOutput {
            job_status: self.job_status
            ,
            status_message: self.status_message
            ,
            video_metadata: self.video_metadata
            ,
            next_token: self.next_token
            ,
            labels: self.labels
            ,
            label_model_version: self.label_model_version
            ,
            _request_id: self._request_id,
        }
    }
}

