// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
use std::fmt::Write;

/// See [`CompareFacesInput`](crate::input::CompareFacesInput).
pub mod compare_faces_input {
    
    /// A builder for [`CompareFacesInput`](crate::input::CompareFacesInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) source_image: std::option::Option<crate::model::Image>,
        pub(crate) target_image: std::option::Option<crate::model::Image>,
        pub(crate) similarity_threshold: std::option::Option<f32>,
        pub(crate) quality_filter: std::option::Option<crate::model::QualityFilter>,
    }
    impl Builder {
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn source_image(mut self, input: crate::model::Image) -> Self {
            self.source_image = Some(input);
            self
        }
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn set_source_image(mut self, input: std::option::Option<crate::model::Image>) -> Self {
            self.source_image = input; self
        }
        /// <p>The target image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn target_image(mut self, input: crate::model::Image) -> Self {
            self.target_image = Some(input);
            self
        }
        /// <p>The target image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn set_target_image(mut self, input: std::option::Option<crate::model::Image>) -> Self {
            self.target_image = input; self
        }
        /// <p>The minimum level of confidence in the face matches that a match must meet to be included in the <code>FaceMatches</code> array.</p>
        pub fn similarity_threshold(mut self, input: f32) -> Self {
            self.similarity_threshold = Some(input);
            self
        }
        /// <p>The minimum level of confidence in the face matches that a match must meet to be included in the <code>FaceMatches</code> array.</p>
        pub fn set_similarity_threshold(mut self, input: std::option::Option<f32>) -> Self {
            self.similarity_threshold = input; self
        }
        /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't compared. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. The default value is <code>NONE</code>. </p> 
        /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
        pub fn quality_filter(mut self, input: crate::model::QualityFilter) -> Self {
            self.quality_filter = Some(input);
            self
        }
        /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't compared. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. The default value is <code>NONE</code>. </p> 
        /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
        pub fn set_quality_filter(mut self, input: std::option::Option<crate::model::QualityFilter>) -> Self {
            self.quality_filter = input; self
        }
        /// Consumes the builder and constructs a [`CompareFacesInput`](crate::input::CompareFacesInput).
        pub fn build(self) -> Result<crate::input::CompareFacesInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::CompareFacesInput {
                    source_image: self.source_image
                    ,
                    target_image: self.target_image
                    ,
                    similarity_threshold: self.similarity_threshold
                    ,
                    quality_filter: self.quality_filter
                    ,
                }
            )
        }
    }
    
    
}
impl CompareFacesInput {
    /// Consumes the builder and constructs an Operation<[`CompareFaces`](crate::operation::CompareFaces)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::CompareFaces, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::CompareFacesInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::CompareFacesInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.CompareFaces"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_compare_faces(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::CompareFaces::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("CompareFaces", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`CompareFacesInput`](crate::input::CompareFacesInput).
    pub fn builder() -> crate::input::compare_faces_input::Builder {
        crate::input::compare_faces_input::Builder::default()
    }
}

/// See [`CopyProjectVersionInput`](crate::input::CopyProjectVersionInput).
pub mod copy_project_version_input {
    
    /// A builder for [`CopyProjectVersionInput`](crate::input::CopyProjectVersionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) source_project_arn: std::option::Option<std::string::String>,
        pub(crate) source_project_version_arn: std::option::Option<std::string::String>,
        pub(crate) destination_project_arn: std::option::Option<std::string::String>,
        pub(crate) version_name: std::option::Option<std::string::String>,
        pub(crate) output_config: std::option::Option<crate::model::OutputConfig>,
        pub(crate) tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
        pub(crate) kms_key_id: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The ARN of the source project in the trusting AWS account.</p>
        pub fn source_project_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.source_project_arn = Some(input.into());
            self
        }
        /// <p>The ARN of the source project in the trusting AWS account.</p>
        pub fn set_source_project_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.source_project_arn = input; self
        }
        /// <p>The ARN of the model version in the source project that you want to copy to a destination project.</p>
        pub fn source_project_version_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.source_project_version_arn = Some(input.into());
            self
        }
        /// <p>The ARN of the model version in the source project that you want to copy to a destination project.</p>
        pub fn set_source_project_version_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.source_project_version_arn = input; self
        }
        /// <p>The ARN of the project in the trusted AWS account that you want to copy the model version to. </p>
        pub fn destination_project_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.destination_project_arn = Some(input.into());
            self
        }
        /// <p>The ARN of the project in the trusted AWS account that you want to copy the model version to. </p>
        pub fn set_destination_project_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.destination_project_arn = input; self
        }
        /// <p>A name for the version of the model that's copied to the destination project.</p>
        pub fn version_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.version_name = Some(input.into());
            self
        }
        /// <p>A name for the version of the model that's copied to the destination project.</p>
        pub fn set_version_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.version_name = input; self
        }
        /// <p>The S3 bucket and folder location where the training output for the source model version is placed.</p>
        pub fn output_config(mut self, input: crate::model::OutputConfig) -> Self {
            self.output_config = Some(input);
            self
        }
        /// <p>The S3 bucket and folder location where the training output for the source model version is placed.</p>
        pub fn set_output_config(mut self, input: std::option::Option<crate::model::OutputConfig>) -> Self {
            self.output_config = input; self
        }
        /// Adds a key-value pair to `tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p>The key-value tags to assign to the model version. </p>
        pub fn tags(mut self, k: impl Into<std::string::String>, v: impl Into<std::string::String>) -> Self {
            let mut hash_map = self.tags.unwrap_or_default();
                            hash_map.insert(k.into(), v.into());
                            self.tags = Some(hash_map);
                            self
        }
        /// <p>The key-value tags to assign to the model version. </p>
        pub fn set_tags(mut self, input: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>) -> Self {
            self.tags = input; self
        }
        /// <p>The identifier for your AWS Key Management Service key (AWS KMS key). You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt training results and manifest files written to the output Amazon S3 bucket (<code>OutputConfig</code>).</p> 
        /// <p>If you choose to use your own KMS key, you need the following permissions on the KMS key.</p> 
        /// <ul> 
        /// <li> <p>kms:CreateGrant</p> </li> 
        /// <li> <p>kms:DescribeKey</p> </li> 
        /// <li> <p>kms:GenerateDataKey</p> </li> 
        /// <li> <p>kms:Decrypt</p> </li> 
        /// </ul> 
        /// <p>If you don't specify a value for <code>KmsKeyId</code>, images copied into the service are encrypted using a key that AWS owns and manages.</p>
        pub fn kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.kms_key_id = Some(input.into());
            self
        }
        /// <p>The identifier for your AWS Key Management Service key (AWS KMS key). You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt training results and manifest files written to the output Amazon S3 bucket (<code>OutputConfig</code>).</p> 
        /// <p>If you choose to use your own KMS key, you need the following permissions on the KMS key.</p> 
        /// <ul> 
        /// <li> <p>kms:CreateGrant</p> </li> 
        /// <li> <p>kms:DescribeKey</p> </li> 
        /// <li> <p>kms:GenerateDataKey</p> </li> 
        /// <li> <p>kms:Decrypt</p> </li> 
        /// </ul> 
        /// <p>If you don't specify a value for <code>KmsKeyId</code>, images copied into the service are encrypted using a key that AWS owns and manages.</p>
        pub fn set_kms_key_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.kms_key_id = input; self
        }
        /// Consumes the builder and constructs a [`CopyProjectVersionInput`](crate::input::CopyProjectVersionInput).
        pub fn build(self) -> Result<crate::input::CopyProjectVersionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::CopyProjectVersionInput {
                    source_project_arn: self.source_project_arn
                    ,
                    source_project_version_arn: self.source_project_version_arn
                    ,
                    destination_project_arn: self.destination_project_arn
                    ,
                    version_name: self.version_name
                    ,
                    output_config: self.output_config
                    ,
                    tags: self.tags
                    ,
                    kms_key_id: self.kms_key_id
                    ,
                }
            )
        }
    }
    
    
}
impl CopyProjectVersionInput {
    /// Consumes the builder and constructs an Operation<[`CopyProjectVersion`](crate::operation::CopyProjectVersion)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::CopyProjectVersion, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::CopyProjectVersionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::CopyProjectVersionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.CopyProjectVersion"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_copy_project_version(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::CopyProjectVersion::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("CopyProjectVersion", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`CopyProjectVersionInput`](crate::input::CopyProjectVersionInput).
    pub fn builder() -> crate::input::copy_project_version_input::Builder {
        crate::input::copy_project_version_input::Builder::default()
    }
}

/// See [`CreateCollectionInput`](crate::input::CreateCollectionInput).
pub mod create_collection_input {
    
    /// A builder for [`CreateCollectionInput`](crate::input::CreateCollectionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) collection_id: std::option::Option<std::string::String>,
        pub(crate) tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    }
    impl Builder {
        /// <p>ID for the collection that you are creating.</p>
        pub fn collection_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.collection_id = Some(input.into());
            self
        }
        /// <p>ID for the collection that you are creating.</p>
        pub fn set_collection_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.collection_id = input; self
        }
        /// Adds a key-value pair to `tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p> A set of tags (key-value pairs) that you want to attach to the collection. </p>
        pub fn tags(mut self, k: impl Into<std::string::String>, v: impl Into<std::string::String>) -> Self {
            let mut hash_map = self.tags.unwrap_or_default();
                            hash_map.insert(k.into(), v.into());
                            self.tags = Some(hash_map);
                            self
        }
        /// <p> A set of tags (key-value pairs) that you want to attach to the collection. </p>
        pub fn set_tags(mut self, input: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>) -> Self {
            self.tags = input; self
        }
        /// Consumes the builder and constructs a [`CreateCollectionInput`](crate::input::CreateCollectionInput).
        pub fn build(self) -> Result<crate::input::CreateCollectionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::CreateCollectionInput {
                    collection_id: self.collection_id
                    ,
                    tags: self.tags
                    ,
                }
            )
        }
    }
    
    
}
impl CreateCollectionInput {
    /// Consumes the builder and constructs an Operation<[`CreateCollection`](crate::operation::CreateCollection)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::CreateCollection, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::CreateCollectionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::CreateCollectionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.CreateCollection"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_create_collection(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::CreateCollection::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("CreateCollection", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`CreateCollectionInput`](crate::input::CreateCollectionInput).
    pub fn builder() -> crate::input::create_collection_input::Builder {
        crate::input::create_collection_input::Builder::default()
    }
}

/// See [`CreateDatasetInput`](crate::input::CreateDatasetInput).
pub mod create_dataset_input {
    
    /// A builder for [`CreateDatasetInput`](crate::input::CreateDatasetInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) dataset_source: std::option::Option<crate::model::DatasetSource>,
        pub(crate) dataset_type: std::option::Option<crate::model::DatasetType>,
        pub(crate) project_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p> The source files for the dataset. You can specify the ARN of an existing dataset or specify the Amazon S3 bucket location of an Amazon Sagemaker format manifest file. If you don't specify <code>datasetSource</code>, an empty dataset is created. To add labeled images to the dataset, You can use the console or call <code>UpdateDatasetEntries</code>. </p>
        pub fn dataset_source(mut self, input: crate::model::DatasetSource) -> Self {
            self.dataset_source = Some(input);
            self
        }
        /// <p> The source files for the dataset. You can specify the ARN of an existing dataset or specify the Amazon S3 bucket location of an Amazon Sagemaker format manifest file. If you don't specify <code>datasetSource</code>, an empty dataset is created. To add labeled images to the dataset, You can use the console or call <code>UpdateDatasetEntries</code>. </p>
        pub fn set_dataset_source(mut self, input: std::option::Option<crate::model::DatasetSource>) -> Self {
            self.dataset_source = input; self
        }
        /// <p> The type of the dataset. Specify <code>train</code> to create a training dataset. Specify <code>test</code> to create a test dataset. </p>
        pub fn dataset_type(mut self, input: crate::model::DatasetType) -> Self {
            self.dataset_type = Some(input);
            self
        }
        /// <p> The type of the dataset. Specify <code>train</code> to create a training dataset. Specify <code>test</code> to create a test dataset. </p>
        pub fn set_dataset_type(mut self, input: std::option::Option<crate::model::DatasetType>) -> Self {
            self.dataset_type = input; self
        }
        /// <p> The ARN of the Amazon Rekognition Custom Labels project to which you want to asssign the dataset. </p>
        pub fn project_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_arn = Some(input.into());
            self
        }
        /// <p> The ARN of the Amazon Rekognition Custom Labels project to which you want to asssign the dataset. </p>
        pub fn set_project_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_arn = input; self
        }
        /// Consumes the builder and constructs a [`CreateDatasetInput`](crate::input::CreateDatasetInput).
        pub fn build(self) -> Result<crate::input::CreateDatasetInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::CreateDatasetInput {
                    dataset_source: self.dataset_source
                    ,
                    dataset_type: self.dataset_type
                    ,
                    project_arn: self.project_arn
                    ,
                }
            )
        }
    }
    
    
}
impl CreateDatasetInput {
    /// Consumes the builder and constructs an Operation<[`CreateDataset`](crate::operation::CreateDataset)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::CreateDataset, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::CreateDatasetInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::CreateDatasetInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.CreateDataset"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_create_dataset(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::CreateDataset::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("CreateDataset", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`CreateDatasetInput`](crate::input::CreateDatasetInput).
    pub fn builder() -> crate::input::create_dataset_input::Builder {
        crate::input::create_dataset_input::Builder::default()
    }
}

/// See [`CreateProjectInput`](crate::input::CreateProjectInput).
pub mod create_project_input {
    
    /// A builder for [`CreateProjectInput`](crate::input::CreateProjectInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) project_name: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the project to create.</p>
        pub fn project_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_name = Some(input.into());
            self
        }
        /// <p>The name of the project to create.</p>
        pub fn set_project_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_name = input; self
        }
        /// Consumes the builder and constructs a [`CreateProjectInput`](crate::input::CreateProjectInput).
        pub fn build(self) -> Result<crate::input::CreateProjectInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::CreateProjectInput {
                    project_name: self.project_name
                    ,
                }
            )
        }
    }
    
    
}
impl CreateProjectInput {
    /// Consumes the builder and constructs an Operation<[`CreateProject`](crate::operation::CreateProject)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::CreateProject, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::CreateProjectInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::CreateProjectInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.CreateProject"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_create_project(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::CreateProject::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("CreateProject", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`CreateProjectInput`](crate::input::CreateProjectInput).
    pub fn builder() -> crate::input::create_project_input::Builder {
        crate::input::create_project_input::Builder::default()
    }
}

/// See [`CreateProjectVersionInput`](crate::input::CreateProjectVersionInput).
pub mod create_project_version_input {
    
    /// A builder for [`CreateProjectVersionInput`](crate::input::CreateProjectVersionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) project_arn: std::option::Option<std::string::String>,
        pub(crate) version_name: std::option::Option<std::string::String>,
        pub(crate) output_config: std::option::Option<crate::model::OutputConfig>,
        pub(crate) training_data: std::option::Option<crate::model::TrainingData>,
        pub(crate) testing_data: std::option::Option<crate::model::TestingData>,
        pub(crate) tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
        pub(crate) kms_key_id: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The ARN of the Amazon Rekognition Custom Labels project that manages the model that you want to train.</p>
        pub fn project_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_arn = Some(input.into());
            self
        }
        /// <p>The ARN of the Amazon Rekognition Custom Labels project that manages the model that you want to train.</p>
        pub fn set_project_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_arn = input; self
        }
        /// <p>A name for the version of the model. This value must be unique.</p>
        pub fn version_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.version_name = Some(input.into());
            self
        }
        /// <p>A name for the version of the model. This value must be unique.</p>
        pub fn set_version_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.version_name = input; self
        }
        /// <p>The Amazon S3 bucket location to store the results of training. The S3 bucket can be in any AWS account as long as the caller has <code>s3:PutObject</code> permissions on the S3 bucket.</p>
        pub fn output_config(mut self, input: crate::model::OutputConfig) -> Self {
            self.output_config = Some(input);
            self
        }
        /// <p>The Amazon S3 bucket location to store the results of training. The S3 bucket can be in any AWS account as long as the caller has <code>s3:PutObject</code> permissions on the S3 bucket.</p>
        pub fn set_output_config(mut self, input: std::option::Option<crate::model::OutputConfig>) -> Self {
            self.output_config = input; self
        }
        /// <p>Specifies an external manifest that the services uses to train the model. If you specify <code>TrainingData</code> you must also specify <code>TestingData</code>. The project must not have any associated datasets. </p>
        pub fn training_data(mut self, input: crate::model::TrainingData) -> Self {
            self.training_data = Some(input);
            self
        }
        /// <p>Specifies an external manifest that the services uses to train the model. If you specify <code>TrainingData</code> you must also specify <code>TestingData</code>. The project must not have any associated datasets. </p>
        pub fn set_training_data(mut self, input: std::option::Option<crate::model::TrainingData>) -> Self {
            self.training_data = input; self
        }
        /// <p>Specifies an external manifest that the service uses to test the model. If you specify <code>TestingData</code> you must also specify <code>TrainingData</code>. The project must not have any associated datasets.</p>
        pub fn testing_data(mut self, input: crate::model::TestingData) -> Self {
            self.testing_data = Some(input);
            self
        }
        /// <p>Specifies an external manifest that the service uses to test the model. If you specify <code>TestingData</code> you must also specify <code>TrainingData</code>. The project must not have any associated datasets.</p>
        pub fn set_testing_data(mut self, input: std::option::Option<crate::model::TestingData>) -> Self {
            self.testing_data = input; self
        }
        /// Adds a key-value pair to `tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p> A set of tags (key-value pairs) that you want to attach to the model. </p>
        pub fn tags(mut self, k: impl Into<std::string::String>, v: impl Into<std::string::String>) -> Self {
            let mut hash_map = self.tags.unwrap_or_default();
                            hash_map.insert(k.into(), v.into());
                            self.tags = Some(hash_map);
                            self
        }
        /// <p> A set of tags (key-value pairs) that you want to attach to the model. </p>
        pub fn set_tags(mut self, input: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>) -> Self {
            self.tags = input; self
        }
        /// <p>The identifier for your AWS Key Management Service key (AWS KMS key). You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt training and test images copied into the service for model training. Your source images are unaffected. The key is also used to encrypt training results and manifest files written to the output Amazon S3 bucket (<code>OutputConfig</code>).</p> 
        /// <p>If you choose to use your own KMS key, you need the following permissions on the KMS key.</p> 
        /// <ul> 
        /// <li> <p>kms:CreateGrant</p> </li> 
        /// <li> <p>kms:DescribeKey</p> </li> 
        /// <li> <p>kms:GenerateDataKey</p> </li> 
        /// <li> <p>kms:Decrypt</p> </li> 
        /// </ul> 
        /// <p>If you don't specify a value for <code>KmsKeyId</code>, images copied into the service are encrypted using a key that AWS owns and manages.</p>
        pub fn kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.kms_key_id = Some(input.into());
            self
        }
        /// <p>The identifier for your AWS Key Management Service key (AWS KMS key). You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt training and test images copied into the service for model training. Your source images are unaffected. The key is also used to encrypt training results and manifest files written to the output Amazon S3 bucket (<code>OutputConfig</code>).</p> 
        /// <p>If you choose to use your own KMS key, you need the following permissions on the KMS key.</p> 
        /// <ul> 
        /// <li> <p>kms:CreateGrant</p> </li> 
        /// <li> <p>kms:DescribeKey</p> </li> 
        /// <li> <p>kms:GenerateDataKey</p> </li> 
        /// <li> <p>kms:Decrypt</p> </li> 
        /// </ul> 
        /// <p>If you don't specify a value for <code>KmsKeyId</code>, images copied into the service are encrypted using a key that AWS owns and manages.</p>
        pub fn set_kms_key_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.kms_key_id = input; self
        }
        /// Consumes the builder and constructs a [`CreateProjectVersionInput`](crate::input::CreateProjectVersionInput).
        pub fn build(self) -> Result<crate::input::CreateProjectVersionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::CreateProjectVersionInput {
                    project_arn: self.project_arn
                    ,
                    version_name: self.version_name
                    ,
                    output_config: self.output_config
                    ,
                    training_data: self.training_data
                    ,
                    testing_data: self.testing_data
                    ,
                    tags: self.tags
                    ,
                    kms_key_id: self.kms_key_id
                    ,
                }
            )
        }
    }
    
    
}
impl CreateProjectVersionInput {
    /// Consumes the builder and constructs an Operation<[`CreateProjectVersion`](crate::operation::CreateProjectVersion)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::CreateProjectVersion, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::CreateProjectVersionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::CreateProjectVersionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.CreateProjectVersion"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_create_project_version(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::CreateProjectVersion::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("CreateProjectVersion", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`CreateProjectVersionInput`](crate::input::CreateProjectVersionInput).
    pub fn builder() -> crate::input::create_project_version_input::Builder {
        crate::input::create_project_version_input::Builder::default()
    }
}

/// See [`CreateStreamProcessorInput`](crate::input::CreateStreamProcessorInput).
pub mod create_stream_processor_input {
    
    /// A builder for [`CreateStreamProcessorInput`](crate::input::CreateStreamProcessorInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) input: std::option::Option<crate::model::StreamProcessorInput>,
        pub(crate) output: std::option::Option<crate::model::StreamProcessorOutput>,
        pub(crate) name: std::option::Option<std::string::String>,
        pub(crate) settings: std::option::Option<crate::model::StreamProcessorSettings>,
        pub(crate) role_arn: std::option::Option<std::string::String>,
        pub(crate) tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
        pub(crate) notification_channel: std::option::Option<crate::model::StreamProcessorNotificationChannel>,
        pub(crate) kms_key_id: std::option::Option<std::string::String>,
        pub(crate) regions_of_interest: std::option::Option<std::vec::Vec<crate::model::RegionOfInterest>>,
        pub(crate) data_sharing_preference: std::option::Option<crate::model::StreamProcessorDataSharingPreference>,
    }
    impl Builder {
        /// <p>Kinesis video stream stream that provides the source streaming video. If you are using the AWS CLI, the parameter name is <code>StreamProcessorInput</code>. This is required for both face search and label detection stream processors.</p>
        pub fn input(mut self, input: crate::model::StreamProcessorInput) -> Self {
            self.input = Some(input);
            self
        }
        /// <p>Kinesis video stream stream that provides the source streaming video. If you are using the AWS CLI, the parameter name is <code>StreamProcessorInput</code>. This is required for both face search and label detection stream processors.</p>
        pub fn set_input(mut self, input: std::option::Option<crate::model::StreamProcessorInput>) -> Self {
            self.input = input; self
        }
        /// <p>Kinesis data stream stream or Amazon S3 bucket location to which Amazon Rekognition Video puts the analysis results. If you are using the AWS CLI, the parameter name is <code>StreamProcessorOutput</code>. This must be a <code>S3Destination</code> of an Amazon S3 bucket that you own for a label detection stream processor or a Kinesis data stream ARN for a face search stream processor.</p>
        pub fn output(mut self, input: crate::model::StreamProcessorOutput) -> Self {
            self.output = Some(input);
            self
        }
        /// <p>Kinesis data stream stream or Amazon S3 bucket location to which Amazon Rekognition Video puts the analysis results. If you are using the AWS CLI, the parameter name is <code>StreamProcessorOutput</code>. This must be a <code>S3Destination</code> of an Amazon S3 bucket that you own for a label detection stream processor or a Kinesis data stream ARN for a face search stream processor.</p>
        pub fn set_output(mut self, input: std::option::Option<crate::model::StreamProcessorOutput>) -> Self {
            self.output = input; self
        }
        /// <p>An identifier you assign to the stream processor. You can use <code>Name</code> to manage the stream processor. For example, you can get the current status of the stream processor by calling <code>DescribeStreamProcessor</code>. <code>Name</code> is idempotent. This is required for both face search and label detection stream processors. </p>
        pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
            self.name = Some(input.into());
            self
        }
        /// <p>An identifier you assign to the stream processor. You can use <code>Name</code> to manage the stream processor. For example, you can get the current status of the stream processor by calling <code>DescribeStreamProcessor</code>. <code>Name</code> is idempotent. This is required for both face search and label detection stream processors. </p>
        pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.name = input; self
        }
        /// <p>Input parameters used in a streaming video analyzed by a stream processor. You can use <code>FaceSearch</code> to recognize faces in a streaming video, or you can use <code>ConnectedHome</code> to detect labels.</p>
        pub fn settings(mut self, input: crate::model::StreamProcessorSettings) -> Self {
            self.settings = Some(input);
            self
        }
        /// <p>Input parameters used in a streaming video analyzed by a stream processor. You can use <code>FaceSearch</code> to recognize faces in a streaming video, or you can use <code>ConnectedHome</code> to detect labels.</p>
        pub fn set_settings(mut self, input: std::option::Option<crate::model::StreamProcessorSettings>) -> Self {
            self.settings = input; self
        }
        /// <p>The Amazon Resource Number (ARN) of the IAM role that allows access to the stream processor. The IAM role provides Rekognition read permissions for a Kinesis stream. It also provides write permissions to an Amazon S3 bucket and Amazon Simple Notification Service topic for a label detection stream processor. This is required for both face search and label detection stream processors.</p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.role_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Number (ARN) of the IAM role that allows access to the stream processor. The IAM role provides Rekognition read permissions for a Kinesis stream. It also provides write permissions to an Amazon S3 bucket and Amazon Simple Notification Service topic for a label detection stream processor. This is required for both face search and label detection stream processors.</p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.role_arn = input; self
        }
        /// Adds a key-value pair to `tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p> A set of tags (key-value pairs) that you want to attach to the stream processor. </p>
        pub fn tags(mut self, k: impl Into<std::string::String>, v: impl Into<std::string::String>) -> Self {
            let mut hash_map = self.tags.unwrap_or_default();
                            hash_map.insert(k.into(), v.into());
                            self.tags = Some(hash_map);
                            self
        }
        /// <p> A set of tags (key-value pairs) that you want to attach to the stream processor. </p>
        pub fn set_tags(mut self, input: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>) -> Self {
            self.tags = input; self
        }
        /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the object detection results and completion status of a video analysis operation.</p> 
        /// <p>Amazon Rekognition publishes a notification the first time an object of interest or a person is detected in the video stream. For example, if Amazon Rekognition detects a person at second 2, a pet at second 4, and a person again at second 5, Amazon Rekognition sends 2 object class detected notifications, one for a person at second 2 and one for a pet at second 4.</p> 
        /// <p>Amazon Rekognition also publishes an an end-of-session notification with a summary when the stream processing session is complete.</p>
        pub fn notification_channel(mut self, input: crate::model::StreamProcessorNotificationChannel) -> Self {
            self.notification_channel = Some(input);
            self
        }
        /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the object detection results and completion status of a video analysis operation.</p> 
        /// <p>Amazon Rekognition publishes a notification the first time an object of interest or a person is detected in the video stream. For example, if Amazon Rekognition detects a person at second 2, a pet at second 4, and a person again at second 5, Amazon Rekognition sends 2 object class detected notifications, one for a person at second 2 and one for a pet at second 4.</p> 
        /// <p>Amazon Rekognition also publishes an an end-of-session notification with a summary when the stream processing session is complete.</p>
        pub fn set_notification_channel(mut self, input: std::option::Option<crate::model::StreamProcessorNotificationChannel>) -> Self {
            self.notification_channel = input; self
        }
        /// <p> The identifier for your AWS Key Management Service key (AWS KMS key). This is an optional parameter for label detection stream processors and should not be used to create a face search stream processor. You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt results and data published to your Amazon S3 bucket, which includes image frames and hero images. Your source images are unaffected. </p> 
        /// <p> </p>
        pub fn kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.kms_key_id = Some(input.into());
            self
        }
        /// <p> The identifier for your AWS Key Management Service key (AWS KMS key). This is an optional parameter for label detection stream processors and should not be used to create a face search stream processor. You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt results and data published to your Amazon S3 bucket, which includes image frames and hero images. Your source images are unaffected. </p> 
        /// <p> </p>
        pub fn set_kms_key_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.kms_key_id = input; self
        }
        /// Appends an item to `regions_of_interest`.
        ///
        /// To override the contents of this collection use [`set_regions_of_interest`](Self::set_regions_of_interest).
        ///
        /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. You can specify up to 10 regions of interest, and each region has either a polygon or a bounding box. This is an optional parameter for label detection stream processors and should not be used to create a face search stream processor. </p>
        pub fn regions_of_interest(mut self, input: crate::model::RegionOfInterest) -> Self {
            let mut v = self.regions_of_interest.unwrap_or_default();
                            v.push(input);
                            self.regions_of_interest = Some(v);
                            self
        }
        /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. You can specify up to 10 regions of interest, and each region has either a polygon or a bounding box. This is an optional parameter for label detection stream processors and should not be used to create a face search stream processor. </p>
        pub fn set_regions_of_interest(mut self, input: std::option::Option<std::vec::Vec<crate::model::RegionOfInterest>>) -> Self {
            self.regions_of_interest = input; self
        }
        /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
        pub fn data_sharing_preference(mut self, input: crate::model::StreamProcessorDataSharingPreference) -> Self {
            self.data_sharing_preference = Some(input);
            self
        }
        /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
        pub fn set_data_sharing_preference(mut self, input: std::option::Option<crate::model::StreamProcessorDataSharingPreference>) -> Self {
            self.data_sharing_preference = input; self
        }
        /// Consumes the builder and constructs a [`CreateStreamProcessorInput`](crate::input::CreateStreamProcessorInput).
        pub fn build(self) -> Result<crate::input::CreateStreamProcessorInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::CreateStreamProcessorInput {
                    input: self.input
                    ,
                    output: self.output
                    ,
                    name: self.name
                    ,
                    settings: self.settings
                    ,
                    role_arn: self.role_arn
                    ,
                    tags: self.tags
                    ,
                    notification_channel: self.notification_channel
                    ,
                    kms_key_id: self.kms_key_id
                    ,
                    regions_of_interest: self.regions_of_interest
                    ,
                    data_sharing_preference: self.data_sharing_preference
                    ,
                }
            )
        }
    }
    
    
}
impl CreateStreamProcessorInput {
    /// Consumes the builder and constructs an Operation<[`CreateStreamProcessor`](crate::operation::CreateStreamProcessor)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::CreateStreamProcessor, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::CreateStreamProcessorInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::CreateStreamProcessorInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.CreateStreamProcessor"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_create_stream_processor(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::CreateStreamProcessor::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("CreateStreamProcessor", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`CreateStreamProcessorInput`](crate::input::CreateStreamProcessorInput).
    pub fn builder() -> crate::input::create_stream_processor_input::Builder {
        crate::input::create_stream_processor_input::Builder::default()
    }
}

/// See [`DeleteCollectionInput`](crate::input::DeleteCollectionInput).
pub mod delete_collection_input {
    
    /// A builder for [`DeleteCollectionInput`](crate::input::DeleteCollectionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) collection_id: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>ID of the collection to delete.</p>
        pub fn collection_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.collection_id = Some(input.into());
            self
        }
        /// <p>ID of the collection to delete.</p>
        pub fn set_collection_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.collection_id = input; self
        }
        /// Consumes the builder and constructs a [`DeleteCollectionInput`](crate::input::DeleteCollectionInput).
        pub fn build(self) -> Result<crate::input::DeleteCollectionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DeleteCollectionInput {
                    collection_id: self.collection_id
                    ,
                }
            )
        }
    }
    
    
}
impl DeleteCollectionInput {
    /// Consumes the builder and constructs an Operation<[`DeleteCollection`](crate::operation::DeleteCollection)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DeleteCollection, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DeleteCollectionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DeleteCollectionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DeleteCollection"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_delete_collection(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DeleteCollection::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DeleteCollection", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DeleteCollectionInput`](crate::input::DeleteCollectionInput).
    pub fn builder() -> crate::input::delete_collection_input::Builder {
        crate::input::delete_collection_input::Builder::default()
    }
}

/// See [`DeleteDatasetInput`](crate::input::DeleteDatasetInput).
pub mod delete_dataset_input {
    
    /// A builder for [`DeleteDatasetInput`](crate::input::DeleteDatasetInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p> The ARN of the Amazon Rekognition Custom Labels dataset that you want to delete. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p> The ARN of the Amazon Rekognition Custom Labels dataset that you want to delete. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input; self
        }
        /// Consumes the builder and constructs a [`DeleteDatasetInput`](crate::input::DeleteDatasetInput).
        pub fn build(self) -> Result<crate::input::DeleteDatasetInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DeleteDatasetInput {
                    dataset_arn: self.dataset_arn
                    ,
                }
            )
        }
    }
    
    
}
impl DeleteDatasetInput {
    /// Consumes the builder and constructs an Operation<[`DeleteDataset`](crate::operation::DeleteDataset)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DeleteDataset, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DeleteDatasetInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DeleteDatasetInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DeleteDataset"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_delete_dataset(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DeleteDataset::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DeleteDataset", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DeleteDatasetInput`](crate::input::DeleteDatasetInput).
    pub fn builder() -> crate::input::delete_dataset_input::Builder {
        crate::input::delete_dataset_input::Builder::default()
    }
}

/// See [`DeleteFacesInput`](crate::input::DeleteFacesInput).
pub mod delete_faces_input {
    
    /// A builder for [`DeleteFacesInput`](crate::input::DeleteFacesInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) collection_id: std::option::Option<std::string::String>,
        pub(crate) face_ids: std::option::Option<std::vec::Vec<std::string::String>>,
    }
    impl Builder {
        /// <p>Collection from which to remove the specific faces.</p>
        pub fn collection_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.collection_id = Some(input.into());
            self
        }
        /// <p>Collection from which to remove the specific faces.</p>
        pub fn set_collection_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.collection_id = input; self
        }
        /// Appends an item to `face_ids`.
        ///
        /// To override the contents of this collection use [`set_face_ids`](Self::set_face_ids).
        ///
        /// <p>An array of face IDs to delete.</p>
        pub fn face_ids(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.face_ids.unwrap_or_default();
                            v.push(input.into());
                            self.face_ids = Some(v);
                            self
        }
        /// <p>An array of face IDs to delete.</p>
        pub fn set_face_ids(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.face_ids = input; self
        }
        /// Consumes the builder and constructs a [`DeleteFacesInput`](crate::input::DeleteFacesInput).
        pub fn build(self) -> Result<crate::input::DeleteFacesInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DeleteFacesInput {
                    collection_id: self.collection_id
                    ,
                    face_ids: self.face_ids
                    ,
                }
            )
        }
    }
    
    
}
impl DeleteFacesInput {
    /// Consumes the builder and constructs an Operation<[`DeleteFaces`](crate::operation::DeleteFaces)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DeleteFaces, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DeleteFacesInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DeleteFacesInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DeleteFaces"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_delete_faces(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DeleteFaces::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DeleteFaces", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DeleteFacesInput`](crate::input::DeleteFacesInput).
    pub fn builder() -> crate::input::delete_faces_input::Builder {
        crate::input::delete_faces_input::Builder::default()
    }
}

/// See [`DeleteProjectInput`](crate::input::DeleteProjectInput).
pub mod delete_project_input {
    
    /// A builder for [`DeleteProjectInput`](crate::input::DeleteProjectInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) project_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the project that you want to delete.</p>
        pub fn project_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the project that you want to delete.</p>
        pub fn set_project_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_arn = input; self
        }
        /// Consumes the builder and constructs a [`DeleteProjectInput`](crate::input::DeleteProjectInput).
        pub fn build(self) -> Result<crate::input::DeleteProjectInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DeleteProjectInput {
                    project_arn: self.project_arn
                    ,
                }
            )
        }
    }
    
    
}
impl DeleteProjectInput {
    /// Consumes the builder and constructs an Operation<[`DeleteProject`](crate::operation::DeleteProject)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DeleteProject, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DeleteProjectInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DeleteProjectInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DeleteProject"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_delete_project(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DeleteProject::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DeleteProject", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DeleteProjectInput`](crate::input::DeleteProjectInput).
    pub fn builder() -> crate::input::delete_project_input::Builder {
        crate::input::delete_project_input::Builder::default()
    }
}

/// See [`DeleteProjectPolicyInput`](crate::input::DeleteProjectPolicyInput).
pub mod delete_project_policy_input {
    
    /// A builder for [`DeleteProjectPolicyInput`](crate::input::DeleteProjectPolicyInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) project_arn: std::option::Option<std::string::String>,
        pub(crate) policy_name: std::option::Option<std::string::String>,
        pub(crate) policy_revision_id: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the project that the project policy you want to delete is attached to.</p>
        pub fn project_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the project that the project policy you want to delete is attached to.</p>
        pub fn set_project_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_arn = input; self
        }
        /// <p>The name of the policy that you want to delete.</p>
        pub fn policy_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.policy_name = Some(input.into());
            self
        }
        /// <p>The name of the policy that you want to delete.</p>
        pub fn set_policy_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.policy_name = input; self
        }
        /// <p>The ID of the project policy revision that you want to delete.</p>
        pub fn policy_revision_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.policy_revision_id = Some(input.into());
            self
        }
        /// <p>The ID of the project policy revision that you want to delete.</p>
        pub fn set_policy_revision_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.policy_revision_id = input; self
        }
        /// Consumes the builder and constructs a [`DeleteProjectPolicyInput`](crate::input::DeleteProjectPolicyInput).
        pub fn build(self) -> Result<crate::input::DeleteProjectPolicyInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DeleteProjectPolicyInput {
                    project_arn: self.project_arn
                    ,
                    policy_name: self.policy_name
                    ,
                    policy_revision_id: self.policy_revision_id
                    ,
                }
            )
        }
    }
    
    
}
impl DeleteProjectPolicyInput {
    /// Consumes the builder and constructs an Operation<[`DeleteProjectPolicy`](crate::operation::DeleteProjectPolicy)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DeleteProjectPolicy, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DeleteProjectPolicyInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DeleteProjectPolicyInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DeleteProjectPolicy"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_delete_project_policy(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DeleteProjectPolicy::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DeleteProjectPolicy", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DeleteProjectPolicyInput`](crate::input::DeleteProjectPolicyInput).
    pub fn builder() -> crate::input::delete_project_policy_input::Builder {
        crate::input::delete_project_policy_input::Builder::default()
    }
}

/// See [`DeleteProjectVersionInput`](crate::input::DeleteProjectVersionInput).
pub mod delete_project_version_input {
    
    /// A builder for [`DeleteProjectVersionInput`](crate::input::DeleteProjectVersionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) project_version_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the model version that you want to delete.</p>
        pub fn project_version_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_version_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the model version that you want to delete.</p>
        pub fn set_project_version_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_version_arn = input; self
        }
        /// Consumes the builder and constructs a [`DeleteProjectVersionInput`](crate::input::DeleteProjectVersionInput).
        pub fn build(self) -> Result<crate::input::DeleteProjectVersionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DeleteProjectVersionInput {
                    project_version_arn: self.project_version_arn
                    ,
                }
            )
        }
    }
    
    
}
impl DeleteProjectVersionInput {
    /// Consumes the builder and constructs an Operation<[`DeleteProjectVersion`](crate::operation::DeleteProjectVersion)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DeleteProjectVersion, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DeleteProjectVersionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DeleteProjectVersionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DeleteProjectVersion"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_delete_project_version(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DeleteProjectVersion::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DeleteProjectVersion", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DeleteProjectVersionInput`](crate::input::DeleteProjectVersionInput).
    pub fn builder() -> crate::input::delete_project_version_input::Builder {
        crate::input::delete_project_version_input::Builder::default()
    }
}

/// See [`DeleteStreamProcessorInput`](crate::input::DeleteStreamProcessorInput).
pub mod delete_stream_processor_input {
    
    /// A builder for [`DeleteStreamProcessorInput`](crate::input::DeleteStreamProcessorInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) name: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the stream processor you want to delete.</p>
        pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
            self.name = Some(input.into());
            self
        }
        /// <p>The name of the stream processor you want to delete.</p>
        pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.name = input; self
        }
        /// Consumes the builder and constructs a [`DeleteStreamProcessorInput`](crate::input::DeleteStreamProcessorInput).
        pub fn build(self) -> Result<crate::input::DeleteStreamProcessorInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DeleteStreamProcessorInput {
                    name: self.name
                    ,
                }
            )
        }
    }
    
    
}
impl DeleteStreamProcessorInput {
    /// Consumes the builder and constructs an Operation<[`DeleteStreamProcessor`](crate::operation::DeleteStreamProcessor)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DeleteStreamProcessor, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DeleteStreamProcessorInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DeleteStreamProcessorInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DeleteStreamProcessor"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_delete_stream_processor(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DeleteStreamProcessor::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DeleteStreamProcessor", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DeleteStreamProcessorInput`](crate::input::DeleteStreamProcessorInput).
    pub fn builder() -> crate::input::delete_stream_processor_input::Builder {
        crate::input::delete_stream_processor_input::Builder::default()
    }
}

/// See [`DescribeCollectionInput`](crate::input::DescribeCollectionInput).
pub mod describe_collection_input {
    
    /// A builder for [`DescribeCollectionInput`](crate::input::DescribeCollectionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) collection_id: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The ID of the collection to describe.</p>
        pub fn collection_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.collection_id = Some(input.into());
            self
        }
        /// <p>The ID of the collection to describe.</p>
        pub fn set_collection_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.collection_id = input; self
        }
        /// Consumes the builder and constructs a [`DescribeCollectionInput`](crate::input::DescribeCollectionInput).
        pub fn build(self) -> Result<crate::input::DescribeCollectionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DescribeCollectionInput {
                    collection_id: self.collection_id
                    ,
                }
            )
        }
    }
    
    
}
impl DescribeCollectionInput {
    /// Consumes the builder and constructs an Operation<[`DescribeCollection`](crate::operation::DescribeCollection)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DescribeCollection, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DescribeCollectionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DescribeCollectionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DescribeCollection"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_describe_collection(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DescribeCollection::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DescribeCollection", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DescribeCollectionInput`](crate::input::DescribeCollectionInput).
    pub fn builder() -> crate::input::describe_collection_input::Builder {
        crate::input::describe_collection_input::Builder::default()
    }
}

/// See [`DescribeDatasetInput`](crate::input::DescribeDatasetInput).
pub mod describe_dataset_input {
    
    /// A builder for [`DescribeDatasetInput`](crate::input::DescribeDatasetInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p> The Amazon Resource Name (ARN) of the dataset that you want to describe. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) of the dataset that you want to describe. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input; self
        }
        /// Consumes the builder and constructs a [`DescribeDatasetInput`](crate::input::DescribeDatasetInput).
        pub fn build(self) -> Result<crate::input::DescribeDatasetInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DescribeDatasetInput {
                    dataset_arn: self.dataset_arn
                    ,
                }
            )
        }
    }
    
    
}
impl DescribeDatasetInput {
    /// Consumes the builder and constructs an Operation<[`DescribeDataset`](crate::operation::DescribeDataset)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DescribeDataset, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DescribeDatasetInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DescribeDatasetInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DescribeDataset"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_describe_dataset(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DescribeDataset::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DescribeDataset", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DescribeDatasetInput`](crate::input::DescribeDatasetInput).
    pub fn builder() -> crate::input::describe_dataset_input::Builder {
        crate::input::describe_dataset_input::Builder::default()
    }
}

/// See [`DescribeProjectsInput`](crate::input::DescribeProjectsInput).
pub mod describe_projects_input {
    
    /// A builder for [`DescribeProjectsInput`](crate::input::DescribeProjectsInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
        pub(crate) project_names: std::option::Option<std::vec::Vec<std::string::String>>,
    }
    impl Builder {
        /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// Appends an item to `project_names`.
        ///
        /// To override the contents of this collection use [`set_project_names`](Self::set_project_names).
        ///
        /// <p>A list of the projects that you want Amazon Rekognition Custom Labels to describe. If you don't specify a value, the response includes descriptions for all the projects in your AWS account.</p>
        pub fn project_names(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.project_names.unwrap_or_default();
                            v.push(input.into());
                            self.project_names = Some(v);
                            self
        }
        /// <p>A list of the projects that you want Amazon Rekognition Custom Labels to describe. If you don't specify a value, the response includes descriptions for all the projects in your AWS account.</p>
        pub fn set_project_names(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.project_names = input; self
        }
        /// Consumes the builder and constructs a [`DescribeProjectsInput`](crate::input::DescribeProjectsInput).
        pub fn build(self) -> Result<crate::input::DescribeProjectsInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DescribeProjectsInput {
                    next_token: self.next_token
                    ,
                    max_results: self.max_results
                    ,
                    project_names: self.project_names
                    ,
                }
            )
        }
    }
    
    
}
impl DescribeProjectsInput {
    /// Consumes the builder and constructs an Operation<[`DescribeProjects`](crate::operation::DescribeProjects)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DescribeProjects, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DescribeProjectsInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DescribeProjectsInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DescribeProjects"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_describe_projects(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DescribeProjects::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DescribeProjects", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DescribeProjectsInput`](crate::input::DescribeProjectsInput).
    pub fn builder() -> crate::input::describe_projects_input::Builder {
        crate::input::describe_projects_input::Builder::default()
    }
}

/// See [`DescribeProjectVersionsInput`](crate::input::DescribeProjectVersionsInput).
pub mod describe_project_versions_input {
    
    /// A builder for [`DescribeProjectVersionsInput`](crate::input::DescribeProjectVersionsInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) project_arn: std::option::Option<std::string::String>,
        pub(crate) version_names: std::option::Option<std::vec::Vec<std::string::String>>,
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the project that contains the models you want to describe.</p>
        pub fn project_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the project that contains the models you want to describe.</p>
        pub fn set_project_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_arn = input; self
        }
        /// Appends an item to `version_names`.
        ///
        /// To override the contents of this collection use [`set_version_names`](Self::set_version_names).
        ///
        /// <p>A list of model version names that you want to describe. You can add up to 10 model version names to the list. If you don't specify a value, all model descriptions are returned. A version name is part of a model (ProjectVersion) ARN. For example, <code>my-model.2020-01-21T09.10.15</code> is the version name in the following ARN. <code>arn:aws:rekognition:us-east-1:123456789012:project/getting-started/version/<i>my-model.2020-01-21T09.10.15</i>/1234567890123</code>.</p>
        pub fn version_names(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.version_names.unwrap_or_default();
                            v.push(input.into());
                            self.version_names = Some(v);
                            self
        }
        /// <p>A list of model version names that you want to describe. You can add up to 10 model version names to the list. If you don't specify a value, all model descriptions are returned. A version name is part of a model (ProjectVersion) ARN. For example, <code>my-model.2020-01-21T09.10.15</code> is the version name in the following ARN. <code>arn:aws:rekognition:us-east-1:123456789012:project/getting-started/version/<i>my-model.2020-01-21T09.10.15</i>/1234567890123</code>.</p>
        pub fn set_version_names(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.version_names = input; self
        }
        /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// Consumes the builder and constructs a [`DescribeProjectVersionsInput`](crate::input::DescribeProjectVersionsInput).
        pub fn build(self) -> Result<crate::input::DescribeProjectVersionsInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DescribeProjectVersionsInput {
                    project_arn: self.project_arn
                    ,
                    version_names: self.version_names
                    ,
                    next_token: self.next_token
                    ,
                    max_results: self.max_results
                    ,
                }
            )
        }
    }
    
    
}
impl DescribeProjectVersionsInput {
    /// Consumes the builder and constructs an Operation<[`DescribeProjectVersions`](crate::operation::DescribeProjectVersions)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DescribeProjectVersions, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DescribeProjectVersionsInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DescribeProjectVersionsInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DescribeProjectVersions"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_describe_project_versions(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DescribeProjectVersions::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DescribeProjectVersions", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DescribeProjectVersionsInput`](crate::input::DescribeProjectVersionsInput).
    pub fn builder() -> crate::input::describe_project_versions_input::Builder {
        crate::input::describe_project_versions_input::Builder::default()
    }
}

/// See [`DescribeStreamProcessorInput`](crate::input::DescribeStreamProcessorInput).
pub mod describe_stream_processor_input {
    
    /// A builder for [`DescribeStreamProcessorInput`](crate::input::DescribeStreamProcessorInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) name: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>Name of the stream processor for which you want information.</p>
        pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
            self.name = Some(input.into());
            self
        }
        /// <p>Name of the stream processor for which you want information.</p>
        pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.name = input; self
        }
        /// Consumes the builder and constructs a [`DescribeStreamProcessorInput`](crate::input::DescribeStreamProcessorInput).
        pub fn build(self) -> Result<crate::input::DescribeStreamProcessorInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DescribeStreamProcessorInput {
                    name: self.name
                    ,
                }
            )
        }
    }
    
    
}
impl DescribeStreamProcessorInput {
    /// Consumes the builder and constructs an Operation<[`DescribeStreamProcessor`](crate::operation::DescribeStreamProcessor)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DescribeStreamProcessor, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DescribeStreamProcessorInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DescribeStreamProcessorInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DescribeStreamProcessor"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_describe_stream_processor(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DescribeStreamProcessor::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DescribeStreamProcessor", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DescribeStreamProcessorInput`](crate::input::DescribeStreamProcessorInput).
    pub fn builder() -> crate::input::describe_stream_processor_input::Builder {
        crate::input::describe_stream_processor_input::Builder::default()
    }
}

/// See [`DetectCustomLabelsInput`](crate::input::DetectCustomLabelsInput).
pub mod detect_custom_labels_input {
    
    /// A builder for [`DetectCustomLabelsInput`](crate::input::DetectCustomLabelsInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) project_version_arn: std::option::Option<std::string::String>,
        pub(crate) image: std::option::Option<crate::model::Image>,
        pub(crate) max_results: std::option::Option<i32>,
        pub(crate) min_confidence: std::option::Option<f32>,
    }
    impl Builder {
        /// <p>The ARN of the model version that you want to use.</p>
        pub fn project_version_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_version_arn = Some(input.into());
            self
        }
        /// <p>The ARN of the model version that you want to use.</p>
        pub fn set_project_version_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_version_arn = input; self
        }
        /// <p>Provides the input image either as bytes or an S3 object.</p> 
        /// <p>You pass image bytes to an Amazon Rekognition API operation by using the <code>Bytes</code> property. For example, you would use the <code>Bytes</code> property to pass an image loaded from a local file system. Image bytes passed by using the <code>Bytes</code> property must be base64-encoded. Your code may not need to encode image bytes if you are using an AWS SDK to call Amazon Rekognition API operations. </p> 
        /// <p>For more information, see Analyzing an Image Loaded from a Local File System in the Amazon Rekognition Developer Guide.</p> 
        /// <p> You pass images stored in an S3 bucket to an Amazon Rekognition API operation by using the <code>S3Object</code> property. Images stored in an S3 bucket do not need to be base64-encoded.</p> 
        /// <p>The region for the S3 bucket containing the S3 object must match the region you use for Amazon Rekognition operations.</p> 
        /// <p>If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes using the Bytes property is not supported. You must first upload the image to an Amazon S3 bucket and then call the operation using the S3Object property.</p> 
        /// <p>For Amazon Rekognition to process an S3 object, the user must have permission to access the S3 object. For more information, see How Amazon Rekognition works with IAM in the Amazon Rekognition Developer Guide. </p>
        pub fn image(mut self, input: crate::model::Image) -> Self {
            self.image = Some(input);
            self
        }
        /// <p>Provides the input image either as bytes or an S3 object.</p> 
        /// <p>You pass image bytes to an Amazon Rekognition API operation by using the <code>Bytes</code> property. For example, you would use the <code>Bytes</code> property to pass an image loaded from a local file system. Image bytes passed by using the <code>Bytes</code> property must be base64-encoded. Your code may not need to encode image bytes if you are using an AWS SDK to call Amazon Rekognition API operations. </p> 
        /// <p>For more information, see Analyzing an Image Loaded from a Local File System in the Amazon Rekognition Developer Guide.</p> 
        /// <p> You pass images stored in an S3 bucket to an Amazon Rekognition API operation by using the <code>S3Object</code> property. Images stored in an S3 bucket do not need to be base64-encoded.</p> 
        /// <p>The region for the S3 bucket containing the S3 object must match the region you use for Amazon Rekognition operations.</p> 
        /// <p>If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes using the Bytes property is not supported. You must first upload the image to an Amazon S3 bucket and then call the operation using the S3Object property.</p> 
        /// <p>For Amazon Rekognition to process an S3 object, the user must have permission to access the S3 object. For more information, see How Amazon Rekognition works with IAM in the Amazon Rekognition Developer Guide. </p>
        pub fn set_image(mut self, input: std::option::Option<crate::model::Image>) -> Self {
            self.image = input; self
        }
        /// <p>Maximum number of results you want the service to return in the response. The service returns the specified number of highest confidence labels ranked from highest confidence to lowest.</p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of results you want the service to return in the response. The service returns the specified number of highest confidence labels ranked from highest confidence to lowest.</p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// <p>Specifies the minimum confidence level for the labels to return. <code>DetectCustomLabels</code> doesn't return any labels with a confidence value that's lower than this specified value. If you specify a value of 0, <code>DetectCustomLabels</code> returns all labels, regardless of the assumed threshold applied to each label. If you don't specify a value for <code>MinConfidence</code>, <code>DetectCustomLabels</code> returns labels based on the assumed threshold of each label.</p>
        pub fn min_confidence(mut self, input: f32) -> Self {
            self.min_confidence = Some(input);
            self
        }
        /// <p>Specifies the minimum confidence level for the labels to return. <code>DetectCustomLabels</code> doesn't return any labels with a confidence value that's lower than this specified value. If you specify a value of 0, <code>DetectCustomLabels</code> returns all labels, regardless of the assumed threshold applied to each label. If you don't specify a value for <code>MinConfidence</code>, <code>DetectCustomLabels</code> returns labels based on the assumed threshold of each label.</p>
        pub fn set_min_confidence(mut self, input: std::option::Option<f32>) -> Self {
            self.min_confidence = input; self
        }
        /// Consumes the builder and constructs a [`DetectCustomLabelsInput`](crate::input::DetectCustomLabelsInput).
        pub fn build(self) -> Result<crate::input::DetectCustomLabelsInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DetectCustomLabelsInput {
                    project_version_arn: self.project_version_arn
                    ,
                    image: self.image
                    ,
                    max_results: self.max_results
                    ,
                    min_confidence: self.min_confidence
                    ,
                }
            )
        }
    }
    
    
}
impl DetectCustomLabelsInput {
    /// Consumes the builder and constructs an Operation<[`DetectCustomLabels`](crate::operation::DetectCustomLabels)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DetectCustomLabels, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DetectCustomLabelsInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DetectCustomLabelsInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DetectCustomLabels"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_detect_custom_labels(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DetectCustomLabels::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DetectCustomLabels", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DetectCustomLabelsInput`](crate::input::DetectCustomLabelsInput).
    pub fn builder() -> crate::input::detect_custom_labels_input::Builder {
        crate::input::detect_custom_labels_input::Builder::default()
    }
}

/// See [`DetectFacesInput`](crate::input::DetectFacesInput).
pub mod detect_faces_input {
    
    /// A builder for [`DetectFacesInput`](crate::input::DetectFacesInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) image: std::option::Option<crate::model::Image>,
        pub(crate) attributes: std::option::Option<std::vec::Vec<crate::model::Attribute>>,
    }
    impl Builder {
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn image(mut self, input: crate::model::Image) -> Self {
            self.image = Some(input);
            self
        }
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn set_image(mut self, input: std::option::Option<crate::model::Image>) -> Self {
            self.image = input; self
        }
        /// Appends an item to `attributes`.
        ///
        /// To override the contents of this collection use [`set_attributes`](Self::set_attributes).
        ///
        /// <p>An array of facial attributes you want to be returned. This can be the default list of attributes or all attributes. If you don't specify a value for <code>Attributes</code> or if you specify <code>["DEFAULT"]</code>, the API returns the following subset of facial attributes: <code>BoundingBox</code>, <code>Confidence</code>, <code>Pose</code>, <code>Quality</code>, and <code>Landmarks</code>. If you provide <code>["ALL"]</code>, all facial attributes are returned, but the operation takes longer to complete.</p> 
        /// <p>If you provide both, <code>["ALL", "DEFAULT"]</code>, the service uses a logical AND operator to determine which attributes to return (in this case, all attributes). </p>
        pub fn attributes(mut self, input: crate::model::Attribute) -> Self {
            let mut v = self.attributes.unwrap_or_default();
                            v.push(input);
                            self.attributes = Some(v);
                            self
        }
        /// <p>An array of facial attributes you want to be returned. This can be the default list of attributes or all attributes. If you don't specify a value for <code>Attributes</code> or if you specify <code>["DEFAULT"]</code>, the API returns the following subset of facial attributes: <code>BoundingBox</code>, <code>Confidence</code>, <code>Pose</code>, <code>Quality</code>, and <code>Landmarks</code>. If you provide <code>["ALL"]</code>, all facial attributes are returned, but the operation takes longer to complete.</p> 
        /// <p>If you provide both, <code>["ALL", "DEFAULT"]</code>, the service uses a logical AND operator to determine which attributes to return (in this case, all attributes). </p>
        pub fn set_attributes(mut self, input: std::option::Option<std::vec::Vec<crate::model::Attribute>>) -> Self {
            self.attributes = input; self
        }
        /// Consumes the builder and constructs a [`DetectFacesInput`](crate::input::DetectFacesInput).
        pub fn build(self) -> Result<crate::input::DetectFacesInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DetectFacesInput {
                    image: self.image
                    ,
                    attributes: self.attributes
                    ,
                }
            )
        }
    }
    
    
}
impl DetectFacesInput {
    /// Consumes the builder and constructs an Operation<[`DetectFaces`](crate::operation::DetectFaces)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DetectFaces, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DetectFacesInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DetectFacesInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DetectFaces"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_detect_faces(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DetectFaces::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DetectFaces", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DetectFacesInput`](crate::input::DetectFacesInput).
    pub fn builder() -> crate::input::detect_faces_input::Builder {
        crate::input::detect_faces_input::Builder::default()
    }
}

/// See [`DetectLabelsInput`](crate::input::DetectLabelsInput).
pub mod detect_labels_input {
    
    /// A builder for [`DetectLabelsInput`](crate::input::DetectLabelsInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) image: std::option::Option<crate::model::Image>,
        pub(crate) max_labels: std::option::Option<i32>,
        pub(crate) min_confidence: std::option::Option<f32>,
        pub(crate) features: std::option::Option<std::vec::Vec<crate::model::DetectLabelsFeatureName>>,
        pub(crate) settings: std::option::Option<crate::model::DetectLabelsSettings>,
    }
    impl Builder {
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. Images stored in an S3 Bucket do not need to be base64-encoded.</p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn image(mut self, input: crate::model::Image) -> Self {
            self.image = Some(input);
            self
        }
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. Images stored in an S3 Bucket do not need to be base64-encoded.</p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn set_image(mut self, input: std::option::Option<crate::model::Image>) -> Self {
            self.image = input; self
        }
        /// <p>Maximum number of labels you want the service to return in the response. The service returns the specified number of highest confidence labels. </p>
        pub fn max_labels(mut self, input: i32) -> Self {
            self.max_labels = Some(input);
            self
        }
        /// <p>Maximum number of labels you want the service to return in the response. The service returns the specified number of highest confidence labels. </p>
        pub fn set_max_labels(mut self, input: std::option::Option<i32>) -> Self {
            self.max_labels = input; self
        }
        /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with confidence lower than this specified value.</p> 
        /// <p>If <code>MinConfidence</code> is not specified, the operation returns labels with a confidence values greater than or equal to 55 percent.</p>
        pub fn min_confidence(mut self, input: f32) -> Self {
            self.min_confidence = Some(input);
            self
        }
        /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with confidence lower than this specified value.</p> 
        /// <p>If <code>MinConfidence</code> is not specified, the operation returns labels with a confidence values greater than or equal to 55 percent.</p>
        pub fn set_min_confidence(mut self, input: std::option::Option<f32>) -> Self {
            self.min_confidence = input; self
        }
        /// Appends an item to `features`.
        ///
        /// To override the contents of this collection use [`set_features`](Self::set_features).
        ///
        /// <p>A list of the types of analysis to perform. Specifying GENERAL_LABELS uses the label detection feature, while specifying IMAGE_PROPERTIES returns information regarding image color and quality. If no option is specified GENERAL_LABELS is used by default.</p>
        pub fn features(mut self, input: crate::model::DetectLabelsFeatureName) -> Self {
            let mut v = self.features.unwrap_or_default();
                            v.push(input);
                            self.features = Some(v);
                            self
        }
        /// <p>A list of the types of analysis to perform. Specifying GENERAL_LABELS uses the label detection feature, while specifying IMAGE_PROPERTIES returns information regarding image color and quality. If no option is specified GENERAL_LABELS is used by default.</p>
        pub fn set_features(mut self, input: std::option::Option<std::vec::Vec<crate::model::DetectLabelsFeatureName>>) -> Self {
            self.features = input; self
        }
        /// <p>A list of the filters to be applied to returned detected labels and image properties. Specified filters can be inclusive, exclusive, or a combination of both. Filters can be used for individual labels or label categories. The exact label names or label categories must be supplied. For a full list of labels and label categories, see LINK HERE.</p>
        pub fn settings(mut self, input: crate::model::DetectLabelsSettings) -> Self {
            self.settings = Some(input);
            self
        }
        /// <p>A list of the filters to be applied to returned detected labels and image properties. Specified filters can be inclusive, exclusive, or a combination of both. Filters can be used for individual labels or label categories. The exact label names or label categories must be supplied. For a full list of labels and label categories, see LINK HERE.</p>
        pub fn set_settings(mut self, input: std::option::Option<crate::model::DetectLabelsSettings>) -> Self {
            self.settings = input; self
        }
        /// Consumes the builder and constructs a [`DetectLabelsInput`](crate::input::DetectLabelsInput).
        pub fn build(self) -> Result<crate::input::DetectLabelsInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DetectLabelsInput {
                    image: self.image
                    ,
                    max_labels: self.max_labels
                    ,
                    min_confidence: self.min_confidence
                    ,
                    features: self.features
                    ,
                    settings: self.settings
                    ,
                }
            )
        }
    }
    
    
}
impl DetectLabelsInput {
    /// Consumes the builder and constructs an Operation<[`DetectLabels`](crate::operation::DetectLabels)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DetectLabels, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DetectLabelsInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DetectLabelsInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DetectLabels"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_detect_labels(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DetectLabels::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DetectLabels", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DetectLabelsInput`](crate::input::DetectLabelsInput).
    pub fn builder() -> crate::input::detect_labels_input::Builder {
        crate::input::detect_labels_input::Builder::default()
    }
}

/// See [`DetectModerationLabelsInput`](crate::input::DetectModerationLabelsInput).
pub mod detect_moderation_labels_input {
    
    /// A builder for [`DetectModerationLabelsInput`](crate::input::DetectModerationLabelsInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) image: std::option::Option<crate::model::Image>,
        pub(crate) min_confidence: std::option::Option<f32>,
        pub(crate) human_loop_config: std::option::Option<crate::model::HumanLoopConfig>,
    }
    impl Builder {
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn image(mut self, input: crate::model::Image) -> Self {
            self.image = Some(input);
            self
        }
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn set_image(mut self, input: std::option::Option<crate::model::Image>) -> Self {
            self.image = input; self
        }
        /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with a confidence level lower than this specified value.</p> 
        /// <p>If you don't specify <code>MinConfidence</code>, the operation returns labels with confidence values greater than or equal to 50 percent.</p>
        pub fn min_confidence(mut self, input: f32) -> Self {
            self.min_confidence = Some(input);
            self
        }
        /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with a confidence level lower than this specified value.</p> 
        /// <p>If you don't specify <code>MinConfidence</code>, the operation returns labels with confidence values greater than or equal to 50 percent.</p>
        pub fn set_min_confidence(mut self, input: std::option::Option<f32>) -> Self {
            self.min_confidence = input; self
        }
        /// <p>Sets up the configuration for human evaluation, including the FlowDefinition the image will be sent to.</p>
        pub fn human_loop_config(mut self, input: crate::model::HumanLoopConfig) -> Self {
            self.human_loop_config = Some(input);
            self
        }
        /// <p>Sets up the configuration for human evaluation, including the FlowDefinition the image will be sent to.</p>
        pub fn set_human_loop_config(mut self, input: std::option::Option<crate::model::HumanLoopConfig>) -> Self {
            self.human_loop_config = input; self
        }
        /// Consumes the builder and constructs a [`DetectModerationLabelsInput`](crate::input::DetectModerationLabelsInput).
        pub fn build(self) -> Result<crate::input::DetectModerationLabelsInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DetectModerationLabelsInput {
                    image: self.image
                    ,
                    min_confidence: self.min_confidence
                    ,
                    human_loop_config: self.human_loop_config
                    ,
                }
            )
        }
    }
    
    
}
impl DetectModerationLabelsInput {
    /// Consumes the builder and constructs an Operation<[`DetectModerationLabels`](crate::operation::DetectModerationLabels)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DetectModerationLabels, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DetectModerationLabelsInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DetectModerationLabelsInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DetectModerationLabels"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_detect_moderation_labels(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DetectModerationLabels::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DetectModerationLabels", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DetectModerationLabelsInput`](crate::input::DetectModerationLabelsInput).
    pub fn builder() -> crate::input::detect_moderation_labels_input::Builder {
        crate::input::detect_moderation_labels_input::Builder::default()
    }
}

/// See [`DetectProtectiveEquipmentInput`](crate::input::DetectProtectiveEquipmentInput).
pub mod detect_protective_equipment_input {
    
    /// A builder for [`DetectProtectiveEquipmentInput`](crate::input::DetectProtectiveEquipmentInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) image: std::option::Option<crate::model::Image>,
        pub(crate) summarization_attributes: std::option::Option<crate::model::ProtectiveEquipmentSummarizationAttributes>,
    }
    impl Builder {
        /// <p>The image in which you want to detect PPE on detected persons. The image can be passed as image bytes or you can reference an image stored in an Amazon S3 bucket. </p>
        pub fn image(mut self, input: crate::model::Image) -> Self {
            self.image = Some(input);
            self
        }
        /// <p>The image in which you want to detect PPE on detected persons. The image can be passed as image bytes or you can reference an image stored in an Amazon S3 bucket. </p>
        pub fn set_image(mut self, input: std::option::Option<crate::model::Image>) -> Self {
            self.image = input; self
        }
        /// <p>An array of PPE types that you want to summarize.</p>
        pub fn summarization_attributes(mut self, input: crate::model::ProtectiveEquipmentSummarizationAttributes) -> Self {
            self.summarization_attributes = Some(input);
            self
        }
        /// <p>An array of PPE types that you want to summarize.</p>
        pub fn set_summarization_attributes(mut self, input: std::option::Option<crate::model::ProtectiveEquipmentSummarizationAttributes>) -> Self {
            self.summarization_attributes = input; self
        }
        /// Consumes the builder and constructs a [`DetectProtectiveEquipmentInput`](crate::input::DetectProtectiveEquipmentInput).
        pub fn build(self) -> Result<crate::input::DetectProtectiveEquipmentInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DetectProtectiveEquipmentInput {
                    image: self.image
                    ,
                    summarization_attributes: self.summarization_attributes
                    ,
                }
            )
        }
    }
    
    
}
impl DetectProtectiveEquipmentInput {
    /// Consumes the builder and constructs an Operation<[`DetectProtectiveEquipment`](crate::operation::DetectProtectiveEquipment)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DetectProtectiveEquipment, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DetectProtectiveEquipmentInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DetectProtectiveEquipmentInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DetectProtectiveEquipment"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_detect_protective_equipment(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DetectProtectiveEquipment::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DetectProtectiveEquipment", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DetectProtectiveEquipmentInput`](crate::input::DetectProtectiveEquipmentInput).
    pub fn builder() -> crate::input::detect_protective_equipment_input::Builder {
        crate::input::detect_protective_equipment_input::Builder::default()
    }
}

/// See [`DetectTextInput`](crate::input::DetectTextInput).
pub mod detect_text_input {
    
    /// A builder for [`DetectTextInput`](crate::input::DetectTextInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) image: std::option::Option<crate::model::Image>,
        pub(crate) filters: std::option::Option<crate::model::DetectTextFilters>,
    }
    impl Builder {
        /// <p>The input image as base64-encoded bytes or an Amazon S3 object. If you use the AWS CLI to call Amazon Rekognition operations, you can't pass image bytes. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn image(mut self, input: crate::model::Image) -> Self {
            self.image = Some(input);
            self
        }
        /// <p>The input image as base64-encoded bytes or an Amazon S3 object. If you use the AWS CLI to call Amazon Rekognition operations, you can't pass image bytes. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn set_image(mut self, input: std::option::Option<crate::model::Image>) -> Self {
            self.image = input; self
        }
        /// <p>Optional parameters that let you set the criteria that the text must meet to be included in your response.</p>
        pub fn filters(mut self, input: crate::model::DetectTextFilters) -> Self {
            self.filters = Some(input);
            self
        }
        /// <p>Optional parameters that let you set the criteria that the text must meet to be included in your response.</p>
        pub fn set_filters(mut self, input: std::option::Option<crate::model::DetectTextFilters>) -> Self {
            self.filters = input; self
        }
        /// Consumes the builder and constructs a [`DetectTextInput`](crate::input::DetectTextInput).
        pub fn build(self) -> Result<crate::input::DetectTextInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DetectTextInput {
                    image: self.image
                    ,
                    filters: self.filters
                    ,
                }
            )
        }
    }
    
    
}
impl DetectTextInput {
    /// Consumes the builder and constructs an Operation<[`DetectText`](crate::operation::DetectText)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DetectText, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DetectTextInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DetectTextInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DetectText"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_detect_text(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DetectText::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DetectText", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DetectTextInput`](crate::input::DetectTextInput).
    pub fn builder() -> crate::input::detect_text_input::Builder {
        crate::input::detect_text_input::Builder::default()
    }
}

/// See [`DistributeDatasetEntriesInput`](crate::input::DistributeDatasetEntriesInput).
pub mod distribute_dataset_entries_input {
    
    /// A builder for [`DistributeDatasetEntriesInput`](crate::input::DistributeDatasetEntriesInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) datasets: std::option::Option<std::vec::Vec<crate::model::DistributeDataset>>,
    }
    impl Builder {
        /// Appends an item to `datasets`.
        ///
        /// To override the contents of this collection use [`set_datasets`](Self::set_datasets).
        ///
        /// <p>The ARNS for the training dataset and test dataset that you want to use. The datasets must belong to the same project. The test dataset must be empty. </p>
        pub fn datasets(mut self, input: crate::model::DistributeDataset) -> Self {
            let mut v = self.datasets.unwrap_or_default();
                            v.push(input);
                            self.datasets = Some(v);
                            self
        }
        /// <p>The ARNS for the training dataset and test dataset that you want to use. The datasets must belong to the same project. The test dataset must be empty. </p>
        pub fn set_datasets(mut self, input: std::option::Option<std::vec::Vec<crate::model::DistributeDataset>>) -> Self {
            self.datasets = input; self
        }
        /// Consumes the builder and constructs a [`DistributeDatasetEntriesInput`](crate::input::DistributeDatasetEntriesInput).
        pub fn build(self) -> Result<crate::input::DistributeDatasetEntriesInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::DistributeDatasetEntriesInput {
                    datasets: self.datasets
                    ,
                }
            )
        }
    }
    
    
}
impl DistributeDatasetEntriesInput {
    /// Consumes the builder and constructs an Operation<[`DistributeDatasetEntries`](crate::operation::DistributeDatasetEntries)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::DistributeDatasetEntries, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::DistributeDatasetEntriesInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::DistributeDatasetEntriesInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.DistributeDatasetEntries"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_distribute_dataset_entries(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::DistributeDatasetEntries::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("DistributeDatasetEntries", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`DistributeDatasetEntriesInput`](crate::input::DistributeDatasetEntriesInput).
    pub fn builder() -> crate::input::distribute_dataset_entries_input::Builder {
        crate::input::distribute_dataset_entries_input::Builder::default()
    }
}

/// See [`GetCelebrityInfoInput`](crate::input::GetCelebrityInfoInput).
pub mod get_celebrity_info_input {
    
    /// A builder for [`GetCelebrityInfoInput`](crate::input::GetCelebrityInfoInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) id: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The ID for the celebrity. You get the celebrity ID from a call to the <code>RecognizeCelebrities</code> operation, which recognizes celebrities in an image. </p>
        pub fn id(mut self, input: impl Into<std::string::String>) -> Self {
            self.id = Some(input.into());
            self
        }
        /// <p>The ID for the celebrity. You get the celebrity ID from a call to the <code>RecognizeCelebrities</code> operation, which recognizes celebrities in an image. </p>
        pub fn set_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.id = input; self
        }
        /// Consumes the builder and constructs a [`GetCelebrityInfoInput`](crate::input::GetCelebrityInfoInput).
        pub fn build(self) -> Result<crate::input::GetCelebrityInfoInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::GetCelebrityInfoInput {
                    id: self.id
                    ,
                }
            )
        }
    }
    
    
}
impl GetCelebrityInfoInput {
    /// Consumes the builder and constructs an Operation<[`GetCelebrityInfo`](crate::operation::GetCelebrityInfo)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::GetCelebrityInfo, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::GetCelebrityInfoInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::GetCelebrityInfoInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.GetCelebrityInfo"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_get_celebrity_info(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::GetCelebrityInfo::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("GetCelebrityInfo", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`GetCelebrityInfoInput`](crate::input::GetCelebrityInfoInput).
    pub fn builder() -> crate::input::get_celebrity_info_input::Builder {
        crate::input::get_celebrity_info_input::Builder::default()
    }
}

/// See [`GetCelebrityRecognitionInput`](crate::input::GetCelebrityRecognitionInput).
pub mod get_celebrity_recognition_input {
    
    /// A builder for [`GetCelebrityRecognitionInput`](crate::input::GetCelebrityRecognitionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) sort_by: std::option::Option<crate::model::CelebrityRecognitionSortBy>,
    }
    impl Builder {
        /// <p>Job identifier for the required celebrity recognition analysis. You can get the job identifer from a call to <code>StartCelebrityRecognition</code>.</p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>Job identifier for the required celebrity recognition analysis. You can get the job identifer from a call to <code>StartCelebrityRecognition</code>.</p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input; self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// <p>If the previous response was incomplete (because there is more recognized celebrities to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of celebrities. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there is more recognized celebrities to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of celebrities. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>Sort to use for celebrities returned in <code>Celebrities</code> field. Specify <code>ID</code> to sort by the celebrity identifier, specify <code>TIMESTAMP</code> to sort by the time the celebrity was recognized.</p>
        pub fn sort_by(mut self, input: crate::model::CelebrityRecognitionSortBy) -> Self {
            self.sort_by = Some(input);
            self
        }
        /// <p>Sort to use for celebrities returned in <code>Celebrities</code> field. Specify <code>ID</code> to sort by the celebrity identifier, specify <code>TIMESTAMP</code> to sort by the time the celebrity was recognized.</p>
        pub fn set_sort_by(mut self, input: std::option::Option<crate::model::CelebrityRecognitionSortBy>) -> Self {
            self.sort_by = input; self
        }
        /// Consumes the builder and constructs a [`GetCelebrityRecognitionInput`](crate::input::GetCelebrityRecognitionInput).
        pub fn build(self) -> Result<crate::input::GetCelebrityRecognitionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::GetCelebrityRecognitionInput {
                    job_id: self.job_id
                    ,
                    max_results: self.max_results
                    ,
                    next_token: self.next_token
                    ,
                    sort_by: self.sort_by
                    ,
                }
            )
        }
    }
    
    
}
impl GetCelebrityRecognitionInput {
    /// Consumes the builder and constructs an Operation<[`GetCelebrityRecognition`](crate::operation::GetCelebrityRecognition)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::GetCelebrityRecognition, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::GetCelebrityRecognitionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::GetCelebrityRecognitionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.GetCelebrityRecognition"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_get_celebrity_recognition(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::GetCelebrityRecognition::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("GetCelebrityRecognition", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`GetCelebrityRecognitionInput`](crate::input::GetCelebrityRecognitionInput).
    pub fn builder() -> crate::input::get_celebrity_recognition_input::Builder {
        crate::input::get_celebrity_recognition_input::Builder::default()
    }
}

/// See [`GetContentModerationInput`](crate::input::GetContentModerationInput).
pub mod get_content_moderation_input {
    
    /// A builder for [`GetContentModerationInput`](crate::input::GetContentModerationInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) sort_by: std::option::Option<crate::model::ContentModerationSortBy>,
    }
    impl Builder {
        /// <p>The identifier for the inappropriate, unwanted, or offensive content moderation job. Use <code>JobId</code> to identify the job in a subsequent call to <code>GetContentModeration</code>.</p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>The identifier for the inappropriate, unwanted, or offensive content moderation job. Use <code>JobId</code> to identify the job in a subsequent call to <code>GetContentModeration</code>.</p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input; self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// <p>If the previous response was incomplete (because there is more data to retrieve), Amazon Rekognition returns a pagination token in the response. You can use this pagination token to retrieve the next set of content moderation labels.</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there is more data to retrieve), Amazon Rekognition returns a pagination token in the response. You can use this pagination token to retrieve the next set of content moderation labels.</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>Sort to use for elements in the <code>ModerationLabelDetections</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time labels are detected. Use <code>NAME</code> to alphabetically group elements for a label together. Within each label group, the array element are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
        pub fn sort_by(mut self, input: crate::model::ContentModerationSortBy) -> Self {
            self.sort_by = Some(input);
            self
        }
        /// <p>Sort to use for elements in the <code>ModerationLabelDetections</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time labels are detected. Use <code>NAME</code> to alphabetically group elements for a label together. Within each label group, the array element are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
        pub fn set_sort_by(mut self, input: std::option::Option<crate::model::ContentModerationSortBy>) -> Self {
            self.sort_by = input; self
        }
        /// Consumes the builder and constructs a [`GetContentModerationInput`](crate::input::GetContentModerationInput).
        pub fn build(self) -> Result<crate::input::GetContentModerationInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::GetContentModerationInput {
                    job_id: self.job_id
                    ,
                    max_results: self.max_results
                    ,
                    next_token: self.next_token
                    ,
                    sort_by: self.sort_by
                    ,
                }
            )
        }
    }
    
    
}
impl GetContentModerationInput {
    /// Consumes the builder and constructs an Operation<[`GetContentModeration`](crate::operation::GetContentModeration)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::GetContentModeration, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::GetContentModerationInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::GetContentModerationInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.GetContentModeration"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_get_content_moderation(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::GetContentModeration::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("GetContentModeration", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`GetContentModerationInput`](crate::input::GetContentModerationInput).
    pub fn builder() -> crate::input::get_content_moderation_input::Builder {
        crate::input::get_content_moderation_input::Builder::default()
    }
}

/// See [`GetFaceDetectionInput`](crate::input::GetFaceDetectionInput).
pub mod get_face_detection_input {
    
    /// A builder for [`GetFaceDetectionInput`](crate::input::GetFaceDetectionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
        pub(crate) next_token: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>Unique identifier for the face detection job. The <code>JobId</code> is returned from <code>StartFaceDetection</code>.</p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>Unique identifier for the face detection job. The <code>JobId</code> is returned from <code>StartFaceDetection</code>.</p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input; self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// <p>If the previous response was incomplete (because there are more faces to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of faces.</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there are more faces to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of faces.</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// Consumes the builder and constructs a [`GetFaceDetectionInput`](crate::input::GetFaceDetectionInput).
        pub fn build(self) -> Result<crate::input::GetFaceDetectionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::GetFaceDetectionInput {
                    job_id: self.job_id
                    ,
                    max_results: self.max_results
                    ,
                    next_token: self.next_token
                    ,
                }
            )
        }
    }
    
    
}
impl GetFaceDetectionInput {
    /// Consumes the builder and constructs an Operation<[`GetFaceDetection`](crate::operation::GetFaceDetection)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::GetFaceDetection, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::GetFaceDetectionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::GetFaceDetectionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.GetFaceDetection"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_get_face_detection(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::GetFaceDetection::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("GetFaceDetection", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`GetFaceDetectionInput`](crate::input::GetFaceDetectionInput).
    pub fn builder() -> crate::input::get_face_detection_input::Builder {
        crate::input::get_face_detection_input::Builder::default()
    }
}

/// See [`GetFaceSearchInput`](crate::input::GetFaceSearchInput).
pub mod get_face_search_input {
    
    /// A builder for [`GetFaceSearchInput`](crate::input::GetFaceSearchInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) sort_by: std::option::Option<crate::model::FaceSearchSortBy>,
    }
    impl Builder {
        /// <p>The job identifer for the search request. You get the job identifier from an initial call to <code>StartFaceSearch</code>.</p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>The job identifer for the search request. You get the job identifier from an initial call to <code>StartFaceSearch</code>.</p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input; self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// <p>If the previous response was incomplete (because there is more search results to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of search results. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there is more search results to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of search results. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>Sort to use for grouping faces in the response. Use <code>TIMESTAMP</code> to group faces by the time that they are recognized. Use <code>INDEX</code> to sort by recognized faces. </p>
        pub fn sort_by(mut self, input: crate::model::FaceSearchSortBy) -> Self {
            self.sort_by = Some(input);
            self
        }
        /// <p>Sort to use for grouping faces in the response. Use <code>TIMESTAMP</code> to group faces by the time that they are recognized. Use <code>INDEX</code> to sort by recognized faces. </p>
        pub fn set_sort_by(mut self, input: std::option::Option<crate::model::FaceSearchSortBy>) -> Self {
            self.sort_by = input; self
        }
        /// Consumes the builder and constructs a [`GetFaceSearchInput`](crate::input::GetFaceSearchInput).
        pub fn build(self) -> Result<crate::input::GetFaceSearchInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::GetFaceSearchInput {
                    job_id: self.job_id
                    ,
                    max_results: self.max_results
                    ,
                    next_token: self.next_token
                    ,
                    sort_by: self.sort_by
                    ,
                }
            )
        }
    }
    
    
}
impl GetFaceSearchInput {
    /// Consumes the builder and constructs an Operation<[`GetFaceSearch`](crate::operation::GetFaceSearch)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::GetFaceSearch, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::GetFaceSearchInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::GetFaceSearchInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.GetFaceSearch"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_get_face_search(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::GetFaceSearch::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("GetFaceSearch", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`GetFaceSearchInput`](crate::input::GetFaceSearchInput).
    pub fn builder() -> crate::input::get_face_search_input::Builder {
        crate::input::get_face_search_input::Builder::default()
    }
}

/// See [`GetLabelDetectionInput`](crate::input::GetLabelDetectionInput).
pub mod get_label_detection_input {
    
    /// A builder for [`GetLabelDetectionInput`](crate::input::GetLabelDetectionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) sort_by: std::option::Option<crate::model::LabelDetectionSortBy>,
        pub(crate) aggregate_by: std::option::Option<crate::model::LabelDetectionAggregateBy>,
    }
    impl Builder {
        /// <p>Job identifier for the label detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartlabelDetection</code>.</p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>Job identifier for the label detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartlabelDetection</code>.</p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input; self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// <p>If the previous response was incomplete (because there are more labels to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of labels. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there are more labels to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of labels. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>Sort to use for elements in the <code>Labels</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time labels are detected. Use <code>NAME</code> to alphabetically group elements for a label together. Within each label group, the array element are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
        pub fn sort_by(mut self, input: crate::model::LabelDetectionSortBy) -> Self {
            self.sort_by = Some(input);
            self
        }
        /// <p>Sort to use for elements in the <code>Labels</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time labels are detected. Use <code>NAME</code> to alphabetically group elements for a label together. Within each label group, the array element are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
        pub fn set_sort_by(mut self, input: std::option::Option<crate::model::LabelDetectionSortBy>) -> Self {
            self.sort_by = input; self
        }
        /// <p>Defines how to aggregate the returned results. Results can be aggregated by timestamps or segments.</p>
        pub fn aggregate_by(mut self, input: crate::model::LabelDetectionAggregateBy) -> Self {
            self.aggregate_by = Some(input);
            self
        }
        /// <p>Defines how to aggregate the returned results. Results can be aggregated by timestamps or segments.</p>
        pub fn set_aggregate_by(mut self, input: std::option::Option<crate::model::LabelDetectionAggregateBy>) -> Self {
            self.aggregate_by = input; self
        }
        /// Consumes the builder and constructs a [`GetLabelDetectionInput`](crate::input::GetLabelDetectionInput).
        pub fn build(self) -> Result<crate::input::GetLabelDetectionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::GetLabelDetectionInput {
                    job_id: self.job_id
                    ,
                    max_results: self.max_results
                    ,
                    next_token: self.next_token
                    ,
                    sort_by: self.sort_by
                    ,
                    aggregate_by: self.aggregate_by
                    ,
                }
            )
        }
    }
    
    
}
impl GetLabelDetectionInput {
    /// Consumes the builder and constructs an Operation<[`GetLabelDetection`](crate::operation::GetLabelDetection)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::GetLabelDetection, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::GetLabelDetectionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::GetLabelDetectionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.GetLabelDetection"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_get_label_detection(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::GetLabelDetection::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("GetLabelDetection", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`GetLabelDetectionInput`](crate::input::GetLabelDetectionInput).
    pub fn builder() -> crate::input::get_label_detection_input::Builder {
        crate::input::get_label_detection_input::Builder::default()
    }
}

/// See [`GetPersonTrackingInput`](crate::input::GetPersonTrackingInput).
pub mod get_person_tracking_input {
    
    /// A builder for [`GetPersonTrackingInput`](crate::input::GetPersonTrackingInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) sort_by: std::option::Option<crate::model::PersonTrackingSortBy>,
    }
    impl Builder {
        /// <p>The identifier for a job that tracks persons in a video. You get the <code>JobId</code> from a call to <code>StartPersonTracking</code>. </p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>The identifier for a job that tracks persons in a video. You get the <code>JobId</code> from a call to <code>StartPersonTracking</code>. </p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input; self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// <p>If the previous response was incomplete (because there are more persons to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of persons. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there are more persons to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of persons. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>Sort to use for elements in the <code>Persons</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time persons are detected. Use <code>INDEX</code> to sort by the tracked persons. If you sort by <code>INDEX</code>, the array elements for each person are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
        pub fn sort_by(mut self, input: crate::model::PersonTrackingSortBy) -> Self {
            self.sort_by = Some(input);
            self
        }
        /// <p>Sort to use for elements in the <code>Persons</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time persons are detected. Use <code>INDEX</code> to sort by the tracked persons. If you sort by <code>INDEX</code>, the array elements for each person are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
        pub fn set_sort_by(mut self, input: std::option::Option<crate::model::PersonTrackingSortBy>) -> Self {
            self.sort_by = input; self
        }
        /// Consumes the builder and constructs a [`GetPersonTrackingInput`](crate::input::GetPersonTrackingInput).
        pub fn build(self) -> Result<crate::input::GetPersonTrackingInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::GetPersonTrackingInput {
                    job_id: self.job_id
                    ,
                    max_results: self.max_results
                    ,
                    next_token: self.next_token
                    ,
                    sort_by: self.sort_by
                    ,
                }
            )
        }
    }
    
    
}
impl GetPersonTrackingInput {
    /// Consumes the builder and constructs an Operation<[`GetPersonTracking`](crate::operation::GetPersonTracking)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::GetPersonTracking, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::GetPersonTrackingInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::GetPersonTrackingInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.GetPersonTracking"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_get_person_tracking(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::GetPersonTracking::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("GetPersonTracking", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`GetPersonTrackingInput`](crate::input::GetPersonTrackingInput).
    pub fn builder() -> crate::input::get_person_tracking_input::Builder {
        crate::input::get_person_tracking_input::Builder::default()
    }
}

/// See [`GetSegmentDetectionInput`](crate::input::GetSegmentDetectionInput).
pub mod get_segment_detection_input {
    
    /// A builder for [`GetSegmentDetectionInput`](crate::input::GetSegmentDetectionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
        pub(crate) next_token: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartSegmentDetection</code>.</p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartSegmentDetection</code>.</p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input; self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of text.</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of text.</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// Consumes the builder and constructs a [`GetSegmentDetectionInput`](crate::input::GetSegmentDetectionInput).
        pub fn build(self) -> Result<crate::input::GetSegmentDetectionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::GetSegmentDetectionInput {
                    job_id: self.job_id
                    ,
                    max_results: self.max_results
                    ,
                    next_token: self.next_token
                    ,
                }
            )
        }
    }
    
    
}
impl GetSegmentDetectionInput {
    /// Consumes the builder and constructs an Operation<[`GetSegmentDetection`](crate::operation::GetSegmentDetection)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::GetSegmentDetection, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::GetSegmentDetectionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::GetSegmentDetectionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.GetSegmentDetection"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_get_segment_detection(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::GetSegmentDetection::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("GetSegmentDetection", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`GetSegmentDetectionInput`](crate::input::GetSegmentDetectionInput).
    pub fn builder() -> crate::input::get_segment_detection_input::Builder {
        crate::input::get_segment_detection_input::Builder::default()
    }
}

/// See [`GetTextDetectionInput`](crate::input::GetTextDetectionInput).
pub mod get_text_detection_input {
    
    /// A builder for [`GetTextDetectionInput`](crate::input::GetTextDetectionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
        pub(crate) next_token: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartTextDetection</code>.</p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartTextDetection</code>.</p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input; self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// <p>If the previous response was incomplete (because there are more labels to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of text.</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there are more labels to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of text.</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// Consumes the builder and constructs a [`GetTextDetectionInput`](crate::input::GetTextDetectionInput).
        pub fn build(self) -> Result<crate::input::GetTextDetectionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::GetTextDetectionInput {
                    job_id: self.job_id
                    ,
                    max_results: self.max_results
                    ,
                    next_token: self.next_token
                    ,
                }
            )
        }
    }
    
    
}
impl GetTextDetectionInput {
    /// Consumes the builder and constructs an Operation<[`GetTextDetection`](crate::operation::GetTextDetection)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::GetTextDetection, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::GetTextDetectionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::GetTextDetectionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.GetTextDetection"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_get_text_detection(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::GetTextDetection::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("GetTextDetection", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`GetTextDetectionInput`](crate::input::GetTextDetectionInput).
    pub fn builder() -> crate::input::get_text_detection_input::Builder {
        crate::input::get_text_detection_input::Builder::default()
    }
}

/// See [`IndexFacesInput`](crate::input::IndexFacesInput).
pub mod index_faces_input {
    
    /// A builder for [`IndexFacesInput`](crate::input::IndexFacesInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) collection_id: std::option::Option<std::string::String>,
        pub(crate) image: std::option::Option<crate::model::Image>,
        pub(crate) external_image_id: std::option::Option<std::string::String>,
        pub(crate) detection_attributes: std::option::Option<std::vec::Vec<crate::model::Attribute>>,
        pub(crate) max_faces: std::option::Option<i32>,
        pub(crate) quality_filter: std::option::Option<crate::model::QualityFilter>,
    }
    impl Builder {
        /// <p>The ID of an existing collection to which you want to add the faces that are detected in the input images.</p>
        pub fn collection_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.collection_id = Some(input.into());
            self
        }
        /// <p>The ID of an existing collection to which you want to add the faces that are detected in the input images.</p>
        pub fn set_collection_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.collection_id = input; self
        }
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes isn't supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn image(mut self, input: crate::model::Image) -> Self {
            self.image = Some(input);
            self
        }
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes isn't supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn set_image(mut self, input: std::option::Option<crate::model::Image>) -> Self {
            self.image = input; self
        }
        /// <p>The ID you want to assign to all the faces detected in the image.</p>
        pub fn external_image_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.external_image_id = Some(input.into());
            self
        }
        /// <p>The ID you want to assign to all the faces detected in the image.</p>
        pub fn set_external_image_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.external_image_id = input; self
        }
        /// Appends an item to `detection_attributes`.
        ///
        /// To override the contents of this collection use [`set_detection_attributes`](Self::set_detection_attributes).
        ///
        /// <p>An array of facial attributes that you want to be returned. This can be the default list of attributes or all attributes. If you don't specify a value for <code>Attributes</code> or if you specify <code>["DEFAULT"]</code>, the API returns the following subset of facial attributes: <code>BoundingBox</code>, <code>Confidence</code>, <code>Pose</code>, <code>Quality</code>, and <code>Landmarks</code>. If you provide <code>["ALL"]</code>, all facial attributes are returned, but the operation takes longer to complete.</p> 
        /// <p>If you provide both, <code>["ALL", "DEFAULT"]</code>, the service uses a logical AND operator to determine which attributes to return (in this case, all attributes). </p>
        pub fn detection_attributes(mut self, input: crate::model::Attribute) -> Self {
            let mut v = self.detection_attributes.unwrap_or_default();
                            v.push(input);
                            self.detection_attributes = Some(v);
                            self
        }
        /// <p>An array of facial attributes that you want to be returned. This can be the default list of attributes or all attributes. If you don't specify a value for <code>Attributes</code> or if you specify <code>["DEFAULT"]</code>, the API returns the following subset of facial attributes: <code>BoundingBox</code>, <code>Confidence</code>, <code>Pose</code>, <code>Quality</code>, and <code>Landmarks</code>. If you provide <code>["ALL"]</code>, all facial attributes are returned, but the operation takes longer to complete.</p> 
        /// <p>If you provide both, <code>["ALL", "DEFAULT"]</code>, the service uses a logical AND operator to determine which attributes to return (in this case, all attributes). </p>
        pub fn set_detection_attributes(mut self, input: std::option::Option<std::vec::Vec<crate::model::Attribute>>) -> Self {
            self.detection_attributes = input; self
        }
        /// <p>The maximum number of faces to index. The value of <code>MaxFaces</code> must be greater than or equal to 1. <code>IndexFaces</code> returns no more than 100 detected faces in an image, even if you specify a larger value for <code>MaxFaces</code>.</p> 
        /// <p>If <code>IndexFaces</code> detects more faces than the value of <code>MaxFaces</code>, the faces with the lowest quality are filtered out first. If there are still more faces than the value of <code>MaxFaces</code>, the faces with the smallest bounding boxes are filtered out (up to the number that's needed to satisfy the value of <code>MaxFaces</code>). Information about the unindexed faces is available in the <code>UnindexedFaces</code> array. </p> 
        /// <p>The faces that are returned by <code>IndexFaces</code> are sorted by the largest face bounding box size to the smallest size, in descending order.</p> 
        /// <p> <code>MaxFaces</code> can be used with a collection associated with any version of the face model.</p>
        pub fn max_faces(mut self, input: i32) -> Self {
            self.max_faces = Some(input);
            self
        }
        /// <p>The maximum number of faces to index. The value of <code>MaxFaces</code> must be greater than or equal to 1. <code>IndexFaces</code> returns no more than 100 detected faces in an image, even if you specify a larger value for <code>MaxFaces</code>.</p> 
        /// <p>If <code>IndexFaces</code> detects more faces than the value of <code>MaxFaces</code>, the faces with the lowest quality are filtered out first. If there are still more faces than the value of <code>MaxFaces</code>, the faces with the smallest bounding boxes are filtered out (up to the number that's needed to satisfy the value of <code>MaxFaces</code>). Information about the unindexed faces is available in the <code>UnindexedFaces</code> array. </p> 
        /// <p>The faces that are returned by <code>IndexFaces</code> are sorted by the largest face bounding box size to the smallest size, in descending order.</p> 
        /// <p> <code>MaxFaces</code> can be used with a collection associated with any version of the face model.</p>
        pub fn set_max_faces(mut self, input: std::option::Option<i32>) -> Self {
            self.max_faces = input; self
        }
        /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't indexed. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The default value is <code>AUTO</code>. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. </p> 
        /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
        pub fn quality_filter(mut self, input: crate::model::QualityFilter) -> Self {
            self.quality_filter = Some(input);
            self
        }
        /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't indexed. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The default value is <code>AUTO</code>. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. </p> 
        /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
        pub fn set_quality_filter(mut self, input: std::option::Option<crate::model::QualityFilter>) -> Self {
            self.quality_filter = input; self
        }
        /// Consumes the builder and constructs a [`IndexFacesInput`](crate::input::IndexFacesInput).
        pub fn build(self) -> Result<crate::input::IndexFacesInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::IndexFacesInput {
                    collection_id: self.collection_id
                    ,
                    image: self.image
                    ,
                    external_image_id: self.external_image_id
                    ,
                    detection_attributes: self.detection_attributes
                    ,
                    max_faces: self.max_faces
                    ,
                    quality_filter: self.quality_filter
                    ,
                }
            )
        }
    }
    
    
}
impl IndexFacesInput {
    /// Consumes the builder and constructs an Operation<[`IndexFaces`](crate::operation::IndexFaces)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::IndexFaces, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::IndexFacesInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::IndexFacesInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.IndexFaces"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_index_faces(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::IndexFaces::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("IndexFaces", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`IndexFacesInput`](crate::input::IndexFacesInput).
    pub fn builder() -> crate::input::index_faces_input::Builder {
        crate::input::index_faces_input::Builder::default()
    }
}

/// See [`ListCollectionsInput`](crate::input::ListCollectionsInput).
pub mod list_collections_input {
    
    /// A builder for [`ListCollectionsInput`](crate::input::ListCollectionsInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>Pagination token from the previous response.</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>Pagination token from the previous response.</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>Maximum number of collection IDs to return. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of collection IDs to return. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// Consumes the builder and constructs a [`ListCollectionsInput`](crate::input::ListCollectionsInput).
        pub fn build(self) -> Result<crate::input::ListCollectionsInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::ListCollectionsInput {
                    next_token: self.next_token
                    ,
                    max_results: self.max_results
                    ,
                }
            )
        }
    }
    
    
}
impl ListCollectionsInput {
    /// Consumes the builder and constructs an Operation<[`ListCollections`](crate::operation::ListCollections)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::ListCollections, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::ListCollectionsInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::ListCollectionsInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.ListCollections"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_list_collections(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::ListCollections::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("ListCollections", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`ListCollectionsInput`](crate::input::ListCollectionsInput).
    pub fn builder() -> crate::input::list_collections_input::Builder {
        crate::input::list_collections_input::Builder::default()
    }
}

/// See [`ListDatasetEntriesInput`](crate::input::ListDatasetEntriesInput).
pub mod list_dataset_entries_input {
    
    /// A builder for [`ListDatasetEntriesInput`](crate::input::ListDatasetEntriesInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
        pub(crate) contains_labels: std::option::Option<std::vec::Vec<std::string::String>>,
        pub(crate) labeled: std::option::Option<bool>,
        pub(crate) source_ref_contains: std::option::Option<std::string::String>,
        pub(crate) has_errors: std::option::Option<bool>,
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
    }
    impl Builder {
        /// <p> The Amazon Resource Name (ARN) for the dataset that you want to use. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) for the dataset that you want to use. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input; self
        }
        /// Appends an item to `contains_labels`.
        ///
        /// To override the contents of this collection use [`set_contains_labels`](Self::set_contains_labels).
        ///
        /// <p>Specifies a label filter for the response. The response includes an entry only if one or more of the labels in <code>ContainsLabels</code> exist in the entry. </p>
        pub fn contains_labels(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.contains_labels.unwrap_or_default();
                            v.push(input.into());
                            self.contains_labels = Some(v);
                            self
        }
        /// <p>Specifies a label filter for the response. The response includes an entry only if one or more of the labels in <code>ContainsLabels</code> exist in the entry. </p>
        pub fn set_contains_labels(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.contains_labels = input; self
        }
        /// <p> Specify <code>true</code> to get only the JSON Lines where the image is labeled. Specify <code>false</code> to get only the JSON Lines where the image isn't labeled. If you don't specify <code>Labeled</code>, <code>ListDatasetEntries</code> returns JSON Lines for labeled and unlabeled images. </p>
        pub fn labeled(mut self, input: bool) -> Self {
            self.labeled = Some(input);
            self
        }
        /// <p> Specify <code>true</code> to get only the JSON Lines where the image is labeled. Specify <code>false</code> to get only the JSON Lines where the image isn't labeled. If you don't specify <code>Labeled</code>, <code>ListDatasetEntries</code> returns JSON Lines for labeled and unlabeled images. </p>
        pub fn set_labeled(mut self, input: std::option::Option<bool>) -> Self {
            self.labeled = input; self
        }
        /// <p>If specified, <code>ListDatasetEntries</code> only returns JSON Lines where the value of <code>SourceRefContains</code> is part of the <code>source-ref</code> field. The <code>source-ref</code> field contains the Amazon S3 location of the image. You can use <code>SouceRefContains</code> for tasks such as getting the JSON Line for a single image, or gettting JSON Lines for all images within a specific folder.</p>
        pub fn source_ref_contains(mut self, input: impl Into<std::string::String>) -> Self {
            self.source_ref_contains = Some(input.into());
            self
        }
        /// <p>If specified, <code>ListDatasetEntries</code> only returns JSON Lines where the value of <code>SourceRefContains</code> is part of the <code>source-ref</code> field. The <code>source-ref</code> field contains the Amazon S3 location of the image. You can use <code>SouceRefContains</code> for tasks such as getting the JSON Line for a single image, or gettting JSON Lines for all images within a specific folder.</p>
        pub fn set_source_ref_contains(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.source_ref_contains = input; self
        }
        /// <p>Specifies an error filter for the response. Specify <code>True</code> to only include entries that have errors. </p>
        pub fn has_errors(mut self, input: bool) -> Self {
            self.has_errors = Some(input);
            self
        }
        /// <p>Specifies an error filter for the response. Specify <code>True</code> to only include entries that have errors. </p>
        pub fn set_has_errors(mut self, input: std::option::Option<bool>) -> Self {
            self.has_errors = input; self
        }
        /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// Consumes the builder and constructs a [`ListDatasetEntriesInput`](crate::input::ListDatasetEntriesInput).
        pub fn build(self) -> Result<crate::input::ListDatasetEntriesInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::ListDatasetEntriesInput {
                    dataset_arn: self.dataset_arn
                    ,
                    contains_labels: self.contains_labels
                    ,
                    labeled: self.labeled
                    ,
                    source_ref_contains: self.source_ref_contains
                    ,
                    has_errors: self.has_errors
                    ,
                    next_token: self.next_token
                    ,
                    max_results: self.max_results
                    ,
                }
            )
        }
    }
    
    
}
impl ListDatasetEntriesInput {
    /// Consumes the builder and constructs an Operation<[`ListDatasetEntries`](crate::operation::ListDatasetEntries)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::ListDatasetEntries, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::ListDatasetEntriesInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::ListDatasetEntriesInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.ListDatasetEntries"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_list_dataset_entries(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::ListDatasetEntries::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("ListDatasetEntries", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`ListDatasetEntriesInput`](crate::input::ListDatasetEntriesInput).
    pub fn builder() -> crate::input::list_dataset_entries_input::Builder {
        crate::input::list_dataset_entries_input::Builder::default()
    }
}

/// See [`ListDatasetLabelsInput`](crate::input::ListDatasetLabelsInput).
pub mod list_dataset_labels_input {
    
    /// A builder for [`ListDatasetLabelsInput`](crate::input::ListDatasetLabelsInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
    }
    impl Builder {
        /// <p> The Amazon Resource Name (ARN) of the dataset that you want to use. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) of the dataset that you want to use. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input; self
        }
        /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// Consumes the builder and constructs a [`ListDatasetLabelsInput`](crate::input::ListDatasetLabelsInput).
        pub fn build(self) -> Result<crate::input::ListDatasetLabelsInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::ListDatasetLabelsInput {
                    dataset_arn: self.dataset_arn
                    ,
                    next_token: self.next_token
                    ,
                    max_results: self.max_results
                    ,
                }
            )
        }
    }
    
    
}
impl ListDatasetLabelsInput {
    /// Consumes the builder and constructs an Operation<[`ListDatasetLabels`](crate::operation::ListDatasetLabels)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::ListDatasetLabels, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::ListDatasetLabelsInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::ListDatasetLabelsInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.ListDatasetLabels"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_list_dataset_labels(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::ListDatasetLabels::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("ListDatasetLabels", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`ListDatasetLabelsInput`](crate::input::ListDatasetLabelsInput).
    pub fn builder() -> crate::input::list_dataset_labels_input::Builder {
        crate::input::list_dataset_labels_input::Builder::default()
    }
}

/// See [`ListFacesInput`](crate::input::ListFacesInput).
pub mod list_faces_input {
    
    /// A builder for [`ListFacesInput`](crate::input::ListFacesInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) collection_id: std::option::Option<std::string::String>,
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>ID of the collection from which to list the faces.</p>
        pub fn collection_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.collection_id = Some(input.into());
            self
        }
        /// <p>ID of the collection from which to list the faces.</p>
        pub fn set_collection_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.collection_id = input; self
        }
        /// <p>If the previous response was incomplete (because there is more data to retrieve), Amazon Rekognition returns a pagination token in the response. You can use this pagination token to retrieve the next set of faces.</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there is more data to retrieve), Amazon Rekognition returns a pagination token in the response. You can use this pagination token to retrieve the next set of faces.</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>Maximum number of faces to return.</p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of faces to return.</p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// Consumes the builder and constructs a [`ListFacesInput`](crate::input::ListFacesInput).
        pub fn build(self) -> Result<crate::input::ListFacesInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::ListFacesInput {
                    collection_id: self.collection_id
                    ,
                    next_token: self.next_token
                    ,
                    max_results: self.max_results
                    ,
                }
            )
        }
    }
    
    
}
impl ListFacesInput {
    /// Consumes the builder and constructs an Operation<[`ListFaces`](crate::operation::ListFaces)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::ListFaces, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::ListFacesInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::ListFacesInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.ListFaces"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_list_faces(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::ListFaces::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("ListFaces", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`ListFacesInput`](crate::input::ListFacesInput).
    pub fn builder() -> crate::input::list_faces_input::Builder {
        crate::input::list_faces_input::Builder::default()
    }
}

/// See [`ListProjectPoliciesInput`](crate::input::ListProjectPoliciesInput).
pub mod list_project_policies_input {
    
    /// A builder for [`ListProjectPoliciesInput`](crate::input::ListProjectPoliciesInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) project_arn: std::option::Option<std::string::String>,
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The ARN of the project for which you want to list the project policies.</p>
        pub fn project_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_arn = Some(input.into());
            self
        }
        /// <p>The ARN of the project for which you want to list the project policies.</p>
        pub fn set_project_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_arn = input; self
        }
        /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 5. If you specify a value greater than 5, a ValidationException error occurs. The default value is 5. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 5. If you specify a value greater than 5, a ValidationException error occurs. The default value is 5. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// Consumes the builder and constructs a [`ListProjectPoliciesInput`](crate::input::ListProjectPoliciesInput).
        pub fn build(self) -> Result<crate::input::ListProjectPoliciesInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::ListProjectPoliciesInput {
                    project_arn: self.project_arn
                    ,
                    next_token: self.next_token
                    ,
                    max_results: self.max_results
                    ,
                }
            )
        }
    }
    
    
}
impl ListProjectPoliciesInput {
    /// Consumes the builder and constructs an Operation<[`ListProjectPolicies`](crate::operation::ListProjectPolicies)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::ListProjectPolicies, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::ListProjectPoliciesInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::ListProjectPoliciesInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.ListProjectPolicies"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_list_project_policies(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::ListProjectPolicies::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("ListProjectPolicies", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`ListProjectPoliciesInput`](crate::input::ListProjectPoliciesInput).
    pub fn builder() -> crate::input::list_project_policies_input::Builder {
        crate::input::list_project_policies_input::Builder::default()
    }
}

/// See [`ListStreamProcessorsInput`](crate::input::ListStreamProcessorsInput).
pub mod list_stream_processors_input {
    
    /// A builder for [`ListStreamProcessorsInput`](crate::input::ListStreamProcessorsInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) max_results: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>If the previous response was incomplete (because there are more stream processors to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of stream processors. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>If the previous response was incomplete (because there are more stream processors to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of stream processors. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input; self
        }
        /// <p>Maximum number of stream processors you want Amazon Rekognition Video to return in the response. The default is 1000. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.max_results = Some(input);
            self
        }
        /// <p>Maximum number of stream processors you want Amazon Rekognition Video to return in the response. The default is 1000. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.max_results = input; self
        }
        /// Consumes the builder and constructs a [`ListStreamProcessorsInput`](crate::input::ListStreamProcessorsInput).
        pub fn build(self) -> Result<crate::input::ListStreamProcessorsInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::ListStreamProcessorsInput {
                    next_token: self.next_token
                    ,
                    max_results: self.max_results
                    ,
                }
            )
        }
    }
    
    
}
impl ListStreamProcessorsInput {
    /// Consumes the builder and constructs an Operation<[`ListStreamProcessors`](crate::operation::ListStreamProcessors)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::ListStreamProcessors, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::ListStreamProcessorsInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::ListStreamProcessorsInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.ListStreamProcessors"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_list_stream_processors(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::ListStreamProcessors::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("ListStreamProcessors", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`ListStreamProcessorsInput`](crate::input::ListStreamProcessorsInput).
    pub fn builder() -> crate::input::list_stream_processors_input::Builder {
        crate::input::list_stream_processors_input::Builder::default()
    }
}

/// See [`ListTagsForResourceInput`](crate::input::ListTagsForResourceInput).
pub mod list_tags_for_resource_input {
    
    /// A builder for [`ListTagsForResourceInput`](crate::input::ListTagsForResourceInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) resource_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that contains the tags that you want a list of. </p>
        pub fn resource_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.resource_arn = Some(input.into());
            self
        }
        /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that contains the tags that you want a list of. </p>
        pub fn set_resource_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.resource_arn = input; self
        }
        /// Consumes the builder and constructs a [`ListTagsForResourceInput`](crate::input::ListTagsForResourceInput).
        pub fn build(self) -> Result<crate::input::ListTagsForResourceInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::ListTagsForResourceInput {
                    resource_arn: self.resource_arn
                    ,
                }
            )
        }
    }
    
    
}
impl ListTagsForResourceInput {
    /// Consumes the builder and constructs an Operation<[`ListTagsForResource`](crate::operation::ListTagsForResource)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::ListTagsForResource, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::ListTagsForResourceInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::ListTagsForResourceInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.ListTagsForResource"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_list_tags_for_resource(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::ListTagsForResource::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("ListTagsForResource", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`ListTagsForResourceInput`](crate::input::ListTagsForResourceInput).
    pub fn builder() -> crate::input::list_tags_for_resource_input::Builder {
        crate::input::list_tags_for_resource_input::Builder::default()
    }
}

/// See [`PutProjectPolicyInput`](crate::input::PutProjectPolicyInput).
pub mod put_project_policy_input {
    
    /// A builder for [`PutProjectPolicyInput`](crate::input::PutProjectPolicyInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) project_arn: std::option::Option<std::string::String>,
        pub(crate) policy_name: std::option::Option<std::string::String>,
        pub(crate) policy_revision_id: std::option::Option<std::string::String>,
        pub(crate) policy_document: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the project that the project policy is attached to.</p>
        pub fn project_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the project that the project policy is attached to.</p>
        pub fn set_project_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_arn = input; self
        }
        /// <p>A name for the policy.</p>
        pub fn policy_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.policy_name = Some(input.into());
            self
        }
        /// <p>A name for the policy.</p>
        pub fn set_policy_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.policy_name = input; self
        }
        /// <p>The revision ID for the Project Policy. Each time you modify a policy, Amazon Rekognition Custom Labels generates and assigns a new <code>PolicyRevisionId</code> and then deletes the previous version of the policy.</p>
        pub fn policy_revision_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.policy_revision_id = Some(input.into());
            self
        }
        /// <p>The revision ID for the Project Policy. Each time you modify a policy, Amazon Rekognition Custom Labels generates and assigns a new <code>PolicyRevisionId</code> and then deletes the previous version of the policy.</p>
        pub fn set_policy_revision_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.policy_revision_id = input; self
        }
        /// <p>A resource policy to add to the model. The policy is a JSON structure that contains one or more statements that define the policy. The policy must follow the IAM syntax. For more information about the contents of a JSON policy document, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies.html">IAM JSON policy reference</a>. </p>
        pub fn policy_document(mut self, input: impl Into<std::string::String>) -> Self {
            self.policy_document = Some(input.into());
            self
        }
        /// <p>A resource policy to add to the model. The policy is a JSON structure that contains one or more statements that define the policy. The policy must follow the IAM syntax. For more information about the contents of a JSON policy document, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies.html">IAM JSON policy reference</a>. </p>
        pub fn set_policy_document(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.policy_document = input; self
        }
        /// Consumes the builder and constructs a [`PutProjectPolicyInput`](crate::input::PutProjectPolicyInput).
        pub fn build(self) -> Result<crate::input::PutProjectPolicyInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::PutProjectPolicyInput {
                    project_arn: self.project_arn
                    ,
                    policy_name: self.policy_name
                    ,
                    policy_revision_id: self.policy_revision_id
                    ,
                    policy_document: self.policy_document
                    ,
                }
            )
        }
    }
    
    
}
impl PutProjectPolicyInput {
    /// Consumes the builder and constructs an Operation<[`PutProjectPolicy`](crate::operation::PutProjectPolicy)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::PutProjectPolicy, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::PutProjectPolicyInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::PutProjectPolicyInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.PutProjectPolicy"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_put_project_policy(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::PutProjectPolicy::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("PutProjectPolicy", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`PutProjectPolicyInput`](crate::input::PutProjectPolicyInput).
    pub fn builder() -> crate::input::put_project_policy_input::Builder {
        crate::input::put_project_policy_input::Builder::default()
    }
}

/// See [`RecognizeCelebritiesInput`](crate::input::RecognizeCelebritiesInput).
pub mod recognize_celebrities_input {
    
    /// A builder for [`RecognizeCelebritiesInput`](crate::input::RecognizeCelebritiesInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) image: std::option::Option<crate::model::Image>,
    }
    impl Builder {
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn image(mut self, input: crate::model::Image) -> Self {
            self.image = Some(input);
            self
        }
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn set_image(mut self, input: std::option::Option<crate::model::Image>) -> Self {
            self.image = input; self
        }
        /// Consumes the builder and constructs a [`RecognizeCelebritiesInput`](crate::input::RecognizeCelebritiesInput).
        pub fn build(self) -> Result<crate::input::RecognizeCelebritiesInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::RecognizeCelebritiesInput {
                    image: self.image
                    ,
                }
            )
        }
    }
    
    
}
impl RecognizeCelebritiesInput {
    /// Consumes the builder and constructs an Operation<[`RecognizeCelebrities`](crate::operation::RecognizeCelebrities)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::RecognizeCelebrities, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::RecognizeCelebritiesInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::RecognizeCelebritiesInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.RecognizeCelebrities"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_recognize_celebrities(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::RecognizeCelebrities::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("RecognizeCelebrities", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`RecognizeCelebritiesInput`](crate::input::RecognizeCelebritiesInput).
    pub fn builder() -> crate::input::recognize_celebrities_input::Builder {
        crate::input::recognize_celebrities_input::Builder::default()
    }
}

/// See [`SearchFacesInput`](crate::input::SearchFacesInput).
pub mod search_faces_input {
    
    /// A builder for [`SearchFacesInput`](crate::input::SearchFacesInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) collection_id: std::option::Option<std::string::String>,
        pub(crate) face_id: std::option::Option<std::string::String>,
        pub(crate) max_faces: std::option::Option<i32>,
        pub(crate) face_match_threshold: std::option::Option<f32>,
    }
    impl Builder {
        /// <p>ID of the collection the face belongs to.</p>
        pub fn collection_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.collection_id = Some(input.into());
            self
        }
        /// <p>ID of the collection the face belongs to.</p>
        pub fn set_collection_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.collection_id = input; self
        }
        /// <p>ID of a face to find matches for in the collection.</p>
        pub fn face_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.face_id = Some(input.into());
            self
        }
        /// <p>ID of a face to find matches for in the collection.</p>
        pub fn set_face_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.face_id = input; self
        }
        /// <p>Maximum number of faces to return. The operation returns the maximum number of faces with the highest confidence in the match.</p>
        pub fn max_faces(mut self, input: i32) -> Self {
            self.max_faces = Some(input);
            self
        }
        /// <p>Maximum number of faces to return. The operation returns the maximum number of faces with the highest confidence in the match.</p>
        pub fn set_max_faces(mut self, input: std::option::Option<i32>) -> Self {
            self.max_faces = input; self
        }
        /// <p>Optional value specifying the minimum confidence in the face match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%. </p>
        pub fn face_match_threshold(mut self, input: f32) -> Self {
            self.face_match_threshold = Some(input);
            self
        }
        /// <p>Optional value specifying the minimum confidence in the face match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%. </p>
        pub fn set_face_match_threshold(mut self, input: std::option::Option<f32>) -> Self {
            self.face_match_threshold = input; self
        }
        /// Consumes the builder and constructs a [`SearchFacesInput`](crate::input::SearchFacesInput).
        pub fn build(self) -> Result<crate::input::SearchFacesInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::SearchFacesInput {
                    collection_id: self.collection_id
                    ,
                    face_id: self.face_id
                    ,
                    max_faces: self.max_faces
                    ,
                    face_match_threshold: self.face_match_threshold
                    ,
                }
            )
        }
    }
    
    
}
impl SearchFacesInput {
    /// Consumes the builder and constructs an Operation<[`SearchFaces`](crate::operation::SearchFaces)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::SearchFaces, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::SearchFacesInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::SearchFacesInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.SearchFaces"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_search_faces(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::SearchFaces::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("SearchFaces", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`SearchFacesInput`](crate::input::SearchFacesInput).
    pub fn builder() -> crate::input::search_faces_input::Builder {
        crate::input::search_faces_input::Builder::default()
    }
}

/// See [`SearchFacesByImageInput`](crate::input::SearchFacesByImageInput).
pub mod search_faces_by_image_input {
    
    /// A builder for [`SearchFacesByImageInput`](crate::input::SearchFacesByImageInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) collection_id: std::option::Option<std::string::String>,
        pub(crate) image: std::option::Option<crate::model::Image>,
        pub(crate) max_faces: std::option::Option<i32>,
        pub(crate) face_match_threshold: std::option::Option<f32>,
        pub(crate) quality_filter: std::option::Option<crate::model::QualityFilter>,
    }
    impl Builder {
        /// <p>ID of the collection to search.</p>
        pub fn collection_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.collection_id = Some(input.into());
            self
        }
        /// <p>ID of the collection to search.</p>
        pub fn set_collection_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.collection_id = input; self
        }
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn image(mut self, input: crate::model::Image) -> Self {
            self.image = Some(input);
            self
        }
        /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
        /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
        pub fn set_image(mut self, input: std::option::Option<crate::model::Image>) -> Self {
            self.image = input; self
        }
        /// <p>Maximum number of faces to return. The operation returns the maximum number of faces with the highest confidence in the match.</p>
        pub fn max_faces(mut self, input: i32) -> Self {
            self.max_faces = Some(input);
            self
        }
        /// <p>Maximum number of faces to return. The operation returns the maximum number of faces with the highest confidence in the match.</p>
        pub fn set_max_faces(mut self, input: std::option::Option<i32>) -> Self {
            self.max_faces = input; self
        }
        /// <p>(Optional) Specifies the minimum confidence in the face match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%.</p>
        pub fn face_match_threshold(mut self, input: f32) -> Self {
            self.face_match_threshold = Some(input);
            self
        }
        /// <p>(Optional) Specifies the minimum confidence in the face match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%.</p>
        pub fn set_face_match_threshold(mut self, input: std::option::Option<f32>) -> Self {
            self.face_match_threshold = input; self
        }
        /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't searched for in the collection. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. The default value is <code>NONE</code>. </p> 
        /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
        pub fn quality_filter(mut self, input: crate::model::QualityFilter) -> Self {
            self.quality_filter = Some(input);
            self
        }
        /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't searched for in the collection. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. The default value is <code>NONE</code>. </p> 
        /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
        pub fn set_quality_filter(mut self, input: std::option::Option<crate::model::QualityFilter>) -> Self {
            self.quality_filter = input; self
        }
        /// Consumes the builder and constructs a [`SearchFacesByImageInput`](crate::input::SearchFacesByImageInput).
        pub fn build(self) -> Result<crate::input::SearchFacesByImageInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::SearchFacesByImageInput {
                    collection_id: self.collection_id
                    ,
                    image: self.image
                    ,
                    max_faces: self.max_faces
                    ,
                    face_match_threshold: self.face_match_threshold
                    ,
                    quality_filter: self.quality_filter
                    ,
                }
            )
        }
    }
    
    
}
impl SearchFacesByImageInput {
    /// Consumes the builder and constructs an Operation<[`SearchFacesByImage`](crate::operation::SearchFacesByImage)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::SearchFacesByImage, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::SearchFacesByImageInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::SearchFacesByImageInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.SearchFacesByImage"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_search_faces_by_image(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::SearchFacesByImage::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("SearchFacesByImage", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`SearchFacesByImageInput`](crate::input::SearchFacesByImageInput).
    pub fn builder() -> crate::input::search_faces_by_image_input::Builder {
        crate::input::search_faces_by_image_input::Builder::default()
    }
}

/// See [`StartCelebrityRecognitionInput`](crate::input::StartCelebrityRecognitionInput).
pub mod start_celebrity_recognition_input {
    
    /// A builder for [`StartCelebrityRecognitionInput`](crate::input::StartCelebrityRecognitionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) video: std::option::Option<crate::model::Video>,
        pub(crate) client_request_token: std::option::Option<std::string::String>,
        pub(crate) notification_channel: std::option::Option<crate::model::NotificationChannel>,
        pub(crate) job_tag: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The video in which you want to recognize celebrities. The video must be stored in an Amazon S3 bucket.</p>
        pub fn video(mut self, input: crate::model::Video) -> Self {
            self.video = Some(input);
            self
        }
        /// <p>The video in which you want to recognize celebrities. The video must be stored in an Amazon S3 bucket.</p>
        pub fn set_video(mut self, input: std::option::Option<crate::model::Video>) -> Self {
            self.video = input; self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartCelebrityRecognition</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn client_request_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.client_request_token = Some(input.into());
            self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartCelebrityRecognition</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn set_client_request_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.client_request_token = input; self
        }
        /// <p>The Amazon SNS topic ARN that you want Amazon Rekognition Video to publish the completion status of the celebrity recognition analysis to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
        pub fn notification_channel(mut self, input: crate::model::NotificationChannel) -> Self {
            self.notification_channel = Some(input);
            self
        }
        /// <p>The Amazon SNS topic ARN that you want Amazon Rekognition Video to publish the completion status of the celebrity recognition analysis to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
        pub fn set_notification_channel(mut self, input: std::option::Option<crate::model::NotificationChannel>) -> Self {
            self.notification_channel = input; self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn job_tag(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_tag = Some(input.into());
            self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn set_job_tag(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_tag = input; self
        }
        /// Consumes the builder and constructs a [`StartCelebrityRecognitionInput`](crate::input::StartCelebrityRecognitionInput).
        pub fn build(self) -> Result<crate::input::StartCelebrityRecognitionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StartCelebrityRecognitionInput {
                    video: self.video
                    ,
                    client_request_token: self.client_request_token
                    ,
                    notification_channel: self.notification_channel
                    ,
                    job_tag: self.job_tag
                    ,
                }
            )
        }
    }
    
    
}
impl StartCelebrityRecognitionInput {
    /// Consumes the builder and constructs an Operation<[`StartCelebrityRecognition`](crate::operation::StartCelebrityRecognition)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StartCelebrityRecognition, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StartCelebrityRecognitionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StartCelebrityRecognitionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StartCelebrityRecognition"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_start_celebrity_recognition(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StartCelebrityRecognition::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StartCelebrityRecognition", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StartCelebrityRecognitionInput`](crate::input::StartCelebrityRecognitionInput).
    pub fn builder() -> crate::input::start_celebrity_recognition_input::Builder {
        crate::input::start_celebrity_recognition_input::Builder::default()
    }
}

/// See [`StartContentModerationInput`](crate::input::StartContentModerationInput).
pub mod start_content_moderation_input {
    
    /// A builder for [`StartContentModerationInput`](crate::input::StartContentModerationInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) video: std::option::Option<crate::model::Video>,
        pub(crate) min_confidence: std::option::Option<f32>,
        pub(crate) client_request_token: std::option::Option<std::string::String>,
        pub(crate) notification_channel: std::option::Option<crate::model::NotificationChannel>,
        pub(crate) job_tag: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The video in which you want to detect inappropriate, unwanted, or offensive content. The video must be stored in an Amazon S3 bucket.</p>
        pub fn video(mut self, input: crate::model::Video) -> Self {
            self.video = Some(input);
            self
        }
        /// <p>The video in which you want to detect inappropriate, unwanted, or offensive content. The video must be stored in an Amazon S3 bucket.</p>
        pub fn set_video(mut self, input: std::option::Option<crate::model::Video>) -> Self {
            self.video = input; self
        }
        /// <p>Specifies the minimum confidence that Amazon Rekognition must have in order to return a moderated content label. Confidence represents how certain Amazon Rekognition is that the moderated content is correctly identified. 0 is the lowest confidence. 100 is the highest confidence. Amazon Rekognition doesn't return any moderated content labels with a confidence level lower than this specified value. If you don't specify <code>MinConfidence</code>, <code>GetContentModeration</code> returns labels with confidence values greater than or equal to 50 percent.</p>
        pub fn min_confidence(mut self, input: f32) -> Self {
            self.min_confidence = Some(input);
            self
        }
        /// <p>Specifies the minimum confidence that Amazon Rekognition must have in order to return a moderated content label. Confidence represents how certain Amazon Rekognition is that the moderated content is correctly identified. 0 is the lowest confidence. 100 is the highest confidence. Amazon Rekognition doesn't return any moderated content labels with a confidence level lower than this specified value. If you don't specify <code>MinConfidence</code>, <code>GetContentModeration</code> returns labels with confidence values greater than or equal to 50 percent.</p>
        pub fn set_min_confidence(mut self, input: std::option::Option<f32>) -> Self {
            self.min_confidence = input; self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartContentModeration</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn client_request_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.client_request_token = Some(input.into());
            self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartContentModeration</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn set_client_request_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.client_request_token = input; self
        }
        /// <p>The Amazon SNS topic ARN that you want Amazon Rekognition Video to publish the completion status of the content analysis to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
        pub fn notification_channel(mut self, input: crate::model::NotificationChannel) -> Self {
            self.notification_channel = Some(input);
            self
        }
        /// <p>The Amazon SNS topic ARN that you want Amazon Rekognition Video to publish the completion status of the content analysis to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
        pub fn set_notification_channel(mut self, input: std::option::Option<crate::model::NotificationChannel>) -> Self {
            self.notification_channel = input; self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn job_tag(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_tag = Some(input.into());
            self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn set_job_tag(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_tag = input; self
        }
        /// Consumes the builder and constructs a [`StartContentModerationInput`](crate::input::StartContentModerationInput).
        pub fn build(self) -> Result<crate::input::StartContentModerationInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StartContentModerationInput {
                    video: self.video
                    ,
                    min_confidence: self.min_confidence
                    ,
                    client_request_token: self.client_request_token
                    ,
                    notification_channel: self.notification_channel
                    ,
                    job_tag: self.job_tag
                    ,
                }
            )
        }
    }
    
    
}
impl StartContentModerationInput {
    /// Consumes the builder and constructs an Operation<[`StartContentModeration`](crate::operation::StartContentModeration)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StartContentModeration, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StartContentModerationInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StartContentModerationInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StartContentModeration"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_start_content_moderation(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StartContentModeration::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StartContentModeration", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StartContentModerationInput`](crate::input::StartContentModerationInput).
    pub fn builder() -> crate::input::start_content_moderation_input::Builder {
        crate::input::start_content_moderation_input::Builder::default()
    }
}

/// See [`StartFaceDetectionInput`](crate::input::StartFaceDetectionInput).
pub mod start_face_detection_input {
    
    /// A builder for [`StartFaceDetectionInput`](crate::input::StartFaceDetectionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) video: std::option::Option<crate::model::Video>,
        pub(crate) client_request_token: std::option::Option<std::string::String>,
        pub(crate) notification_channel: std::option::Option<crate::model::NotificationChannel>,
        pub(crate) face_attributes: std::option::Option<crate::model::FaceAttributes>,
        pub(crate) job_tag: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The video in which you want to detect faces. The video must be stored in an Amazon S3 bucket.</p>
        pub fn video(mut self, input: crate::model::Video) -> Self {
            self.video = Some(input);
            self
        }
        /// <p>The video in which you want to detect faces. The video must be stored in an Amazon S3 bucket.</p>
        pub fn set_video(mut self, input: std::option::Option<crate::model::Video>) -> Self {
            self.video = input; self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartFaceDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn client_request_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.client_request_token = Some(input.into());
            self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartFaceDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn set_client_request_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.client_request_token = input; self
        }
        /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the face detection operation. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
        pub fn notification_channel(mut self, input: crate::model::NotificationChannel) -> Self {
            self.notification_channel = Some(input);
            self
        }
        /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the face detection operation. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
        pub fn set_notification_channel(mut self, input: std::option::Option<crate::model::NotificationChannel>) -> Self {
            self.notification_channel = input; self
        }
        /// <p>The face attributes you want returned.</p> 
        /// <p> <code>DEFAULT</code> - The following subset of facial attributes are returned: BoundingBox, Confidence, Pose, Quality and Landmarks. </p> 
        /// <p> <code>ALL</code> - All facial attributes are returned.</p>
        pub fn face_attributes(mut self, input: crate::model::FaceAttributes) -> Self {
            self.face_attributes = Some(input);
            self
        }
        /// <p>The face attributes you want returned.</p> 
        /// <p> <code>DEFAULT</code> - The following subset of facial attributes are returned: BoundingBox, Confidence, Pose, Quality and Landmarks. </p> 
        /// <p> <code>ALL</code> - All facial attributes are returned.</p>
        pub fn set_face_attributes(mut self, input: std::option::Option<crate::model::FaceAttributes>) -> Self {
            self.face_attributes = input; self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn job_tag(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_tag = Some(input.into());
            self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn set_job_tag(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_tag = input; self
        }
        /// Consumes the builder and constructs a [`StartFaceDetectionInput`](crate::input::StartFaceDetectionInput).
        pub fn build(self) -> Result<crate::input::StartFaceDetectionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StartFaceDetectionInput {
                    video: self.video
                    ,
                    client_request_token: self.client_request_token
                    ,
                    notification_channel: self.notification_channel
                    ,
                    face_attributes: self.face_attributes
                    ,
                    job_tag: self.job_tag
                    ,
                }
            )
        }
    }
    
    
}
impl StartFaceDetectionInput {
    /// Consumes the builder and constructs an Operation<[`StartFaceDetection`](crate::operation::StartFaceDetection)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StartFaceDetection, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StartFaceDetectionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StartFaceDetectionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StartFaceDetection"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_start_face_detection(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StartFaceDetection::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StartFaceDetection", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StartFaceDetectionInput`](crate::input::StartFaceDetectionInput).
    pub fn builder() -> crate::input::start_face_detection_input::Builder {
        crate::input::start_face_detection_input::Builder::default()
    }
}

/// See [`StartFaceSearchInput`](crate::input::StartFaceSearchInput).
pub mod start_face_search_input {
    
    /// A builder for [`StartFaceSearchInput`](crate::input::StartFaceSearchInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) video: std::option::Option<crate::model::Video>,
        pub(crate) client_request_token: std::option::Option<std::string::String>,
        pub(crate) face_match_threshold: std::option::Option<f32>,
        pub(crate) collection_id: std::option::Option<std::string::String>,
        pub(crate) notification_channel: std::option::Option<crate::model::NotificationChannel>,
        pub(crate) job_tag: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The video you want to search. The video must be stored in an Amazon S3 bucket. </p>
        pub fn video(mut self, input: crate::model::Video) -> Self {
            self.video = Some(input);
            self
        }
        /// <p>The video you want to search. The video must be stored in an Amazon S3 bucket. </p>
        pub fn set_video(mut self, input: std::option::Option<crate::model::Video>) -> Self {
            self.video = input; self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartFaceSearch</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn client_request_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.client_request_token = Some(input.into());
            self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartFaceSearch</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn set_client_request_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.client_request_token = input; self
        }
        /// <p>The minimum confidence in the person match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%.</p>
        pub fn face_match_threshold(mut self, input: f32) -> Self {
            self.face_match_threshold = Some(input);
            self
        }
        /// <p>The minimum confidence in the person match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%.</p>
        pub fn set_face_match_threshold(mut self, input: std::option::Option<f32>) -> Self {
            self.face_match_threshold = input; self
        }
        /// <p>ID of the collection that contains the faces you want to search for.</p>
        pub fn collection_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.collection_id = Some(input.into());
            self
        }
        /// <p>ID of the collection that contains the faces you want to search for.</p>
        pub fn set_collection_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.collection_id = input; self
        }
        /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the search. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
        pub fn notification_channel(mut self, input: crate::model::NotificationChannel) -> Self {
            self.notification_channel = Some(input);
            self
        }
        /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the search. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
        pub fn set_notification_channel(mut self, input: std::option::Option<crate::model::NotificationChannel>) -> Self {
            self.notification_channel = input; self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn job_tag(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_tag = Some(input.into());
            self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn set_job_tag(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_tag = input; self
        }
        /// Consumes the builder and constructs a [`StartFaceSearchInput`](crate::input::StartFaceSearchInput).
        pub fn build(self) -> Result<crate::input::StartFaceSearchInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StartFaceSearchInput {
                    video: self.video
                    ,
                    client_request_token: self.client_request_token
                    ,
                    face_match_threshold: self.face_match_threshold
                    ,
                    collection_id: self.collection_id
                    ,
                    notification_channel: self.notification_channel
                    ,
                    job_tag: self.job_tag
                    ,
                }
            )
        }
    }
    
    
}
impl StartFaceSearchInput {
    /// Consumes the builder and constructs an Operation<[`StartFaceSearch`](crate::operation::StartFaceSearch)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StartFaceSearch, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StartFaceSearchInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StartFaceSearchInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StartFaceSearch"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_start_face_search(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StartFaceSearch::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StartFaceSearch", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StartFaceSearchInput`](crate::input::StartFaceSearchInput).
    pub fn builder() -> crate::input::start_face_search_input::Builder {
        crate::input::start_face_search_input::Builder::default()
    }
}

/// See [`StartLabelDetectionInput`](crate::input::StartLabelDetectionInput).
pub mod start_label_detection_input {
    
    /// A builder for [`StartLabelDetectionInput`](crate::input::StartLabelDetectionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) video: std::option::Option<crate::model::Video>,
        pub(crate) client_request_token: std::option::Option<std::string::String>,
        pub(crate) min_confidence: std::option::Option<f32>,
        pub(crate) notification_channel: std::option::Option<crate::model::NotificationChannel>,
        pub(crate) job_tag: std::option::Option<std::string::String>,
        pub(crate) features: std::option::Option<std::vec::Vec<crate::model::LabelDetectionFeatureName>>,
        pub(crate) settings: std::option::Option<crate::model::LabelDetectionSettings>,
    }
    impl Builder {
        /// <p>The video in which you want to detect labels. The video must be stored in an Amazon S3 bucket.</p>
        pub fn video(mut self, input: crate::model::Video) -> Self {
            self.video = Some(input);
            self
        }
        /// <p>The video in which you want to detect labels. The video must be stored in an Amazon S3 bucket.</p>
        pub fn set_video(mut self, input: std::option::Option<crate::model::Video>) -> Self {
            self.video = input; self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartLabelDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn client_request_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.client_request_token = Some(input.into());
            self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartLabelDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn set_client_request_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.client_request_token = input; self
        }
        /// <p>Specifies the minimum confidence that Amazon Rekognition Video must have in order to return a detected label. Confidence represents how certain Amazon Rekognition is that a label is correctly identified.0 is the lowest confidence. 100 is the highest confidence. Amazon Rekognition Video doesn't return any labels with a confidence level lower than this specified value.</p> 
        /// <p>If you don't specify <code>MinConfidence</code>, the operation returns labels and bounding boxes (if detected) with confidence values greater than or equal to 50 percent.</p>
        pub fn min_confidence(mut self, input: f32) -> Self {
            self.min_confidence = Some(input);
            self
        }
        /// <p>Specifies the minimum confidence that Amazon Rekognition Video must have in order to return a detected label. Confidence represents how certain Amazon Rekognition is that a label is correctly identified.0 is the lowest confidence. 100 is the highest confidence. Amazon Rekognition Video doesn't return any labels with a confidence level lower than this specified value.</p> 
        /// <p>If you don't specify <code>MinConfidence</code>, the operation returns labels and bounding boxes (if detected) with confidence values greater than or equal to 50 percent.</p>
        pub fn set_min_confidence(mut self, input: std::option::Option<f32>) -> Self {
            self.min_confidence = input; self
        }
        /// <p>The Amazon SNS topic ARN you want Amazon Rekognition Video to publish the completion status of the label detection operation to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
        pub fn notification_channel(mut self, input: crate::model::NotificationChannel) -> Self {
            self.notification_channel = Some(input);
            self
        }
        /// <p>The Amazon SNS topic ARN you want Amazon Rekognition Video to publish the completion status of the label detection operation to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
        pub fn set_notification_channel(mut self, input: std::option::Option<crate::model::NotificationChannel>) -> Self {
            self.notification_channel = input; self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn job_tag(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_tag = Some(input.into());
            self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn set_job_tag(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_tag = input; self
        }
        /// Appends an item to `features`.
        ///
        /// To override the contents of this collection use [`set_features`](Self::set_features).
        ///
        /// <p>The features to return after video analysis. You can specify that GENERAL_LABELS are returned.</p>
        pub fn features(mut self, input: crate::model::LabelDetectionFeatureName) -> Self {
            let mut v = self.features.unwrap_or_default();
                            v.push(input);
                            self.features = Some(v);
                            self
        }
        /// <p>The features to return after video analysis. You can specify that GENERAL_LABELS are returned.</p>
        pub fn set_features(mut self, input: std::option::Option<std::vec::Vec<crate::model::LabelDetectionFeatureName>>) -> Self {
            self.features = input; self
        }
        /// <p>The settings for a StartLabelDetection request.Contains the specified parameters for the label detection request of an asynchronous label analysis operation. Settings can include filters for GENERAL_LABELS.</p>
        pub fn settings(mut self, input: crate::model::LabelDetectionSettings) -> Self {
            self.settings = Some(input);
            self
        }
        /// <p>The settings for a StartLabelDetection request.Contains the specified parameters for the label detection request of an asynchronous label analysis operation. Settings can include filters for GENERAL_LABELS.</p>
        pub fn set_settings(mut self, input: std::option::Option<crate::model::LabelDetectionSettings>) -> Self {
            self.settings = input; self
        }
        /// Consumes the builder and constructs a [`StartLabelDetectionInput`](crate::input::StartLabelDetectionInput).
        pub fn build(self) -> Result<crate::input::StartLabelDetectionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StartLabelDetectionInput {
                    video: self.video
                    ,
                    client_request_token: self.client_request_token
                    ,
                    min_confidence: self.min_confidence
                    ,
                    notification_channel: self.notification_channel
                    ,
                    job_tag: self.job_tag
                    ,
                    features: self.features
                    ,
                    settings: self.settings
                    ,
                }
            )
        }
    }
    
    
}
impl StartLabelDetectionInput {
    /// Consumes the builder and constructs an Operation<[`StartLabelDetection`](crate::operation::StartLabelDetection)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StartLabelDetection, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StartLabelDetectionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StartLabelDetectionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StartLabelDetection"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_start_label_detection(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StartLabelDetection::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StartLabelDetection", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StartLabelDetectionInput`](crate::input::StartLabelDetectionInput).
    pub fn builder() -> crate::input::start_label_detection_input::Builder {
        crate::input::start_label_detection_input::Builder::default()
    }
}

/// See [`StartPersonTrackingInput`](crate::input::StartPersonTrackingInput).
pub mod start_person_tracking_input {
    
    /// A builder for [`StartPersonTrackingInput`](crate::input::StartPersonTrackingInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) video: std::option::Option<crate::model::Video>,
        pub(crate) client_request_token: std::option::Option<std::string::String>,
        pub(crate) notification_channel: std::option::Option<crate::model::NotificationChannel>,
        pub(crate) job_tag: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The video in which you want to detect people. The video must be stored in an Amazon S3 bucket.</p>
        pub fn video(mut self, input: crate::model::Video) -> Self {
            self.video = Some(input);
            self
        }
        /// <p>The video in which you want to detect people. The video must be stored in an Amazon S3 bucket.</p>
        pub fn set_video(mut self, input: std::option::Option<crate::model::Video>) -> Self {
            self.video = input; self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartPersonTracking</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn client_request_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.client_request_token = Some(input.into());
            self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartPersonTracking</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn set_client_request_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.client_request_token = input; self
        }
        /// <p>The Amazon SNS topic ARN you want Amazon Rekognition Video to publish the completion status of the people detection operation to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
        pub fn notification_channel(mut self, input: crate::model::NotificationChannel) -> Self {
            self.notification_channel = Some(input);
            self
        }
        /// <p>The Amazon SNS topic ARN you want Amazon Rekognition Video to publish the completion status of the people detection operation to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
        pub fn set_notification_channel(mut self, input: std::option::Option<crate::model::NotificationChannel>) -> Self {
            self.notification_channel = input; self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn job_tag(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_tag = Some(input.into());
            self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn set_job_tag(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_tag = input; self
        }
        /// Consumes the builder and constructs a [`StartPersonTrackingInput`](crate::input::StartPersonTrackingInput).
        pub fn build(self) -> Result<crate::input::StartPersonTrackingInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StartPersonTrackingInput {
                    video: self.video
                    ,
                    client_request_token: self.client_request_token
                    ,
                    notification_channel: self.notification_channel
                    ,
                    job_tag: self.job_tag
                    ,
                }
            )
        }
    }
    
    
}
impl StartPersonTrackingInput {
    /// Consumes the builder and constructs an Operation<[`StartPersonTracking`](crate::operation::StartPersonTracking)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StartPersonTracking, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StartPersonTrackingInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StartPersonTrackingInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StartPersonTracking"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_start_person_tracking(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StartPersonTracking::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StartPersonTracking", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StartPersonTrackingInput`](crate::input::StartPersonTrackingInput).
    pub fn builder() -> crate::input::start_person_tracking_input::Builder {
        crate::input::start_person_tracking_input::Builder::default()
    }
}

/// See [`StartProjectVersionInput`](crate::input::StartProjectVersionInput).
pub mod start_project_version_input {
    
    /// A builder for [`StartProjectVersionInput`](crate::input::StartProjectVersionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) project_version_arn: std::option::Option<std::string::String>,
        pub(crate) min_inference_units: std::option::Option<i32>,
        pub(crate) max_inference_units: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name(ARN) of the model version that you want to start.</p>
        pub fn project_version_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_version_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name(ARN) of the model version that you want to start.</p>
        pub fn set_project_version_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_version_arn = input; self
        }
        /// <p>The minimum number of inference units to use. A single inference unit represents 1 hour of processing. </p> 
        /// <p>For information about the number of transactions per second (TPS) that an inference unit can support, see <i>Running a trained Amazon Rekognition Custom Labels model</i> in the Amazon Rekognition Custom Labels Guide. </p> 
        /// <p>Use a higher number to increase the TPS throughput of your model. You are charged for the number of inference units that you use. </p>
        pub fn min_inference_units(mut self, input: i32) -> Self {
            self.min_inference_units = Some(input);
            self
        }
        /// <p>The minimum number of inference units to use. A single inference unit represents 1 hour of processing. </p> 
        /// <p>For information about the number of transactions per second (TPS) that an inference unit can support, see <i>Running a trained Amazon Rekognition Custom Labels model</i> in the Amazon Rekognition Custom Labels Guide. </p> 
        /// <p>Use a higher number to increase the TPS throughput of your model. You are charged for the number of inference units that you use. </p>
        pub fn set_min_inference_units(mut self, input: std::option::Option<i32>) -> Self {
            self.min_inference_units = input; self
        }
        /// <p>The maximum number of inference units to use for auto-scaling the model. If you don't specify a value, Amazon Rekognition Custom Labels doesn't auto-scale the model.</p>
        pub fn max_inference_units(mut self, input: i32) -> Self {
            self.max_inference_units = Some(input);
            self
        }
        /// <p>The maximum number of inference units to use for auto-scaling the model. If you don't specify a value, Amazon Rekognition Custom Labels doesn't auto-scale the model.</p>
        pub fn set_max_inference_units(mut self, input: std::option::Option<i32>) -> Self {
            self.max_inference_units = input; self
        }
        /// Consumes the builder and constructs a [`StartProjectVersionInput`](crate::input::StartProjectVersionInput).
        pub fn build(self) -> Result<crate::input::StartProjectVersionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StartProjectVersionInput {
                    project_version_arn: self.project_version_arn
                    ,
                    min_inference_units: self.min_inference_units
                    ,
                    max_inference_units: self.max_inference_units
                    ,
                }
            )
        }
    }
    
    
}
impl StartProjectVersionInput {
    /// Consumes the builder and constructs an Operation<[`StartProjectVersion`](crate::operation::StartProjectVersion)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StartProjectVersion, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StartProjectVersionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StartProjectVersionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StartProjectVersion"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_start_project_version(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StartProjectVersion::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StartProjectVersion", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StartProjectVersionInput`](crate::input::StartProjectVersionInput).
    pub fn builder() -> crate::input::start_project_version_input::Builder {
        crate::input::start_project_version_input::Builder::default()
    }
}

/// See [`StartSegmentDetectionInput`](crate::input::StartSegmentDetectionInput).
pub mod start_segment_detection_input {
    
    /// A builder for [`StartSegmentDetectionInput`](crate::input::StartSegmentDetectionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) video: std::option::Option<crate::model::Video>,
        pub(crate) client_request_token: std::option::Option<std::string::String>,
        pub(crate) notification_channel: std::option::Option<crate::model::NotificationChannel>,
        pub(crate) job_tag: std::option::Option<std::string::String>,
        pub(crate) filters: std::option::Option<crate::model::StartSegmentDetectionFilters>,
        pub(crate) segment_types: std::option::Option<std::vec::Vec<crate::model::SegmentType>>,
    }
    impl Builder {
        /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
        pub fn video(mut self, input: crate::model::Video) -> Self {
            self.video = Some(input);
            self
        }
        /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
        pub fn set_video(mut self, input: std::option::Option<crate::model::Video>) -> Self {
            self.video = input; self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartSegmentDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn client_request_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.client_request_token = Some(input.into());
            self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartSegmentDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
        pub fn set_client_request_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.client_request_token = input; self
        }
        /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the segment detection operation. Note that the Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
        pub fn notification_channel(mut self, input: crate::model::NotificationChannel) -> Self {
            self.notification_channel = Some(input);
            self
        }
        /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the segment detection operation. Note that the Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
        pub fn set_notification_channel(mut self, input: std::option::Option<crate::model::NotificationChannel>) -> Self {
            self.notification_channel = input; self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn job_tag(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_tag = Some(input.into());
            self
        }
        /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn set_job_tag(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_tag = input; self
        }
        /// <p>Filters for technical cue or shot detection.</p>
        pub fn filters(mut self, input: crate::model::StartSegmentDetectionFilters) -> Self {
            self.filters = Some(input);
            self
        }
        /// <p>Filters for technical cue or shot detection.</p>
        pub fn set_filters(mut self, input: std::option::Option<crate::model::StartSegmentDetectionFilters>) -> Self {
            self.filters = input; self
        }
        /// Appends an item to `segment_types`.
        ///
        /// To override the contents of this collection use [`set_segment_types`](Self::set_segment_types).
        ///
        /// <p>An array of segment types to detect in the video. Valid values are TECHNICAL_CUE and SHOT.</p>
        pub fn segment_types(mut self, input: crate::model::SegmentType) -> Self {
            let mut v = self.segment_types.unwrap_or_default();
                            v.push(input);
                            self.segment_types = Some(v);
                            self
        }
        /// <p>An array of segment types to detect in the video. Valid values are TECHNICAL_CUE and SHOT.</p>
        pub fn set_segment_types(mut self, input: std::option::Option<std::vec::Vec<crate::model::SegmentType>>) -> Self {
            self.segment_types = input; self
        }
        /// Consumes the builder and constructs a [`StartSegmentDetectionInput`](crate::input::StartSegmentDetectionInput).
        pub fn build(self) -> Result<crate::input::StartSegmentDetectionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StartSegmentDetectionInput {
                    video: self.video
                    ,
                    client_request_token: self.client_request_token
                    ,
                    notification_channel: self.notification_channel
                    ,
                    job_tag: self.job_tag
                    ,
                    filters: self.filters
                    ,
                    segment_types: self.segment_types
                    ,
                }
            )
        }
    }
    
    
}
impl StartSegmentDetectionInput {
    /// Consumes the builder and constructs an Operation<[`StartSegmentDetection`](crate::operation::StartSegmentDetection)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StartSegmentDetection, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StartSegmentDetectionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StartSegmentDetectionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StartSegmentDetection"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_start_segment_detection(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StartSegmentDetection::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StartSegmentDetection", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StartSegmentDetectionInput`](crate::input::StartSegmentDetectionInput).
    pub fn builder() -> crate::input::start_segment_detection_input::Builder {
        crate::input::start_segment_detection_input::Builder::default()
    }
}

/// See [`StartStreamProcessorInput`](crate::input::StartStreamProcessorInput).
pub mod start_stream_processor_input {
    
    /// A builder for [`StartStreamProcessorInput`](crate::input::StartStreamProcessorInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) name: std::option::Option<std::string::String>,
        pub(crate) start_selector: std::option::Option<crate::model::StreamProcessingStartSelector>,
        pub(crate) stop_selector: std::option::Option<crate::model::StreamProcessingStopSelector>,
    }
    impl Builder {
        /// <p>The name of the stream processor to start processing.</p>
        pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
            self.name = Some(input.into());
            self
        }
        /// <p>The name of the stream processor to start processing.</p>
        pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.name = input; self
        }
        /// <p> Specifies the starting point in the Kinesis stream to start processing. You can use the producer timestamp or the fragment number. If you use the producer timestamp, you must put the time in milliseconds. For more information about fragment numbers, see <a href="https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/API_reader_Fragment.html">Fragment</a>. </p> 
        /// <p>This is a required parameter for label detection stream processors and should not be used to start a face search stream processor.</p>
        pub fn start_selector(mut self, input: crate::model::StreamProcessingStartSelector) -> Self {
            self.start_selector = Some(input);
            self
        }
        /// <p> Specifies the starting point in the Kinesis stream to start processing. You can use the producer timestamp or the fragment number. If you use the producer timestamp, you must put the time in milliseconds. For more information about fragment numbers, see <a href="https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/API_reader_Fragment.html">Fragment</a>. </p> 
        /// <p>This is a required parameter for label detection stream processors and should not be used to start a face search stream processor.</p>
        pub fn set_start_selector(mut self, input: std::option::Option<crate::model::StreamProcessingStartSelector>) -> Self {
            self.start_selector = input; self
        }
        /// <p> Specifies when to stop processing the stream. You can specify a maximum amount of time to process the video. </p> 
        /// <p>This is a required parameter for label detection stream processors and should not be used to start a face search stream processor.</p>
        pub fn stop_selector(mut self, input: crate::model::StreamProcessingStopSelector) -> Self {
            self.stop_selector = Some(input);
            self
        }
        /// <p> Specifies when to stop processing the stream. You can specify a maximum amount of time to process the video. </p> 
        /// <p>This is a required parameter for label detection stream processors and should not be used to start a face search stream processor.</p>
        pub fn set_stop_selector(mut self, input: std::option::Option<crate::model::StreamProcessingStopSelector>) -> Self {
            self.stop_selector = input; self
        }
        /// Consumes the builder and constructs a [`StartStreamProcessorInput`](crate::input::StartStreamProcessorInput).
        pub fn build(self) -> Result<crate::input::StartStreamProcessorInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StartStreamProcessorInput {
                    name: self.name
                    ,
                    start_selector: self.start_selector
                    ,
                    stop_selector: self.stop_selector
                    ,
                }
            )
        }
    }
    
    
}
impl StartStreamProcessorInput {
    /// Consumes the builder and constructs an Operation<[`StartStreamProcessor`](crate::operation::StartStreamProcessor)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StartStreamProcessor, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StartStreamProcessorInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StartStreamProcessorInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StartStreamProcessor"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_start_stream_processor(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StartStreamProcessor::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StartStreamProcessor", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StartStreamProcessorInput`](crate::input::StartStreamProcessorInput).
    pub fn builder() -> crate::input::start_stream_processor_input::Builder {
        crate::input::start_stream_processor_input::Builder::default()
    }
}

/// See [`StartTextDetectionInput`](crate::input::StartTextDetectionInput).
pub mod start_text_detection_input {
    
    /// A builder for [`StartTextDetectionInput`](crate::input::StartTextDetectionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) video: std::option::Option<crate::model::Video>,
        pub(crate) client_request_token: std::option::Option<std::string::String>,
        pub(crate) notification_channel: std::option::Option<crate::model::NotificationChannel>,
        pub(crate) job_tag: std::option::Option<std::string::String>,
        pub(crate) filters: std::option::Option<crate::model::StartTextDetectionFilters>,
    }
    impl Builder {
        /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
        pub fn video(mut self, input: crate::model::Video) -> Self {
            self.video = Some(input);
            self
        }
        /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
        pub fn set_video(mut self, input: std::option::Option<crate::model::Video>) -> Self {
            self.video = input; self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartTextDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidentaly started more than once.</p>
        pub fn client_request_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.client_request_token = Some(input.into());
            self
        }
        /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartTextDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidentaly started more than once.</p>
        pub fn set_client_request_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.client_request_token = input; self
        }
        /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the completion status of a video analysis operation. For more information, see <a href="https://docs.aws.amazon.com/rekognition/latest/dg/api-video.html">Calling Amazon Rekognition Video operations</a>. Note that the Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic. For more information, see <a href="https://docs.aws.amazon.com/rekognition/latest/dg/api-video-roles.html#api-video-roles-all-topics">Giving access to multiple Amazon SNS topics</a>.</p>
        pub fn notification_channel(mut self, input: crate::model::NotificationChannel) -> Self {
            self.notification_channel = Some(input);
            self
        }
        /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the completion status of a video analysis operation. For more information, see <a href="https://docs.aws.amazon.com/rekognition/latest/dg/api-video.html">Calling Amazon Rekognition Video operations</a>. Note that the Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic. For more information, see <a href="https://docs.aws.amazon.com/rekognition/latest/dg/api-video-roles.html#api-video-roles-all-topics">Giving access to multiple Amazon SNS topics</a>.</p>
        pub fn set_notification_channel(mut self, input: std::option::Option<crate::model::NotificationChannel>) -> Self {
            self.notification_channel = input; self
        }
        /// <p>An identifier returned in the completion status published by your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn job_tag(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_tag = Some(input.into());
            self
        }
        /// <p>An identifier returned in the completion status published by your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
        pub fn set_job_tag(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_tag = input; self
        }
        /// <p>Optional parameters that let you set criteria the text must meet to be included in your response.</p>
        pub fn filters(mut self, input: crate::model::StartTextDetectionFilters) -> Self {
            self.filters = Some(input);
            self
        }
        /// <p>Optional parameters that let you set criteria the text must meet to be included in your response.</p>
        pub fn set_filters(mut self, input: std::option::Option<crate::model::StartTextDetectionFilters>) -> Self {
            self.filters = input; self
        }
        /// Consumes the builder and constructs a [`StartTextDetectionInput`](crate::input::StartTextDetectionInput).
        pub fn build(self) -> Result<crate::input::StartTextDetectionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StartTextDetectionInput {
                    video: self.video
                    ,
                    client_request_token: self.client_request_token
                    ,
                    notification_channel: self.notification_channel
                    ,
                    job_tag: self.job_tag
                    ,
                    filters: self.filters
                    ,
                }
            )
        }
    }
    
    
}
impl StartTextDetectionInput {
    /// Consumes the builder and constructs an Operation<[`StartTextDetection`](crate::operation::StartTextDetection)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StartTextDetection, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StartTextDetectionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StartTextDetectionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StartTextDetection"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_start_text_detection(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StartTextDetection::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StartTextDetection", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StartTextDetectionInput`](crate::input::StartTextDetectionInput).
    pub fn builder() -> crate::input::start_text_detection_input::Builder {
        crate::input::start_text_detection_input::Builder::default()
    }
}

/// See [`StopProjectVersionInput`](crate::input::StopProjectVersionInput).
pub mod stop_project_version_input {
    
    /// A builder for [`StopProjectVersionInput`](crate::input::StopProjectVersionInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) project_version_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the model version that you want to delete.</p> 
        /// <p>This operation requires permissions to perform the <code>rekognition:StopProjectVersion</code> action.</p>
        pub fn project_version_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.project_version_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the model version that you want to delete.</p> 
        /// <p>This operation requires permissions to perform the <code>rekognition:StopProjectVersion</code> action.</p>
        pub fn set_project_version_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.project_version_arn = input; self
        }
        /// Consumes the builder and constructs a [`StopProjectVersionInput`](crate::input::StopProjectVersionInput).
        pub fn build(self) -> Result<crate::input::StopProjectVersionInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StopProjectVersionInput {
                    project_version_arn: self.project_version_arn
                    ,
                }
            )
        }
    }
    
    
}
impl StopProjectVersionInput {
    /// Consumes the builder and constructs an Operation<[`StopProjectVersion`](crate::operation::StopProjectVersion)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StopProjectVersion, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StopProjectVersionInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StopProjectVersionInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StopProjectVersion"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_stop_project_version(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StopProjectVersion::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StopProjectVersion", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StopProjectVersionInput`](crate::input::StopProjectVersionInput).
    pub fn builder() -> crate::input::stop_project_version_input::Builder {
        crate::input::stop_project_version_input::Builder::default()
    }
}

/// See [`StopStreamProcessorInput`](crate::input::StopStreamProcessorInput).
pub mod stop_stream_processor_input {
    
    /// A builder for [`StopStreamProcessorInput`](crate::input::StopStreamProcessorInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) name: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of a stream processor created by <code>CreateStreamProcessor</code>.</p>
        pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
            self.name = Some(input.into());
            self
        }
        /// <p>The name of a stream processor created by <code>CreateStreamProcessor</code>.</p>
        pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.name = input; self
        }
        /// Consumes the builder and constructs a [`StopStreamProcessorInput`](crate::input::StopStreamProcessorInput).
        pub fn build(self) -> Result<crate::input::StopStreamProcessorInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::StopStreamProcessorInput {
                    name: self.name
                    ,
                }
            )
        }
    }
    
    
}
impl StopStreamProcessorInput {
    /// Consumes the builder and constructs an Operation<[`StopStreamProcessor`](crate::operation::StopStreamProcessor)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::StopStreamProcessor, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::StopStreamProcessorInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::StopStreamProcessorInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.StopStreamProcessor"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_stop_stream_processor(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::StopStreamProcessor::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("StopStreamProcessor", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`StopStreamProcessorInput`](crate::input::StopStreamProcessorInput).
    pub fn builder() -> crate::input::stop_stream_processor_input::Builder {
        crate::input::stop_stream_processor_input::Builder::default()
    }
}

/// See [`TagResourceInput`](crate::input::TagResourceInput).
pub mod tag_resource_input {
    
    /// A builder for [`TagResourceInput`](crate::input::TagResourceInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) resource_arn: std::option::Option<std::string::String>,
        pub(crate) tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    }
    impl Builder {
        /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that you want to assign the tags to. </p>
        pub fn resource_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.resource_arn = Some(input.into());
            self
        }
        /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that you want to assign the tags to. </p>
        pub fn set_resource_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.resource_arn = input; self
        }
        /// Adds a key-value pair to `tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p> The key-value tags to assign to the resource. </p>
        pub fn tags(mut self, k: impl Into<std::string::String>, v: impl Into<std::string::String>) -> Self {
            let mut hash_map = self.tags.unwrap_or_default();
                            hash_map.insert(k.into(), v.into());
                            self.tags = Some(hash_map);
                            self
        }
        /// <p> The key-value tags to assign to the resource. </p>
        pub fn set_tags(mut self, input: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>) -> Self {
            self.tags = input; self
        }
        /// Consumes the builder and constructs a [`TagResourceInput`](crate::input::TagResourceInput).
        pub fn build(self) -> Result<crate::input::TagResourceInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::TagResourceInput {
                    resource_arn: self.resource_arn
                    ,
                    tags: self.tags
                    ,
                }
            )
        }
    }
    
    
}
impl TagResourceInput {
    /// Consumes the builder and constructs an Operation<[`TagResource`](crate::operation::TagResource)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::TagResource, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::TagResourceInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::TagResourceInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.TagResource"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_tag_resource(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::TagResource::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("TagResource", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`TagResourceInput`](crate::input::TagResourceInput).
    pub fn builder() -> crate::input::tag_resource_input::Builder {
        crate::input::tag_resource_input::Builder::default()
    }
}

/// See [`UntagResourceInput`](crate::input::UntagResourceInput).
pub mod untag_resource_input {
    
    /// A builder for [`UntagResourceInput`](crate::input::UntagResourceInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) resource_arn: std::option::Option<std::string::String>,
        pub(crate) tag_keys: std::option::Option<std::vec::Vec<std::string::String>>,
    }
    impl Builder {
        /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that you want to remove the tags from. </p>
        pub fn resource_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.resource_arn = Some(input.into());
            self
        }
        /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that you want to remove the tags from. </p>
        pub fn set_resource_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.resource_arn = input; self
        }
        /// Appends an item to `tag_keys`.
        ///
        /// To override the contents of this collection use [`set_tag_keys`](Self::set_tag_keys).
        ///
        /// <p> A list of the tags that you want to remove. </p>
        pub fn tag_keys(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.tag_keys.unwrap_or_default();
                            v.push(input.into());
                            self.tag_keys = Some(v);
                            self
        }
        /// <p> A list of the tags that you want to remove. </p>
        pub fn set_tag_keys(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.tag_keys = input; self
        }
        /// Consumes the builder and constructs a [`UntagResourceInput`](crate::input::UntagResourceInput).
        pub fn build(self) -> Result<crate::input::UntagResourceInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::UntagResourceInput {
                    resource_arn: self.resource_arn
                    ,
                    tag_keys: self.tag_keys
                    ,
                }
            )
        }
    }
    
    
}
impl UntagResourceInput {
    /// Consumes the builder and constructs an Operation<[`UntagResource`](crate::operation::UntagResource)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::UntagResource, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::UntagResourceInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::UntagResourceInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.UntagResource"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_untag_resource(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::UntagResource::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("UntagResource", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`UntagResourceInput`](crate::input::UntagResourceInput).
    pub fn builder() -> crate::input::untag_resource_input::Builder {
        crate::input::untag_resource_input::Builder::default()
    }
}

/// See [`UpdateDatasetEntriesInput`](crate::input::UpdateDatasetEntriesInput).
pub mod update_dataset_entries_input {
    
    /// A builder for [`UpdateDatasetEntriesInput`](crate::input::UpdateDatasetEntriesInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
        pub(crate) changes: std::option::Option<crate::model::DatasetChanges>,
    }
    impl Builder {
        /// <p> The Amazon Resource Name (ARN) of the dataset that you want to update. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) of the dataset that you want to update. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input; self
        }
        /// <p> The changes that you want to make to the dataset. </p>
        pub fn changes(mut self, input: crate::model::DatasetChanges) -> Self {
            self.changes = Some(input);
            self
        }
        /// <p> The changes that you want to make to the dataset. </p>
        pub fn set_changes(mut self, input: std::option::Option<crate::model::DatasetChanges>) -> Self {
            self.changes = input; self
        }
        /// Consumes the builder and constructs a [`UpdateDatasetEntriesInput`](crate::input::UpdateDatasetEntriesInput).
        pub fn build(self) -> Result<crate::input::UpdateDatasetEntriesInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::UpdateDatasetEntriesInput {
                    dataset_arn: self.dataset_arn
                    ,
                    changes: self.changes
                    ,
                }
            )
        }
    }
    
    
}
impl UpdateDatasetEntriesInput {
    /// Consumes the builder and constructs an Operation<[`UpdateDatasetEntries`](crate::operation::UpdateDatasetEntries)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::UpdateDatasetEntries, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::UpdateDatasetEntriesInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::UpdateDatasetEntriesInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.UpdateDatasetEntries"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_update_dataset_entries(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::UpdateDatasetEntries::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("UpdateDatasetEntries", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`UpdateDatasetEntriesInput`](crate::input::UpdateDatasetEntriesInput).
    pub fn builder() -> crate::input::update_dataset_entries_input::Builder {
        crate::input::update_dataset_entries_input::Builder::default()
    }
}

/// See [`UpdateStreamProcessorInput`](crate::input::UpdateStreamProcessorInput).
pub mod update_stream_processor_input {
    
    /// A builder for [`UpdateStreamProcessorInput`](crate::input::UpdateStreamProcessorInput).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) name: std::option::Option<std::string::String>,
        pub(crate) settings_for_update: std::option::Option<crate::model::StreamProcessorSettingsForUpdate>,
        pub(crate) regions_of_interest_for_update: std::option::Option<std::vec::Vec<crate::model::RegionOfInterest>>,
        pub(crate) data_sharing_preference_for_update: std::option::Option<crate::model::StreamProcessorDataSharingPreference>,
        pub(crate) parameters_to_delete: std::option::Option<std::vec::Vec<crate::model::StreamProcessorParameterToDelete>>,
    }
    impl Builder {
        /// <p> Name of the stream processor that you want to update. </p>
        pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
            self.name = Some(input.into());
            self
        }
        /// <p> Name of the stream processor that you want to update. </p>
        pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.name = input; self
        }
        /// <p> The stream processor settings that you want to update. Label detection settings can be updated to detect different labels with a different minimum confidence. </p>
        pub fn settings_for_update(mut self, input: crate::model::StreamProcessorSettingsForUpdate) -> Self {
            self.settings_for_update = Some(input);
            self
        }
        /// <p> The stream processor settings that you want to update. Label detection settings can be updated to detect different labels with a different minimum confidence. </p>
        pub fn set_settings_for_update(mut self, input: std::option::Option<crate::model::StreamProcessorSettingsForUpdate>) -> Self {
            self.settings_for_update = input; self
        }
        /// Appends an item to `regions_of_interest_for_update`.
        ///
        /// To override the contents of this collection use [`set_regions_of_interest_for_update`](Self::set_regions_of_interest_for_update).
        ///
        /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. This is an optional parameter for label detection stream processors. </p>
        pub fn regions_of_interest_for_update(mut self, input: crate::model::RegionOfInterest) -> Self {
            let mut v = self.regions_of_interest_for_update.unwrap_or_default();
                            v.push(input);
                            self.regions_of_interest_for_update = Some(v);
                            self
        }
        /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. This is an optional parameter for label detection stream processors. </p>
        pub fn set_regions_of_interest_for_update(mut self, input: std::option::Option<std::vec::Vec<crate::model::RegionOfInterest>>) -> Self {
            self.regions_of_interest_for_update = input; self
        }
        /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
        pub fn data_sharing_preference_for_update(mut self, input: crate::model::StreamProcessorDataSharingPreference) -> Self {
            self.data_sharing_preference_for_update = Some(input);
            self
        }
        /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
        pub fn set_data_sharing_preference_for_update(mut self, input: std::option::Option<crate::model::StreamProcessorDataSharingPreference>) -> Self {
            self.data_sharing_preference_for_update = input; self
        }
        /// Appends an item to `parameters_to_delete`.
        ///
        /// To override the contents of this collection use [`set_parameters_to_delete`](Self::set_parameters_to_delete).
        ///
        /// <p> A list of parameters you want to delete from the stream processor. </p>
        pub fn parameters_to_delete(mut self, input: crate::model::StreamProcessorParameterToDelete) -> Self {
            let mut v = self.parameters_to_delete.unwrap_or_default();
                            v.push(input);
                            self.parameters_to_delete = Some(v);
                            self
        }
        /// <p> A list of parameters you want to delete from the stream processor. </p>
        pub fn set_parameters_to_delete(mut self, input: std::option::Option<std::vec::Vec<crate::model::StreamProcessorParameterToDelete>>) -> Self {
            self.parameters_to_delete = input; self
        }
        /// Consumes the builder and constructs a [`UpdateStreamProcessorInput`](crate::input::UpdateStreamProcessorInput).
        pub fn build(self) -> Result<crate::input::UpdateStreamProcessorInput, aws_smithy_http::operation::error::BuildError> {
            Ok(
                crate::input::UpdateStreamProcessorInput {
                    name: self.name
                    ,
                    settings_for_update: self.settings_for_update
                    ,
                    regions_of_interest_for_update: self.regions_of_interest_for_update
                    ,
                    data_sharing_preference_for_update: self.data_sharing_preference_for_update
                    ,
                    parameters_to_delete: self.parameters_to_delete
                    ,
                }
            )
        }
    }
    
    
}
impl UpdateStreamProcessorInput {
    /// Consumes the builder and constructs an Operation<[`UpdateStreamProcessor`](crate::operation::UpdateStreamProcessor)>
    #[allow(unused_mut)]
    #[allow(clippy::let_and_return)]
    #[allow(clippy::needless_borrow)]
    pub async fn make_operation(&self, _config: &crate::config::Config) -> std::result::Result<aws_smithy_http::operation::Operation<crate::operation::UpdateStreamProcessor, aws_http::retry::AwsResponseRetryClassifier>, aws_smithy_http::operation::error::BuildError> {
        let params_result = crate::endpoint::Params::builder().set_region(_config.region.as_ref().map(|r|r.as_ref().to_owned()))
        .set_use_dual_stack(_config.use_dual_stack)
        .set_use_fips(_config.use_fips)
        .set_endpoint(_config.endpoint_url
        .clone()).build()
                                    .map_err(|err|aws_smithy_http::endpoint::ResolveEndpointError::from_source("could not construct endpoint parameters", err));
                                let (endpoint_result, params) = match params_result {
                                    Ok(params) => (_config.endpoint_resolver.resolve_endpoint(&params), Some(params)),
                                    Err(e) => (Err(e), None)
                                };
        let mut request = {
            fn uri_base(_input: &crate::input::UpdateStreamProcessorInput, output: &mut String) -> Result<(), aws_smithy_http::operation::error::BuildError> {
                write!(output, "/").expect("formatting should succeed");
                Ok(())
            }
            #[allow(clippy::unnecessary_wraps)]
            fn update_http_builder(
                            input: &crate::input::UpdateStreamProcessorInput,
                            builder: http::request::Builder
                        ) -> std::result::Result<http::request::Builder, aws_smithy_http::operation::error::BuildError> {
                let mut uri = String::new();
                uri_base(input, &mut uri)?;
                Ok(builder.method("POST").uri(uri))
            }
            let mut builder = update_http_builder(&self, http::request::Builder::new())?;
            builder = aws_smithy_http::header::set_request_header_if_absent(builder, http::header::CONTENT_TYPE, "application/x-amz-json-1.1");
            builder = aws_smithy_http::header::set_request_header_if_absent(
                                builder,
                                http::header::HeaderName::from_static("x-amz-target"),
                                "RekognitionService.UpdateStreamProcessor"
                            );
            builder
        };
        let mut properties = aws_smithy_http::property_bag::SharedPropertyBag::new();
        #[allow(clippy::useless_conversion)]
        let body = aws_smithy_http::body::SdkBody::from(
            crate::operation_ser::serialize_operation_crate_operation_update_stream_processor(&self)?
        );
        if let Some(content_length) = body.content_length() {
                                request = aws_smithy_http::header::set_request_header_if_absent(request, http::header::CONTENT_LENGTH, content_length);
                            }
        let request = request.body(body).expect("should be valid request");
        let mut request = aws_smithy_http::operation::Request::from_parts(request, properties);
        request.properties_mut().insert(endpoint_result);
        if let Some(params) = params { request.properties_mut().insert(params); }
        request.properties_mut().insert(aws_smithy_http::http_versions::DEFAULT_HTTP_VERSION_LIST.clone());
        let mut user_agent = aws_http::user_agent::AwsUserAgent::new_from_environment(
                                aws_types::os_shim_internal::Env::real(),
                                crate::API_METADATA.clone(),
                            );
                            if let Some(app_name) = _config.app_name() {
                                user_agent = user_agent.with_app_name(app_name.clone());
                            }
                            request.properties_mut().insert(user_agent);
        let mut signing_config = aws_sig_auth::signer::OperationSigningConfig::default_config();
        request.properties_mut().insert(signing_config);
                            request.properties_mut().insert(aws_types::SigningService::from_static(_config.signing_service()));
                            if let Some(region) = &_config.region {
                                request.properties_mut().insert(aws_types::region::SigningRegion::from(region.clone()));
                            }
        if let Some(region) = &_config.region {
                                request.properties_mut().insert(region.clone());
                            }
        aws_http::auth::set_credentials_cache(&mut request.properties_mut(), _config.credentials_cache.clone());
        let op = aws_smithy_http::operation::Operation::new(request, crate::operation::UpdateStreamProcessor::new())
                            .with_metadata(aws_smithy_http::operation::Metadata::new("UpdateStreamProcessor", "rekognition"));
        let op = op.with_retry_classifier(aws_http::retry::AwsResponseRetryClassifier::new());
        Ok(op)
    }
    /// Creates a new builder-style object to manufacture [`UpdateStreamProcessorInput`](crate::input::UpdateStreamProcessorInput).
    pub fn builder() -> crate::input::update_stream_processor_input::Builder {
        crate::input::update_stream_processor_input::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct UpdateStreamProcessorInput  {
    /// <p> Name of the stream processor that you want to update. </p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
    /// <p> The stream processor settings that you want to update. Label detection settings can be updated to detect different labels with a different minimum confidence. </p>
    #[doc(hidden)]
    pub settings_for_update: std::option::Option<crate::model::StreamProcessorSettingsForUpdate>,
    /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. This is an optional parameter for label detection stream processors. </p>
    #[doc(hidden)]
    pub regions_of_interest_for_update: std::option::Option<std::vec::Vec<crate::model::RegionOfInterest>>,
    /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
    #[doc(hidden)]
    pub data_sharing_preference_for_update: std::option::Option<crate::model::StreamProcessorDataSharingPreference>,
    /// <p> A list of parameters you want to delete from the stream processor. </p>
    #[doc(hidden)]
    pub parameters_to_delete: std::option::Option<std::vec::Vec<crate::model::StreamProcessorParameterToDelete>>,
}
impl UpdateStreamProcessorInput {
    /// <p> Name of the stream processor that you want to update. </p>
    pub fn name(&self) -> std::option::Option<& str> {
        self.name.as_deref()
    }
    /// <p> The stream processor settings that you want to update. Label detection settings can be updated to detect different labels with a different minimum confidence. </p>
    pub fn settings_for_update(&self) -> std::option::Option<& crate::model::StreamProcessorSettingsForUpdate> {
        self.settings_for_update.as_ref()
    }
    /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. This is an optional parameter for label detection stream processors. </p>
    pub fn regions_of_interest_for_update(&self) -> std::option::Option<& [crate::model::RegionOfInterest]> {
        self.regions_of_interest_for_update.as_deref()
    }
    /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
    pub fn data_sharing_preference_for_update(&self) -> std::option::Option<& crate::model::StreamProcessorDataSharingPreference> {
        self.data_sharing_preference_for_update.as_ref()
    }
    /// <p> A list of parameters you want to delete from the stream processor. </p>
    pub fn parameters_to_delete(&self) -> std::option::Option<& [crate::model::StreamProcessorParameterToDelete]> {
        self.parameters_to_delete.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct UpdateDatasetEntriesInput  {
    /// <p> The Amazon Resource Name (ARN) of the dataset that you want to update. </p>
    #[doc(hidden)]
    pub dataset_arn: std::option::Option<std::string::String>,
    /// <p> The changes that you want to make to the dataset. </p>
    #[doc(hidden)]
    pub changes: std::option::Option<crate::model::DatasetChanges>,
}
impl UpdateDatasetEntriesInput {
    /// <p> The Amazon Resource Name (ARN) of the dataset that you want to update. </p>
    pub fn dataset_arn(&self) -> std::option::Option<& str> {
        self.dataset_arn.as_deref()
    }
    /// <p> The changes that you want to make to the dataset. </p>
    pub fn changes(&self) -> std::option::Option<& crate::model::DatasetChanges> {
        self.changes.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct UntagResourceInput  {
    /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that you want to remove the tags from. </p>
    #[doc(hidden)]
    pub resource_arn: std::option::Option<std::string::String>,
    /// <p> A list of the tags that you want to remove. </p>
    #[doc(hidden)]
    pub tag_keys: std::option::Option<std::vec::Vec<std::string::String>>,
}
impl UntagResourceInput {
    /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that you want to remove the tags from. </p>
    pub fn resource_arn(&self) -> std::option::Option<& str> {
        self.resource_arn.as_deref()
    }
    /// <p> A list of the tags that you want to remove. </p>
    pub fn tag_keys(&self) -> std::option::Option<& [std::string::String]> {
        self.tag_keys.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct TagResourceInput  {
    /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that you want to assign the tags to. </p>
    #[doc(hidden)]
    pub resource_arn: std::option::Option<std::string::String>,
    /// <p> The key-value tags to assign to the resource. </p>
    #[doc(hidden)]
    pub tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
}
impl TagResourceInput {
    /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that you want to assign the tags to. </p>
    pub fn resource_arn(&self) -> std::option::Option<& str> {
        self.resource_arn.as_deref()
    }
    /// <p> The key-value tags to assign to the resource. </p>
    pub fn tags(&self) -> std::option::Option<& std::collections::HashMap<std::string::String, std::string::String>> {
        self.tags.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StopStreamProcessorInput  {
    /// <p>The name of a stream processor created by <code>CreateStreamProcessor</code>.</p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
}
impl StopStreamProcessorInput {
    /// <p>The name of a stream processor created by <code>CreateStreamProcessor</code>.</p>
    pub fn name(&self) -> std::option::Option<& str> {
        self.name.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StopProjectVersionInput  {
    /// <p>The Amazon Resource Name (ARN) of the model version that you want to delete.</p> 
    /// <p>This operation requires permissions to perform the <code>rekognition:StopProjectVersion</code> action.</p>
    #[doc(hidden)]
    pub project_version_arn: std::option::Option<std::string::String>,
}
impl StopProjectVersionInput {
    /// <p>The Amazon Resource Name (ARN) of the model version that you want to delete.</p> 
    /// <p>This operation requires permissions to perform the <code>rekognition:StopProjectVersion</code> action.</p>
    pub fn project_version_arn(&self) -> std::option::Option<& str> {
        self.project_version_arn.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartTextDetectionInput  {
    /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
    #[doc(hidden)]
    pub video: std::option::Option<crate::model::Video>,
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartTextDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidentaly started more than once.</p>
    #[doc(hidden)]
    pub client_request_token: std::option::Option<std::string::String>,
    /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the completion status of a video analysis operation. For more information, see <a href="https://docs.aws.amazon.com/rekognition/latest/dg/api-video.html">Calling Amazon Rekognition Video operations</a>. Note that the Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic. For more information, see <a href="https://docs.aws.amazon.com/rekognition/latest/dg/api-video-roles.html#api-video-roles-all-topics">Giving access to multiple Amazon SNS topics</a>.</p>
    #[doc(hidden)]
    pub notification_channel: std::option::Option<crate::model::NotificationChannel>,
    /// <p>An identifier returned in the completion status published by your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    #[doc(hidden)]
    pub job_tag: std::option::Option<std::string::String>,
    /// <p>Optional parameters that let you set criteria the text must meet to be included in your response.</p>
    #[doc(hidden)]
    pub filters: std::option::Option<crate::model::StartTextDetectionFilters>,
}
impl StartTextDetectionInput {
    /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
    pub fn video(&self) -> std::option::Option<& crate::model::Video> {
        self.video.as_ref()
    }
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartTextDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidentaly started more than once.</p>
    pub fn client_request_token(&self) -> std::option::Option<& str> {
        self.client_request_token.as_deref()
    }
    /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the completion status of a video analysis operation. For more information, see <a href="https://docs.aws.amazon.com/rekognition/latest/dg/api-video.html">Calling Amazon Rekognition Video operations</a>. Note that the Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic. For more information, see <a href="https://docs.aws.amazon.com/rekognition/latest/dg/api-video-roles.html#api-video-roles-all-topics">Giving access to multiple Amazon SNS topics</a>.</p>
    pub fn notification_channel(&self) -> std::option::Option<& crate::model::NotificationChannel> {
        self.notification_channel.as_ref()
    }
    /// <p>An identifier returned in the completion status published by your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    pub fn job_tag(&self) -> std::option::Option<& str> {
        self.job_tag.as_deref()
    }
    /// <p>Optional parameters that let you set criteria the text must meet to be included in your response.</p>
    pub fn filters(&self) -> std::option::Option<& crate::model::StartTextDetectionFilters> {
        self.filters.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartStreamProcessorInput  {
    /// <p>The name of the stream processor to start processing.</p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
    /// <p> Specifies the starting point in the Kinesis stream to start processing. You can use the producer timestamp or the fragment number. If you use the producer timestamp, you must put the time in milliseconds. For more information about fragment numbers, see <a href="https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/API_reader_Fragment.html">Fragment</a>. </p> 
    /// <p>This is a required parameter for label detection stream processors and should not be used to start a face search stream processor.</p>
    #[doc(hidden)]
    pub start_selector: std::option::Option<crate::model::StreamProcessingStartSelector>,
    /// <p> Specifies when to stop processing the stream. You can specify a maximum amount of time to process the video. </p> 
    /// <p>This is a required parameter for label detection stream processors and should not be used to start a face search stream processor.</p>
    #[doc(hidden)]
    pub stop_selector: std::option::Option<crate::model::StreamProcessingStopSelector>,
}
impl StartStreamProcessorInput {
    /// <p>The name of the stream processor to start processing.</p>
    pub fn name(&self) -> std::option::Option<& str> {
        self.name.as_deref()
    }
    /// <p> Specifies the starting point in the Kinesis stream to start processing. You can use the producer timestamp or the fragment number. If you use the producer timestamp, you must put the time in milliseconds. For more information about fragment numbers, see <a href="https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/API_reader_Fragment.html">Fragment</a>. </p> 
    /// <p>This is a required parameter for label detection stream processors and should not be used to start a face search stream processor.</p>
    pub fn start_selector(&self) -> std::option::Option<& crate::model::StreamProcessingStartSelector> {
        self.start_selector.as_ref()
    }
    /// <p> Specifies when to stop processing the stream. You can specify a maximum amount of time to process the video. </p> 
    /// <p>This is a required parameter for label detection stream processors and should not be used to start a face search stream processor.</p>
    pub fn stop_selector(&self) -> std::option::Option<& crate::model::StreamProcessingStopSelector> {
        self.stop_selector.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartSegmentDetectionInput  {
    /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
    #[doc(hidden)]
    pub video: std::option::Option<crate::model::Video>,
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartSegmentDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    #[doc(hidden)]
    pub client_request_token: std::option::Option<std::string::String>,
    /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the segment detection operation. Note that the Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
    #[doc(hidden)]
    pub notification_channel: std::option::Option<crate::model::NotificationChannel>,
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    #[doc(hidden)]
    pub job_tag: std::option::Option<std::string::String>,
    /// <p>Filters for technical cue or shot detection.</p>
    #[doc(hidden)]
    pub filters: std::option::Option<crate::model::StartSegmentDetectionFilters>,
    /// <p>An array of segment types to detect in the video. Valid values are TECHNICAL_CUE and SHOT.</p>
    #[doc(hidden)]
    pub segment_types: std::option::Option<std::vec::Vec<crate::model::SegmentType>>,
}
impl StartSegmentDetectionInput {
    /// <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
    pub fn video(&self) -> std::option::Option<& crate::model::Video> {
        self.video.as_ref()
    }
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartSegmentDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    pub fn client_request_token(&self) -> std::option::Option<& str> {
        self.client_request_token.as_deref()
    }
    /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the segment detection operation. Note that the Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
    pub fn notification_channel(&self) -> std::option::Option<& crate::model::NotificationChannel> {
        self.notification_channel.as_ref()
    }
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    pub fn job_tag(&self) -> std::option::Option<& str> {
        self.job_tag.as_deref()
    }
    /// <p>Filters for technical cue or shot detection.</p>
    pub fn filters(&self) -> std::option::Option<& crate::model::StartSegmentDetectionFilters> {
        self.filters.as_ref()
    }
    /// <p>An array of segment types to detect in the video. Valid values are TECHNICAL_CUE and SHOT.</p>
    pub fn segment_types(&self) -> std::option::Option<& [crate::model::SegmentType]> {
        self.segment_types.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartProjectVersionInput  {
    /// <p>The Amazon Resource Name(ARN) of the model version that you want to start.</p>
    #[doc(hidden)]
    pub project_version_arn: std::option::Option<std::string::String>,
    /// <p>The minimum number of inference units to use. A single inference unit represents 1 hour of processing. </p> 
    /// <p>For information about the number of transactions per second (TPS) that an inference unit can support, see <i>Running a trained Amazon Rekognition Custom Labels model</i> in the Amazon Rekognition Custom Labels Guide. </p> 
    /// <p>Use a higher number to increase the TPS throughput of your model. You are charged for the number of inference units that you use. </p>
    #[doc(hidden)]
    pub min_inference_units: std::option::Option<i32>,
    /// <p>The maximum number of inference units to use for auto-scaling the model. If you don't specify a value, Amazon Rekognition Custom Labels doesn't auto-scale the model.</p>
    #[doc(hidden)]
    pub max_inference_units: std::option::Option<i32>,
}
impl StartProjectVersionInput {
    /// <p>The Amazon Resource Name(ARN) of the model version that you want to start.</p>
    pub fn project_version_arn(&self) -> std::option::Option<& str> {
        self.project_version_arn.as_deref()
    }
    /// <p>The minimum number of inference units to use. A single inference unit represents 1 hour of processing. </p> 
    /// <p>For information about the number of transactions per second (TPS) that an inference unit can support, see <i>Running a trained Amazon Rekognition Custom Labels model</i> in the Amazon Rekognition Custom Labels Guide. </p> 
    /// <p>Use a higher number to increase the TPS throughput of your model. You are charged for the number of inference units that you use. </p>
    pub fn min_inference_units(&self) -> std::option::Option<i32> {
        self.min_inference_units
    }
    /// <p>The maximum number of inference units to use for auto-scaling the model. If you don't specify a value, Amazon Rekognition Custom Labels doesn't auto-scale the model.</p>
    pub fn max_inference_units(&self) -> std::option::Option<i32> {
        self.max_inference_units
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartPersonTrackingInput  {
    /// <p>The video in which you want to detect people. The video must be stored in an Amazon S3 bucket.</p>
    #[doc(hidden)]
    pub video: std::option::Option<crate::model::Video>,
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartPersonTracking</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    #[doc(hidden)]
    pub client_request_token: std::option::Option<std::string::String>,
    /// <p>The Amazon SNS topic ARN you want Amazon Rekognition Video to publish the completion status of the people detection operation to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
    #[doc(hidden)]
    pub notification_channel: std::option::Option<crate::model::NotificationChannel>,
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    #[doc(hidden)]
    pub job_tag: std::option::Option<std::string::String>,
}
impl StartPersonTrackingInput {
    /// <p>The video in which you want to detect people. The video must be stored in an Amazon S3 bucket.</p>
    pub fn video(&self) -> std::option::Option<& crate::model::Video> {
        self.video.as_ref()
    }
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartPersonTracking</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    pub fn client_request_token(&self) -> std::option::Option<& str> {
        self.client_request_token.as_deref()
    }
    /// <p>The Amazon SNS topic ARN you want Amazon Rekognition Video to publish the completion status of the people detection operation to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
    pub fn notification_channel(&self) -> std::option::Option<& crate::model::NotificationChannel> {
        self.notification_channel.as_ref()
    }
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    pub fn job_tag(&self) -> std::option::Option<& str> {
        self.job_tag.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartLabelDetectionInput  {
    /// <p>The video in which you want to detect labels. The video must be stored in an Amazon S3 bucket.</p>
    #[doc(hidden)]
    pub video: std::option::Option<crate::model::Video>,
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartLabelDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    #[doc(hidden)]
    pub client_request_token: std::option::Option<std::string::String>,
    /// <p>Specifies the minimum confidence that Amazon Rekognition Video must have in order to return a detected label. Confidence represents how certain Amazon Rekognition is that a label is correctly identified.0 is the lowest confidence. 100 is the highest confidence. Amazon Rekognition Video doesn't return any labels with a confidence level lower than this specified value.</p> 
    /// <p>If you don't specify <code>MinConfidence</code>, the operation returns labels and bounding boxes (if detected) with confidence values greater than or equal to 50 percent.</p>
    #[doc(hidden)]
    pub min_confidence: std::option::Option<f32>,
    /// <p>The Amazon SNS topic ARN you want Amazon Rekognition Video to publish the completion status of the label detection operation to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
    #[doc(hidden)]
    pub notification_channel: std::option::Option<crate::model::NotificationChannel>,
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    #[doc(hidden)]
    pub job_tag: std::option::Option<std::string::String>,
    /// <p>The features to return after video analysis. You can specify that GENERAL_LABELS are returned.</p>
    #[doc(hidden)]
    pub features: std::option::Option<std::vec::Vec<crate::model::LabelDetectionFeatureName>>,
    /// <p>The settings for a StartLabelDetection request.Contains the specified parameters for the label detection request of an asynchronous label analysis operation. Settings can include filters for GENERAL_LABELS.</p>
    #[doc(hidden)]
    pub settings: std::option::Option<crate::model::LabelDetectionSettings>,
}
impl StartLabelDetectionInput {
    /// <p>The video in which you want to detect labels. The video must be stored in an Amazon S3 bucket.</p>
    pub fn video(&self) -> std::option::Option<& crate::model::Video> {
        self.video.as_ref()
    }
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartLabelDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    pub fn client_request_token(&self) -> std::option::Option<& str> {
        self.client_request_token.as_deref()
    }
    /// <p>Specifies the minimum confidence that Amazon Rekognition Video must have in order to return a detected label. Confidence represents how certain Amazon Rekognition is that a label is correctly identified.0 is the lowest confidence. 100 is the highest confidence. Amazon Rekognition Video doesn't return any labels with a confidence level lower than this specified value.</p> 
    /// <p>If you don't specify <code>MinConfidence</code>, the operation returns labels and bounding boxes (if detected) with confidence values greater than or equal to 50 percent.</p>
    pub fn min_confidence(&self) -> std::option::Option<f32> {
        self.min_confidence
    }
    /// <p>The Amazon SNS topic ARN you want Amazon Rekognition Video to publish the completion status of the label detection operation to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
    pub fn notification_channel(&self) -> std::option::Option<& crate::model::NotificationChannel> {
        self.notification_channel.as_ref()
    }
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    pub fn job_tag(&self) -> std::option::Option<& str> {
        self.job_tag.as_deref()
    }
    /// <p>The features to return after video analysis. You can specify that GENERAL_LABELS are returned.</p>
    pub fn features(&self) -> std::option::Option<& [crate::model::LabelDetectionFeatureName]> {
        self.features.as_deref()
    }
    /// <p>The settings for a StartLabelDetection request.Contains the specified parameters for the label detection request of an asynchronous label analysis operation. Settings can include filters for GENERAL_LABELS.</p>
    pub fn settings(&self) -> std::option::Option<& crate::model::LabelDetectionSettings> {
        self.settings.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartFaceSearchInput  {
    /// <p>The video you want to search. The video must be stored in an Amazon S3 bucket. </p>
    #[doc(hidden)]
    pub video: std::option::Option<crate::model::Video>,
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartFaceSearch</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    #[doc(hidden)]
    pub client_request_token: std::option::Option<std::string::String>,
    /// <p>The minimum confidence in the person match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%.</p>
    #[doc(hidden)]
    pub face_match_threshold: std::option::Option<f32>,
    /// <p>ID of the collection that contains the faces you want to search for.</p>
    #[doc(hidden)]
    pub collection_id: std::option::Option<std::string::String>,
    /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the search. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
    #[doc(hidden)]
    pub notification_channel: std::option::Option<crate::model::NotificationChannel>,
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    #[doc(hidden)]
    pub job_tag: std::option::Option<std::string::String>,
}
impl StartFaceSearchInput {
    /// <p>The video you want to search. The video must be stored in an Amazon S3 bucket. </p>
    pub fn video(&self) -> std::option::Option<& crate::model::Video> {
        self.video.as_ref()
    }
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartFaceSearch</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    pub fn client_request_token(&self) -> std::option::Option<& str> {
        self.client_request_token.as_deref()
    }
    /// <p>The minimum confidence in the person match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%.</p>
    pub fn face_match_threshold(&self) -> std::option::Option<f32> {
        self.face_match_threshold
    }
    /// <p>ID of the collection that contains the faces you want to search for.</p>
    pub fn collection_id(&self) -> std::option::Option<& str> {
        self.collection_id.as_deref()
    }
    /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the search. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
    pub fn notification_channel(&self) -> std::option::Option<& crate::model::NotificationChannel> {
        self.notification_channel.as_ref()
    }
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    pub fn job_tag(&self) -> std::option::Option<& str> {
        self.job_tag.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartFaceDetectionInput  {
    /// <p>The video in which you want to detect faces. The video must be stored in an Amazon S3 bucket.</p>
    #[doc(hidden)]
    pub video: std::option::Option<crate::model::Video>,
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartFaceDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    #[doc(hidden)]
    pub client_request_token: std::option::Option<std::string::String>,
    /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the face detection operation. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
    #[doc(hidden)]
    pub notification_channel: std::option::Option<crate::model::NotificationChannel>,
    /// <p>The face attributes you want returned.</p> 
    /// <p> <code>DEFAULT</code> - The following subset of facial attributes are returned: BoundingBox, Confidence, Pose, Quality and Landmarks. </p> 
    /// <p> <code>ALL</code> - All facial attributes are returned.</p>
    #[doc(hidden)]
    pub face_attributes: std::option::Option<crate::model::FaceAttributes>,
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    #[doc(hidden)]
    pub job_tag: std::option::Option<std::string::String>,
}
impl StartFaceDetectionInput {
    /// <p>The video in which you want to detect faces. The video must be stored in an Amazon S3 bucket.</p>
    pub fn video(&self) -> std::option::Option<& crate::model::Video> {
        self.video.as_ref()
    }
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartFaceDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    pub fn client_request_token(&self) -> std::option::Option<& str> {
        self.client_request_token.as_deref()
    }
    /// <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the face detection operation. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
    pub fn notification_channel(&self) -> std::option::Option<& crate::model::NotificationChannel> {
        self.notification_channel.as_ref()
    }
    /// <p>The face attributes you want returned.</p> 
    /// <p> <code>DEFAULT</code> - The following subset of facial attributes are returned: BoundingBox, Confidence, Pose, Quality and Landmarks. </p> 
    /// <p> <code>ALL</code> - All facial attributes are returned.</p>
    pub fn face_attributes(&self) -> std::option::Option<& crate::model::FaceAttributes> {
        self.face_attributes.as_ref()
    }
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    pub fn job_tag(&self) -> std::option::Option<& str> {
        self.job_tag.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartContentModerationInput  {
    /// <p>The video in which you want to detect inappropriate, unwanted, or offensive content. The video must be stored in an Amazon S3 bucket.</p>
    #[doc(hidden)]
    pub video: std::option::Option<crate::model::Video>,
    /// <p>Specifies the minimum confidence that Amazon Rekognition must have in order to return a moderated content label. Confidence represents how certain Amazon Rekognition is that the moderated content is correctly identified. 0 is the lowest confidence. 100 is the highest confidence. Amazon Rekognition doesn't return any moderated content labels with a confidence level lower than this specified value. If you don't specify <code>MinConfidence</code>, <code>GetContentModeration</code> returns labels with confidence values greater than or equal to 50 percent.</p>
    #[doc(hidden)]
    pub min_confidence: std::option::Option<f32>,
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartContentModeration</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    #[doc(hidden)]
    pub client_request_token: std::option::Option<std::string::String>,
    /// <p>The Amazon SNS topic ARN that you want Amazon Rekognition Video to publish the completion status of the content analysis to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
    #[doc(hidden)]
    pub notification_channel: std::option::Option<crate::model::NotificationChannel>,
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    #[doc(hidden)]
    pub job_tag: std::option::Option<std::string::String>,
}
impl StartContentModerationInput {
    /// <p>The video in which you want to detect inappropriate, unwanted, or offensive content. The video must be stored in an Amazon S3 bucket.</p>
    pub fn video(&self) -> std::option::Option<& crate::model::Video> {
        self.video.as_ref()
    }
    /// <p>Specifies the minimum confidence that Amazon Rekognition must have in order to return a moderated content label. Confidence represents how certain Amazon Rekognition is that the moderated content is correctly identified. 0 is the lowest confidence. 100 is the highest confidence. Amazon Rekognition doesn't return any moderated content labels with a confidence level lower than this specified value. If you don't specify <code>MinConfidence</code>, <code>GetContentModeration</code> returns labels with confidence values greater than or equal to 50 percent.</p>
    pub fn min_confidence(&self) -> std::option::Option<f32> {
        self.min_confidence
    }
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartContentModeration</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    pub fn client_request_token(&self) -> std::option::Option<& str> {
        self.client_request_token.as_deref()
    }
    /// <p>The Amazon SNS topic ARN that you want Amazon Rekognition Video to publish the completion status of the content analysis to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
    pub fn notification_channel(&self) -> std::option::Option<& crate::model::NotificationChannel> {
        self.notification_channel.as_ref()
    }
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    pub fn job_tag(&self) -> std::option::Option<& str> {
        self.job_tag.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartCelebrityRecognitionInput  {
    /// <p>The video in which you want to recognize celebrities. The video must be stored in an Amazon S3 bucket.</p>
    #[doc(hidden)]
    pub video: std::option::Option<crate::model::Video>,
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartCelebrityRecognition</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    #[doc(hidden)]
    pub client_request_token: std::option::Option<std::string::String>,
    /// <p>The Amazon SNS topic ARN that you want Amazon Rekognition Video to publish the completion status of the celebrity recognition analysis to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
    #[doc(hidden)]
    pub notification_channel: std::option::Option<crate::model::NotificationChannel>,
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    #[doc(hidden)]
    pub job_tag: std::option::Option<std::string::String>,
}
impl StartCelebrityRecognitionInput {
    /// <p>The video in which you want to recognize celebrities. The video must be stored in an Amazon S3 bucket.</p>
    pub fn video(&self) -> std::option::Option<& crate::model::Video> {
        self.video.as_ref()
    }
    /// <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartCelebrityRecognition</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    pub fn client_request_token(&self) -> std::option::Option<& str> {
        self.client_request_token.as_deref()
    }
    /// <p>The Amazon SNS topic ARN that you want Amazon Rekognition Video to publish the completion status of the celebrity recognition analysis to. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
    pub fn notification_channel(&self) -> std::option::Option<& crate::model::NotificationChannel> {
        self.notification_channel.as_ref()
    }
    /// <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    pub fn job_tag(&self) -> std::option::Option<& str> {
        self.job_tag.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct SearchFacesByImageInput  {
    /// <p>ID of the collection to search.</p>
    #[doc(hidden)]
    pub collection_id: std::option::Option<std::string::String>,
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    #[doc(hidden)]
    pub image: std::option::Option<crate::model::Image>,
    /// <p>Maximum number of faces to return. The operation returns the maximum number of faces with the highest confidence in the match.</p>
    #[doc(hidden)]
    pub max_faces: std::option::Option<i32>,
    /// <p>(Optional) Specifies the minimum confidence in the face match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%.</p>
    #[doc(hidden)]
    pub face_match_threshold: std::option::Option<f32>,
    /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't searched for in the collection. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. The default value is <code>NONE</code>. </p> 
    /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
    #[doc(hidden)]
    pub quality_filter: std::option::Option<crate::model::QualityFilter>,
}
impl SearchFacesByImageInput {
    /// <p>ID of the collection to search.</p>
    pub fn collection_id(&self) -> std::option::Option<& str> {
        self.collection_id.as_deref()
    }
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn image(&self) -> std::option::Option<& crate::model::Image> {
        self.image.as_ref()
    }
    /// <p>Maximum number of faces to return. The operation returns the maximum number of faces with the highest confidence in the match.</p>
    pub fn max_faces(&self) -> std::option::Option<i32> {
        self.max_faces
    }
    /// <p>(Optional) Specifies the minimum confidence in the face match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%.</p>
    pub fn face_match_threshold(&self) -> std::option::Option<f32> {
        self.face_match_threshold
    }
    /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't searched for in the collection. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. The default value is <code>NONE</code>. </p> 
    /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
    pub fn quality_filter(&self) -> std::option::Option<& crate::model::QualityFilter> {
        self.quality_filter.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct SearchFacesInput  {
    /// <p>ID of the collection the face belongs to.</p>
    #[doc(hidden)]
    pub collection_id: std::option::Option<std::string::String>,
    /// <p>ID of a face to find matches for in the collection.</p>
    #[doc(hidden)]
    pub face_id: std::option::Option<std::string::String>,
    /// <p>Maximum number of faces to return. The operation returns the maximum number of faces with the highest confidence in the match.</p>
    #[doc(hidden)]
    pub max_faces: std::option::Option<i32>,
    /// <p>Optional value specifying the minimum confidence in the face match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%. </p>
    #[doc(hidden)]
    pub face_match_threshold: std::option::Option<f32>,
}
impl SearchFacesInput {
    /// <p>ID of the collection the face belongs to.</p>
    pub fn collection_id(&self) -> std::option::Option<& str> {
        self.collection_id.as_deref()
    }
    /// <p>ID of a face to find matches for in the collection.</p>
    pub fn face_id(&self) -> std::option::Option<& str> {
        self.face_id.as_deref()
    }
    /// <p>Maximum number of faces to return. The operation returns the maximum number of faces with the highest confidence in the match.</p>
    pub fn max_faces(&self) -> std::option::Option<i32> {
        self.max_faces
    }
    /// <p>Optional value specifying the minimum confidence in the face match to return. For example, don't return any matches where confidence in matches is less than 70%. The default value is 80%. </p>
    pub fn face_match_threshold(&self) -> std::option::Option<f32> {
        self.face_match_threshold
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct RecognizeCelebritiesInput  {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    #[doc(hidden)]
    pub image: std::option::Option<crate::model::Image>,
}
impl RecognizeCelebritiesInput {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn image(&self) -> std::option::Option<& crate::model::Image> {
        self.image.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct PutProjectPolicyInput  {
    /// <p>The Amazon Resource Name (ARN) of the project that the project policy is attached to.</p>
    #[doc(hidden)]
    pub project_arn: std::option::Option<std::string::String>,
    /// <p>A name for the policy.</p>
    #[doc(hidden)]
    pub policy_name: std::option::Option<std::string::String>,
    /// <p>The revision ID for the Project Policy. Each time you modify a policy, Amazon Rekognition Custom Labels generates and assigns a new <code>PolicyRevisionId</code> and then deletes the previous version of the policy.</p>
    #[doc(hidden)]
    pub policy_revision_id: std::option::Option<std::string::String>,
    /// <p>A resource policy to add to the model. The policy is a JSON structure that contains one or more statements that define the policy. The policy must follow the IAM syntax. For more information about the contents of a JSON policy document, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies.html">IAM JSON policy reference</a>. </p>
    #[doc(hidden)]
    pub policy_document: std::option::Option<std::string::String>,
}
impl PutProjectPolicyInput {
    /// <p>The Amazon Resource Name (ARN) of the project that the project policy is attached to.</p>
    pub fn project_arn(&self) -> std::option::Option<& str> {
        self.project_arn.as_deref()
    }
    /// <p>A name for the policy.</p>
    pub fn policy_name(&self) -> std::option::Option<& str> {
        self.policy_name.as_deref()
    }
    /// <p>The revision ID for the Project Policy. Each time you modify a policy, Amazon Rekognition Custom Labels generates and assigns a new <code>PolicyRevisionId</code> and then deletes the previous version of the policy.</p>
    pub fn policy_revision_id(&self) -> std::option::Option<& str> {
        self.policy_revision_id.as_deref()
    }
    /// <p>A resource policy to add to the model. The policy is a JSON structure that contains one or more statements that define the policy. The policy must follow the IAM syntax. For more information about the contents of a JSON policy document, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies.html">IAM JSON policy reference</a>. </p>
    pub fn policy_document(&self) -> std::option::Option<& str> {
        self.policy_document.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListTagsForResourceInput  {
    /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that contains the tags that you want a list of. </p>
    #[doc(hidden)]
    pub resource_arn: std::option::Option<std::string::String>,
}
impl ListTagsForResourceInput {
    /// <p> Amazon Resource Name (ARN) of the model, collection, or stream processor that contains the tags that you want a list of. </p>
    pub fn resource_arn(&self) -> std::option::Option<& str> {
        self.resource_arn.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListStreamProcessorsInput  {
    /// <p>If the previous response was incomplete (because there are more stream processors to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of stream processors. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Maximum number of stream processors you want Amazon Rekognition Video to return in the response. The default is 1000. </p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
}
impl ListStreamProcessorsInput {
    /// <p>If the previous response was incomplete (because there are more stream processors to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of stream processors. </p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>Maximum number of stream processors you want Amazon Rekognition Video to return in the response. The default is 1000. </p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListProjectPoliciesInput  {
    /// <p>The ARN of the project for which you want to list the project policies.</p>
    #[doc(hidden)]
    pub project_arn: std::option::Option<std::string::String>,
    /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 5. If you specify a value greater than 5, a ValidationException error occurs. The default value is 5. </p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
}
impl ListProjectPoliciesInput {
    /// <p>The ARN of the project for which you want to list the project policies.</p>
    pub fn project_arn(&self) -> std::option::Option<& str> {
        self.project_arn.as_deref()
    }
    /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 5. If you specify a value greater than 5, a ValidationException error occurs. The default value is 5. </p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListFacesInput  {
    /// <p>ID of the collection from which to list the faces.</p>
    #[doc(hidden)]
    pub collection_id: std::option::Option<std::string::String>,
    /// <p>If the previous response was incomplete (because there is more data to retrieve), Amazon Rekognition returns a pagination token in the response. You can use this pagination token to retrieve the next set of faces.</p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Maximum number of faces to return.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
}
impl ListFacesInput {
    /// <p>ID of the collection from which to list the faces.</p>
    pub fn collection_id(&self) -> std::option::Option<& str> {
        self.collection_id.as_deref()
    }
    /// <p>If the previous response was incomplete (because there is more data to retrieve), Amazon Rekognition returns a pagination token in the response. You can use this pagination token to retrieve the next set of faces.</p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>Maximum number of faces to return.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListDatasetLabelsInput  {
    /// <p> The Amazon Resource Name (ARN) of the dataset that you want to use. </p>
    #[doc(hidden)]
    pub dataset_arn: std::option::Option<std::string::String>,
    /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
}
impl ListDatasetLabelsInput {
    /// <p> The Amazon Resource Name (ARN) of the dataset that you want to use. </p>
    pub fn dataset_arn(&self) -> std::option::Option<& str> {
        self.dataset_arn.as_deref()
    }
    /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListDatasetEntriesInput  {
    /// <p> The Amazon Resource Name (ARN) for the dataset that you want to use. </p>
    #[doc(hidden)]
    pub dataset_arn: std::option::Option<std::string::String>,
    /// <p>Specifies a label filter for the response. The response includes an entry only if one or more of the labels in <code>ContainsLabels</code> exist in the entry. </p>
    #[doc(hidden)]
    pub contains_labels: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p> Specify <code>true</code> to get only the JSON Lines where the image is labeled. Specify <code>false</code> to get only the JSON Lines where the image isn't labeled. If you don't specify <code>Labeled</code>, <code>ListDatasetEntries</code> returns JSON Lines for labeled and unlabeled images. </p>
    #[doc(hidden)]
    pub labeled: std::option::Option<bool>,
    /// <p>If specified, <code>ListDatasetEntries</code> only returns JSON Lines where the value of <code>SourceRefContains</code> is part of the <code>source-ref</code> field. The <code>source-ref</code> field contains the Amazon S3 location of the image. You can use <code>SouceRefContains</code> for tasks such as getting the JSON Line for a single image, or gettting JSON Lines for all images within a specific folder.</p>
    #[doc(hidden)]
    pub source_ref_contains: std::option::Option<std::string::String>,
    /// <p>Specifies an error filter for the response. Specify <code>True</code> to only include entries that have errors. </p>
    #[doc(hidden)]
    pub has_errors: std::option::Option<bool>,
    /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
}
impl ListDatasetEntriesInput {
    /// <p> The Amazon Resource Name (ARN) for the dataset that you want to use. </p>
    pub fn dataset_arn(&self) -> std::option::Option<& str> {
        self.dataset_arn.as_deref()
    }
    /// <p>Specifies a label filter for the response. The response includes an entry only if one or more of the labels in <code>ContainsLabels</code> exist in the entry. </p>
    pub fn contains_labels(&self) -> std::option::Option<& [std::string::String]> {
        self.contains_labels.as_deref()
    }
    /// <p> Specify <code>true</code> to get only the JSON Lines where the image is labeled. Specify <code>false</code> to get only the JSON Lines where the image isn't labeled. If you don't specify <code>Labeled</code>, <code>ListDatasetEntries</code> returns JSON Lines for labeled and unlabeled images. </p>
    pub fn labeled(&self) -> std::option::Option<bool> {
        self.labeled
    }
    /// <p>If specified, <code>ListDatasetEntries</code> only returns JSON Lines where the value of <code>SourceRefContains</code> is part of the <code>source-ref</code> field. The <code>source-ref</code> field contains the Amazon S3 location of the image. You can use <code>SouceRefContains</code> for tasks such as getting the JSON Line for a single image, or gettting JSON Lines for all images within a specific folder.</p>
    pub fn source_ref_contains(&self) -> std::option::Option<& str> {
        self.source_ref_contains.as_deref()
    }
    /// <p>Specifies an error filter for the response. Specify <code>True</code> to only include entries that have errors. </p>
    pub fn has_errors(&self) -> std::option::Option<bool> {
        self.has_errors
    }
    /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListCollectionsInput  {
    /// <p>Pagination token from the previous response.</p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Maximum number of collection IDs to return. </p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
}
impl ListCollectionsInput {
    /// <p>Pagination token from the previous response.</p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>Maximum number of collection IDs to return. </p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct IndexFacesInput  {
    /// <p>The ID of an existing collection to which you want to add the faces that are detected in the input images.</p>
    #[doc(hidden)]
    pub collection_id: std::option::Option<std::string::String>,
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes isn't supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    #[doc(hidden)]
    pub image: std::option::Option<crate::model::Image>,
    /// <p>The ID you want to assign to all the faces detected in the image.</p>
    #[doc(hidden)]
    pub external_image_id: std::option::Option<std::string::String>,
    /// <p>An array of facial attributes that you want to be returned. This can be the default list of attributes or all attributes. If you don't specify a value for <code>Attributes</code> or if you specify <code>["DEFAULT"]</code>, the API returns the following subset of facial attributes: <code>BoundingBox</code>, <code>Confidence</code>, <code>Pose</code>, <code>Quality</code>, and <code>Landmarks</code>. If you provide <code>["ALL"]</code>, all facial attributes are returned, but the operation takes longer to complete.</p> 
    /// <p>If you provide both, <code>["ALL", "DEFAULT"]</code>, the service uses a logical AND operator to determine which attributes to return (in this case, all attributes). </p>
    #[doc(hidden)]
    pub detection_attributes: std::option::Option<std::vec::Vec<crate::model::Attribute>>,
    /// <p>The maximum number of faces to index. The value of <code>MaxFaces</code> must be greater than or equal to 1. <code>IndexFaces</code> returns no more than 100 detected faces in an image, even if you specify a larger value for <code>MaxFaces</code>.</p> 
    /// <p>If <code>IndexFaces</code> detects more faces than the value of <code>MaxFaces</code>, the faces with the lowest quality are filtered out first. If there are still more faces than the value of <code>MaxFaces</code>, the faces with the smallest bounding boxes are filtered out (up to the number that's needed to satisfy the value of <code>MaxFaces</code>). Information about the unindexed faces is available in the <code>UnindexedFaces</code> array. </p> 
    /// <p>The faces that are returned by <code>IndexFaces</code> are sorted by the largest face bounding box size to the smallest size, in descending order.</p> 
    /// <p> <code>MaxFaces</code> can be used with a collection associated with any version of the face model.</p>
    #[doc(hidden)]
    pub max_faces: std::option::Option<i32>,
    /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't indexed. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The default value is <code>AUTO</code>. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. </p> 
    /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
    #[doc(hidden)]
    pub quality_filter: std::option::Option<crate::model::QualityFilter>,
}
impl IndexFacesInput {
    /// <p>The ID of an existing collection to which you want to add the faces that are detected in the input images.</p>
    pub fn collection_id(&self) -> std::option::Option<& str> {
        self.collection_id.as_deref()
    }
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes isn't supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn image(&self) -> std::option::Option<& crate::model::Image> {
        self.image.as_ref()
    }
    /// <p>The ID you want to assign to all the faces detected in the image.</p>
    pub fn external_image_id(&self) -> std::option::Option<& str> {
        self.external_image_id.as_deref()
    }
    /// <p>An array of facial attributes that you want to be returned. This can be the default list of attributes or all attributes. If you don't specify a value for <code>Attributes</code> or if you specify <code>["DEFAULT"]</code>, the API returns the following subset of facial attributes: <code>BoundingBox</code>, <code>Confidence</code>, <code>Pose</code>, <code>Quality</code>, and <code>Landmarks</code>. If you provide <code>["ALL"]</code>, all facial attributes are returned, but the operation takes longer to complete.</p> 
    /// <p>If you provide both, <code>["ALL", "DEFAULT"]</code>, the service uses a logical AND operator to determine which attributes to return (in this case, all attributes). </p>
    pub fn detection_attributes(&self) -> std::option::Option<& [crate::model::Attribute]> {
        self.detection_attributes.as_deref()
    }
    /// <p>The maximum number of faces to index. The value of <code>MaxFaces</code> must be greater than or equal to 1. <code>IndexFaces</code> returns no more than 100 detected faces in an image, even if you specify a larger value for <code>MaxFaces</code>.</p> 
    /// <p>If <code>IndexFaces</code> detects more faces than the value of <code>MaxFaces</code>, the faces with the lowest quality are filtered out first. If there are still more faces than the value of <code>MaxFaces</code>, the faces with the smallest bounding boxes are filtered out (up to the number that's needed to satisfy the value of <code>MaxFaces</code>). Information about the unindexed faces is available in the <code>UnindexedFaces</code> array. </p> 
    /// <p>The faces that are returned by <code>IndexFaces</code> are sorted by the largest face bounding box size to the smallest size, in descending order.</p> 
    /// <p> <code>MaxFaces</code> can be used with a collection associated with any version of the face model.</p>
    pub fn max_faces(&self) -> std::option::Option<i32> {
        self.max_faces
    }
    /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't indexed. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The default value is <code>AUTO</code>. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. </p> 
    /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
    pub fn quality_filter(&self) -> std::option::Option<& crate::model::QualityFilter> {
        self.quality_filter.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct GetTextDetectionInput  {
    /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartTextDetection</code>.</p>
    #[doc(hidden)]
    pub job_id: std::option::Option<std::string::String>,
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>If the previous response was incomplete (because there are more labels to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of text.</p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
}
impl GetTextDetectionInput {
    /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartTextDetection</code>.</p>
    pub fn job_id(&self) -> std::option::Option<& str> {
        self.job_id.as_deref()
    }
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>If the previous response was incomplete (because there are more labels to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of text.</p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct GetSegmentDetectionInput  {
    /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartSegmentDetection</code>.</p>
    #[doc(hidden)]
    pub job_id: std::option::Option<std::string::String>,
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of text.</p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
}
impl GetSegmentDetectionInput {
    /// <p>Job identifier for the text detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartSegmentDetection</code>.</p>
    pub fn job_id(&self) -> std::option::Option<& str> {
        self.job_id.as_deref()
    }
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of text.</p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct GetPersonTrackingInput  {
    /// <p>The identifier for a job that tracks persons in a video. You get the <code>JobId</code> from a call to <code>StartPersonTracking</code>. </p>
    #[doc(hidden)]
    pub job_id: std::option::Option<std::string::String>,
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>If the previous response was incomplete (because there are more persons to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of persons. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Sort to use for elements in the <code>Persons</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time persons are detected. Use <code>INDEX</code> to sort by the tracked persons. If you sort by <code>INDEX</code>, the array elements for each person are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
    #[doc(hidden)]
    pub sort_by: std::option::Option<crate::model::PersonTrackingSortBy>,
}
impl GetPersonTrackingInput {
    /// <p>The identifier for a job that tracks persons in a video. You get the <code>JobId</code> from a call to <code>StartPersonTracking</code>. </p>
    pub fn job_id(&self) -> std::option::Option<& str> {
        self.job_id.as_deref()
    }
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>If the previous response was incomplete (because there are more persons to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of persons. </p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>Sort to use for elements in the <code>Persons</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time persons are detected. Use <code>INDEX</code> to sort by the tracked persons. If you sort by <code>INDEX</code>, the array elements for each person are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
    pub fn sort_by(&self) -> std::option::Option<& crate::model::PersonTrackingSortBy> {
        self.sort_by.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct GetLabelDetectionInput  {
    /// <p>Job identifier for the label detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartlabelDetection</code>.</p>
    #[doc(hidden)]
    pub job_id: std::option::Option<std::string::String>,
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>If the previous response was incomplete (because there are more labels to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of labels. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Sort to use for elements in the <code>Labels</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time labels are detected. Use <code>NAME</code> to alphabetically group elements for a label together. Within each label group, the array element are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
    #[doc(hidden)]
    pub sort_by: std::option::Option<crate::model::LabelDetectionSortBy>,
    /// <p>Defines how to aggregate the returned results. Results can be aggregated by timestamps or segments.</p>
    #[doc(hidden)]
    pub aggregate_by: std::option::Option<crate::model::LabelDetectionAggregateBy>,
}
impl GetLabelDetectionInput {
    /// <p>Job identifier for the label detection operation for which you want results returned. You get the job identifer from an initial call to <code>StartlabelDetection</code>.</p>
    pub fn job_id(&self) -> std::option::Option<& str> {
        self.job_id.as_deref()
    }
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>If the previous response was incomplete (because there are more labels to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of labels. </p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>Sort to use for elements in the <code>Labels</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time labels are detected. Use <code>NAME</code> to alphabetically group elements for a label together. Within each label group, the array element are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
    pub fn sort_by(&self) -> std::option::Option<& crate::model::LabelDetectionSortBy> {
        self.sort_by.as_ref()
    }
    /// <p>Defines how to aggregate the returned results. Results can be aggregated by timestamps or segments.</p>
    pub fn aggregate_by(&self) -> std::option::Option<& crate::model::LabelDetectionAggregateBy> {
        self.aggregate_by.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct GetFaceSearchInput  {
    /// <p>The job identifer for the search request. You get the job identifier from an initial call to <code>StartFaceSearch</code>.</p>
    #[doc(hidden)]
    pub job_id: std::option::Option<std::string::String>,
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>If the previous response was incomplete (because there is more search results to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of search results. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Sort to use for grouping faces in the response. Use <code>TIMESTAMP</code> to group faces by the time that they are recognized. Use <code>INDEX</code> to sort by recognized faces. </p>
    #[doc(hidden)]
    pub sort_by: std::option::Option<crate::model::FaceSearchSortBy>,
}
impl GetFaceSearchInput {
    /// <p>The job identifer for the search request. You get the job identifier from an initial call to <code>StartFaceSearch</code>.</p>
    pub fn job_id(&self) -> std::option::Option<& str> {
        self.job_id.as_deref()
    }
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>If the previous response was incomplete (because there is more search results to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of search results. </p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>Sort to use for grouping faces in the response. Use <code>TIMESTAMP</code> to group faces by the time that they are recognized. Use <code>INDEX</code> to sort by recognized faces. </p>
    pub fn sort_by(&self) -> std::option::Option<& crate::model::FaceSearchSortBy> {
        self.sort_by.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct GetFaceDetectionInput  {
    /// <p>Unique identifier for the face detection job. The <code>JobId</code> is returned from <code>StartFaceDetection</code>.</p>
    #[doc(hidden)]
    pub job_id: std::option::Option<std::string::String>,
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>If the previous response was incomplete (because there are more faces to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of faces.</p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
}
impl GetFaceDetectionInput {
    /// <p>Unique identifier for the face detection job. The <code>JobId</code> is returned from <code>StartFaceDetection</code>.</p>
    pub fn job_id(&self) -> std::option::Option<& str> {
        self.job_id.as_deref()
    }
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>If the previous response was incomplete (because there are more faces to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of faces.</p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct GetContentModerationInput  {
    /// <p>The identifier for the inappropriate, unwanted, or offensive content moderation job. Use <code>JobId</code> to identify the job in a subsequent call to <code>GetContentModeration</code>.</p>
    #[doc(hidden)]
    pub job_id: std::option::Option<std::string::String>,
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>If the previous response was incomplete (because there is more data to retrieve), Amazon Rekognition returns a pagination token in the response. You can use this pagination token to retrieve the next set of content moderation labels.</p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Sort to use for elements in the <code>ModerationLabelDetections</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time labels are detected. Use <code>NAME</code> to alphabetically group elements for a label together. Within each label group, the array element are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
    #[doc(hidden)]
    pub sort_by: std::option::Option<crate::model::ContentModerationSortBy>,
}
impl GetContentModerationInput {
    /// <p>The identifier for the inappropriate, unwanted, or offensive content moderation job. Use <code>JobId</code> to identify the job in a subsequent call to <code>GetContentModeration</code>.</p>
    pub fn job_id(&self) -> std::option::Option<& str> {
        self.job_id.as_deref()
    }
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>If the previous response was incomplete (because there is more data to retrieve), Amazon Rekognition returns a pagination token in the response. You can use this pagination token to retrieve the next set of content moderation labels.</p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>Sort to use for elements in the <code>ModerationLabelDetections</code> array. Use <code>TIMESTAMP</code> to sort array elements by the time labels are detected. Use <code>NAME</code> to alphabetically group elements for a label together. Within each label group, the array element are sorted by detection confidence. The default sort is by <code>TIMESTAMP</code>.</p>
    pub fn sort_by(&self) -> std::option::Option<& crate::model::ContentModerationSortBy> {
        self.sort_by.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct GetCelebrityRecognitionInput  {
    /// <p>Job identifier for the required celebrity recognition analysis. You can get the job identifer from a call to <code>StartCelebrityRecognition</code>.</p>
    #[doc(hidden)]
    pub job_id: std::option::Option<std::string::String>,
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>If the previous response was incomplete (because there is more recognized celebrities to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of celebrities. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Sort to use for celebrities returned in <code>Celebrities</code> field. Specify <code>ID</code> to sort by the celebrity identifier, specify <code>TIMESTAMP</code> to sort by the time the celebrity was recognized.</p>
    #[doc(hidden)]
    pub sort_by: std::option::Option<crate::model::CelebrityRecognitionSortBy>,
}
impl GetCelebrityRecognitionInput {
    /// <p>Job identifier for the required celebrity recognition analysis. You can get the job identifer from a call to <code>StartCelebrityRecognition</code>.</p>
    pub fn job_id(&self) -> std::option::Option<& str> {
        self.job_id.as_deref()
    }
    /// <p>Maximum number of results to return per paginated call. The largest value you can specify is 1000. If you specify a value greater than 1000, a maximum of 1000 results is returned. The default value is 1000.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>If the previous response was incomplete (because there is more recognized celebrities to retrieve), Amazon Rekognition Video returns a pagination token in the response. You can use this pagination token to retrieve the next set of celebrities. </p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>Sort to use for celebrities returned in <code>Celebrities</code> field. Specify <code>ID</code> to sort by the celebrity identifier, specify <code>TIMESTAMP</code> to sort by the time the celebrity was recognized.</p>
    pub fn sort_by(&self) -> std::option::Option<& crate::model::CelebrityRecognitionSortBy> {
        self.sort_by.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct GetCelebrityInfoInput  {
    /// <p>The ID for the celebrity. You get the celebrity ID from a call to the <code>RecognizeCelebrities</code> operation, which recognizes celebrities in an image. </p>
    #[doc(hidden)]
    pub id: std::option::Option<std::string::String>,
}
impl GetCelebrityInfoInput {
    /// <p>The ID for the celebrity. You get the celebrity ID from a call to the <code>RecognizeCelebrities</code> operation, which recognizes celebrities in an image. </p>
    pub fn id(&self) -> std::option::Option<& str> {
        self.id.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DistributeDatasetEntriesInput  {
    /// <p>The ARNS for the training dataset and test dataset that you want to use. The datasets must belong to the same project. The test dataset must be empty. </p>
    #[doc(hidden)]
    pub datasets: std::option::Option<std::vec::Vec<crate::model::DistributeDataset>>,
}
impl DistributeDatasetEntriesInput {
    /// <p>The ARNS for the training dataset and test dataset that you want to use. The datasets must belong to the same project. The test dataset must be empty. </p>
    pub fn datasets(&self) -> std::option::Option<& [crate::model::DistributeDataset]> {
        self.datasets.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DetectTextInput  {
    /// <p>The input image as base64-encoded bytes or an Amazon S3 object. If you use the AWS CLI to call Amazon Rekognition operations, you can't pass image bytes. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    #[doc(hidden)]
    pub image: std::option::Option<crate::model::Image>,
    /// <p>Optional parameters that let you set the criteria that the text must meet to be included in your response.</p>
    #[doc(hidden)]
    pub filters: std::option::Option<crate::model::DetectTextFilters>,
}
impl DetectTextInput {
    /// <p>The input image as base64-encoded bytes or an Amazon S3 object. If you use the AWS CLI to call Amazon Rekognition operations, you can't pass image bytes. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn image(&self) -> std::option::Option<& crate::model::Image> {
        self.image.as_ref()
    }
    /// <p>Optional parameters that let you set the criteria that the text must meet to be included in your response.</p>
    pub fn filters(&self) -> std::option::Option<& crate::model::DetectTextFilters> {
        self.filters.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DetectProtectiveEquipmentInput  {
    /// <p>The image in which you want to detect PPE on detected persons. The image can be passed as image bytes or you can reference an image stored in an Amazon S3 bucket. </p>
    #[doc(hidden)]
    pub image: std::option::Option<crate::model::Image>,
    /// <p>An array of PPE types that you want to summarize.</p>
    #[doc(hidden)]
    pub summarization_attributes: std::option::Option<crate::model::ProtectiveEquipmentSummarizationAttributes>,
}
impl DetectProtectiveEquipmentInput {
    /// <p>The image in which you want to detect PPE on detected persons. The image can be passed as image bytes or you can reference an image stored in an Amazon S3 bucket. </p>
    pub fn image(&self) -> std::option::Option<& crate::model::Image> {
        self.image.as_ref()
    }
    /// <p>An array of PPE types that you want to summarize.</p>
    pub fn summarization_attributes(&self) -> std::option::Option<& crate::model::ProtectiveEquipmentSummarizationAttributes> {
        self.summarization_attributes.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DetectModerationLabelsInput  {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    #[doc(hidden)]
    pub image: std::option::Option<crate::model::Image>,
    /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with a confidence level lower than this specified value.</p> 
    /// <p>If you don't specify <code>MinConfidence</code>, the operation returns labels with confidence values greater than or equal to 50 percent.</p>
    #[doc(hidden)]
    pub min_confidence: std::option::Option<f32>,
    /// <p>Sets up the configuration for human evaluation, including the FlowDefinition the image will be sent to.</p>
    #[doc(hidden)]
    pub human_loop_config: std::option::Option<crate::model::HumanLoopConfig>,
}
impl DetectModerationLabelsInput {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn image(&self) -> std::option::Option<& crate::model::Image> {
        self.image.as_ref()
    }
    /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with a confidence level lower than this specified value.</p> 
    /// <p>If you don't specify <code>MinConfidence</code>, the operation returns labels with confidence values greater than or equal to 50 percent.</p>
    pub fn min_confidence(&self) -> std::option::Option<f32> {
        self.min_confidence
    }
    /// <p>Sets up the configuration for human evaluation, including the FlowDefinition the image will be sent to.</p>
    pub fn human_loop_config(&self) -> std::option::Option<& crate::model::HumanLoopConfig> {
        self.human_loop_config.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DetectLabelsInput  {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. Images stored in an S3 Bucket do not need to be base64-encoded.</p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    #[doc(hidden)]
    pub image: std::option::Option<crate::model::Image>,
    /// <p>Maximum number of labels you want the service to return in the response. The service returns the specified number of highest confidence labels. </p>
    #[doc(hidden)]
    pub max_labels: std::option::Option<i32>,
    /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with confidence lower than this specified value.</p> 
    /// <p>If <code>MinConfidence</code> is not specified, the operation returns labels with a confidence values greater than or equal to 55 percent.</p>
    #[doc(hidden)]
    pub min_confidence: std::option::Option<f32>,
    /// <p>A list of the types of analysis to perform. Specifying GENERAL_LABELS uses the label detection feature, while specifying IMAGE_PROPERTIES returns information regarding image color and quality. If no option is specified GENERAL_LABELS is used by default.</p>
    #[doc(hidden)]
    pub features: std::option::Option<std::vec::Vec<crate::model::DetectLabelsFeatureName>>,
    /// <p>A list of the filters to be applied to returned detected labels and image properties. Specified filters can be inclusive, exclusive, or a combination of both. Filters can be used for individual labels or label categories. The exact label names or label categories must be supplied. For a full list of labels and label categories, see LINK HERE.</p>
    #[doc(hidden)]
    pub settings: std::option::Option<crate::model::DetectLabelsSettings>,
}
impl DetectLabelsInput {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. Images stored in an S3 Bucket do not need to be base64-encoded.</p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn image(&self) -> std::option::Option<& crate::model::Image> {
        self.image.as_ref()
    }
    /// <p>Maximum number of labels you want the service to return in the response. The service returns the specified number of highest confidence labels. </p>
    pub fn max_labels(&self) -> std::option::Option<i32> {
        self.max_labels
    }
    /// <p>Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with confidence lower than this specified value.</p> 
    /// <p>If <code>MinConfidence</code> is not specified, the operation returns labels with a confidence values greater than or equal to 55 percent.</p>
    pub fn min_confidence(&self) -> std::option::Option<f32> {
        self.min_confidence
    }
    /// <p>A list of the types of analysis to perform. Specifying GENERAL_LABELS uses the label detection feature, while specifying IMAGE_PROPERTIES returns information regarding image color and quality. If no option is specified GENERAL_LABELS is used by default.</p>
    pub fn features(&self) -> std::option::Option<& [crate::model::DetectLabelsFeatureName]> {
        self.features.as_deref()
    }
    /// <p>A list of the filters to be applied to returned detected labels and image properties. Specified filters can be inclusive, exclusive, or a combination of both. Filters can be used for individual labels or label categories. The exact label names or label categories must be supplied. For a full list of labels and label categories, see LINK HERE.</p>
    pub fn settings(&self) -> std::option::Option<& crate::model::DetectLabelsSettings> {
        self.settings.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DetectFacesInput  {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    #[doc(hidden)]
    pub image: std::option::Option<crate::model::Image>,
    /// <p>An array of facial attributes you want to be returned. This can be the default list of attributes or all attributes. If you don't specify a value for <code>Attributes</code> or if you specify <code>["DEFAULT"]</code>, the API returns the following subset of facial attributes: <code>BoundingBox</code>, <code>Confidence</code>, <code>Pose</code>, <code>Quality</code>, and <code>Landmarks</code>. If you provide <code>["ALL"]</code>, all facial attributes are returned, but the operation takes longer to complete.</p> 
    /// <p>If you provide both, <code>["ALL", "DEFAULT"]</code>, the service uses a logical AND operator to determine which attributes to return (in this case, all attributes). </p>
    #[doc(hidden)]
    pub attributes: std::option::Option<std::vec::Vec<crate::model::Attribute>>,
}
impl DetectFacesInput {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn image(&self) -> std::option::Option<& crate::model::Image> {
        self.image.as_ref()
    }
    /// <p>An array of facial attributes you want to be returned. This can be the default list of attributes or all attributes. If you don't specify a value for <code>Attributes</code> or if you specify <code>["DEFAULT"]</code>, the API returns the following subset of facial attributes: <code>BoundingBox</code>, <code>Confidence</code>, <code>Pose</code>, <code>Quality</code>, and <code>Landmarks</code>. If you provide <code>["ALL"]</code>, all facial attributes are returned, but the operation takes longer to complete.</p> 
    /// <p>If you provide both, <code>["ALL", "DEFAULT"]</code>, the service uses a logical AND operator to determine which attributes to return (in this case, all attributes). </p>
    pub fn attributes(&self) -> std::option::Option<& [crate::model::Attribute]> {
        self.attributes.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DetectCustomLabelsInput  {
    /// <p>The ARN of the model version that you want to use.</p>
    #[doc(hidden)]
    pub project_version_arn: std::option::Option<std::string::String>,
    /// <p>Provides the input image either as bytes or an S3 object.</p> 
    /// <p>You pass image bytes to an Amazon Rekognition API operation by using the <code>Bytes</code> property. For example, you would use the <code>Bytes</code> property to pass an image loaded from a local file system. Image bytes passed by using the <code>Bytes</code> property must be base64-encoded. Your code may not need to encode image bytes if you are using an AWS SDK to call Amazon Rekognition API operations. </p> 
    /// <p>For more information, see Analyzing an Image Loaded from a Local File System in the Amazon Rekognition Developer Guide.</p> 
    /// <p> You pass images stored in an S3 bucket to an Amazon Rekognition API operation by using the <code>S3Object</code> property. Images stored in an S3 bucket do not need to be base64-encoded.</p> 
    /// <p>The region for the S3 bucket containing the S3 object must match the region you use for Amazon Rekognition operations.</p> 
    /// <p>If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes using the Bytes property is not supported. You must first upload the image to an Amazon S3 bucket and then call the operation using the S3Object property.</p> 
    /// <p>For Amazon Rekognition to process an S3 object, the user must have permission to access the S3 object. For more information, see How Amazon Rekognition works with IAM in the Amazon Rekognition Developer Guide. </p>
    #[doc(hidden)]
    pub image: std::option::Option<crate::model::Image>,
    /// <p>Maximum number of results you want the service to return in the response. The service returns the specified number of highest confidence labels ranked from highest confidence to lowest.</p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>Specifies the minimum confidence level for the labels to return. <code>DetectCustomLabels</code> doesn't return any labels with a confidence value that's lower than this specified value. If you specify a value of 0, <code>DetectCustomLabels</code> returns all labels, regardless of the assumed threshold applied to each label. If you don't specify a value for <code>MinConfidence</code>, <code>DetectCustomLabels</code> returns labels based on the assumed threshold of each label.</p>
    #[doc(hidden)]
    pub min_confidence: std::option::Option<f32>,
}
impl DetectCustomLabelsInput {
    /// <p>The ARN of the model version that you want to use.</p>
    pub fn project_version_arn(&self) -> std::option::Option<& str> {
        self.project_version_arn.as_deref()
    }
    /// <p>Provides the input image either as bytes or an S3 object.</p> 
    /// <p>You pass image bytes to an Amazon Rekognition API operation by using the <code>Bytes</code> property. For example, you would use the <code>Bytes</code> property to pass an image loaded from a local file system. Image bytes passed by using the <code>Bytes</code> property must be base64-encoded. Your code may not need to encode image bytes if you are using an AWS SDK to call Amazon Rekognition API operations. </p> 
    /// <p>For more information, see Analyzing an Image Loaded from a Local File System in the Amazon Rekognition Developer Guide.</p> 
    /// <p> You pass images stored in an S3 bucket to an Amazon Rekognition API operation by using the <code>S3Object</code> property. Images stored in an S3 bucket do not need to be base64-encoded.</p> 
    /// <p>The region for the S3 bucket containing the S3 object must match the region you use for Amazon Rekognition operations.</p> 
    /// <p>If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes using the Bytes property is not supported. You must first upload the image to an Amazon S3 bucket and then call the operation using the S3Object property.</p> 
    /// <p>For Amazon Rekognition to process an S3 object, the user must have permission to access the S3 object. For more information, see How Amazon Rekognition works with IAM in the Amazon Rekognition Developer Guide. </p>
    pub fn image(&self) -> std::option::Option<& crate::model::Image> {
        self.image.as_ref()
    }
    /// <p>Maximum number of results you want the service to return in the response. The service returns the specified number of highest confidence labels ranked from highest confidence to lowest.</p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>Specifies the minimum confidence level for the labels to return. <code>DetectCustomLabels</code> doesn't return any labels with a confidence value that's lower than this specified value. If you specify a value of 0, <code>DetectCustomLabels</code> returns all labels, regardless of the assumed threshold applied to each label. If you don't specify a value for <code>MinConfidence</code>, <code>DetectCustomLabels</code> returns labels based on the assumed threshold of each label.</p>
    pub fn min_confidence(&self) -> std::option::Option<f32> {
        self.min_confidence
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeStreamProcessorInput  {
    /// <p>Name of the stream processor for which you want information.</p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
}
impl DescribeStreamProcessorInput {
    /// <p>Name of the stream processor for which you want information.</p>
    pub fn name(&self) -> std::option::Option<& str> {
        self.name.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeProjectVersionsInput  {
    /// <p>The Amazon Resource Name (ARN) of the project that contains the models you want to describe.</p>
    #[doc(hidden)]
    pub project_arn: std::option::Option<std::string::String>,
    /// <p>A list of model version names that you want to describe. You can add up to 10 model version names to the list. If you don't specify a value, all model descriptions are returned. A version name is part of a model (ProjectVersion) ARN. For example, <code>my-model.2020-01-21T09.10.15</code> is the version name in the following ARN. <code>arn:aws:rekognition:us-east-1:123456789012:project/getting-started/version/<i>my-model.2020-01-21T09.10.15</i>/1234567890123</code>.</p>
    #[doc(hidden)]
    pub version_names: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
}
impl DescribeProjectVersionsInput {
    /// <p>The Amazon Resource Name (ARN) of the project that contains the models you want to describe.</p>
    pub fn project_arn(&self) -> std::option::Option<& str> {
        self.project_arn.as_deref()
    }
    /// <p>A list of model version names that you want to describe. You can add up to 10 model version names to the list. If you don't specify a value, all model descriptions are returned. A version name is part of a model (ProjectVersion) ARN. For example, <code>my-model.2020-01-21T09.10.15</code> is the version name in the following ARN. <code>arn:aws:rekognition:us-east-1:123456789012:project/getting-started/version/<i>my-model.2020-01-21T09.10.15</i>/1234567890123</code>.</p>
    pub fn version_names(&self) -> std::option::Option<& [std::string::String]> {
        self.version_names.as_deref()
    }
    /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeProjectsInput  {
    /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>A list of the projects that you want Amazon Rekognition Custom Labels to describe. If you don't specify a value, the response includes descriptions for all the projects in your AWS account.</p>
    #[doc(hidden)]
    pub project_names: std::option::Option<std::vec::Vec<std::string::String>>,
}
impl DescribeProjectsInput {
    /// <p>If the previous response was incomplete (because there is more results to retrieve), Amazon Rekognition Custom Labels returns a pagination token in the response. You can use this pagination token to retrieve the next set of results. </p>
    pub fn next_token(&self) -> std::option::Option<& str> {
        self.next_token.as_deref()
    }
    /// <p>The maximum number of results to return per paginated call. The largest value you can specify is 100. If you specify a value greater than 100, a ValidationException error occurs. The default value is 100. </p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>A list of the projects that you want Amazon Rekognition Custom Labels to describe. If you don't specify a value, the response includes descriptions for all the projects in your AWS account.</p>
    pub fn project_names(&self) -> std::option::Option<& [std::string::String]> {
        self.project_names.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeDatasetInput  {
    /// <p> The Amazon Resource Name (ARN) of the dataset that you want to describe. </p>
    #[doc(hidden)]
    pub dataset_arn: std::option::Option<std::string::String>,
}
impl DescribeDatasetInput {
    /// <p> The Amazon Resource Name (ARN) of the dataset that you want to describe. </p>
    pub fn dataset_arn(&self) -> std::option::Option<& str> {
        self.dataset_arn.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeCollectionInput  {
    /// <p>The ID of the collection to describe.</p>
    #[doc(hidden)]
    pub collection_id: std::option::Option<std::string::String>,
}
impl DescribeCollectionInput {
    /// <p>The ID of the collection to describe.</p>
    pub fn collection_id(&self) -> std::option::Option<& str> {
        self.collection_id.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteStreamProcessorInput  {
    /// <p>The name of the stream processor you want to delete.</p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
}
impl DeleteStreamProcessorInput {
    /// <p>The name of the stream processor you want to delete.</p>
    pub fn name(&self) -> std::option::Option<& str> {
        self.name.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteProjectVersionInput  {
    /// <p>The Amazon Resource Name (ARN) of the model version that you want to delete.</p>
    #[doc(hidden)]
    pub project_version_arn: std::option::Option<std::string::String>,
}
impl DeleteProjectVersionInput {
    /// <p>The Amazon Resource Name (ARN) of the model version that you want to delete.</p>
    pub fn project_version_arn(&self) -> std::option::Option<& str> {
        self.project_version_arn.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteProjectPolicyInput  {
    /// <p>The Amazon Resource Name (ARN) of the project that the project policy you want to delete is attached to.</p>
    #[doc(hidden)]
    pub project_arn: std::option::Option<std::string::String>,
    /// <p>The name of the policy that you want to delete.</p>
    #[doc(hidden)]
    pub policy_name: std::option::Option<std::string::String>,
    /// <p>The ID of the project policy revision that you want to delete.</p>
    #[doc(hidden)]
    pub policy_revision_id: std::option::Option<std::string::String>,
}
impl DeleteProjectPolicyInput {
    /// <p>The Amazon Resource Name (ARN) of the project that the project policy you want to delete is attached to.</p>
    pub fn project_arn(&self) -> std::option::Option<& str> {
        self.project_arn.as_deref()
    }
    /// <p>The name of the policy that you want to delete.</p>
    pub fn policy_name(&self) -> std::option::Option<& str> {
        self.policy_name.as_deref()
    }
    /// <p>The ID of the project policy revision that you want to delete.</p>
    pub fn policy_revision_id(&self) -> std::option::Option<& str> {
        self.policy_revision_id.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteProjectInput  {
    /// <p>The Amazon Resource Name (ARN) of the project that you want to delete.</p>
    #[doc(hidden)]
    pub project_arn: std::option::Option<std::string::String>,
}
impl DeleteProjectInput {
    /// <p>The Amazon Resource Name (ARN) of the project that you want to delete.</p>
    pub fn project_arn(&self) -> std::option::Option<& str> {
        self.project_arn.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteFacesInput  {
    /// <p>Collection from which to remove the specific faces.</p>
    #[doc(hidden)]
    pub collection_id: std::option::Option<std::string::String>,
    /// <p>An array of face IDs to delete.</p>
    #[doc(hidden)]
    pub face_ids: std::option::Option<std::vec::Vec<std::string::String>>,
}
impl DeleteFacesInput {
    /// <p>Collection from which to remove the specific faces.</p>
    pub fn collection_id(&self) -> std::option::Option<& str> {
        self.collection_id.as_deref()
    }
    /// <p>An array of face IDs to delete.</p>
    pub fn face_ids(&self) -> std::option::Option<& [std::string::String]> {
        self.face_ids.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteDatasetInput  {
    /// <p> The ARN of the Amazon Rekognition Custom Labels dataset that you want to delete. </p>
    #[doc(hidden)]
    pub dataset_arn: std::option::Option<std::string::String>,
}
impl DeleteDatasetInput {
    /// <p> The ARN of the Amazon Rekognition Custom Labels dataset that you want to delete. </p>
    pub fn dataset_arn(&self) -> std::option::Option<& str> {
        self.dataset_arn.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteCollectionInput  {
    /// <p>ID of the collection to delete.</p>
    #[doc(hidden)]
    pub collection_id: std::option::Option<std::string::String>,
}
impl DeleteCollectionInput {
    /// <p>ID of the collection to delete.</p>
    pub fn collection_id(&self) -> std::option::Option<& str> {
        self.collection_id.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateStreamProcessorInput  {
    /// <p>Kinesis video stream stream that provides the source streaming video. If you are using the AWS CLI, the parameter name is <code>StreamProcessorInput</code>. This is required for both face search and label detection stream processors.</p>
    #[doc(hidden)]
    pub input: std::option::Option<crate::model::StreamProcessorInput>,
    /// <p>Kinesis data stream stream or Amazon S3 bucket location to which Amazon Rekognition Video puts the analysis results. If you are using the AWS CLI, the parameter name is <code>StreamProcessorOutput</code>. This must be a <code>S3Destination</code> of an Amazon S3 bucket that you own for a label detection stream processor or a Kinesis data stream ARN for a face search stream processor.</p>
    #[doc(hidden)]
    pub output: std::option::Option<crate::model::StreamProcessorOutput>,
    /// <p>An identifier you assign to the stream processor. You can use <code>Name</code> to manage the stream processor. For example, you can get the current status of the stream processor by calling <code>DescribeStreamProcessor</code>. <code>Name</code> is idempotent. This is required for both face search and label detection stream processors. </p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
    /// <p>Input parameters used in a streaming video analyzed by a stream processor. You can use <code>FaceSearch</code> to recognize faces in a streaming video, or you can use <code>ConnectedHome</code> to detect labels.</p>
    #[doc(hidden)]
    pub settings: std::option::Option<crate::model::StreamProcessorSettings>,
    /// <p>The Amazon Resource Number (ARN) of the IAM role that allows access to the stream processor. The IAM role provides Rekognition read permissions for a Kinesis stream. It also provides write permissions to an Amazon S3 bucket and Amazon Simple Notification Service topic for a label detection stream processor. This is required for both face search and label detection stream processors.</p>
    #[doc(hidden)]
    pub role_arn: std::option::Option<std::string::String>,
    /// <p> A set of tags (key-value pairs) that you want to attach to the stream processor. </p>
    #[doc(hidden)]
    pub tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the object detection results and completion status of a video analysis operation.</p> 
    /// <p>Amazon Rekognition publishes a notification the first time an object of interest or a person is detected in the video stream. For example, if Amazon Rekognition detects a person at second 2, a pet at second 4, and a person again at second 5, Amazon Rekognition sends 2 object class detected notifications, one for a person at second 2 and one for a pet at second 4.</p> 
    /// <p>Amazon Rekognition also publishes an an end-of-session notification with a summary when the stream processing session is complete.</p>
    #[doc(hidden)]
    pub notification_channel: std::option::Option<crate::model::StreamProcessorNotificationChannel>,
    /// <p> The identifier for your AWS Key Management Service key (AWS KMS key). This is an optional parameter for label detection stream processors and should not be used to create a face search stream processor. You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt results and data published to your Amazon S3 bucket, which includes image frames and hero images. Your source images are unaffected. </p> 
    /// <p> </p>
    #[doc(hidden)]
    pub kms_key_id: std::option::Option<std::string::String>,
    /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. You can specify up to 10 regions of interest, and each region has either a polygon or a bounding box. This is an optional parameter for label detection stream processors and should not be used to create a face search stream processor. </p>
    #[doc(hidden)]
    pub regions_of_interest: std::option::Option<std::vec::Vec<crate::model::RegionOfInterest>>,
    /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
    #[doc(hidden)]
    pub data_sharing_preference: std::option::Option<crate::model::StreamProcessorDataSharingPreference>,
}
impl CreateStreamProcessorInput {
    /// <p>Kinesis video stream stream that provides the source streaming video. If you are using the AWS CLI, the parameter name is <code>StreamProcessorInput</code>. This is required for both face search and label detection stream processors.</p>
    pub fn input(&self) -> std::option::Option<& crate::model::StreamProcessorInput> {
        self.input.as_ref()
    }
    /// <p>Kinesis data stream stream or Amazon S3 bucket location to which Amazon Rekognition Video puts the analysis results. If you are using the AWS CLI, the parameter name is <code>StreamProcessorOutput</code>. This must be a <code>S3Destination</code> of an Amazon S3 bucket that you own for a label detection stream processor or a Kinesis data stream ARN for a face search stream processor.</p>
    pub fn output(&self) -> std::option::Option<& crate::model::StreamProcessorOutput> {
        self.output.as_ref()
    }
    /// <p>An identifier you assign to the stream processor. You can use <code>Name</code> to manage the stream processor. For example, you can get the current status of the stream processor by calling <code>DescribeStreamProcessor</code>. <code>Name</code> is idempotent. This is required for both face search and label detection stream processors. </p>
    pub fn name(&self) -> std::option::Option<& str> {
        self.name.as_deref()
    }
    /// <p>Input parameters used in a streaming video analyzed by a stream processor. You can use <code>FaceSearch</code> to recognize faces in a streaming video, or you can use <code>ConnectedHome</code> to detect labels.</p>
    pub fn settings(&self) -> std::option::Option<& crate::model::StreamProcessorSettings> {
        self.settings.as_ref()
    }
    /// <p>The Amazon Resource Number (ARN) of the IAM role that allows access to the stream processor. The IAM role provides Rekognition read permissions for a Kinesis stream. It also provides write permissions to an Amazon S3 bucket and Amazon Simple Notification Service topic for a label detection stream processor. This is required for both face search and label detection stream processors.</p>
    pub fn role_arn(&self) -> std::option::Option<& str> {
        self.role_arn.as_deref()
    }
    /// <p> A set of tags (key-value pairs) that you want to attach to the stream processor. </p>
    pub fn tags(&self) -> std::option::Option<& std::collections::HashMap<std::string::String, std::string::String>> {
        self.tags.as_ref()
    }
    /// <p>The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the object detection results and completion status of a video analysis operation.</p> 
    /// <p>Amazon Rekognition publishes a notification the first time an object of interest or a person is detected in the video stream. For example, if Amazon Rekognition detects a person at second 2, a pet at second 4, and a person again at second 5, Amazon Rekognition sends 2 object class detected notifications, one for a person at second 2 and one for a pet at second 4.</p> 
    /// <p>Amazon Rekognition also publishes an an end-of-session notification with a summary when the stream processing session is complete.</p>
    pub fn notification_channel(&self) -> std::option::Option<& crate::model::StreamProcessorNotificationChannel> {
        self.notification_channel.as_ref()
    }
    /// <p> The identifier for your AWS Key Management Service key (AWS KMS key). This is an optional parameter for label detection stream processors and should not be used to create a face search stream processor. You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt results and data published to your Amazon S3 bucket, which includes image frames and hero images. Your source images are unaffected. </p> 
    /// <p> </p>
    pub fn kms_key_id(&self) -> std::option::Option<& str> {
        self.kms_key_id.as_deref()
    }
    /// <p> Specifies locations in the frames where Amazon Rekognition checks for objects or people. You can specify up to 10 regions of interest, and each region has either a polygon or a bounding box. This is an optional parameter for label detection stream processors and should not be used to create a face search stream processor. </p>
    pub fn regions_of_interest(&self) -> std::option::Option<& [crate::model::RegionOfInterest]> {
        self.regions_of_interest.as_deref()
    }
    /// <p> Shows whether you are sharing data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level this setting is ignored on individual streams. </p>
    pub fn data_sharing_preference(&self) -> std::option::Option<& crate::model::StreamProcessorDataSharingPreference> {
        self.data_sharing_preference.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateProjectVersionInput  {
    /// <p>The ARN of the Amazon Rekognition Custom Labels project that manages the model that you want to train.</p>
    #[doc(hidden)]
    pub project_arn: std::option::Option<std::string::String>,
    /// <p>A name for the version of the model. This value must be unique.</p>
    #[doc(hidden)]
    pub version_name: std::option::Option<std::string::String>,
    /// <p>The Amazon S3 bucket location to store the results of training. The S3 bucket can be in any AWS account as long as the caller has <code>s3:PutObject</code> permissions on the S3 bucket.</p>
    #[doc(hidden)]
    pub output_config: std::option::Option<crate::model::OutputConfig>,
    /// <p>Specifies an external manifest that the services uses to train the model. If you specify <code>TrainingData</code> you must also specify <code>TestingData</code>. The project must not have any associated datasets. </p>
    #[doc(hidden)]
    pub training_data: std::option::Option<crate::model::TrainingData>,
    /// <p>Specifies an external manifest that the service uses to test the model. If you specify <code>TestingData</code> you must also specify <code>TrainingData</code>. The project must not have any associated datasets.</p>
    #[doc(hidden)]
    pub testing_data: std::option::Option<crate::model::TestingData>,
    /// <p> A set of tags (key-value pairs) that you want to attach to the model. </p>
    #[doc(hidden)]
    pub tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    /// <p>The identifier for your AWS Key Management Service key (AWS KMS key). You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt training and test images copied into the service for model training. Your source images are unaffected. The key is also used to encrypt training results and manifest files written to the output Amazon S3 bucket (<code>OutputConfig</code>).</p> 
    /// <p>If you choose to use your own KMS key, you need the following permissions on the KMS key.</p> 
    /// <ul> 
    /// <li> <p>kms:CreateGrant</p> </li> 
    /// <li> <p>kms:DescribeKey</p> </li> 
    /// <li> <p>kms:GenerateDataKey</p> </li> 
    /// <li> <p>kms:Decrypt</p> </li> 
    /// </ul> 
    /// <p>If you don't specify a value for <code>KmsKeyId</code>, images copied into the service are encrypted using a key that AWS owns and manages.</p>
    #[doc(hidden)]
    pub kms_key_id: std::option::Option<std::string::String>,
}
impl CreateProjectVersionInput {
    /// <p>The ARN of the Amazon Rekognition Custom Labels project that manages the model that you want to train.</p>
    pub fn project_arn(&self) -> std::option::Option<& str> {
        self.project_arn.as_deref()
    }
    /// <p>A name for the version of the model. This value must be unique.</p>
    pub fn version_name(&self) -> std::option::Option<& str> {
        self.version_name.as_deref()
    }
    /// <p>The Amazon S3 bucket location to store the results of training. The S3 bucket can be in any AWS account as long as the caller has <code>s3:PutObject</code> permissions on the S3 bucket.</p>
    pub fn output_config(&self) -> std::option::Option<& crate::model::OutputConfig> {
        self.output_config.as_ref()
    }
    /// <p>Specifies an external manifest that the services uses to train the model. If you specify <code>TrainingData</code> you must also specify <code>TestingData</code>. The project must not have any associated datasets. </p>
    pub fn training_data(&self) -> std::option::Option<& crate::model::TrainingData> {
        self.training_data.as_ref()
    }
    /// <p>Specifies an external manifest that the service uses to test the model. If you specify <code>TestingData</code> you must also specify <code>TrainingData</code>. The project must not have any associated datasets.</p>
    pub fn testing_data(&self) -> std::option::Option<& crate::model::TestingData> {
        self.testing_data.as_ref()
    }
    /// <p> A set of tags (key-value pairs) that you want to attach to the model. </p>
    pub fn tags(&self) -> std::option::Option<& std::collections::HashMap<std::string::String, std::string::String>> {
        self.tags.as_ref()
    }
    /// <p>The identifier for your AWS Key Management Service key (AWS KMS key). You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt training and test images copied into the service for model training. Your source images are unaffected. The key is also used to encrypt training results and manifest files written to the output Amazon S3 bucket (<code>OutputConfig</code>).</p> 
    /// <p>If you choose to use your own KMS key, you need the following permissions on the KMS key.</p> 
    /// <ul> 
    /// <li> <p>kms:CreateGrant</p> </li> 
    /// <li> <p>kms:DescribeKey</p> </li> 
    /// <li> <p>kms:GenerateDataKey</p> </li> 
    /// <li> <p>kms:Decrypt</p> </li> 
    /// </ul> 
    /// <p>If you don't specify a value for <code>KmsKeyId</code>, images copied into the service are encrypted using a key that AWS owns and manages.</p>
    pub fn kms_key_id(&self) -> std::option::Option<& str> {
        self.kms_key_id.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateProjectInput  {
    /// <p>The name of the project to create.</p>
    #[doc(hidden)]
    pub project_name: std::option::Option<std::string::String>,
}
impl CreateProjectInput {
    /// <p>The name of the project to create.</p>
    pub fn project_name(&self) -> std::option::Option<& str> {
        self.project_name.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateDatasetInput  {
    /// <p> The source files for the dataset. You can specify the ARN of an existing dataset or specify the Amazon S3 bucket location of an Amazon Sagemaker format manifest file. If you don't specify <code>datasetSource</code>, an empty dataset is created. To add labeled images to the dataset, You can use the console or call <code>UpdateDatasetEntries</code>. </p>
    #[doc(hidden)]
    pub dataset_source: std::option::Option<crate::model::DatasetSource>,
    /// <p> The type of the dataset. Specify <code>train</code> to create a training dataset. Specify <code>test</code> to create a test dataset. </p>
    #[doc(hidden)]
    pub dataset_type: std::option::Option<crate::model::DatasetType>,
    /// <p> The ARN of the Amazon Rekognition Custom Labels project to which you want to asssign the dataset. </p>
    #[doc(hidden)]
    pub project_arn: std::option::Option<std::string::String>,
}
impl CreateDatasetInput {
    /// <p> The source files for the dataset. You can specify the ARN of an existing dataset or specify the Amazon S3 bucket location of an Amazon Sagemaker format manifest file. If you don't specify <code>datasetSource</code>, an empty dataset is created. To add labeled images to the dataset, You can use the console or call <code>UpdateDatasetEntries</code>. </p>
    pub fn dataset_source(&self) -> std::option::Option<& crate::model::DatasetSource> {
        self.dataset_source.as_ref()
    }
    /// <p> The type of the dataset. Specify <code>train</code> to create a training dataset. Specify <code>test</code> to create a test dataset. </p>
    pub fn dataset_type(&self) -> std::option::Option<& crate::model::DatasetType> {
        self.dataset_type.as_ref()
    }
    /// <p> The ARN of the Amazon Rekognition Custom Labels project to which you want to asssign the dataset. </p>
    pub fn project_arn(&self) -> std::option::Option<& str> {
        self.project_arn.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateCollectionInput  {
    /// <p>ID for the collection that you are creating.</p>
    #[doc(hidden)]
    pub collection_id: std::option::Option<std::string::String>,
    /// <p> A set of tags (key-value pairs) that you want to attach to the collection. </p>
    #[doc(hidden)]
    pub tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
}
impl CreateCollectionInput {
    /// <p>ID for the collection that you are creating.</p>
    pub fn collection_id(&self) -> std::option::Option<& str> {
        self.collection_id.as_deref()
    }
    /// <p> A set of tags (key-value pairs) that you want to attach to the collection. </p>
    pub fn tags(&self) -> std::option::Option<& std::collections::HashMap<std::string::String, std::string::String>> {
        self.tags.as_ref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CopyProjectVersionInput  {
    /// <p>The ARN of the source project in the trusting AWS account.</p>
    #[doc(hidden)]
    pub source_project_arn: std::option::Option<std::string::String>,
    /// <p>The ARN of the model version in the source project that you want to copy to a destination project.</p>
    #[doc(hidden)]
    pub source_project_version_arn: std::option::Option<std::string::String>,
    /// <p>The ARN of the project in the trusted AWS account that you want to copy the model version to. </p>
    #[doc(hidden)]
    pub destination_project_arn: std::option::Option<std::string::String>,
    /// <p>A name for the version of the model that's copied to the destination project.</p>
    #[doc(hidden)]
    pub version_name: std::option::Option<std::string::String>,
    /// <p>The S3 bucket and folder location where the training output for the source model version is placed.</p>
    #[doc(hidden)]
    pub output_config: std::option::Option<crate::model::OutputConfig>,
    /// <p>The key-value tags to assign to the model version. </p>
    #[doc(hidden)]
    pub tags: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    /// <p>The identifier for your AWS Key Management Service key (AWS KMS key). You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt training results and manifest files written to the output Amazon S3 bucket (<code>OutputConfig</code>).</p> 
    /// <p>If you choose to use your own KMS key, you need the following permissions on the KMS key.</p> 
    /// <ul> 
    /// <li> <p>kms:CreateGrant</p> </li> 
    /// <li> <p>kms:DescribeKey</p> </li> 
    /// <li> <p>kms:GenerateDataKey</p> </li> 
    /// <li> <p>kms:Decrypt</p> </li> 
    /// </ul> 
    /// <p>If you don't specify a value for <code>KmsKeyId</code>, images copied into the service are encrypted using a key that AWS owns and manages.</p>
    #[doc(hidden)]
    pub kms_key_id: std::option::Option<std::string::String>,
}
impl CopyProjectVersionInput {
    /// <p>The ARN of the source project in the trusting AWS account.</p>
    pub fn source_project_arn(&self) -> std::option::Option<& str> {
        self.source_project_arn.as_deref()
    }
    /// <p>The ARN of the model version in the source project that you want to copy to a destination project.</p>
    pub fn source_project_version_arn(&self) -> std::option::Option<& str> {
        self.source_project_version_arn.as_deref()
    }
    /// <p>The ARN of the project in the trusted AWS account that you want to copy the model version to. </p>
    pub fn destination_project_arn(&self) -> std::option::Option<& str> {
        self.destination_project_arn.as_deref()
    }
    /// <p>A name for the version of the model that's copied to the destination project.</p>
    pub fn version_name(&self) -> std::option::Option<& str> {
        self.version_name.as_deref()
    }
    /// <p>The S3 bucket and folder location where the training output for the source model version is placed.</p>
    pub fn output_config(&self) -> std::option::Option<& crate::model::OutputConfig> {
        self.output_config.as_ref()
    }
    /// <p>The key-value tags to assign to the model version. </p>
    pub fn tags(&self) -> std::option::Option<& std::collections::HashMap<std::string::String, std::string::String>> {
        self.tags.as_ref()
    }
    /// <p>The identifier for your AWS Key Management Service key (AWS KMS key). You can supply the Amazon Resource Name (ARN) of your KMS key, the ID of your KMS key, an alias for your KMS key, or an alias ARN. The key is used to encrypt training results and manifest files written to the output Amazon S3 bucket (<code>OutputConfig</code>).</p> 
    /// <p>If you choose to use your own KMS key, you need the following permissions on the KMS key.</p> 
    /// <ul> 
    /// <li> <p>kms:CreateGrant</p> </li> 
    /// <li> <p>kms:DescribeKey</p> </li> 
    /// <li> <p>kms:GenerateDataKey</p> </li> 
    /// <li> <p>kms:Decrypt</p> </li> 
    /// </ul> 
    /// <p>If you don't specify a value for <code>KmsKeyId</code>, images copied into the service are encrypted using a key that AWS owns and manages.</p>
    pub fn kms_key_id(&self) -> std::option::Option<& str> {
        self.kms_key_id.as_deref()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CompareFacesInput  {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    #[doc(hidden)]
    pub source_image: std::option::Option<crate::model::Image>,
    /// <p>The target image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    #[doc(hidden)]
    pub target_image: std::option::Option<crate::model::Image>,
    /// <p>The minimum level of confidence in the face matches that a match must meet to be included in the <code>FaceMatches</code> array.</p>
    #[doc(hidden)]
    pub similarity_threshold: std::option::Option<f32>,
    /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't compared. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. The default value is <code>NONE</code>. </p> 
    /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
    #[doc(hidden)]
    pub quality_filter: std::option::Option<crate::model::QualityFilter>,
}
impl CompareFacesInput {
    /// <p>The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn source_image(&self) -> std::option::Option<& crate::model::Image> {
        self.source_image.as_ref()
    }
    /// <p>The target image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. </p> 
    /// <p>If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the <code>Bytes</code> field. For more information, see Images in the Amazon Rekognition developer guide.</p>
    pub fn target_image(&self) -> std::option::Option<& crate::model::Image> {
        self.target_image.as_ref()
    }
    /// <p>The minimum level of confidence in the face matches that a match must meet to be included in the <code>FaceMatches</code> array.</p>
    pub fn similarity_threshold(&self) -> std::option::Option<f32> {
        self.similarity_threshold
    }
    /// <p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't compared. If you specify <code>AUTO</code>, Amazon Rekognition chooses the quality bar. If you specify <code>LOW</code>, <code>MEDIUM</code>, or <code>HIGH</code>, filtering removes all faces that don’t meet the chosen quality bar. The quality bar is based on a variety of common use cases. Low-quality detections can occur for a number of reasons. Some examples are an object that's misidentified as a face, a face that's too blurry, or a face with a pose that's too extreme to use. If you specify <code>NONE</code>, no filtering is performed. The default value is <code>NONE</code>. </p> 
    /// <p>To use quality filtering, the collection you are using must be associated with version 3 of the face model or higher.</p>
    pub fn quality_filter(&self) -> std::option::Option<& crate::model::QualityFilter> {
        self.quality_filter.as_ref()
    }
}

