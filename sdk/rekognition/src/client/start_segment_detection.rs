// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`StartSegmentDetection`](crate::client::fluent_builders::StartSegmentDetection) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`video(Video)`](crate::client::fluent_builders::StartSegmentDetection::video) / [`set_video(Option<Video>)`](crate::client::fluent_builders::StartSegmentDetection::set_video): <p>Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as <code>StartLabelDetection</code> use <code>Video</code> to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.</p>
    ///   - [`client_request_token(impl Into<String>)`](crate::client::fluent_builders::StartSegmentDetection::client_request_token) / [`set_client_request_token(Option<String>)`](crate::client::fluent_builders::StartSegmentDetection::set_client_request_token): <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartSegmentDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    ///   - [`notification_channel(NotificationChannel)`](crate::client::fluent_builders::StartSegmentDetection::notification_channel) / [`set_notification_channel(Option<NotificationChannel>)`](crate::client::fluent_builders::StartSegmentDetection::set_notification_channel): <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the segment detection operation. Note that the Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.</p>
    ///   - [`job_tag(impl Into<String>)`](crate::client::fluent_builders::StartSegmentDetection::job_tag) / [`set_job_tag(Option<String>)`](crate::client::fluent_builders::StartSegmentDetection::set_job_tag): <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    ///   - [`filters(StartSegmentDetectionFilters)`](crate::client::fluent_builders::StartSegmentDetection::filters) / [`set_filters(Option<StartSegmentDetectionFilters>)`](crate::client::fluent_builders::StartSegmentDetection::set_filters): <p>Filters for technical cue or shot detection.</p>
    ///   - [`segment_types(Vec<SegmentType>)`](crate::client::fluent_builders::StartSegmentDetection::segment_types) / [`set_segment_types(Option<Vec<SegmentType>>)`](crate::client::fluent_builders::StartSegmentDetection::set_segment_types): <p>An array of segment types to detect in the video. Valid values are TECHNICAL_CUE and SHOT.</p>
    /// - On success, responds with [`StartSegmentDetectionOutput`](crate::output::StartSegmentDetectionOutput) with field(s):
    ///   - [`job_id(Option<String>)`](crate::output::StartSegmentDetectionOutput::job_id): <p>Unique identifier for the segment detection job. The <code>JobId</code> is returned from <code>StartSegmentDetection</code>. </p>
    /// - On failure, responds with [`SdkError<StartSegmentDetectionError>`](crate::error::StartSegmentDetectionError)
    pub fn start_segment_detection(&self) -> crate::client::fluent_builders::StartSegmentDetection {
        crate::client::fluent_builders::StartSegmentDetection::new(self.handle.clone())
    }
}
