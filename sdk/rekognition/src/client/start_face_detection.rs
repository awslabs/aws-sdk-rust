// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`StartFaceDetection`](crate::client::fluent_builders::StartFaceDetection) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`video(Video)`](crate::client::fluent_builders::StartFaceDetection::video) / [`set_video(Option<Video>)`](crate::client::fluent_builders::StartFaceDetection::set_video): <p>The video in which you want to detect faces. The video must be stored in an Amazon S3 bucket.</p>
    ///   - [`client_request_token(impl Into<String>)`](crate::client::fluent_builders::StartFaceDetection::client_request_token) / [`set_client_request_token(Option<String>)`](crate::client::fluent_builders::StartFaceDetection::set_client_request_token): <p>Idempotent token used to identify the start request. If you use the same token with multiple <code>StartFaceDetection</code> requests, the same <code>JobId</code> is returned. Use <code>ClientRequestToken</code> to prevent the same job from being accidently started more than once. </p>
    ///   - [`notification_channel(NotificationChannel)`](crate::client::fluent_builders::StartFaceDetection::notification_channel) / [`set_notification_channel(Option<NotificationChannel>)`](crate::client::fluent_builders::StartFaceDetection::set_notification_channel): <p>The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the face detection operation. The Amazon SNS topic must have a topic name that begins with <i>AmazonRekognition</i> if you are using the AmazonRekognitionServiceRole permissions policy.</p>
    ///   - [`face_attributes(FaceAttributes)`](crate::client::fluent_builders::StartFaceDetection::face_attributes) / [`set_face_attributes(Option<FaceAttributes>)`](crate::client::fluent_builders::StartFaceDetection::set_face_attributes): <p>The face attributes you want returned.</p>  <p> <code>DEFAULT</code> - The following subset of facial attributes are returned: BoundingBox, Confidence, Pose, Quality and Landmarks. </p>  <p> <code>ALL</code> - All facial attributes are returned.</p>
    ///   - [`job_tag(impl Into<String>)`](crate::client::fluent_builders::StartFaceDetection::job_tag) / [`set_job_tag(Option<String>)`](crate::client::fluent_builders::StartFaceDetection::set_job_tag): <p>An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use <code>JobTag</code> to group related jobs and identify them in the completion notification.</p>
    /// - On success, responds with [`StartFaceDetectionOutput`](crate::output::StartFaceDetectionOutput) with field(s):
    ///   - [`job_id(Option<String>)`](crate::output::StartFaceDetectionOutput::job_id): <p>The identifier for the face detection job. Use <code>JobId</code> to identify the job in a subsequent call to <code>GetFaceDetection</code>.</p>
    /// - On failure, responds with [`SdkError<StartFaceDetectionError>`](crate::error::StartFaceDetectionError)
    pub fn start_face_detection(&self) -> crate::client::fluent_builders::StartFaceDetection {
        crate::client::fluent_builders::StartFaceDetection::new(self.handle.clone())
    }
}
