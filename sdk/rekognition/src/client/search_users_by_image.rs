// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`SearchUsersByImage`](crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`collection_id(impl Into<String>)`](crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder::collection_id) / [`set_collection_id(Option<String>)`](crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder::set_collection_id):<br>required: **true**<br><p>The ID of an existing collection containing the UserID.</p><br>
    ///   - [`image(Image)`](crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder::image) / [`set_image(Option<Image>)`](crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder::set_image):<br>required: **true**<br><p>Provides the input image either as bytes or an S3 object.</p> <p>You pass image bytes to an Amazon Rekognition API operation by using the <code>Bytes</code> property. For example, you would use the <code>Bytes</code> property to pass an image loaded from a local file system. Image bytes passed by using the <code>Bytes</code> property must be base64-encoded. Your code may not need to encode image bytes if you are using an AWS SDK to call Amazon Rekognition API operations.</p> <p>For more information, see Analyzing an Image Loaded from a Local File System in the Amazon Rekognition Developer Guide.</p> <p>You pass images stored in an S3 bucket to an Amazon Rekognition API operation by using the <code>S3Object</code> property. Images stored in an S3 bucket do not need to be base64-encoded.</p> <p>The region for the S3 bucket containing the S3 object must match the region you use for Amazon Rekognition operations.</p> <p>If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes using the Bytes property is not supported. You must first upload the image to an Amazon S3 bucket and then call the operation using the S3Object property.</p> <p>For Amazon Rekognition to process an S3 object, the user must have permission to access the S3 object. For more information, see How Amazon Rekognition works with IAM in the Amazon Rekognition Developer Guide.</p><br>
    ///   - [`user_match_threshold(f32)`](crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder::user_match_threshold) / [`set_user_match_threshold(Option<f32>)`](crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder::set_user_match_threshold):<br>required: **false**<br><p>Specifies the minimum confidence in the UserID match to return. Default value is 80.</p><br>
    ///   - [`max_users(i32)`](crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder::max_users) / [`set_max_users(Option<i32>)`](crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder::set_max_users):<br>required: **false**<br><p>Maximum number of UserIDs to return.</p><br>
    ///   - [`quality_filter(QualityFilter)`](crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder::quality_filter) / [`set_quality_filter(Option<QualityFilter>)`](crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder::set_quality_filter):<br>required: **false**<br><p>A filter that specifies a quality bar for how much filtering is done to identify faces. Filtered faces aren't searched for in the collection. The default value is NONE.</p><br>
    /// - On success, responds with [`SearchUsersByImageOutput`](crate::operation::search_users_by_image::SearchUsersByImageOutput) with field(s):
    ///   - [`user_matches(Option<Vec::<UserMatch>>)`](crate::operation::search_users_by_image::SearchUsersByImageOutput::user_matches): <p>An array of UserID objects that matched the input face, along with the confidence in the match. The returned structure will be empty if there are no matches. Returned if the SearchUsersByImageResponse action is successful.</p>
    ///   - [`face_model_version(Option<String>)`](crate::operation::search_users_by_image::SearchUsersByImageOutput::face_model_version): <p>Version number of the face detection model associated with the input collection CollectionId.</p>
    ///   - [`searched_face(Option<SearchedFaceDetails>)`](crate::operation::search_users_by_image::SearchUsersByImageOutput::searched_face): <p>A list of FaceDetail objects containing the BoundingBox for the largest face in image, as well as the confidence in the bounding box, that was searched for matches. If no valid face is detected in the image the response will contain no SearchedFace object.</p>
    ///   - [`unsearched_faces(Option<Vec::<UnsearchedFace>>)`](crate::operation::search_users_by_image::SearchUsersByImageOutput::unsearched_faces): <p>List of UnsearchedFace objects. Contains the face details infered from the specified image but not used for search. Contains reasons that describe why a face wasn't used for Search.</p>
    /// - On failure, responds with [`SdkError<SearchUsersByImageError>`](crate::operation::search_users_by_image::SearchUsersByImageError)
    pub fn search_users_by_image(&self) -> crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder {
        crate::operation::search_users_by_image::builders::SearchUsersByImageFluentBuilder::new(self.handle.clone())
    }
}
