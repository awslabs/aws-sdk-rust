// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`CreateInferenceScheduler`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`model_name(impl Into<String>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::model_name) / [`set_model_name(Option<String>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::set_model_name): <p>The name of the previously trained ML model being used to create the inference scheduler. </p>
    ///   - [`inference_scheduler_name(impl Into<String>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::inference_scheduler_name) / [`set_inference_scheduler_name(Option<String>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::set_inference_scheduler_name): <p>The name of the inference scheduler being created. </p>
    ///   - [`data_delay_offset_in_minutes(i64)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::data_delay_offset_in_minutes) / [`set_data_delay_offset_in_minutes(Option<i64>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::set_data_delay_offset_in_minutes): <p>The interval (in minutes) of planned delay at the start of each inference segment. For example, if inference is set to run every ten minutes, the delay is set to five minutes and the time is 09:08. The inference scheduler will wake up at the configured interval (which, without a delay configured, would be 09:10) plus the additional five minute delay time (so 09:15) to check your Amazon S3 bucket. The delay provides a buffer for you to upload data at the same frequency, so that you don't have to stop and restart the scheduler when uploading new data.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/understanding-inference-process.html">Understanding the inference process</a>.</p>
    ///   - [`data_upload_frequency(DataUploadFrequency)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::data_upload_frequency) / [`set_data_upload_frequency(Option<DataUploadFrequency>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::set_data_upload_frequency): <p> How often data is uploaded to the source Amazon S3 bucket for the input data. The value chosen is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment runs inference on your data.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/understanding-inference-process.html">Understanding the inference process</a>.</p>
    ///   - [`data_input_configuration(InferenceInputConfiguration)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::data_input_configuration) / [`set_data_input_configuration(Option<InferenceInputConfiguration>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::set_data_input_configuration): <p>Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>
    ///   - [`data_output_configuration(InferenceOutputConfiguration)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::data_output_configuration) / [`set_data_output_configuration(Option<InferenceOutputConfiguration>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::set_data_output_configuration): <p>Specifies configuration information for the output results for the inference scheduler, including the S3 location for the output. </p>
    ///   - [`role_arn(impl Into<String>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::role_arn) / [`set_role_arn(Option<String>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::set_role_arn): <p>The Amazon Resource Name (ARN) of a role with permission to access the data source being used for the inference. </p>
    ///   - [`server_side_kms_key_id(impl Into<String>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::server_side_kms_key_id) / [`set_server_side_kms_key_id(Option<String>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::set_server_side_kms_key_id): <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
    ///   - [`client_token(impl Into<String>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::client_token) / [`set_client_token(Option<String>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::set_client_token): <p> A unique identifier for the request. If you do not set the client request token, Amazon Lookout for Equipment generates one. </p>
    ///   - [`tags(Vec<Tag>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::tags) / [`set_tags(Option<Vec<Tag>>)`](crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::set_tags): <p>Any tags associated with the inference scheduler. </p>
    /// - On success, responds with [`CreateInferenceSchedulerOutput`](crate::operation::create_inference_scheduler::CreateInferenceSchedulerOutput) with field(s):
    ///   - [`inference_scheduler_arn(Option<String>)`](crate::operation::create_inference_scheduler::CreateInferenceSchedulerOutput::inference_scheduler_arn): <p>The Amazon Resource Name (ARN) of the inference scheduler being created. </p>
    ///   - [`inference_scheduler_name(Option<String>)`](crate::operation::create_inference_scheduler::CreateInferenceSchedulerOutput::inference_scheduler_name): <p>The name of inference scheduler being created. </p>
    ///   - [`status(Option<InferenceSchedulerStatus>)`](crate::operation::create_inference_scheduler::CreateInferenceSchedulerOutput::status): <p>Indicates the status of the <code>CreateInferenceScheduler</code> operation. </p>
    /// - On failure, responds with [`SdkError<CreateInferenceSchedulerError>`](crate::operation::create_inference_scheduler::CreateInferenceSchedulerError)
    pub fn create_inference_scheduler(
        &self,
    ) -> crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder
    {
        crate::operation::create_inference_scheduler::builders::CreateInferenceSchedulerFluentBuilder::new(self.handle.clone())
    }
}
