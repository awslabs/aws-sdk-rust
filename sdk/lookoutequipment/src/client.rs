// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[derive(std::fmt::Debug)]
pub(crate) struct Handle<C = aws_hyper::DynConnector> {
    client: aws_hyper::Client<C>,
    conf: crate::Config,
}

#[derive(Clone, std::fmt::Debug)]
pub struct Client<C = aws_hyper::DynConnector> {
    handle: std::sync::Arc<Handle<C>>,
}
impl<C> Client<C> {
    pub fn from_conf_conn(conf: crate::Config, conn: C) -> Self {
        let client = aws_hyper::Client::new(conn);
        Self {
            handle: std::sync::Arc::new(Handle { client, conf }),
        }
    }

    pub fn conf(&self) -> &crate::Config {
        &self.handle.conf
    }
}
impl Client {
    #[cfg(any(feature = "rustls", feature = "native-tls"))]
    pub fn from_env() -> Self {
        Self::from_conf(crate::Config::builder().build())
    }

    #[cfg(any(feature = "rustls", feature = "native-tls"))]
    pub fn from_conf(conf: crate::Config) -> Self {
        let client = aws_hyper::Client::https();
        Self {
            handle: std::sync::Arc::new(Handle { client, conf }),
        }
    }
}
impl<C> Client<C>
where
    C: aws_hyper::SmithyConnector,
{
    pub fn create_dataset(&self) -> fluent_builders::CreateDataset<C> {
        fluent_builders::CreateDataset::new(self.handle.clone())
    }
    pub fn create_inference_scheduler(&self) -> fluent_builders::CreateInferenceScheduler<C> {
        fluent_builders::CreateInferenceScheduler::new(self.handle.clone())
    }
    pub fn create_model(&self) -> fluent_builders::CreateModel<C> {
        fluent_builders::CreateModel::new(self.handle.clone())
    }
    pub fn delete_dataset(&self) -> fluent_builders::DeleteDataset<C> {
        fluent_builders::DeleteDataset::new(self.handle.clone())
    }
    pub fn delete_inference_scheduler(&self) -> fluent_builders::DeleteInferenceScheduler<C> {
        fluent_builders::DeleteInferenceScheduler::new(self.handle.clone())
    }
    pub fn delete_model(&self) -> fluent_builders::DeleteModel<C> {
        fluent_builders::DeleteModel::new(self.handle.clone())
    }
    pub fn describe_data_ingestion_job(&self) -> fluent_builders::DescribeDataIngestionJob<C> {
        fluent_builders::DescribeDataIngestionJob::new(self.handle.clone())
    }
    pub fn describe_dataset(&self) -> fluent_builders::DescribeDataset<C> {
        fluent_builders::DescribeDataset::new(self.handle.clone())
    }
    pub fn describe_inference_scheduler(&self) -> fluent_builders::DescribeInferenceScheduler<C> {
        fluent_builders::DescribeInferenceScheduler::new(self.handle.clone())
    }
    pub fn describe_model(&self) -> fluent_builders::DescribeModel<C> {
        fluent_builders::DescribeModel::new(self.handle.clone())
    }
    pub fn list_data_ingestion_jobs(&self) -> fluent_builders::ListDataIngestionJobs<C> {
        fluent_builders::ListDataIngestionJobs::new(self.handle.clone())
    }
    pub fn list_datasets(&self) -> fluent_builders::ListDatasets<C> {
        fluent_builders::ListDatasets::new(self.handle.clone())
    }
    pub fn list_inference_executions(&self) -> fluent_builders::ListInferenceExecutions<C> {
        fluent_builders::ListInferenceExecutions::new(self.handle.clone())
    }
    pub fn list_inference_schedulers(&self) -> fluent_builders::ListInferenceSchedulers<C> {
        fluent_builders::ListInferenceSchedulers::new(self.handle.clone())
    }
    pub fn list_models(&self) -> fluent_builders::ListModels<C> {
        fluent_builders::ListModels::new(self.handle.clone())
    }
    pub fn list_tags_for_resource(&self) -> fluent_builders::ListTagsForResource<C> {
        fluent_builders::ListTagsForResource::new(self.handle.clone())
    }
    pub fn start_data_ingestion_job(&self) -> fluent_builders::StartDataIngestionJob<C> {
        fluent_builders::StartDataIngestionJob::new(self.handle.clone())
    }
    pub fn start_inference_scheduler(&self) -> fluent_builders::StartInferenceScheduler<C> {
        fluent_builders::StartInferenceScheduler::new(self.handle.clone())
    }
    pub fn stop_inference_scheduler(&self) -> fluent_builders::StopInferenceScheduler<C> {
        fluent_builders::StopInferenceScheduler::new(self.handle.clone())
    }
    pub fn tag_resource(&self) -> fluent_builders::TagResource<C> {
        fluent_builders::TagResource::new(self.handle.clone())
    }
    pub fn untag_resource(&self) -> fluent_builders::UntagResource<C> {
        fluent_builders::UntagResource::new(self.handle.clone())
    }
    pub fn update_inference_scheduler(&self) -> fluent_builders::UpdateInferenceScheduler<C> {
        fluent_builders::UpdateInferenceScheduler::new(self.handle.clone())
    }
}
pub mod fluent_builders {
    #[derive(std::fmt::Debug)]
    pub struct CreateDataset<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::create_dataset_input::Builder,
    }
    impl<C> CreateDataset<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::CreateDatasetOutput,
            smithy_http::result::SdkError<crate::error::CreateDatasetError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the dataset being created. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(input);
            self
        }
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
        /// <p>A JSON description of the data that is in each time series dataset, including names,
        /// column names, and data types. </p>
        pub fn dataset_schema(mut self, input: crate::model::DatasetSchema) -> Self {
            self.inner = self.inner.dataset_schema(input);
            self
        }
        pub fn set_dataset_schema(
            mut self,
            input: std::option::Option<crate::model::DatasetSchema>,
        ) -> Self {
            self.inner = self.inner.set_dataset_schema(input);
            self
        }
        /// <p>Provides the identifier of the AWS KMS customer master key (CMK) used to encrypt dataset data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.server_side_kms_key_id(input);
            self
        }
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_server_side_kms_key_id(input);
            self
        }
        /// <p> A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn client_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.client_token(input);
            self
        }
        pub fn set_client_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_client_token(input);
            self
        }
        /// <p>Any tags associated with the ingested data described in the dataset. </p>
        pub fn tags(mut self, inp: impl Into<crate::model::Tag>) -> Self {
            self.inner = self.inner.tags(inp);
            self
        }
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.inner = self.inner.set_tags(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct CreateInferenceScheduler<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::create_inference_scheduler_input::Builder,
    }
    impl<C> CreateInferenceScheduler<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::CreateInferenceSchedulerOutput,
            smithy_http::result::SdkError<crate::error::CreateInferenceSchedulerError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the previously trained ML model being used to create the inference
        /// scheduler. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name(input);
            self
        }
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_model_name(input);
            self
        }
        /// <p>The name of the inference scheduler being created. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(input);
            self
        }
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
        /// <p> A period of time (in minutes) by which inference on the data is delayed after the data
        /// starts. For instance, if you select an offset delay time of five minutes, inference will
        /// not begin on the data until the first data measurement after the five minute mark. For example, if
        /// five minutes is selected, the inference scheduler will wake up at the configured frequency with the
        /// additional five minute delay time to check the customer S3 bucket. The customer can upload data at
        /// the same frequency and they don't need to stop and restart the scheduler when uploading new data. </p>
        pub fn data_delay_offset_in_minutes(mut self, input: i64) -> Self {
            self.inner = self.inner.data_delay_offset_in_minutes(input);
            self
        }
        pub fn set_data_delay_offset_in_minutes(mut self, input: std::option::Option<i64>) -> Self {
            self.inner = self.inner.set_data_delay_offset_in_minutes(input);
            self
        }
        /// <p> How often data is uploaded to the source S3 bucket for the input data. The value chosen
        /// is the length of time between data uploads. For instance, if you select 5 minutes, Amazon
        /// Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency
        /// also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this
        /// example, it starts once every 5 minutes. </p>
        pub fn data_upload_frequency(mut self, input: crate::model::DataUploadFrequency) -> Self {
            self.inner = self.inner.data_upload_frequency(input);
            self
        }
        pub fn set_data_upload_frequency(
            mut self,
            input: std::option::Option<crate::model::DataUploadFrequency>,
        ) -> Self {
            self.inner = self.inner.set_data_upload_frequency(input);
            self
        }
        /// <p>Specifies configuration information for the input data for the inference scheduler,
        /// including delimiter, format, and dataset location. </p>
        pub fn data_input_configuration(
            mut self,
            input: crate::model::InferenceInputConfiguration,
        ) -> Self {
            self.inner = self.inner.data_input_configuration(input);
            self
        }
        pub fn set_data_input_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceInputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_data_input_configuration(input);
            self
        }
        /// <p>Specifies configuration information for the output results for the inference scheduler,
        /// including the S3 location for the output. </p>
        pub fn data_output_configuration(
            mut self,
            input: crate::model::InferenceOutputConfiguration,
        ) -> Self {
            self.inner = self.inner.data_output_configuration(input);
            self
        }
        pub fn set_data_output_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceOutputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_data_output_configuration(input);
            self
        }
        /// <p>The Amazon Resource Name (ARN) of a role with permission to access the data source being
        /// used for the inference. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.role_arn(input);
            self
        }
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_role_arn(input);
            self
        }
        /// <p>Provides the identifier of the AWS KMS customer master key (CMK) used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.server_side_kms_key_id(input);
            self
        }
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_server_side_kms_key_id(input);
            self
        }
        /// <p> A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn client_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.client_token(input);
            self
        }
        pub fn set_client_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_client_token(input);
            self
        }
        /// <p>Any tags associated with the inference scheduler. </p>
        pub fn tags(mut self, inp: impl Into<crate::model::Tag>) -> Self {
            self.inner = self.inner.tags(inp);
            self
        }
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.inner = self.inner.set_tags(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct CreateModel<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::create_model_input::Builder,
    }
    impl<C> CreateModel<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::CreateModelOutput,
            smithy_http::result::SdkError<crate::error::CreateModelError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name for the ML model to be created.</p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name(input);
            self
        }
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_model_name(input);
            self
        }
        /// <p>The name of the dataset for the ML model being created. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(input);
            self
        }
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
        /// <p>The data schema for the ML model being created. </p>
        pub fn dataset_schema(mut self, input: crate::model::DatasetSchema) -> Self {
            self.inner = self.inner.dataset_schema(input);
            self
        }
        pub fn set_dataset_schema(
            mut self,
            input: std::option::Option<crate::model::DatasetSchema>,
        ) -> Self {
            self.inner = self.inner.set_dataset_schema(input);
            self
        }
        /// <p>The input configuration for the labels being used for the ML model that's being created.
        /// </p>
        pub fn labels_input_configuration(
            mut self,
            input: crate::model::LabelsInputConfiguration,
        ) -> Self {
            self.inner = self.inner.labels_input_configuration(input);
            self
        }
        pub fn set_labels_input_configuration(
            mut self,
            input: std::option::Option<crate::model::LabelsInputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_labels_input_configuration(input);
            self
        }
        /// <p>A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn client_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.client_token(input);
            self
        }
        pub fn set_client_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_client_token(input);
            self
        }
        /// <p>Indicates the time reference in the dataset that should be used to begin the subset of
        /// training data for the ML model. </p>
        pub fn training_data_start_time(mut self, input: smithy_types::Instant) -> Self {
            self.inner = self.inner.training_data_start_time(input);
            self
        }
        pub fn set_training_data_start_time(
            mut self,
            input: std::option::Option<smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_training_data_start_time(input);
            self
        }
        /// <p>Indicates the time reference in the dataset that should be used to end the subset of
        /// training data for the ML model. </p>
        pub fn training_data_end_time(mut self, input: smithy_types::Instant) -> Self {
            self.inner = self.inner.training_data_end_time(input);
            self
        }
        pub fn set_training_data_end_time(
            mut self,
            input: std::option::Option<smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_training_data_end_time(input);
            self
        }
        /// <p>Indicates the time reference in the dataset that should be used to begin the subset of
        /// evaluation data for the ML model. </p>
        pub fn evaluation_data_start_time(mut self, input: smithy_types::Instant) -> Self {
            self.inner = self.inner.evaluation_data_start_time(input);
            self
        }
        pub fn set_evaluation_data_start_time(
            mut self,
            input: std::option::Option<smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_evaluation_data_start_time(input);
            self
        }
        /// <p> Indicates the time reference in the dataset that should be used to end the subset of
        /// evaluation data for the ML model. </p>
        pub fn evaluation_data_end_time(mut self, input: smithy_types::Instant) -> Self {
            self.inner = self.inner.evaluation_data_end_time(input);
            self
        }
        pub fn set_evaluation_data_end_time(
            mut self,
            input: std::option::Option<smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_evaluation_data_end_time(input);
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source
        /// being used to create the ML model. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.role_arn(input);
            self
        }
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_role_arn(input);
            self
        }
        /// <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of
        /// the data after post processing by
        /// Amazon Lookout for Equipment. For example, if you provide data that
        /// has been collected at a 1 second level and you want the system to resample
        /// the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p>
        /// <p>When providing a value for the <code>TargetSamplingRate</code>, you must
        /// attach the prefix "PT" to the rate you want.  The value for a 1 second rate
        /// is therefore <i>PT1S</i>, the value for a 15 minute rate
        /// is <i>PT15M</i>, and the value for a 1 hour rate
        /// is <i>PT1H</i>
        /// </p>
        pub fn data_pre_processing_configuration(
            mut self,
            input: crate::model::DataPreProcessingConfiguration,
        ) -> Self {
            self.inner = self.inner.data_pre_processing_configuration(input);
            self
        }
        pub fn set_data_pre_processing_configuration(
            mut self,
            input: std::option::Option<crate::model::DataPreProcessingConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_data_pre_processing_configuration(input);
            self
        }
        /// <p>Provides the identifier of the AWS KMS customer master key (CMK) used to encrypt model data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.server_side_kms_key_id(input);
            self
        }
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_server_side_kms_key_id(input);
            self
        }
        /// <p> Any tags associated with the ML model being created. </p>
        pub fn tags(mut self, inp: impl Into<crate::model::Tag>) -> Self {
            self.inner = self.inner.tags(inp);
            self
        }
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.inner = self.inner.set_tags(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct DeleteDataset<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::delete_dataset_input::Builder,
    }
    impl<C> DeleteDataset<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteDatasetOutput,
            smithy_http::result::SdkError<crate::error::DeleteDatasetError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the dataset to be deleted. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(input);
            self
        }
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct DeleteInferenceScheduler<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::delete_inference_scheduler_input::Builder,
    }
    impl<C> DeleteInferenceScheduler<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteInferenceSchedulerOutput,
            smithy_http::result::SdkError<crate::error::DeleteInferenceSchedulerError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the inference scheduler to be deleted. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(input);
            self
        }
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct DeleteModel<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::delete_model_input::Builder,
    }
    impl<C> DeleteModel<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteModelOutput,
            smithy_http::result::SdkError<crate::error::DeleteModelError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the ML model to be deleted. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name(input);
            self
        }
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_model_name(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct DescribeDataIngestionJob<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::describe_data_ingestion_job_input::Builder,
    }
    impl<C> DescribeDataIngestionJob<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeDataIngestionJobOutput,
            smithy_http::result::SdkError<crate::error::DescribeDataIngestionJobError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The job ID of the data ingestion job. </p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.job_id(input);
            self
        }
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_job_id(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct DescribeDataset<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::describe_dataset_input::Builder,
    }
    impl<C> DescribeDataset<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeDatasetOutput,
            smithy_http::result::SdkError<crate::error::DescribeDatasetError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the dataset to be described. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(input);
            self
        }
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct DescribeInferenceScheduler<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::describe_inference_scheduler_input::Builder,
    }
    impl<C> DescribeInferenceScheduler<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeInferenceSchedulerOutput,
            smithy_http::result::SdkError<crate::error::DescribeInferenceSchedulerError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the inference scheduler being described. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(input);
            self
        }
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct DescribeModel<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::describe_model_input::Builder,
    }
    impl<C> DescribeModel<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeModelOutput,
            smithy_http::result::SdkError<crate::error::DescribeModelError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the ML model to be described. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name(input);
            self
        }
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_model_name(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct ListDataIngestionJobs<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::list_data_ingestion_jobs_input::Builder,
    }
    impl<C> ListDataIngestionJobs<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListDataIngestionJobsOutput,
            smithy_http::result::SdkError<crate::error::ListDataIngestionJobsError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the dataset being used for the data ingestion job. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(input);
            self
        }
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of data ingestion
        /// jobs. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input);
            self
        }
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p> Specifies the maximum number of data ingestion jobs to list. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.inner = self.inner.max_results(input);
            self
        }
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_results(input);
            self
        }
        /// <p>Indicates the status of the data ingestion job. </p>
        pub fn status(mut self, input: crate::model::IngestionJobStatus) -> Self {
            self.inner = self.inner.status(input);
            self
        }
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::IngestionJobStatus>,
        ) -> Self {
            self.inner = self.inner.set_status(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct ListDatasets<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::list_datasets_input::Builder,
    }
    impl<C> ListDatasets<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListDatasetsOutput,
            smithy_http::result::SdkError<crate::error::ListDatasetsError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p> An opaque pagination token indicating where to continue the listing of datasets.
        /// </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input);
            self
        }
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p> Specifies the maximum number of datasets to list. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.inner = self.inner.max_results(input);
            self
        }
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_results(input);
            self
        }
        /// <p>The beginning of the name of the datasets to be listed. </p>
        pub fn dataset_name_begins_with(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name_begins_with(input);
            self
        }
        pub fn set_dataset_name_begins_with(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_dataset_name_begins_with(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct ListInferenceExecutions<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::list_inference_executions_input::Builder,
    }
    impl<C> ListInferenceExecutions<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListInferenceExecutionsOutput,
            smithy_http::result::SdkError<crate::error::ListInferenceExecutionsError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>An opaque pagination token indicating where to continue the listing of inference
        /// executions.</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input);
            self
        }
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>Specifies the maximum number of inference executions to list. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.inner = self.inner.max_results(input);
            self
        }
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_results(input);
            self
        }
        /// <p>The name of the inference scheduler for the inference execution listed. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(input);
            self
        }
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
        /// <p>The time reference in the inferenced dataset after which Amazon Lookout for Equipment started the
        /// inference execution. </p>
        pub fn data_start_time_after(mut self, input: smithy_types::Instant) -> Self {
            self.inner = self.inner.data_start_time_after(input);
            self
        }
        pub fn set_data_start_time_after(
            mut self,
            input: std::option::Option<smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_data_start_time_after(input);
            self
        }
        /// <p>The time reference in the inferenced dataset before which Amazon Lookout for Equipment stopped the
        /// inference execution. </p>
        pub fn data_end_time_before(mut self, input: smithy_types::Instant) -> Self {
            self.inner = self.inner.data_end_time_before(input);
            self
        }
        pub fn set_data_end_time_before(
            mut self,
            input: std::option::Option<smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_data_end_time_before(input);
            self
        }
        /// <p>The status of the inference execution. </p>
        pub fn status(mut self, input: crate::model::InferenceExecutionStatus) -> Self {
            self.inner = self.inner.status(input);
            self
        }
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::InferenceExecutionStatus>,
        ) -> Self {
            self.inner = self.inner.set_status(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct ListInferenceSchedulers<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::list_inference_schedulers_input::Builder,
    }
    impl<C> ListInferenceSchedulers<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListInferenceSchedulersOutput,
            smithy_http::result::SdkError<crate::error::ListInferenceSchedulersError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p> An opaque pagination token indicating where to continue the listing of inference
        /// schedulers. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input);
            self
        }
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p> Specifies the maximum number of inference schedulers to list. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.inner = self.inner.max_results(input);
            self
        }
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_results(input);
            self
        }
        /// <p>The beginning of the name of the inference schedulers to be listed. </p>
        pub fn inference_scheduler_name_begins_with(
            mut self,
            input: impl Into<std::string::String>,
        ) -> Self {
            self.inner = self.inner.inference_scheduler_name_begins_with(input);
            self
        }
        pub fn set_inference_scheduler_name_begins_with(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name_begins_with(input);
            self
        }
        /// <p>The name of the ML model used by the inference scheduler to be listed. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name(input);
            self
        }
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_model_name(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct ListModels<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::list_models_input::Builder,
    }
    impl<C> ListModels<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListModelsOutput,
            smithy_http::result::SdkError<crate::error::ListModelsError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p> An opaque pagination token indicating where to continue the listing of ML models.
        /// </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input);
            self
        }
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p> Specifies the maximum number of ML models to list. </p>
        pub fn max_results(mut self, input: i32) -> Self {
            self.inner = self.inner.max_results(input);
            self
        }
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_results(input);
            self
        }
        /// <p>The status of the ML model. </p>
        pub fn status(mut self, input: crate::model::ModelStatus) -> Self {
            self.inner = self.inner.status(input);
            self
        }
        pub fn set_status(mut self, input: std::option::Option<crate::model::ModelStatus>) -> Self {
            self.inner = self.inner.set_status(input);
            self
        }
        /// <p>The beginning of the name of the ML models being listed. </p>
        pub fn model_name_begins_with(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name_begins_with(input);
            self
        }
        pub fn set_model_name_begins_with(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_model_name_begins_with(input);
            self
        }
        /// <p>The beginning of the name of the dataset of the ML models to be listed. </p>
        pub fn dataset_name_begins_with(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name_begins_with(input);
            self
        }
        pub fn set_dataset_name_begins_with(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_dataset_name_begins_with(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct ListTagsForResource<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::list_tags_for_resource_input::Builder,
    }
    impl<C> ListTagsForResource<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListTagsForResourceOutput,
            smithy_http::result::SdkError<crate::error::ListTagsForResourceError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The Amazon Resource Name (ARN) of the resource (such as the dataset or model) that is
        /// the focus of the <code>ListTagsForResource</code> operation. </p>
        pub fn resource_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.resource_arn(input);
            self
        }
        pub fn set_resource_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_resource_arn(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct StartDataIngestionJob<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::start_data_ingestion_job_input::Builder,
    }
    impl<C> StartDataIngestionJob<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::StartDataIngestionJobOutput,
            smithy_http::result::SdkError<crate::error::StartDataIngestionJobError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the dataset being used by the data ingestion job. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(input);
            self
        }
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
        /// <p> Specifies information for the input data for the data ingestion job, including dataset
        /// S3 location. </p>
        pub fn ingestion_input_configuration(
            mut self,
            input: crate::model::IngestionInputConfiguration,
        ) -> Self {
            self.inner = self.inner.ingestion_input_configuration(input);
            self
        }
        pub fn set_ingestion_input_configuration(
            mut self,
            input: std::option::Option<crate::model::IngestionInputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_ingestion_input_configuration(input);
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for
        /// the data ingestion job. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.role_arn(input);
            self
        }
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_role_arn(input);
            self
        }
        /// <p> A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn client_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.client_token(input);
            self
        }
        pub fn set_client_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_client_token(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct StartInferenceScheduler<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::start_inference_scheduler_input::Builder,
    }
    impl<C> StartInferenceScheduler<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::StartInferenceSchedulerOutput,
            smithy_http::result::SdkError<crate::error::StartInferenceSchedulerError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the inference scheduler to be started. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(input);
            self
        }
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct StopInferenceScheduler<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::stop_inference_scheduler_input::Builder,
    }
    impl<C> StopInferenceScheduler<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::StopInferenceSchedulerOutput,
            smithy_http::result::SdkError<crate::error::StopInferenceSchedulerError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the inference scheduler to be stopped. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(input);
            self
        }
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct TagResource<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::tag_resource_input::Builder,
    }
    impl<C> TagResource<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::TagResourceOutput,
            smithy_http::result::SdkError<crate::error::TagResourceError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The Amazon Resource Name (ARN) of the specific resource to which the tag should be
        /// associated. </p>
        pub fn resource_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.resource_arn(input);
            self
        }
        pub fn set_resource_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_resource_arn(input);
            self
        }
        /// <p>The tag or tags to be associated with a specific resource. Both the tag key and value
        /// are specified. </p>
        pub fn tags(mut self, inp: impl Into<crate::model::Tag>) -> Self {
            self.inner = self.inner.tags(inp);
            self
        }
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.inner = self.inner.set_tags(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct UntagResource<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::untag_resource_input::Builder,
    }
    impl<C> UntagResource<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::UntagResourceOutput,
            smithy_http::result::SdkError<crate::error::UntagResourceError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The Amazon Resource Name (ARN) of the resource to which the tag is currently associated.
        /// </p>
        pub fn resource_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.resource_arn(input);
            self
        }
        pub fn set_resource_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_resource_arn(input);
            self
        }
        /// <p>Specifies the key of the tag to be removed from a specified resource. </p>
        pub fn tag_keys(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.tag_keys(inp);
            self
        }
        pub fn set_tag_keys(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_tag_keys(input);
            self
        }
    }
    #[derive(std::fmt::Debug)]
    pub struct UpdateInferenceScheduler<C = aws_hyper::DynConnector> {
        handle: std::sync::Arc<super::Handle<C>>,
        inner: crate::input::update_inference_scheduler_input::Builder,
    }
    impl<C> UpdateInferenceScheduler<C> {
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::UpdateInferenceSchedulerOutput,
            smithy_http::result::SdkError<crate::error::UpdateInferenceSchedulerError>,
        >
        where
            C: aws_hyper::SmithyConnector,
        {
            let input = self
                .inner
                .build()
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            let op = input
                .make_operation(&self.handle.conf)
                .map_err(|err| smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the inference scheduler to be updated. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(input);
            self
        }
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
        /// <p>> A period of time (in minutes) by which inference on the data is delayed after the data
        /// starts. For instance, if you select an offset delay time of five minutes, inference will
        /// not begin on the data until the first data measurement after the five minute mark. For example, if
        /// five minutes is selected, the inference scheduler will wake up at the configured frequency with the
        /// additional five minute delay time to check the customer S3 bucket. The customer can upload data at
        /// the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>
        pub fn data_delay_offset_in_minutes(mut self, input: i64) -> Self {
            self.inner = self.inner.data_delay_offset_in_minutes(input);
            self
        }
        pub fn set_data_delay_offset_in_minutes(mut self, input: std::option::Option<i64>) -> Self {
            self.inner = self.inner.set_data_delay_offset_in_minutes(input);
            self
        }
        /// <p>How often data is uploaded to the source S3 bucket for the input data. The value chosen
        /// is the length of time between data uploads. For instance, if you select 5 minutes, Amazon
        /// Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency
        /// also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this
        /// example, it starts once every 5 minutes. </p>
        pub fn data_upload_frequency(mut self, input: crate::model::DataUploadFrequency) -> Self {
            self.inner = self.inner.data_upload_frequency(input);
            self
        }
        pub fn set_data_upload_frequency(
            mut self,
            input: std::option::Option<crate::model::DataUploadFrequency>,
        ) -> Self {
            self.inner = self.inner.set_data_upload_frequency(input);
            self
        }
        /// <p> Specifies information for the input data for the inference scheduler, including
        /// delimiter, format, and dataset location. </p>
        pub fn data_input_configuration(
            mut self,
            input: crate::model::InferenceInputConfiguration,
        ) -> Self {
            self.inner = self.inner.data_input_configuration(input);
            self
        }
        pub fn set_data_input_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceInputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_data_input_configuration(input);
            self
        }
        /// <p> Specifies information for the output results from the inference scheduler, including the output S3 location. </p>
        pub fn data_output_configuration(
            mut self,
            input: crate::model::InferenceOutputConfiguration,
        ) -> Self {
            self.inner = self.inner.data_output_configuration(input);
            self
        }
        pub fn set_data_output_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceOutputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_data_output_configuration(input);
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for
        /// the inference scheduler. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.role_arn(input);
            self
        }
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_role_arn(input);
            self
        }
    }
}
