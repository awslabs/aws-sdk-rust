// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[derive(Debug)]
pub(crate) struct Handle<
    C = aws_smithy_client::erase::DynConnector,
    M = aws_hyper::AwsMiddleware,
    R = aws_smithy_client::retry::Standard,
> {
    client: aws_smithy_client::Client<C, M, R>,
    conf: crate::Config,
}

/// An ergonomic service client for `AWSLookoutEquipmentFrontendService`.
///
/// This client allows ergonomic access to a `AWSLookoutEquipmentFrontendService`-shaped service.
/// Each method corresponds to an endpoint defined in the service's Smithy model,
/// and the request and response shapes are auto-generated from that same model.
///
/// # Using a Client
///
/// Once you have a client set up, you can access the service's endpoints
/// by calling the appropriate method on [`Client`]. Each such method
/// returns a request builder for that endpoint, with methods for setting
/// the various fields of the request. Once your request is complete, use
/// the `send` method to send the request. `send` returns a future, which
/// you then have to `.await` to get the service's response.
///
/// [builder pattern]: https://rust-lang.github.io/api-guidelines/type-safety.html#c-builder
/// [SigV4-signed requests]: https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html
#[derive(std::fmt::Debug)]
pub struct Client<
    C = aws_smithy_client::erase::DynConnector,
    M = aws_hyper::AwsMiddleware,
    R = aws_smithy_client::retry::Standard,
> {
    handle: std::sync::Arc<Handle<C, M, R>>,
}

impl<C, M, R> std::clone::Clone for Client<C, M, R> {
    fn clone(&self) -> Self {
        Self {
            handle: self.handle.clone(),
        }
    }
}

#[doc(inline)]
pub use aws_smithy_client::Builder;

impl<C, M, R> From<aws_smithy_client::Client<C, M, R>> for Client<C, M, R> {
    fn from(client: aws_smithy_client::Client<C, M, R>) -> Self {
        Self::with_config(client, crate::Config::builder().build())
    }
}

impl<C, M, R> Client<C, M, R> {
    /// Creates a client with the given service configuration.
    pub fn with_config(client: aws_smithy_client::Client<C, M, R>, conf: crate::Config) -> Self {
        Self {
            handle: std::sync::Arc::new(Handle { client, conf }),
        }
    }

    /// Returns the client's configuration.
    pub fn conf(&self) -> &crate::Config {
        &self.handle.conf
    }
}
impl<C, M, R> Client<C, M, R>
where
    C: aws_smithy_client::bounds::SmithyConnector,
    M: aws_smithy_client::bounds::SmithyMiddleware<C>,
    R: aws_smithy_client::retry::NewRequestPolicy,
{
    /// Constructs a fluent builder for the `CreateDataset` operation.
    ///
    /// See [`CreateDataset`](crate::client::fluent_builders::CreateDataset) for more information about the
    /// operation and its arguments.
    pub fn create_dataset(&self) -> fluent_builders::CreateDataset<C, M, R> {
        fluent_builders::CreateDataset::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `CreateInferenceScheduler` operation.
    ///
    /// See [`CreateInferenceScheduler`](crate::client::fluent_builders::CreateInferenceScheduler) for more information about the
    /// operation and its arguments.
    pub fn create_inference_scheduler(&self) -> fluent_builders::CreateInferenceScheduler<C, M, R> {
        fluent_builders::CreateInferenceScheduler::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `CreateModel` operation.
    ///
    /// See [`CreateModel`](crate::client::fluent_builders::CreateModel) for more information about the
    /// operation and its arguments.
    pub fn create_model(&self) -> fluent_builders::CreateModel<C, M, R> {
        fluent_builders::CreateModel::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `DeleteDataset` operation.
    ///
    /// See [`DeleteDataset`](crate::client::fluent_builders::DeleteDataset) for more information about the
    /// operation and its arguments.
    pub fn delete_dataset(&self) -> fluent_builders::DeleteDataset<C, M, R> {
        fluent_builders::DeleteDataset::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `DeleteInferenceScheduler` operation.
    ///
    /// See [`DeleteInferenceScheduler`](crate::client::fluent_builders::DeleteInferenceScheduler) for more information about the
    /// operation and its arguments.
    pub fn delete_inference_scheduler(&self) -> fluent_builders::DeleteInferenceScheduler<C, M, R> {
        fluent_builders::DeleteInferenceScheduler::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `DeleteModel` operation.
    ///
    /// See [`DeleteModel`](crate::client::fluent_builders::DeleteModel) for more information about the
    /// operation and its arguments.
    pub fn delete_model(&self) -> fluent_builders::DeleteModel<C, M, R> {
        fluent_builders::DeleteModel::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `DescribeDataIngestionJob` operation.
    ///
    /// See [`DescribeDataIngestionJob`](crate::client::fluent_builders::DescribeDataIngestionJob) for more information about the
    /// operation and its arguments.
    pub fn describe_data_ingestion_job(
        &self,
    ) -> fluent_builders::DescribeDataIngestionJob<C, M, R> {
        fluent_builders::DescribeDataIngestionJob::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `DescribeDataset` operation.
    ///
    /// See [`DescribeDataset`](crate::client::fluent_builders::DescribeDataset) for more information about the
    /// operation and its arguments.
    pub fn describe_dataset(&self) -> fluent_builders::DescribeDataset<C, M, R> {
        fluent_builders::DescribeDataset::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `DescribeInferenceScheduler` operation.
    ///
    /// See [`DescribeInferenceScheduler`](crate::client::fluent_builders::DescribeInferenceScheduler) for more information about the
    /// operation and its arguments.
    pub fn describe_inference_scheduler(
        &self,
    ) -> fluent_builders::DescribeInferenceScheduler<C, M, R> {
        fluent_builders::DescribeInferenceScheduler::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `DescribeModel` operation.
    ///
    /// See [`DescribeModel`](crate::client::fluent_builders::DescribeModel) for more information about the
    /// operation and its arguments.
    pub fn describe_model(&self) -> fluent_builders::DescribeModel<C, M, R> {
        fluent_builders::DescribeModel::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `ListDataIngestionJobs` operation.
    ///
    /// See [`ListDataIngestionJobs`](crate::client::fluent_builders::ListDataIngestionJobs) for more information about the
    /// operation and its arguments.
    pub fn list_data_ingestion_jobs(&self) -> fluent_builders::ListDataIngestionJobs<C, M, R> {
        fluent_builders::ListDataIngestionJobs::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `ListDatasets` operation.
    ///
    /// See [`ListDatasets`](crate::client::fluent_builders::ListDatasets) for more information about the
    /// operation and its arguments.
    pub fn list_datasets(&self) -> fluent_builders::ListDatasets<C, M, R> {
        fluent_builders::ListDatasets::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `ListInferenceExecutions` operation.
    ///
    /// See [`ListInferenceExecutions`](crate::client::fluent_builders::ListInferenceExecutions) for more information about the
    /// operation and its arguments.
    pub fn list_inference_executions(&self) -> fluent_builders::ListInferenceExecutions<C, M, R> {
        fluent_builders::ListInferenceExecutions::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `ListInferenceSchedulers` operation.
    ///
    /// See [`ListInferenceSchedulers`](crate::client::fluent_builders::ListInferenceSchedulers) for more information about the
    /// operation and its arguments.
    pub fn list_inference_schedulers(&self) -> fluent_builders::ListInferenceSchedulers<C, M, R> {
        fluent_builders::ListInferenceSchedulers::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `ListModels` operation.
    ///
    /// See [`ListModels`](crate::client::fluent_builders::ListModels) for more information about the
    /// operation and its arguments.
    pub fn list_models(&self) -> fluent_builders::ListModels<C, M, R> {
        fluent_builders::ListModels::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `ListTagsForResource` operation.
    ///
    /// See [`ListTagsForResource`](crate::client::fluent_builders::ListTagsForResource) for more information about the
    /// operation and its arguments.
    pub fn list_tags_for_resource(&self) -> fluent_builders::ListTagsForResource<C, M, R> {
        fluent_builders::ListTagsForResource::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `StartDataIngestionJob` operation.
    ///
    /// See [`StartDataIngestionJob`](crate::client::fluent_builders::StartDataIngestionJob) for more information about the
    /// operation and its arguments.
    pub fn start_data_ingestion_job(&self) -> fluent_builders::StartDataIngestionJob<C, M, R> {
        fluent_builders::StartDataIngestionJob::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `StartInferenceScheduler` operation.
    ///
    /// See [`StartInferenceScheduler`](crate::client::fluent_builders::StartInferenceScheduler) for more information about the
    /// operation and its arguments.
    pub fn start_inference_scheduler(&self) -> fluent_builders::StartInferenceScheduler<C, M, R> {
        fluent_builders::StartInferenceScheduler::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `StopInferenceScheduler` operation.
    ///
    /// See [`StopInferenceScheduler`](crate::client::fluent_builders::StopInferenceScheduler) for more information about the
    /// operation and its arguments.
    pub fn stop_inference_scheduler(&self) -> fluent_builders::StopInferenceScheduler<C, M, R> {
        fluent_builders::StopInferenceScheduler::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `TagResource` operation.
    ///
    /// See [`TagResource`](crate::client::fluent_builders::TagResource) for more information about the
    /// operation and its arguments.
    pub fn tag_resource(&self) -> fluent_builders::TagResource<C, M, R> {
        fluent_builders::TagResource::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `UntagResource` operation.
    ///
    /// See [`UntagResource`](crate::client::fluent_builders::UntagResource) for more information about the
    /// operation and its arguments.
    pub fn untag_resource(&self) -> fluent_builders::UntagResource<C, M, R> {
        fluent_builders::UntagResource::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the `UpdateInferenceScheduler` operation.
    ///
    /// See [`UpdateInferenceScheduler`](crate::client::fluent_builders::UpdateInferenceScheduler) for more information about the
    /// operation and its arguments.
    pub fn update_inference_scheduler(&self) -> fluent_builders::UpdateInferenceScheduler<C, M, R> {
        fluent_builders::UpdateInferenceScheduler::new(self.handle.clone())
    }
}
pub mod fluent_builders {
    //!
    //! Utilities to ergonomically construct a request to the service.
    //!
    //! Fluent builders are created through the [`Client`](crate::client::Client) by calling
    //! one if its operation methods. After parameters are set using the builder methods,
    //! the `send` method can be called to initiate the request.
    //!
    /// Fluent builder constructing a request to `CreateDataset`.
    ///
    /// <p>Creates a container for a collection of data being ingested for analysis. The dataset
    /// contains the metadata describing where the data is and what the data actually looks like.
    /// In other words, it contains the location of the data source, the data schema, and other
    /// information. A dataset also contains any tags associated with the ingested data. </p>
    #[derive(std::fmt::Debug)]
    pub struct CreateDataset<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::create_dataset_input::Builder,
    }
    impl<C, M, R> CreateDataset<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `CreateDataset`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::CreateDatasetOutput,
            aws_smithy_http::result::SdkError<crate::error::CreateDatasetError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::CreateDatasetInputOperationOutputAlias,
                crate::output::CreateDatasetOutput,
                crate::error::CreateDatasetError,
                crate::input::CreateDatasetInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the dataset being created. </p>
        pub fn dataset_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(inp);
            self
        }
        /// <p>The name of the dataset being created. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
        /// <p>A JSON description of the data that is in each time series dataset, including names,
        /// column names, and data types. </p>
        pub fn dataset_schema(mut self, inp: crate::model::DatasetSchema) -> Self {
            self.inner = self.inner.dataset_schema(inp);
            self
        }
        /// <p>A JSON description of the data that is in each time series dataset, including names,
        /// column names, and data types. </p>
        pub fn set_dataset_schema(
            mut self,
            input: std::option::Option<crate::model::DatasetSchema>,
        ) -> Self {
            self.inner = self.inner.set_dataset_schema(input);
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.server_side_kms_key_id(inp);
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_server_side_kms_key_id(input);
            self
        }
        /// <p> A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn client_token(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.client_token(inp);
            self
        }
        /// <p> A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn set_client_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_client_token(input);
            self
        }
        /// Appends an item to `Tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p>Any tags associated with the ingested data described in the dataset. </p>
        pub fn tags(mut self, inp: impl Into<crate::model::Tag>) -> Self {
            self.inner = self.inner.tags(inp);
            self
        }
        /// <p>Any tags associated with the ingested data described in the dataset. </p>
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.inner = self.inner.set_tags(input);
            self
        }
    }
    /// Fluent builder constructing a request to `CreateInferenceScheduler`.
    ///
    /// <p> Creates a scheduled inference. Scheduling an inference is setting up a continuous
    /// real-time inference plan to analyze new measurement data. When setting up the schedule, you
    /// provide an S3 bucket location for the input data, assign it a delimiter between separate
    /// entries in the data, set an offset delay if desired, and set the frequency of inferencing.
    /// You must also provide an S3 bucket location for the output data. </p>
    #[derive(std::fmt::Debug)]
    pub struct CreateInferenceScheduler<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::create_inference_scheduler_input::Builder,
    }
    impl<C, M, R> CreateInferenceScheduler<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `CreateInferenceScheduler`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::CreateInferenceSchedulerOutput,
            aws_smithy_http::result::SdkError<crate::error::CreateInferenceSchedulerError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::CreateInferenceSchedulerInputOperationOutputAlias,
                crate::output::CreateInferenceSchedulerOutput,
                crate::error::CreateInferenceSchedulerError,
                crate::input::CreateInferenceSchedulerInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the previously trained ML model being used to create the inference
        /// scheduler. </p>
        pub fn model_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name(inp);
            self
        }
        /// <p>The name of the previously trained ML model being used to create the inference
        /// scheduler. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_model_name(input);
            self
        }
        /// <p>The name of the inference scheduler being created. </p>
        pub fn inference_scheduler_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(inp);
            self
        }
        /// <p>The name of the inference scheduler being created. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
        /// <p>A period of time (in minutes) by which inference on the data is delayed after the data
        /// starts. For instance, if you select an offset delay time of five minutes, inference will
        /// not begin on the data until the first data measurement after the five minute mark. For example, if
        /// five minutes is selected, the inference scheduler will wake up at the configured frequency with the
        /// additional five minute delay time to check the customer S3 bucket. The customer can upload data at
        /// the same frequency and they don't need to stop and restart the scheduler when uploading new data. </p>
        pub fn data_delay_offset_in_minutes(mut self, inp: i64) -> Self {
            self.inner = self.inner.data_delay_offset_in_minutes(inp);
            self
        }
        /// <p>A period of time (in minutes) by which inference on the data is delayed after the data
        /// starts. For instance, if you select an offset delay time of five minutes, inference will
        /// not begin on the data until the first data measurement after the five minute mark. For example, if
        /// five minutes is selected, the inference scheduler will wake up at the configured frequency with the
        /// additional five minute delay time to check the customer S3 bucket. The customer can upload data at
        /// the same frequency and they don't need to stop and restart the scheduler when uploading new data. </p>
        pub fn set_data_delay_offset_in_minutes(mut self, input: std::option::Option<i64>) -> Self {
            self.inner = self.inner.set_data_delay_offset_in_minutes(input);
            self
        }
        /// <p> How often data is uploaded to the source S3 bucket for the input data. The value chosen
        /// is the length of time between data uploads. For instance, if you select 5 minutes, Amazon
        /// Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency
        /// also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this
        /// example, it starts once every 5 minutes. </p>
        pub fn data_upload_frequency(mut self, inp: crate::model::DataUploadFrequency) -> Self {
            self.inner = self.inner.data_upload_frequency(inp);
            self
        }
        /// <p> How often data is uploaded to the source S3 bucket for the input data. The value chosen
        /// is the length of time between data uploads. For instance, if you select 5 minutes, Amazon
        /// Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency
        /// also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this
        /// example, it starts once every 5 minutes. </p>
        pub fn set_data_upload_frequency(
            mut self,
            input: std::option::Option<crate::model::DataUploadFrequency>,
        ) -> Self {
            self.inner = self.inner.set_data_upload_frequency(input);
            self
        }
        /// <p>Specifies configuration information for the input data for the inference scheduler,
        /// including delimiter, format, and dataset location. </p>
        pub fn data_input_configuration(
            mut self,
            inp: crate::model::InferenceInputConfiguration,
        ) -> Self {
            self.inner = self.inner.data_input_configuration(inp);
            self
        }
        /// <p>Specifies configuration information for the input data for the inference scheduler,
        /// including delimiter, format, and dataset location. </p>
        pub fn set_data_input_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceInputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_data_input_configuration(input);
            self
        }
        /// <p>Specifies configuration information for the output results for the inference scheduler,
        /// including the S3 location for the output. </p>
        pub fn data_output_configuration(
            mut self,
            inp: crate::model::InferenceOutputConfiguration,
        ) -> Self {
            self.inner = self.inner.data_output_configuration(inp);
            self
        }
        /// <p>Specifies configuration information for the output results for the inference scheduler,
        /// including the S3 location for the output. </p>
        pub fn set_data_output_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceOutputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_data_output_configuration(input);
            self
        }
        /// <p>The Amazon Resource Name (ARN) of a role with permission to access the data source being
        /// used for the inference. </p>
        pub fn role_arn(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.role_arn(inp);
            self
        }
        /// <p>The Amazon Resource Name (ARN) of a role with permission to access the data source being
        /// used for the inference. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_role_arn(input);
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.server_side_kms_key_id(inp);
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_server_side_kms_key_id(input);
            self
        }
        /// <p> A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn client_token(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.client_token(inp);
            self
        }
        /// <p> A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn set_client_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_client_token(input);
            self
        }
        /// Appends an item to `Tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p>Any tags associated with the inference scheduler. </p>
        pub fn tags(mut self, inp: impl Into<crate::model::Tag>) -> Self {
            self.inner = self.inner.tags(inp);
            self
        }
        /// <p>Any tags associated with the inference scheduler. </p>
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.inner = self.inner.set_tags(input);
            self
        }
    }
    /// Fluent builder constructing a request to `CreateModel`.
    ///
    /// <p>Creates an ML model for data inference. </p>
    /// <p>A machine-learning (ML) model is a mathematical model that finds patterns in your data.
    /// In Amazon Lookout for Equipment, the model learns the patterns of normal behavior and detects abnormal
    /// behavior that could be potential equipment failure (or maintenance events). The models are
    /// made by analyzing normal data and abnormalities in machine behavior that have already
    /// occurred.</p>
    /// <p>Your model is trained using a portion of the data from your dataset and uses that data
    /// to learn patterns of normal behavior and abnormal patterns that lead to equipment failure.
    /// Another portion of the data is used to evaluate the model's accuracy. </p>
    #[derive(std::fmt::Debug)]
    pub struct CreateModel<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::create_model_input::Builder,
    }
    impl<C, M, R> CreateModel<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `CreateModel`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::CreateModelOutput,
            aws_smithy_http::result::SdkError<crate::error::CreateModelError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::CreateModelInputOperationOutputAlias,
                crate::output::CreateModelOutput,
                crate::error::CreateModelError,
                crate::input::CreateModelInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name for the ML model to be created.</p>
        pub fn model_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name(inp);
            self
        }
        /// <p>The name for the ML model to be created.</p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_model_name(input);
            self
        }
        /// <p>The name of the dataset for the ML model being created. </p>
        pub fn dataset_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(inp);
            self
        }
        /// <p>The name of the dataset for the ML model being created. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
        /// <p>The data schema for the ML model being created. </p>
        pub fn dataset_schema(mut self, inp: crate::model::DatasetSchema) -> Self {
            self.inner = self.inner.dataset_schema(inp);
            self
        }
        /// <p>The data schema for the ML model being created. </p>
        pub fn set_dataset_schema(
            mut self,
            input: std::option::Option<crate::model::DatasetSchema>,
        ) -> Self {
            self.inner = self.inner.set_dataset_schema(input);
            self
        }
        /// <p>The input configuration for the labels being used for the ML model that's being created.
        /// </p>
        pub fn labels_input_configuration(
            mut self,
            inp: crate::model::LabelsInputConfiguration,
        ) -> Self {
            self.inner = self.inner.labels_input_configuration(inp);
            self
        }
        /// <p>The input configuration for the labels being used for the ML model that's being created.
        /// </p>
        pub fn set_labels_input_configuration(
            mut self,
            input: std::option::Option<crate::model::LabelsInputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_labels_input_configuration(input);
            self
        }
        /// <p>A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn client_token(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.client_token(inp);
            self
        }
        /// <p>A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn set_client_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_client_token(input);
            self
        }
        /// <p>Indicates the time reference in the dataset that should be used to begin the subset of
        /// training data for the ML model. </p>
        pub fn training_data_start_time(mut self, inp: aws_smithy_types::Instant) -> Self {
            self.inner = self.inner.training_data_start_time(inp);
            self
        }
        /// <p>Indicates the time reference in the dataset that should be used to begin the subset of
        /// training data for the ML model. </p>
        pub fn set_training_data_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_training_data_start_time(input);
            self
        }
        /// <p>Indicates the time reference in the dataset that should be used to end the subset of
        /// training data for the ML model. </p>
        pub fn training_data_end_time(mut self, inp: aws_smithy_types::Instant) -> Self {
            self.inner = self.inner.training_data_end_time(inp);
            self
        }
        /// <p>Indicates the time reference in the dataset that should be used to end the subset of
        /// training data for the ML model. </p>
        pub fn set_training_data_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_training_data_end_time(input);
            self
        }
        /// <p>Indicates the time reference in the dataset that should be used to begin the subset of
        /// evaluation data for the ML model. </p>
        pub fn evaluation_data_start_time(mut self, inp: aws_smithy_types::Instant) -> Self {
            self.inner = self.inner.evaluation_data_start_time(inp);
            self
        }
        /// <p>Indicates the time reference in the dataset that should be used to begin the subset of
        /// evaluation data for the ML model. </p>
        pub fn set_evaluation_data_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_evaluation_data_start_time(input);
            self
        }
        /// <p> Indicates the time reference in the dataset that should be used to end the subset of
        /// evaluation data for the ML model. </p>
        pub fn evaluation_data_end_time(mut self, inp: aws_smithy_types::Instant) -> Self {
            self.inner = self.inner.evaluation_data_end_time(inp);
            self
        }
        /// <p> Indicates the time reference in the dataset that should be used to end the subset of
        /// evaluation data for the ML model. </p>
        pub fn set_evaluation_data_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_evaluation_data_end_time(input);
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source
        /// being used to create the ML model. </p>
        pub fn role_arn(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.role_arn(inp);
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source
        /// being used to create the ML model. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_role_arn(input);
            self
        }
        /// <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of
        /// the data after post processing by
        /// Amazon Lookout for Equipment. For example, if you provide data that
        /// has been collected at a 1 second level and you want the system to resample
        /// the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p>
        /// <p>When providing a value for the <code>TargetSamplingRate</code>, you must
        /// attach the prefix "PT" to the rate you want.  The value for a 1 second rate
        /// is therefore <i>PT1S</i>, the value for a 15 minute rate
        /// is <i>PT15M</i>, and the value for a 1 hour rate
        /// is <i>PT1H</i>
        /// </p>
        pub fn data_pre_processing_configuration(
            mut self,
            inp: crate::model::DataPreProcessingConfiguration,
        ) -> Self {
            self.inner = self.inner.data_pre_processing_configuration(inp);
            self
        }
        /// <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of
        /// the data after post processing by
        /// Amazon Lookout for Equipment. For example, if you provide data that
        /// has been collected at a 1 second level and you want the system to resample
        /// the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p>
        /// <p>When providing a value for the <code>TargetSamplingRate</code>, you must
        /// attach the prefix "PT" to the rate you want.  The value for a 1 second rate
        /// is therefore <i>PT1S</i>, the value for a 15 minute rate
        /// is <i>PT15M</i>, and the value for a 1 hour rate
        /// is <i>PT1H</i>
        /// </p>
        pub fn set_data_pre_processing_configuration(
            mut self,
            input: std::option::Option<crate::model::DataPreProcessingConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_data_pre_processing_configuration(input);
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.server_side_kms_key_id(inp);
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_server_side_kms_key_id(input);
            self
        }
        /// Appends an item to `Tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p> Any tags associated with the ML model being created. </p>
        pub fn tags(mut self, inp: impl Into<crate::model::Tag>) -> Self {
            self.inner = self.inner.tags(inp);
            self
        }
        /// <p> Any tags associated with the ML model being created. </p>
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.inner = self.inner.set_tags(input);
            self
        }
        /// <p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>
        pub fn off_condition(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.off_condition(inp);
            self
        }
        /// <p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>
        pub fn set_off_condition(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_off_condition(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DeleteDataset`.
    ///
    /// <p> Deletes a dataset and associated artifacts. The operation will check to see if any
    /// inference scheduler or data ingestion job is currently using the dataset, and if there
    /// isn't, the dataset, its metadata, and any associated data stored in S3 will be deleted.
    /// This does not affect any models that used this dataset for training and evaluation, but
    /// does prevent it from being used in the future. </p>
    #[derive(std::fmt::Debug)]
    pub struct DeleteDataset<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::delete_dataset_input::Builder,
    }
    impl<C, M, R> DeleteDataset<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `DeleteDataset`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteDatasetOutput,
            aws_smithy_http::result::SdkError<crate::error::DeleteDatasetError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::DeleteDatasetInputOperationOutputAlias,
                crate::output::DeleteDatasetOutput,
                crate::error::DeleteDatasetError,
                crate::input::DeleteDatasetInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the dataset to be deleted. </p>
        pub fn dataset_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(inp);
            self
        }
        /// <p>The name of the dataset to be deleted. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DeleteInferenceScheduler`.
    ///
    /// <p>Deletes an inference scheduler that has been set up. Already processed output results
    /// are not affected. </p>
    #[derive(std::fmt::Debug)]
    pub struct DeleteInferenceScheduler<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::delete_inference_scheduler_input::Builder,
    }
    impl<C, M, R> DeleteInferenceScheduler<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `DeleteInferenceScheduler`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteInferenceSchedulerOutput,
            aws_smithy_http::result::SdkError<crate::error::DeleteInferenceSchedulerError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::DeleteInferenceSchedulerInputOperationOutputAlias,
                crate::output::DeleteInferenceSchedulerOutput,
                crate::error::DeleteInferenceSchedulerError,
                crate::input::DeleteInferenceSchedulerInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the inference scheduler to be deleted. </p>
        pub fn inference_scheduler_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(inp);
            self
        }
        /// <p>The name of the inference scheduler to be deleted. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DeleteModel`.
    ///
    /// <p>Deletes an ML model currently available for Amazon Lookout for Equipment. This will prevent it from
    /// being used with an inference scheduler, even one that is already set up. </p>
    #[derive(std::fmt::Debug)]
    pub struct DeleteModel<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::delete_model_input::Builder,
    }
    impl<C, M, R> DeleteModel<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `DeleteModel`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteModelOutput,
            aws_smithy_http::result::SdkError<crate::error::DeleteModelError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::DeleteModelInputOperationOutputAlias,
                crate::output::DeleteModelOutput,
                crate::error::DeleteModelError,
                crate::input::DeleteModelInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the ML model to be deleted. </p>
        pub fn model_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name(inp);
            self
        }
        /// <p>The name of the ML model to be deleted. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_model_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeDataIngestionJob`.
    ///
    /// <p>Provides information on a specific data ingestion job such as creation time, dataset
    /// ARN, status, and so on. </p>
    #[derive(std::fmt::Debug)]
    pub struct DescribeDataIngestionJob<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::describe_data_ingestion_job_input::Builder,
    }
    impl<C, M, R> DescribeDataIngestionJob<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `DescribeDataIngestionJob`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeDataIngestionJobOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeDataIngestionJobError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::DescribeDataIngestionJobInputOperationOutputAlias,
                crate::output::DescribeDataIngestionJobOutput,
                crate::error::DescribeDataIngestionJobError,
                crate::input::DescribeDataIngestionJobInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The job ID of the data ingestion job. </p>
        pub fn job_id(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.job_id(inp);
            self
        }
        /// <p>The job ID of the data ingestion job. </p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_job_id(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeDataset`.
    ///
    /// <p>Provides a JSON description of the data that is in each time series dataset, including names, column names, and data types.</p>
    #[derive(std::fmt::Debug)]
    pub struct DescribeDataset<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::describe_dataset_input::Builder,
    }
    impl<C, M, R> DescribeDataset<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `DescribeDataset`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeDatasetOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeDatasetError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::DescribeDatasetInputOperationOutputAlias,
                crate::output::DescribeDatasetOutput,
                crate::error::DescribeDatasetError,
                crate::input::DescribeDatasetInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the dataset to be described. </p>
        pub fn dataset_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(inp);
            self
        }
        /// <p>The name of the dataset to be described. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeInferenceScheduler`.
    ///
    /// <p> Specifies information about the inference scheduler being used, including name, model,
    /// status, and associated metadata </p>
    #[derive(std::fmt::Debug)]
    pub struct DescribeInferenceScheduler<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::describe_inference_scheduler_input::Builder,
    }
    impl<C, M, R> DescribeInferenceScheduler<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `DescribeInferenceScheduler`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeInferenceSchedulerOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeInferenceSchedulerError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::DescribeInferenceSchedulerInputOperationOutputAlias,
                crate::output::DescribeInferenceSchedulerOutput,
                crate::error::DescribeInferenceSchedulerError,
                crate::input::DescribeInferenceSchedulerInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the inference scheduler being described. </p>
        pub fn inference_scheduler_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(inp);
            self
        }
        /// <p>The name of the inference scheduler being described. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeModel`.
    ///
    /// <p>Provides a JSON containing the overall information about a specific ML model, including model name and ARN,
    /// dataset, training and evaluation information, status, and so on. </p>
    #[derive(std::fmt::Debug)]
    pub struct DescribeModel<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::describe_model_input::Builder,
    }
    impl<C, M, R> DescribeModel<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `DescribeModel`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeModelOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeModelError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::DescribeModelInputOperationOutputAlias,
                crate::output::DescribeModelOutput,
                crate::error::DescribeModelError,
                crate::input::DescribeModelInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the ML model to be described. </p>
        pub fn model_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name(inp);
            self
        }
        /// <p>The name of the ML model to be described. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_model_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `ListDataIngestionJobs`.
    ///
    /// <p>Provides a list of all data ingestion jobs, including dataset name and ARN, S3 location
    /// of the input data, status, and so on. </p>
    #[derive(std::fmt::Debug)]
    pub struct ListDataIngestionJobs<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::list_data_ingestion_jobs_input::Builder,
    }
    impl<C, M, R> ListDataIngestionJobs<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `ListDataIngestionJobs`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListDataIngestionJobsOutput,
            aws_smithy_http::result::SdkError<crate::error::ListDataIngestionJobsError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::ListDataIngestionJobsInputOperationOutputAlias,
                crate::output::ListDataIngestionJobsOutput,
                crate::error::ListDataIngestionJobsError,
                crate::input::ListDataIngestionJobsInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the dataset being used for the data ingestion job. </p>
        pub fn dataset_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(inp);
            self
        }
        /// <p>The name of the dataset being used for the data ingestion job. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of data ingestion
        /// jobs. </p>
        pub fn next_token(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(inp);
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of data ingestion
        /// jobs. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p> Specifies the maximum number of data ingestion jobs to list. </p>
        pub fn max_results(mut self, inp: i32) -> Self {
            self.inner = self.inner.max_results(inp);
            self
        }
        /// <p> Specifies the maximum number of data ingestion jobs to list. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_results(input);
            self
        }
        /// <p>Indicates the status of the data ingestion job. </p>
        pub fn status(mut self, inp: crate::model::IngestionJobStatus) -> Self {
            self.inner = self.inner.status(inp);
            self
        }
        /// <p>Indicates the status of the data ingestion job. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::IngestionJobStatus>,
        ) -> Self {
            self.inner = self.inner.set_status(input);
            self
        }
    }
    /// Fluent builder constructing a request to `ListDatasets`.
    ///
    /// <p>Lists all datasets currently available in your account, filtering on the dataset name.
    /// </p>
    #[derive(std::fmt::Debug)]
    pub struct ListDatasets<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::list_datasets_input::Builder,
    }
    impl<C, M, R> ListDatasets<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `ListDatasets`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListDatasetsOutput,
            aws_smithy_http::result::SdkError<crate::error::ListDatasetsError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::ListDatasetsInputOperationOutputAlias,
                crate::output::ListDatasetsOutput,
                crate::error::ListDatasetsError,
                crate::input::ListDatasetsInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p> An opaque pagination token indicating where to continue the listing of datasets.
        /// </p>
        pub fn next_token(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(inp);
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of datasets.
        /// </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p> Specifies the maximum number of datasets to list. </p>
        pub fn max_results(mut self, inp: i32) -> Self {
            self.inner = self.inner.max_results(inp);
            self
        }
        /// <p> Specifies the maximum number of datasets to list. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_results(input);
            self
        }
        /// <p>The beginning of the name of the datasets to be listed. </p>
        pub fn dataset_name_begins_with(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name_begins_with(inp);
            self
        }
        /// <p>The beginning of the name of the datasets to be listed. </p>
        pub fn set_dataset_name_begins_with(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_dataset_name_begins_with(input);
            self
        }
    }
    /// Fluent builder constructing a request to `ListInferenceExecutions`.
    ///
    /// <p> Lists all inference executions that have been performed by the specified inference
    /// scheduler. </p>
    #[derive(std::fmt::Debug)]
    pub struct ListInferenceExecutions<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::list_inference_executions_input::Builder,
    }
    impl<C, M, R> ListInferenceExecutions<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `ListInferenceExecutions`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListInferenceExecutionsOutput,
            aws_smithy_http::result::SdkError<crate::error::ListInferenceExecutionsError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::ListInferenceExecutionsInputOperationOutputAlias,
                crate::output::ListInferenceExecutionsOutput,
                crate::error::ListInferenceExecutionsError,
                crate::input::ListInferenceExecutionsInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>An opaque pagination token indicating where to continue the listing of inference
        /// executions.</p>
        pub fn next_token(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(inp);
            self
        }
        /// <p>An opaque pagination token indicating where to continue the listing of inference
        /// executions.</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>Specifies the maximum number of inference executions to list. </p>
        pub fn max_results(mut self, inp: i32) -> Self {
            self.inner = self.inner.max_results(inp);
            self
        }
        /// <p>Specifies the maximum number of inference executions to list. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_results(input);
            self
        }
        /// <p>The name of the inference scheduler for the inference execution listed. </p>
        pub fn inference_scheduler_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(inp);
            self
        }
        /// <p>The name of the inference scheduler for the inference execution listed. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
        /// <p>The time reference in the inferenced dataset after which Amazon Lookout for Equipment started the
        /// inference execution. </p>
        pub fn data_start_time_after(mut self, inp: aws_smithy_types::Instant) -> Self {
            self.inner = self.inner.data_start_time_after(inp);
            self
        }
        /// <p>The time reference in the inferenced dataset after which Amazon Lookout for Equipment started the
        /// inference execution. </p>
        pub fn set_data_start_time_after(
            mut self,
            input: std::option::Option<aws_smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_data_start_time_after(input);
            self
        }
        /// <p>The time reference in the inferenced dataset before which Amazon Lookout for Equipment stopped the
        /// inference execution. </p>
        pub fn data_end_time_before(mut self, inp: aws_smithy_types::Instant) -> Self {
            self.inner = self.inner.data_end_time_before(inp);
            self
        }
        /// <p>The time reference in the inferenced dataset before which Amazon Lookout for Equipment stopped the
        /// inference execution. </p>
        pub fn set_data_end_time_before(
            mut self,
            input: std::option::Option<aws_smithy_types::Instant>,
        ) -> Self {
            self.inner = self.inner.set_data_end_time_before(input);
            self
        }
        /// <p>The status of the inference execution. </p>
        pub fn status(mut self, inp: crate::model::InferenceExecutionStatus) -> Self {
            self.inner = self.inner.status(inp);
            self
        }
        /// <p>The status of the inference execution. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::InferenceExecutionStatus>,
        ) -> Self {
            self.inner = self.inner.set_status(input);
            self
        }
    }
    /// Fluent builder constructing a request to `ListInferenceSchedulers`.
    ///
    /// <p>Retrieves a list of all inference schedulers currently available for your account.
    /// </p>
    #[derive(std::fmt::Debug)]
    pub struct ListInferenceSchedulers<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::list_inference_schedulers_input::Builder,
    }
    impl<C, M, R> ListInferenceSchedulers<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `ListInferenceSchedulers`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListInferenceSchedulersOutput,
            aws_smithy_http::result::SdkError<crate::error::ListInferenceSchedulersError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::ListInferenceSchedulersInputOperationOutputAlias,
                crate::output::ListInferenceSchedulersOutput,
                crate::error::ListInferenceSchedulersError,
                crate::input::ListInferenceSchedulersInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p> An opaque pagination token indicating where to continue the listing of inference
        /// schedulers. </p>
        pub fn next_token(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(inp);
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of inference
        /// schedulers. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p> Specifies the maximum number of inference schedulers to list. </p>
        pub fn max_results(mut self, inp: i32) -> Self {
            self.inner = self.inner.max_results(inp);
            self
        }
        /// <p> Specifies the maximum number of inference schedulers to list. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_results(input);
            self
        }
        /// <p>The beginning of the name of the inference schedulers to be listed. </p>
        pub fn inference_scheduler_name_begins_with(
            mut self,
            inp: impl Into<std::string::String>,
        ) -> Self {
            self.inner = self.inner.inference_scheduler_name_begins_with(inp);
            self
        }
        /// <p>The beginning of the name of the inference schedulers to be listed. </p>
        pub fn set_inference_scheduler_name_begins_with(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name_begins_with(input);
            self
        }
        /// <p>The name of the ML model used by the inference scheduler to be listed. </p>
        pub fn model_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name(inp);
            self
        }
        /// <p>The name of the ML model used by the inference scheduler to be listed. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_model_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `ListModels`.
    ///
    /// <p>Generates a list of all models in the account, including model name and ARN, dataset,
    /// and status. </p>
    #[derive(std::fmt::Debug)]
    pub struct ListModels<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::list_models_input::Builder,
    }
    impl<C, M, R> ListModels<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `ListModels`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListModelsOutput,
            aws_smithy_http::result::SdkError<crate::error::ListModelsError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::ListModelsInputOperationOutputAlias,
                crate::output::ListModelsOutput,
                crate::error::ListModelsError,
                crate::input::ListModelsInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p> An opaque pagination token indicating where to continue the listing of ML models.
        /// </p>
        pub fn next_token(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(inp);
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of ML models.
        /// </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p> Specifies the maximum number of ML models to list. </p>
        pub fn max_results(mut self, inp: i32) -> Self {
            self.inner = self.inner.max_results(inp);
            self
        }
        /// <p> Specifies the maximum number of ML models to list. </p>
        pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_results(input);
            self
        }
        /// <p>The status of the ML model. </p>
        pub fn status(mut self, inp: crate::model::ModelStatus) -> Self {
            self.inner = self.inner.status(inp);
            self
        }
        /// <p>The status of the ML model. </p>
        pub fn set_status(mut self, input: std::option::Option<crate::model::ModelStatus>) -> Self {
            self.inner = self.inner.set_status(input);
            self
        }
        /// <p>The beginning of the name of the ML models being listed. </p>
        pub fn model_name_begins_with(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.model_name_begins_with(inp);
            self
        }
        /// <p>The beginning of the name of the ML models being listed. </p>
        pub fn set_model_name_begins_with(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_model_name_begins_with(input);
            self
        }
        /// <p>The beginning of the name of the dataset of the ML models to be listed. </p>
        pub fn dataset_name_begins_with(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name_begins_with(inp);
            self
        }
        /// <p>The beginning of the name of the dataset of the ML models to be listed. </p>
        pub fn set_dataset_name_begins_with(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_dataset_name_begins_with(input);
            self
        }
    }
    /// Fluent builder constructing a request to `ListTagsForResource`.
    ///
    /// <p>Lists all the tags for a specified resource, including key and value. </p>
    #[derive(std::fmt::Debug)]
    pub struct ListTagsForResource<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::list_tags_for_resource_input::Builder,
    }
    impl<C, M, R> ListTagsForResource<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `ListTagsForResource`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ListTagsForResourceOutput,
            aws_smithy_http::result::SdkError<crate::error::ListTagsForResourceError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::ListTagsForResourceInputOperationOutputAlias,
                crate::output::ListTagsForResourceOutput,
                crate::error::ListTagsForResourceError,
                crate::input::ListTagsForResourceInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The Amazon Resource Name (ARN) of the resource (such as the dataset or model) that is
        /// the focus of the <code>ListTagsForResource</code> operation. </p>
        pub fn resource_arn(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.resource_arn(inp);
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the resource (such as the dataset or model) that is
        /// the focus of the <code>ListTagsForResource</code> operation. </p>
        pub fn set_resource_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_resource_arn(input);
            self
        }
    }
    /// Fluent builder constructing a request to `StartDataIngestionJob`.
    ///
    /// <p>Starts a data ingestion job. Amazon Lookout for Equipment returns the job status. </p>
    #[derive(std::fmt::Debug)]
    pub struct StartDataIngestionJob<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::start_data_ingestion_job_input::Builder,
    }
    impl<C, M, R> StartDataIngestionJob<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `StartDataIngestionJob`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::StartDataIngestionJobOutput,
            aws_smithy_http::result::SdkError<crate::error::StartDataIngestionJobError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::StartDataIngestionJobInputOperationOutputAlias,
                crate::output::StartDataIngestionJobOutput,
                crate::error::StartDataIngestionJobError,
                crate::input::StartDataIngestionJobInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the dataset being used by the data ingestion job. </p>
        pub fn dataset_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.dataset_name(inp);
            self
        }
        /// <p>The name of the dataset being used by the data ingestion job. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_dataset_name(input);
            self
        }
        /// <p> Specifies information for the input data for the data ingestion job, including dataset
        /// S3 location. </p>
        pub fn ingestion_input_configuration(
            mut self,
            inp: crate::model::IngestionInputConfiguration,
        ) -> Self {
            self.inner = self.inner.ingestion_input_configuration(inp);
            self
        }
        /// <p> Specifies information for the input data for the data ingestion job, including dataset
        /// S3 location. </p>
        pub fn set_ingestion_input_configuration(
            mut self,
            input: std::option::Option<crate::model::IngestionInputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_ingestion_input_configuration(input);
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for
        /// the data ingestion job. </p>
        pub fn role_arn(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.role_arn(inp);
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for
        /// the data ingestion job. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_role_arn(input);
            self
        }
        /// <p> A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn client_token(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.client_token(inp);
            self
        }
        /// <p> A unique identifier for the request. If you do not set the client request token, Amazon
        /// Lookout for Equipment generates one. </p>
        pub fn set_client_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_client_token(input);
            self
        }
    }
    /// Fluent builder constructing a request to `StartInferenceScheduler`.
    ///
    /// <p>Starts an inference scheduler. </p>
    #[derive(std::fmt::Debug)]
    pub struct StartInferenceScheduler<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::start_inference_scheduler_input::Builder,
    }
    impl<C, M, R> StartInferenceScheduler<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `StartInferenceScheduler`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::StartInferenceSchedulerOutput,
            aws_smithy_http::result::SdkError<crate::error::StartInferenceSchedulerError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::StartInferenceSchedulerInputOperationOutputAlias,
                crate::output::StartInferenceSchedulerOutput,
                crate::error::StartInferenceSchedulerError,
                crate::input::StartInferenceSchedulerInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the inference scheduler to be started. </p>
        pub fn inference_scheduler_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(inp);
            self
        }
        /// <p>The name of the inference scheduler to be started. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `StopInferenceScheduler`.
    ///
    /// <p>Stops an inference scheduler. </p>
    #[derive(std::fmt::Debug)]
    pub struct StopInferenceScheduler<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::stop_inference_scheduler_input::Builder,
    }
    impl<C, M, R> StopInferenceScheduler<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `StopInferenceScheduler`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::StopInferenceSchedulerOutput,
            aws_smithy_http::result::SdkError<crate::error::StopInferenceSchedulerError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::StopInferenceSchedulerInputOperationOutputAlias,
                crate::output::StopInferenceSchedulerOutput,
                crate::error::StopInferenceSchedulerError,
                crate::input::StopInferenceSchedulerInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the inference scheduler to be stopped. </p>
        pub fn inference_scheduler_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(inp);
            self
        }
        /// <p>The name of the inference scheduler to be stopped. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `TagResource`.
    ///
    /// <p>Associates a given tag to a resource in your account. A tag is a key-value pair which
    /// can be added to an Amazon Lookout for Equipment resource as metadata. Tags can be used for organizing your
    /// resources as well as helping you to search and filter by tag. Multiple tags can be added to
    /// a resource, either when you create it, or later. Up to 50 tags can be associated with each
    /// resource. </p>
    #[derive(std::fmt::Debug)]
    pub struct TagResource<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::tag_resource_input::Builder,
    }
    impl<C, M, R> TagResource<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `TagResource`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::TagResourceOutput,
            aws_smithy_http::result::SdkError<crate::error::TagResourceError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::TagResourceInputOperationOutputAlias,
                crate::output::TagResourceOutput,
                crate::error::TagResourceError,
                crate::input::TagResourceInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The Amazon Resource Name (ARN) of the specific resource to which the tag should be
        /// associated. </p>
        pub fn resource_arn(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.resource_arn(inp);
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the specific resource to which the tag should be
        /// associated. </p>
        pub fn set_resource_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_resource_arn(input);
            self
        }
        /// Appends an item to `Tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p>The tag or tags to be associated with a specific resource. Both the tag key and value
        /// are specified. </p>
        pub fn tags(mut self, inp: impl Into<crate::model::Tag>) -> Self {
            self.inner = self.inner.tags(inp);
            self
        }
        /// <p>The tag or tags to be associated with a specific resource. Both the tag key and value
        /// are specified. </p>
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.inner = self.inner.set_tags(input);
            self
        }
    }
    /// Fluent builder constructing a request to `UntagResource`.
    ///
    /// <p>Removes a specific tag from a given resource. The tag is specified by its key. </p>
    #[derive(std::fmt::Debug)]
    pub struct UntagResource<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::untag_resource_input::Builder,
    }
    impl<C, M, R> UntagResource<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `UntagResource`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::UntagResourceOutput,
            aws_smithy_http::result::SdkError<crate::error::UntagResourceError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::UntagResourceInputOperationOutputAlias,
                crate::output::UntagResourceOutput,
                crate::error::UntagResourceError,
                crate::input::UntagResourceInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The Amazon Resource Name (ARN) of the resource to which the tag is currently associated.
        /// </p>
        pub fn resource_arn(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.resource_arn(inp);
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the resource to which the tag is currently associated.
        /// </p>
        pub fn set_resource_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_resource_arn(input);
            self
        }
        /// Appends an item to `TagKeys`.
        ///
        /// To override the contents of this collection use [`set_tag_keys`](Self::set_tag_keys).
        ///
        /// <p>Specifies the key of the tag to be removed from a specified resource. </p>
        pub fn tag_keys(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.tag_keys(inp);
            self
        }
        /// <p>Specifies the key of the tag to be removed from a specified resource. </p>
        pub fn set_tag_keys(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_tag_keys(input);
            self
        }
    }
    /// Fluent builder constructing a request to `UpdateInferenceScheduler`.
    ///
    /// <p>Updates an inference scheduler. </p>
    #[derive(std::fmt::Debug)]
    pub struct UpdateInferenceScheduler<
        C = aws_smithy_client::erase::DynConnector,
        M = aws_hyper::AwsMiddleware,
        R = aws_smithy_client::retry::Standard,
    > {
        handle: std::sync::Arc<super::Handle<C, M, R>>,
        inner: crate::input::update_inference_scheduler_input::Builder,
    }
    impl<C, M, R> UpdateInferenceScheduler<C, M, R>
    where
        C: aws_smithy_client::bounds::SmithyConnector,
        M: aws_smithy_client::bounds::SmithyMiddleware<C>,
        R: aws_smithy_client::retry::NewRequestPolicy,
    {
        /// Creates a new `UpdateInferenceScheduler`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle<C, M, R>>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::UpdateInferenceSchedulerOutput,
            aws_smithy_http::result::SdkError<crate::error::UpdateInferenceSchedulerError>,
        >
        where
            R::Policy: aws_smithy_client::bounds::SmithyRetryPolicy<
                crate::input::UpdateInferenceSchedulerInputOperationOutputAlias,
                crate::output::UpdateInferenceSchedulerOutput,
                crate::error::UpdateInferenceSchedulerError,
                crate::input::UpdateInferenceSchedulerInputOperationRetryAlias,
            >,
        {
            let input = self.inner.build().map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
            let op = input
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the inference scheduler to be updated. </p>
        pub fn inference_scheduler_name(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.inference_scheduler_name(inp);
            self
        }
        /// <p>The name of the inference scheduler to be updated. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_inference_scheduler_name(input);
            self
        }
        /// <p> A period of time (in minutes) by which inference on the data is delayed after the data
        /// starts. For instance, if you select an offset delay time of five minutes, inference will
        /// not begin on the data until the first data measurement after the five minute mark. For example, if
        /// five minutes is selected, the inference scheduler will wake up at the configured frequency with the
        /// additional five minute delay time to check the customer S3 bucket. The customer can upload data at
        /// the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>
        pub fn data_delay_offset_in_minutes(mut self, inp: i64) -> Self {
            self.inner = self.inner.data_delay_offset_in_minutes(inp);
            self
        }
        /// <p> A period of time (in minutes) by which inference on the data is delayed after the data
        /// starts. For instance, if you select an offset delay time of five minutes, inference will
        /// not begin on the data until the first data measurement after the five minute mark. For example, if
        /// five minutes is selected, the inference scheduler will wake up at the configured frequency with the
        /// additional five minute delay time to check the customer S3 bucket. The customer can upload data at
        /// the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>
        pub fn set_data_delay_offset_in_minutes(mut self, input: std::option::Option<i64>) -> Self {
            self.inner = self.inner.set_data_delay_offset_in_minutes(input);
            self
        }
        /// <p>How often data is uploaded to the source S3 bucket for the input data. The value chosen
        /// is the length of time between data uploads. For instance, if you select 5 minutes, Amazon
        /// Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency
        /// also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this
        /// example, it starts once every 5 minutes. </p>
        pub fn data_upload_frequency(mut self, inp: crate::model::DataUploadFrequency) -> Self {
            self.inner = self.inner.data_upload_frequency(inp);
            self
        }
        /// <p>How often data is uploaded to the source S3 bucket for the input data. The value chosen
        /// is the length of time between data uploads. For instance, if you select 5 minutes, Amazon
        /// Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency
        /// also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this
        /// example, it starts once every 5 minutes. </p>
        pub fn set_data_upload_frequency(
            mut self,
            input: std::option::Option<crate::model::DataUploadFrequency>,
        ) -> Self {
            self.inner = self.inner.set_data_upload_frequency(input);
            self
        }
        /// <p> Specifies information for the input data for the inference scheduler, including
        /// delimiter, format, and dataset location. </p>
        pub fn data_input_configuration(
            mut self,
            inp: crate::model::InferenceInputConfiguration,
        ) -> Self {
            self.inner = self.inner.data_input_configuration(inp);
            self
        }
        /// <p> Specifies information for the input data for the inference scheduler, including
        /// delimiter, format, and dataset location. </p>
        pub fn set_data_input_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceInputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_data_input_configuration(input);
            self
        }
        /// <p> Specifies information for the output results from the inference scheduler, including the output S3 location. </p>
        pub fn data_output_configuration(
            mut self,
            inp: crate::model::InferenceOutputConfiguration,
        ) -> Self {
            self.inner = self.inner.data_output_configuration(inp);
            self
        }
        /// <p> Specifies information for the output results from the inference scheduler, including the output S3 location. </p>
        pub fn set_data_output_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceOutputConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_data_output_configuration(input);
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for
        /// the inference scheduler. </p>
        pub fn role_arn(mut self, inp: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.role_arn(inp);
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for
        /// the inference scheduler. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_role_arn(input);
            self
        }
    }
}
impl<C> Client<C, aws_hyper::AwsMiddleware, aws_smithy_client::retry::Standard> {
    /// Creates a client with the given service config and connector override.
    pub fn from_conf_conn(conf: crate::Config, conn: C) -> Self {
        let retry_config = conf.retry_config.as_ref().cloned().unwrap_or_default();
        let client = aws_hyper::Client::new(conn).with_retry_config(retry_config.into());
        Self {
            handle: std::sync::Arc::new(Handle { client, conf }),
        }
    }
}
impl
    Client<
        aws_smithy_client::erase::DynConnector,
        aws_hyper::AwsMiddleware,
        aws_smithy_client::retry::Standard,
    >
{
    /// Creates a new client from a shared config.
    #[cfg(any(feature = "rustls", feature = "native-tls"))]
    pub fn new(config: &aws_types::config::Config) -> Self {
        Self::from_conf(config.into())
    }

    /// Creates a new client from the service [`Config`](crate::Config).
    #[cfg(any(feature = "rustls", feature = "native-tls"))]
    pub fn from_conf(conf: crate::Config) -> Self {
        let retry_config = conf.retry_config.as_ref().cloned().unwrap_or_default();
        let client = aws_hyper::Client::https().with_retry_config(retry_config.into());
        Self {
            handle: std::sync::Arc::new(Handle { client, conf }),
        }
    }
}
