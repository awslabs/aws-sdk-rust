// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListInferenceSchedulersInput {
    /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p> Specifies the maximum number of inference schedulers to list. </p>
    #[doc(hidden)]
    pub max_results: std::option::Option<i32>,
    /// <p>The beginning of the name of the inference schedulers to be listed. </p>
    #[doc(hidden)]
    pub inference_scheduler_name_begins_with: std::option::Option<std::string::String>,
    /// <p>The name of the ML model used by the inference scheduler to be listed. </p>
    #[doc(hidden)]
    pub model_name: std::option::Option<std::string::String>,
    /// <p>Specifies the current status of the inference schedulers to list.</p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::types::InferenceSchedulerStatus>,
}
impl ListInferenceSchedulersInput {
    /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p> Specifies the maximum number of inference schedulers to list. </p>
    pub fn max_results(&self) -> std::option::Option<i32> {
        self.max_results
    }
    /// <p>The beginning of the name of the inference schedulers to be listed. </p>
    pub fn inference_scheduler_name_begins_with(&self) -> std::option::Option<&str> {
        self.inference_scheduler_name_begins_with.as_deref()
    }
    /// <p>The name of the ML model used by the inference scheduler to be listed. </p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>Specifies the current status of the inference schedulers to list.</p>
    pub fn status(&self) -> std::option::Option<&crate::types::InferenceSchedulerStatus> {
        self.status.as_ref()
    }
}
impl ListInferenceSchedulersInput {
    /// Creates a new builder-style object to manufacture [`ListInferenceSchedulersInput`](crate::operation::list_inference_schedulers::ListInferenceSchedulersInput).
    pub fn builder(
    ) -> crate::operation::list_inference_schedulers::builders::ListInferenceSchedulersInputBuilder
    {
        crate::operation::list_inference_schedulers::builders::ListInferenceSchedulersInputBuilder::default()
    }
}

/// A builder for [`ListInferenceSchedulersInput`](crate::operation::list_inference_schedulers::ListInferenceSchedulersInput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct ListInferenceSchedulersInputBuilder {
    pub(crate) next_token: std::option::Option<std::string::String>,
    pub(crate) max_results: std::option::Option<i32>,
    pub(crate) inference_scheduler_name_begins_with: std::option::Option<std::string::String>,
    pub(crate) model_name: std::option::Option<std::string::String>,
    pub(crate) status: std::option::Option<crate::types::InferenceSchedulerStatus>,
}
impl ListInferenceSchedulersInputBuilder {
    /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
    pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
        self.next_token = Some(input.into());
        self
    }
    /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
    pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.next_token = input;
        self
    }
    /// <p> Specifies the maximum number of inference schedulers to list. </p>
    pub fn max_results(mut self, input: i32) -> Self {
        self.max_results = Some(input);
        self
    }
    /// <p> Specifies the maximum number of inference schedulers to list. </p>
    pub fn set_max_results(mut self, input: std::option::Option<i32>) -> Self {
        self.max_results = input;
        self
    }
    /// <p>The beginning of the name of the inference schedulers to be listed. </p>
    pub fn inference_scheduler_name_begins_with(
        mut self,
        input: impl Into<std::string::String>,
    ) -> Self {
        self.inference_scheduler_name_begins_with = Some(input.into());
        self
    }
    /// <p>The beginning of the name of the inference schedulers to be listed. </p>
    pub fn set_inference_scheduler_name_begins_with(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.inference_scheduler_name_begins_with = input;
        self
    }
    /// <p>The name of the ML model used by the inference scheduler to be listed. </p>
    pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.model_name = Some(input.into());
        self
    }
    /// <p>The name of the ML model used by the inference scheduler to be listed. </p>
    pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.model_name = input;
        self
    }
    /// <p>Specifies the current status of the inference schedulers to list.</p>
    pub fn status(mut self, input: crate::types::InferenceSchedulerStatus) -> Self {
        self.status = Some(input);
        self
    }
    /// <p>Specifies the current status of the inference schedulers to list.</p>
    pub fn set_status(
        mut self,
        input: std::option::Option<crate::types::InferenceSchedulerStatus>,
    ) -> Self {
        self.status = input;
        self
    }
    /// Consumes the builder and constructs a [`ListInferenceSchedulersInput`](crate::operation::list_inference_schedulers::ListInferenceSchedulersInput).
    pub fn build(
        self,
    ) -> Result<
        crate::operation::list_inference_schedulers::ListInferenceSchedulersInput,
        aws_smithy_http::operation::error::BuildError,
    > {
        Ok(
            crate::operation::list_inference_schedulers::ListInferenceSchedulersInput {
                next_token: self.next_token,
                max_results: self.max_results,
                inference_scheduler_name_begins_with: self.inference_scheduler_name_begins_with,
                model_name: self.model_name,
                status: self.status,
            },
        )
    }
}
