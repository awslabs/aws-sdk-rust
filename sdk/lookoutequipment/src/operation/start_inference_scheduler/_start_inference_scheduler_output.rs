// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartInferenceSchedulerOutput  {
    /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
    #[doc(hidden)]
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>The name of the ML model being used by the inference scheduler. </p>
    #[doc(hidden)]
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The name of the inference scheduler being started. </p>
    #[doc(hidden)]
    pub inference_scheduler_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
    #[doc(hidden)]
    pub inference_scheduler_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the inference scheduler. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::types::InferenceSchedulerStatus>,
    _request_id: Option<String>,
}
impl StartInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
    pub fn model_arn(&self) -> std::option::Option<& str> {
        self.model_arn.as_deref()
    }
    /// <p>The name of the ML model being used by the inference scheduler. </p>
    pub fn model_name(&self) -> std::option::Option<& str> {
        self.model_name.as_deref()
    }
    /// <p>The name of the inference scheduler being started. </p>
    pub fn inference_scheduler_name(&self) -> std::option::Option<& str> {
        self.inference_scheduler_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
    pub fn inference_scheduler_arn(&self) -> std::option::Option<& str> {
        self.inference_scheduler_arn.as_deref()
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn status(&self) -> std::option::Option<& crate::types::InferenceSchedulerStatus> {
        self.status.as_ref()
    }
}
impl aws_http::request_id::RequestId for StartInferenceSchedulerOutput {
                                fn request_id(&self) -> Option<&str> {
                                    self._request_id.as_deref()
                                }
                            }
impl StartInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`StartInferenceSchedulerOutput`](crate::operation::start_inference_scheduler::StartInferenceSchedulerOutput).
    pub fn builder() -> crate::operation::start_inference_scheduler::builders::StartInferenceSchedulerOutputBuilder {
        crate::operation::start_inference_scheduler::builders::StartInferenceSchedulerOutputBuilder::default()
    }
}

/// A builder for [`StartInferenceSchedulerOutput`](crate::operation::start_inference_scheduler::StartInferenceSchedulerOutput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct StartInferenceSchedulerOutputBuilder {
    pub(crate) model_arn: std::option::Option<std::string::String>,
    pub(crate) model_name: std::option::Option<std::string::String>,
    pub(crate) inference_scheduler_name: std::option::Option<std::string::String>,
    pub(crate) inference_scheduler_arn: std::option::Option<std::string::String>,
    pub(crate) status: std::option::Option<crate::types::InferenceSchedulerStatus>,
    _request_id: Option<String>,
}
impl StartInferenceSchedulerOutputBuilder {
    /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
    pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.model_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
    pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.model_arn = input; self
    }
    /// <p>The name of the ML model being used by the inference scheduler. </p>
    pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.model_name = Some(input.into());
        self
    }
    /// <p>The name of the ML model being used by the inference scheduler. </p>
    pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.model_name = input; self
    }
    /// <p>The name of the inference scheduler being started. </p>
    pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.inference_scheduler_name = Some(input.into());
        self
    }
    /// <p>The name of the inference scheduler being started. </p>
    pub fn set_inference_scheduler_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inference_scheduler_name = input; self
    }
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
    pub fn inference_scheduler_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.inference_scheduler_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
    pub fn set_inference_scheduler_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inference_scheduler_arn = input; self
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn status(mut self, input: crate::types::InferenceSchedulerStatus) -> Self {
        self.status = Some(input);
        self
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn set_status(mut self, input: std::option::Option<crate::types::InferenceSchedulerStatus>) -> Self {
        self.status = input; self
    }
    pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
                                    self._request_id = Some(request_id.into());
                                    self
                                }
    
                                pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
                                    self._request_id = request_id;
                                    self
                                }
    /// Consumes the builder and constructs a [`StartInferenceSchedulerOutput`](crate::operation::start_inference_scheduler::StartInferenceSchedulerOutput).
    pub fn build(self) -> crate::operation::start_inference_scheduler::StartInferenceSchedulerOutput {
        crate::operation::start_inference_scheduler::StartInferenceSchedulerOutput {
            model_arn: self.model_arn
            ,
            model_name: self.model_name
            ,
            inference_scheduler_name: self.inference_scheduler_name
            ,
            inference_scheduler_arn: self.inference_scheduler_arn
            ,
            status: self.status
            ,
            _request_id: self._request_id,
        }
    }
}

