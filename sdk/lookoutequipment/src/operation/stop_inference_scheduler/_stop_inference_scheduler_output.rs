// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StopInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
    #[doc(hidden)]
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
    #[doc(hidden)]
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The name of the inference scheduler being stopped. </p>
    #[doc(hidden)]
    pub inference_scheduler_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
    #[doc(hidden)]
    pub inference_scheduler_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the inference scheduler. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::types::InferenceSchedulerStatus>,
    _request_id: Option<String>,
}
impl StopInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
    pub fn model_arn(&self) -> std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>The name of the inference scheduler being stopped. </p>
    pub fn inference_scheduler_name(&self) -> std::option::Option<&str> {
        self.inference_scheduler_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
    pub fn inference_scheduler_arn(&self) -> std::option::Option<&str> {
        self.inference_scheduler_arn.as_deref()
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn status(&self) -> std::option::Option<&crate::types::InferenceSchedulerStatus> {
        self.status.as_ref()
    }
}
impl aws_http::request_id::RequestId for StopInferenceSchedulerOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
impl StopInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`StopInferenceSchedulerOutput`](crate::operation::stop_inference_scheduler::StopInferenceSchedulerOutput).
    pub fn builder(
    ) -> crate::operation::stop_inference_scheduler::builders::StopInferenceSchedulerOutputBuilder
    {
        crate::operation::stop_inference_scheduler::builders::StopInferenceSchedulerOutputBuilder::default()
    }
}

/// A builder for [`StopInferenceSchedulerOutput`](crate::operation::stop_inference_scheduler::StopInferenceSchedulerOutput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct StopInferenceSchedulerOutputBuilder {
    pub(crate) model_arn: std::option::Option<std::string::String>,
    pub(crate) model_name: std::option::Option<std::string::String>,
    pub(crate) inference_scheduler_name: std::option::Option<std::string::String>,
    pub(crate) inference_scheduler_arn: std::option::Option<std::string::String>,
    pub(crate) status: std::option::Option<crate::types::InferenceSchedulerStatus>,
    _request_id: Option<String>,
}
impl StopInferenceSchedulerOutputBuilder {
    /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
    pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.model_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
    pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.model_arn = input;
        self
    }
    /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
    pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.model_name = Some(input.into());
        self
    }
    /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
    pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.model_name = input;
        self
    }
    /// <p>The name of the inference scheduler being stopped. </p>
    pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.inference_scheduler_name = Some(input.into());
        self
    }
    /// <p>The name of the inference scheduler being stopped. </p>
    pub fn set_inference_scheduler_name(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.inference_scheduler_name = input;
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
    pub fn inference_scheduler_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.inference_scheduler_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
    pub fn set_inference_scheduler_arn(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.inference_scheduler_arn = input;
        self
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn status(mut self, input: crate::types::InferenceSchedulerStatus) -> Self {
        self.status = Some(input);
        self
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn set_status(
        mut self,
        input: std::option::Option<crate::types::InferenceSchedulerStatus>,
    ) -> Self {
        self.status = input;
        self
    }
    pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
        self._request_id = Some(request_id.into());
        self
    }

    pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
        self._request_id = request_id;
        self
    }
    /// Consumes the builder and constructs a [`StopInferenceSchedulerOutput`](crate::operation::stop_inference_scheduler::StopInferenceSchedulerOutput).
    pub fn build(self) -> crate::operation::stop_inference_scheduler::StopInferenceSchedulerOutput {
        crate::operation::stop_inference_scheduler::StopInferenceSchedulerOutput {
            model_arn: self.model_arn,
            model_name: self.model_name,
            inference_scheduler_name: self.inference_scheduler_name,
            inference_scheduler_arn: self.inference_scheduler_arn,
            status: self.status,
            _request_id: self._request_id,
        }
    }
}
