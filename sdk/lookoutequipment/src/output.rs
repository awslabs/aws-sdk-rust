// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct UpdateInferenceSchedulerOutput {}
impl std::fmt::Debug for UpdateInferenceSchedulerOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("UpdateInferenceSchedulerOutput");
        formatter.finish()
    }
}
/// See [`UpdateInferenceSchedulerOutput`](crate::output::UpdateInferenceSchedulerOutput)
pub mod update_inference_scheduler_output {

    /// A builder for [`UpdateInferenceSchedulerOutput`](crate::output::UpdateInferenceSchedulerOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {}
    impl Builder {
        /// Consumes the builder and constructs a [`UpdateInferenceSchedulerOutput`](crate::output::UpdateInferenceSchedulerOutput)
        pub fn build(self) -> crate::output::UpdateInferenceSchedulerOutput {
            crate::output::UpdateInferenceSchedulerOutput {}
        }
    }
}
impl UpdateInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`UpdateInferenceSchedulerOutput`](crate::output::UpdateInferenceSchedulerOutput)
    pub fn builder() -> crate::output::update_inference_scheduler_output::Builder {
        crate::output::update_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct UntagResourceOutput {}
impl std::fmt::Debug for UntagResourceOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("UntagResourceOutput");
        formatter.finish()
    }
}
/// See [`UntagResourceOutput`](crate::output::UntagResourceOutput)
pub mod untag_resource_output {

    /// A builder for [`UntagResourceOutput`](crate::output::UntagResourceOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {}
    impl Builder {
        /// Consumes the builder and constructs a [`UntagResourceOutput`](crate::output::UntagResourceOutput)
        pub fn build(self) -> crate::output::UntagResourceOutput {
            crate::output::UntagResourceOutput {}
        }
    }
}
impl UntagResourceOutput {
    /// Creates a new builder-style object to manufacture [`UntagResourceOutput`](crate::output::UntagResourceOutput)
    pub fn builder() -> crate::output::untag_resource_output::Builder {
        crate::output::untag_resource_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct TagResourceOutput {}
impl std::fmt::Debug for TagResourceOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("TagResourceOutput");
        formatter.finish()
    }
}
/// See [`TagResourceOutput`](crate::output::TagResourceOutput)
pub mod tag_resource_output {

    /// A builder for [`TagResourceOutput`](crate::output::TagResourceOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {}
    impl Builder {
        /// Consumes the builder and constructs a [`TagResourceOutput`](crate::output::TagResourceOutput)
        pub fn build(self) -> crate::output::TagResourceOutput {
            crate::output::TagResourceOutput {}
        }
    }
}
impl TagResourceOutput {
    /// Creates a new builder-style object to manufacture [`TagResourceOutput`](crate::output::TagResourceOutput)
    pub fn builder() -> crate::output::tag_resource_output::Builder {
        crate::output::tag_resource_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct StopInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The name of the inference scheduler being stopped. </p>
    pub inference_scheduler_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
    pub inference_scheduler_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the inference scheduler. </p>
    pub status: std::option::Option<crate::model::InferenceSchedulerStatus>,
}
impl StopInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
    pub fn model_arn(&self) -> std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>The name of the inference scheduler being stopped. </p>
    pub fn inference_scheduler_name(&self) -> std::option::Option<&str> {
        self.inference_scheduler_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
    pub fn inference_scheduler_arn(&self) -> std::option::Option<&str> {
        self.inference_scheduler_arn.as_deref()
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::InferenceSchedulerStatus> {
        self.status.as_ref()
    }
}
impl std::fmt::Debug for StopInferenceSchedulerOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("StopInferenceSchedulerOutput");
        formatter.field("model_arn", &self.model_arn);
        formatter.field("model_name", &self.model_name);
        formatter.field("inference_scheduler_name", &self.inference_scheduler_name);
        formatter.field("inference_scheduler_arn", &self.inference_scheduler_arn);
        formatter.field("status", &self.status);
        formatter.finish()
    }
}
/// See [`StopInferenceSchedulerOutput`](crate::output::StopInferenceSchedulerOutput)
pub mod stop_inference_scheduler_output {

    /// A builder for [`StopInferenceSchedulerOutput`](crate::output::StopInferenceSchedulerOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) model_arn: std::option::Option<std::string::String>,
        pub(crate) model_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_arn: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::InferenceSchedulerStatus>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
        pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
        pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_arn = input;
            self
        }
        /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_name = Some(input.into());
            self
        }
        /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_name = input;
            self
        }
        /// <p>The name of the inference scheduler being stopped. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_name = Some(input.into());
            self
        }
        /// <p>The name of the inference scheduler being stopped. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_name = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
        pub fn inference_scheduler_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
        pub fn set_inference_scheduler_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_arn = input;
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn status(mut self, input: crate::model::InferenceSchedulerStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::InferenceSchedulerStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        /// Consumes the builder and constructs a [`StopInferenceSchedulerOutput`](crate::output::StopInferenceSchedulerOutput)
        pub fn build(self) -> crate::output::StopInferenceSchedulerOutput {
            crate::output::StopInferenceSchedulerOutput {
                model_arn: self.model_arn,
                model_name: self.model_name,
                inference_scheduler_name: self.inference_scheduler_name,
                inference_scheduler_arn: self.inference_scheduler_arn,
                status: self.status,
            }
        }
    }
}
impl StopInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`StopInferenceSchedulerOutput`](crate::output::StopInferenceSchedulerOutput)
    pub fn builder() -> crate::output::stop_inference_scheduler_output::Builder {
        crate::output::stop_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct StartInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>The name of the ML model being used by the inference scheduler. </p>
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The name of the inference scheduler being started. </p>
    pub inference_scheduler_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
    pub inference_scheduler_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the inference scheduler. </p>
    pub status: std::option::Option<crate::model::InferenceSchedulerStatus>,
}
impl StartInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
    pub fn model_arn(&self) -> std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>The name of the ML model being used by the inference scheduler. </p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>The name of the inference scheduler being started. </p>
    pub fn inference_scheduler_name(&self) -> std::option::Option<&str> {
        self.inference_scheduler_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
    pub fn inference_scheduler_arn(&self) -> std::option::Option<&str> {
        self.inference_scheduler_arn.as_deref()
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::InferenceSchedulerStatus> {
        self.status.as_ref()
    }
}
impl std::fmt::Debug for StartInferenceSchedulerOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("StartInferenceSchedulerOutput");
        formatter.field("model_arn", &self.model_arn);
        formatter.field("model_name", &self.model_name);
        formatter.field("inference_scheduler_name", &self.inference_scheduler_name);
        formatter.field("inference_scheduler_arn", &self.inference_scheduler_arn);
        formatter.field("status", &self.status);
        formatter.finish()
    }
}
/// See [`StartInferenceSchedulerOutput`](crate::output::StartInferenceSchedulerOutput)
pub mod start_inference_scheduler_output {

    /// A builder for [`StartInferenceSchedulerOutput`](crate::output::StartInferenceSchedulerOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) model_arn: std::option::Option<std::string::String>,
        pub(crate) model_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_arn: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::InferenceSchedulerStatus>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
        pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
        pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_arn = input;
            self
        }
        /// <p>The name of the ML model being used by the inference scheduler. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_name = Some(input.into());
            self
        }
        /// <p>The name of the ML model being used by the inference scheduler. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_name = input;
            self
        }
        /// <p>The name of the inference scheduler being started. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_name = Some(input.into());
            self
        }
        /// <p>The name of the inference scheduler being started. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_name = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
        pub fn inference_scheduler_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
        pub fn set_inference_scheduler_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_arn = input;
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn status(mut self, input: crate::model::InferenceSchedulerStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::InferenceSchedulerStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        /// Consumes the builder and constructs a [`StartInferenceSchedulerOutput`](crate::output::StartInferenceSchedulerOutput)
        pub fn build(self) -> crate::output::StartInferenceSchedulerOutput {
            crate::output::StartInferenceSchedulerOutput {
                model_arn: self.model_arn,
                model_name: self.model_name,
                inference_scheduler_name: self.inference_scheduler_name,
                inference_scheduler_arn: self.inference_scheduler_arn,
                status: self.status,
            }
        }
    }
}
impl StartInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`StartInferenceSchedulerOutput`](crate::output::StartInferenceSchedulerOutput)
    pub fn builder() -> crate::output::start_inference_scheduler_output::Builder {
        crate::output::start_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct StartDataIngestionJobOutput {
    /// <p>Indicates the job ID of the data ingestion job. </p>
    pub job_id: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the <code>StartDataIngestionJob</code> operation. </p>
    pub status: std::option::Option<crate::model::IngestionJobStatus>,
}
impl StartDataIngestionJobOutput {
    /// <p>Indicates the job ID of the data ingestion job. </p>
    pub fn job_id(&self) -> std::option::Option<&str> {
        self.job_id.as_deref()
    }
    /// <p>Indicates the status of the <code>StartDataIngestionJob</code> operation. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::IngestionJobStatus> {
        self.status.as_ref()
    }
}
impl std::fmt::Debug for StartDataIngestionJobOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("StartDataIngestionJobOutput");
        formatter.field("job_id", &self.job_id);
        formatter.field("status", &self.status);
        formatter.finish()
    }
}
/// See [`StartDataIngestionJobOutput`](crate::output::StartDataIngestionJobOutput)
pub mod start_data_ingestion_job_output {

    /// A builder for [`StartDataIngestionJobOutput`](crate::output::StartDataIngestionJobOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::IngestionJobStatus>,
    }
    impl Builder {
        /// <p>Indicates the job ID of the data ingestion job. </p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>Indicates the job ID of the data ingestion job. </p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input;
            self
        }
        /// <p>Indicates the status of the <code>StartDataIngestionJob</code> operation. </p>
        pub fn status(mut self, input: crate::model::IngestionJobStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the <code>StartDataIngestionJob</code> operation. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::IngestionJobStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        /// Consumes the builder and constructs a [`StartDataIngestionJobOutput`](crate::output::StartDataIngestionJobOutput)
        pub fn build(self) -> crate::output::StartDataIngestionJobOutput {
            crate::output::StartDataIngestionJobOutput {
                job_id: self.job_id,
                status: self.status,
            }
        }
    }
}
impl StartDataIngestionJobOutput {
    /// Creates a new builder-style object to manufacture [`StartDataIngestionJobOutput`](crate::output::StartDataIngestionJobOutput)
    pub fn builder() -> crate::output::start_data_ingestion_job_output::Builder {
        crate::output::start_data_ingestion_job_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct ListTagsForResourceOutput {
    /// <p> Any tags associated with the resource. </p>
    pub tags: std::option::Option<std::vec::Vec<crate::model::Tag>>,
}
impl ListTagsForResourceOutput {
    /// <p> Any tags associated with the resource. </p>
    pub fn tags(&self) -> std::option::Option<&[crate::model::Tag]> {
        self.tags.as_deref()
    }
}
impl std::fmt::Debug for ListTagsForResourceOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("ListTagsForResourceOutput");
        formatter.field("tags", &self.tags);
        formatter.finish()
    }
}
/// See [`ListTagsForResourceOutput`](crate::output::ListTagsForResourceOutput)
pub mod list_tags_for_resource_output {

    /// A builder for [`ListTagsForResourceOutput`](crate::output::ListTagsForResourceOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) tags: std::option::Option<std::vec::Vec<crate::model::Tag>>,
    }
    impl Builder {
        /// Appends an item to `tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p> Any tags associated with the resource. </p>
        pub fn tags(mut self, input: crate::model::Tag) -> Self {
            let mut v = self.tags.unwrap_or_default();
            v.push(input);
            self.tags = Some(v);
            self
        }
        /// <p> Any tags associated with the resource. </p>
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.tags = input;
            self
        }
        /// Consumes the builder and constructs a [`ListTagsForResourceOutput`](crate::output::ListTagsForResourceOutput)
        pub fn build(self) -> crate::output::ListTagsForResourceOutput {
            crate::output::ListTagsForResourceOutput { tags: self.tags }
        }
    }
}
impl ListTagsForResourceOutput {
    /// Creates a new builder-style object to manufacture [`ListTagsForResourceOutput`](crate::output::ListTagsForResourceOutput)
    pub fn builder() -> crate::output::list_tags_for_resource_output::Builder {
        crate::output::list_tags_for_resource_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct ListSensorStatisticsOutput {
    /// <p> Provides ingestion-based statistics regarding the specified sensor with respect to various validation types, such as whether data exists, the number and percentage of missing values, and the number and percentage of duplicate timestamps. </p>
    pub sensor_statistics_summaries:
        std::option::Option<std::vec::Vec<crate::model::SensorStatisticsSummary>>,
    /// <p> An opaque pagination token indicating where to continue the listing of sensor statistics. </p>
    pub next_token: std::option::Option<std::string::String>,
}
impl ListSensorStatisticsOutput {
    /// <p> Provides ingestion-based statistics regarding the specified sensor with respect to various validation types, such as whether data exists, the number and percentage of missing values, and the number and percentage of duplicate timestamps. </p>
    pub fn sensor_statistics_summaries(
        &self,
    ) -> std::option::Option<&[crate::model::SensorStatisticsSummary]> {
        self.sensor_statistics_summaries.as_deref()
    }
    /// <p> An opaque pagination token indicating where to continue the listing of sensor statistics. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
}
impl std::fmt::Debug for ListSensorStatisticsOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("ListSensorStatisticsOutput");
        formatter.field(
            "sensor_statistics_summaries",
            &self.sensor_statistics_summaries,
        );
        formatter.field("next_token", &self.next_token);
        formatter.finish()
    }
}
/// See [`ListSensorStatisticsOutput`](crate::output::ListSensorStatisticsOutput)
pub mod list_sensor_statistics_output {

    /// A builder for [`ListSensorStatisticsOutput`](crate::output::ListSensorStatisticsOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) sensor_statistics_summaries:
            std::option::Option<std::vec::Vec<crate::model::SensorStatisticsSummary>>,
        pub(crate) next_token: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// Appends an item to `sensor_statistics_summaries`.
        ///
        /// To override the contents of this collection use [`set_sensor_statistics_summaries`](Self::set_sensor_statistics_summaries).
        ///
        /// <p> Provides ingestion-based statistics regarding the specified sensor with respect to various validation types, such as whether data exists, the number and percentage of missing values, and the number and percentage of duplicate timestamps. </p>
        pub fn sensor_statistics_summaries(
            mut self,
            input: crate::model::SensorStatisticsSummary,
        ) -> Self {
            let mut v = self.sensor_statistics_summaries.unwrap_or_default();
            v.push(input);
            self.sensor_statistics_summaries = Some(v);
            self
        }
        /// <p> Provides ingestion-based statistics regarding the specified sensor with respect to various validation types, such as whether data exists, the number and percentage of missing values, and the number and percentage of duplicate timestamps. </p>
        pub fn set_sensor_statistics_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::SensorStatisticsSummary>>,
        ) -> Self {
            self.sensor_statistics_summaries = input;
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of sensor statistics. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of sensor statistics. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Consumes the builder and constructs a [`ListSensorStatisticsOutput`](crate::output::ListSensorStatisticsOutput)
        pub fn build(self) -> crate::output::ListSensorStatisticsOutput {
            crate::output::ListSensorStatisticsOutput {
                sensor_statistics_summaries: self.sensor_statistics_summaries,
                next_token: self.next_token,
            }
        }
    }
}
impl ListSensorStatisticsOutput {
    /// Creates a new builder-style object to manufacture [`ListSensorStatisticsOutput`](crate::output::ListSensorStatisticsOutput)
    pub fn builder() -> crate::output::list_sensor_statistics_output::Builder {
        crate::output::list_sensor_statistics_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct ListModelsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of ML models. </p>
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Provides information on the specified model, including created time, model and dataset ARNs, and status. </p>
    pub model_summaries: std::option::Option<std::vec::Vec<crate::model::ModelSummary>>,
}
impl ListModelsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of ML models. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Provides information on the specified model, including created time, model and dataset ARNs, and status. </p>
    pub fn model_summaries(&self) -> std::option::Option<&[crate::model::ModelSummary]> {
        self.model_summaries.as_deref()
    }
}
impl std::fmt::Debug for ListModelsOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("ListModelsOutput");
        formatter.field("next_token", &self.next_token);
        formatter.field("model_summaries", &self.model_summaries);
        formatter.finish()
    }
}
/// See [`ListModelsOutput`](crate::output::ListModelsOutput)
pub mod list_models_output {

    /// A builder for [`ListModelsOutput`](crate::output::ListModelsOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) model_summaries: std::option::Option<std::vec::Vec<crate::model::ModelSummary>>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of ML models. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of ML models. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `model_summaries`.
        ///
        /// To override the contents of this collection use [`set_model_summaries`](Self::set_model_summaries).
        ///
        /// <p>Provides information on the specified model, including created time, model and dataset ARNs, and status. </p>
        pub fn model_summaries(mut self, input: crate::model::ModelSummary) -> Self {
            let mut v = self.model_summaries.unwrap_or_default();
            v.push(input);
            self.model_summaries = Some(v);
            self
        }
        /// <p>Provides information on the specified model, including created time, model and dataset ARNs, and status. </p>
        pub fn set_model_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::ModelSummary>>,
        ) -> Self {
            self.model_summaries = input;
            self
        }
        /// Consumes the builder and constructs a [`ListModelsOutput`](crate::output::ListModelsOutput)
        pub fn build(self) -> crate::output::ListModelsOutput {
            crate::output::ListModelsOutput {
                next_token: self.next_token,
                model_summaries: self.model_summaries,
            }
        }
    }
}
impl ListModelsOutput {
    /// Creates a new builder-style object to manufacture [`ListModelsOutput`](crate::output::ListModelsOutput)
    pub fn builder() -> crate::output::list_models_output::Builder {
        crate::output::list_models_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct ListInferenceSchedulersOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Provides information about the specified inference scheduler, including data upload frequency, model name and ARN, and status. </p>
    pub inference_scheduler_summaries:
        std::option::Option<std::vec::Vec<crate::model::InferenceSchedulerSummary>>,
}
impl ListInferenceSchedulersOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Provides information about the specified inference scheduler, including data upload frequency, model name and ARN, and status. </p>
    pub fn inference_scheduler_summaries(
        &self,
    ) -> std::option::Option<&[crate::model::InferenceSchedulerSummary]> {
        self.inference_scheduler_summaries.as_deref()
    }
}
impl std::fmt::Debug for ListInferenceSchedulersOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("ListInferenceSchedulersOutput");
        formatter.field("next_token", &self.next_token);
        formatter.field(
            "inference_scheduler_summaries",
            &self.inference_scheduler_summaries,
        );
        formatter.finish()
    }
}
/// See [`ListInferenceSchedulersOutput`](crate::output::ListInferenceSchedulersOutput)
pub mod list_inference_schedulers_output {

    /// A builder for [`ListInferenceSchedulersOutput`](crate::output::ListInferenceSchedulersOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_summaries:
            std::option::Option<std::vec::Vec<crate::model::InferenceSchedulerSummary>>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `inference_scheduler_summaries`.
        ///
        /// To override the contents of this collection use [`set_inference_scheduler_summaries`](Self::set_inference_scheduler_summaries).
        ///
        /// <p>Provides information about the specified inference scheduler, including data upload frequency, model name and ARN, and status. </p>
        pub fn inference_scheduler_summaries(
            mut self,
            input: crate::model::InferenceSchedulerSummary,
        ) -> Self {
            let mut v = self.inference_scheduler_summaries.unwrap_or_default();
            v.push(input);
            self.inference_scheduler_summaries = Some(v);
            self
        }
        /// <p>Provides information about the specified inference scheduler, including data upload frequency, model name and ARN, and status. </p>
        pub fn set_inference_scheduler_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::InferenceSchedulerSummary>>,
        ) -> Self {
            self.inference_scheduler_summaries = input;
            self
        }
        /// Consumes the builder and constructs a [`ListInferenceSchedulersOutput`](crate::output::ListInferenceSchedulersOutput)
        pub fn build(self) -> crate::output::ListInferenceSchedulersOutput {
            crate::output::ListInferenceSchedulersOutput {
                next_token: self.next_token,
                inference_scheduler_summaries: self.inference_scheduler_summaries,
            }
        }
    }
}
impl ListInferenceSchedulersOutput {
    /// Creates a new builder-style object to manufacture [`ListInferenceSchedulersOutput`](crate::output::ListInferenceSchedulersOutput)
    pub fn builder() -> crate::output::list_inference_schedulers_output::Builder {
        crate::output::list_inference_schedulers_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct ListInferenceExecutionsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of inference executions. </p>
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Provides an array of information about the individual inference executions returned from the <code>ListInferenceExecutions</code> operation, including model used, inference scheduler, data configuration, and so on. </p>
    pub inference_execution_summaries:
        std::option::Option<std::vec::Vec<crate::model::InferenceExecutionSummary>>,
}
impl ListInferenceExecutionsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of inference executions. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Provides an array of information about the individual inference executions returned from the <code>ListInferenceExecutions</code> operation, including model used, inference scheduler, data configuration, and so on. </p>
    pub fn inference_execution_summaries(
        &self,
    ) -> std::option::Option<&[crate::model::InferenceExecutionSummary]> {
        self.inference_execution_summaries.as_deref()
    }
}
impl std::fmt::Debug for ListInferenceExecutionsOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("ListInferenceExecutionsOutput");
        formatter.field("next_token", &self.next_token);
        formatter.field(
            "inference_execution_summaries",
            &self.inference_execution_summaries,
        );
        formatter.finish()
    }
}
/// See [`ListInferenceExecutionsOutput`](crate::output::ListInferenceExecutionsOutput)
pub mod list_inference_executions_output {

    /// A builder for [`ListInferenceExecutionsOutput`](crate::output::ListInferenceExecutionsOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) inference_execution_summaries:
            std::option::Option<std::vec::Vec<crate::model::InferenceExecutionSummary>>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of inference executions. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of inference executions. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `inference_execution_summaries`.
        ///
        /// To override the contents of this collection use [`set_inference_execution_summaries`](Self::set_inference_execution_summaries).
        ///
        /// <p>Provides an array of information about the individual inference executions returned from the <code>ListInferenceExecutions</code> operation, including model used, inference scheduler, data configuration, and so on. </p>
        pub fn inference_execution_summaries(
            mut self,
            input: crate::model::InferenceExecutionSummary,
        ) -> Self {
            let mut v = self.inference_execution_summaries.unwrap_or_default();
            v.push(input);
            self.inference_execution_summaries = Some(v);
            self
        }
        /// <p>Provides an array of information about the individual inference executions returned from the <code>ListInferenceExecutions</code> operation, including model used, inference scheduler, data configuration, and so on. </p>
        pub fn set_inference_execution_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::InferenceExecutionSummary>>,
        ) -> Self {
            self.inference_execution_summaries = input;
            self
        }
        /// Consumes the builder and constructs a [`ListInferenceExecutionsOutput`](crate::output::ListInferenceExecutionsOutput)
        pub fn build(self) -> crate::output::ListInferenceExecutionsOutput {
            crate::output::ListInferenceExecutionsOutput {
                next_token: self.next_token,
                inference_execution_summaries: self.inference_execution_summaries,
            }
        }
    }
}
impl ListInferenceExecutionsOutput {
    /// Creates a new builder-style object to manufacture [`ListInferenceExecutionsOutput`](crate::output::ListInferenceExecutionsOutput)
    pub fn builder() -> crate::output::list_inference_executions_output::Builder {
        crate::output::list_inference_executions_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct ListDatasetsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Provides information about the specified dataset, including creation time, dataset ARN, and status. </p>
    pub dataset_summaries: std::option::Option<std::vec::Vec<crate::model::DatasetSummary>>,
}
impl ListDatasetsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Provides information about the specified dataset, including creation time, dataset ARN, and status. </p>
    pub fn dataset_summaries(&self) -> std::option::Option<&[crate::model::DatasetSummary]> {
        self.dataset_summaries.as_deref()
    }
}
impl std::fmt::Debug for ListDatasetsOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("ListDatasetsOutput");
        formatter.field("next_token", &self.next_token);
        formatter.field("dataset_summaries", &self.dataset_summaries);
        formatter.finish()
    }
}
/// See [`ListDatasetsOutput`](crate::output::ListDatasetsOutput)
pub mod list_datasets_output {

    /// A builder for [`ListDatasetsOutput`](crate::output::ListDatasetsOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) dataset_summaries:
            std::option::Option<std::vec::Vec<crate::model::DatasetSummary>>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `dataset_summaries`.
        ///
        /// To override the contents of this collection use [`set_dataset_summaries`](Self::set_dataset_summaries).
        ///
        /// <p>Provides information about the specified dataset, including creation time, dataset ARN, and status. </p>
        pub fn dataset_summaries(mut self, input: crate::model::DatasetSummary) -> Self {
            let mut v = self.dataset_summaries.unwrap_or_default();
            v.push(input);
            self.dataset_summaries = Some(v);
            self
        }
        /// <p>Provides information about the specified dataset, including creation time, dataset ARN, and status. </p>
        pub fn set_dataset_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::DatasetSummary>>,
        ) -> Self {
            self.dataset_summaries = input;
            self
        }
        /// Consumes the builder and constructs a [`ListDatasetsOutput`](crate::output::ListDatasetsOutput)
        pub fn build(self) -> crate::output::ListDatasetsOutput {
            crate::output::ListDatasetsOutput {
                next_token: self.next_token,
                dataset_summaries: self.dataset_summaries,
            }
        }
    }
}
impl ListDatasetsOutput {
    /// Creates a new builder-style object to manufacture [`ListDatasetsOutput`](crate::output::ListDatasetsOutput)
    pub fn builder() -> crate::output::list_datasets_output::Builder {
        crate::output::list_datasets_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct ListDataIngestionJobsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of data ingestion jobs. </p>
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Specifies information about the specific data ingestion job, including dataset name and status. </p>
    pub data_ingestion_job_summaries:
        std::option::Option<std::vec::Vec<crate::model::DataIngestionJobSummary>>,
}
impl ListDataIngestionJobsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of data ingestion jobs. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Specifies information about the specific data ingestion job, including dataset name and status. </p>
    pub fn data_ingestion_job_summaries(
        &self,
    ) -> std::option::Option<&[crate::model::DataIngestionJobSummary]> {
        self.data_ingestion_job_summaries.as_deref()
    }
}
impl std::fmt::Debug for ListDataIngestionJobsOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("ListDataIngestionJobsOutput");
        formatter.field("next_token", &self.next_token);
        formatter.field(
            "data_ingestion_job_summaries",
            &self.data_ingestion_job_summaries,
        );
        formatter.finish()
    }
}
/// See [`ListDataIngestionJobsOutput`](crate::output::ListDataIngestionJobsOutput)
pub mod list_data_ingestion_jobs_output {

    /// A builder for [`ListDataIngestionJobsOutput`](crate::output::ListDataIngestionJobsOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) data_ingestion_job_summaries:
            std::option::Option<std::vec::Vec<crate::model::DataIngestionJobSummary>>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of data ingestion jobs. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of data ingestion jobs. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `data_ingestion_job_summaries`.
        ///
        /// To override the contents of this collection use [`set_data_ingestion_job_summaries`](Self::set_data_ingestion_job_summaries).
        ///
        /// <p>Specifies information about the specific data ingestion job, including dataset name and status. </p>
        pub fn data_ingestion_job_summaries(
            mut self,
            input: crate::model::DataIngestionJobSummary,
        ) -> Self {
            let mut v = self.data_ingestion_job_summaries.unwrap_or_default();
            v.push(input);
            self.data_ingestion_job_summaries = Some(v);
            self
        }
        /// <p>Specifies information about the specific data ingestion job, including dataset name and status. </p>
        pub fn set_data_ingestion_job_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::DataIngestionJobSummary>>,
        ) -> Self {
            self.data_ingestion_job_summaries = input;
            self
        }
        /// Consumes the builder and constructs a [`ListDataIngestionJobsOutput`](crate::output::ListDataIngestionJobsOutput)
        pub fn build(self) -> crate::output::ListDataIngestionJobsOutput {
            crate::output::ListDataIngestionJobsOutput {
                next_token: self.next_token,
                data_ingestion_job_summaries: self.data_ingestion_job_summaries,
            }
        }
    }
}
impl ListDataIngestionJobsOutput {
    /// Creates a new builder-style object to manufacture [`ListDataIngestionJobsOutput`](crate::output::ListDataIngestionJobsOutput)
    pub fn builder() -> crate::output::list_data_ingestion_jobs_output::Builder {
        crate::output::list_data_ingestion_jobs_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct DescribeModelOutput {
    /// <p>The name of the ML model being described. </p>
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the ML model being described. </p>
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>The name of the dataset being used by the ML being described. </p>
    pub dataset_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resouce Name (ARN) of the dataset used to create the ML model being described. </p>
    pub dataset_arn: std::option::Option<std::string::String>,
    /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
    pub schema: std::option::Option<std::string::String>,
    /// <p>Specifies configuration information about the labels input, including its S3 location. </p>
    pub labels_input_configuration: std::option::Option<crate::model::LabelsInputConfiguration>,
    /// <p> Indicates the time reference in the dataset that was used to begin the subset of training data for the ML model. </p>
    pub training_data_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Indicates the time reference in the dataset that was used to end the subset of training data for the ML model. </p>
    pub training_data_end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Indicates the time reference in the dataset that was used to begin the subset of evaluation data for the ML model. </p>
    pub evaluation_data_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Indicates the time reference in the dataset that was used to end the subset of evaluation data for the ML model. </p>
    pub evaluation_data_end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the ML model being described. </p>
    pub role_arn: std::option::Option<std::string::String>,
    /// <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p>
    /// <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix "PT" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>
    pub data_pre_processing_configuration:
        std::option::Option<crate::model::DataPreProcessingConfiguration>,
    /// <p>Specifies the current status of the model being described. Status describes the status of the most recent action of the model. </p>
    pub status: std::option::Option<crate::model::ModelStatus>,
    /// <p>Indicates the time at which the training of the ML model began. </p>
    pub training_execution_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates the time at which the training of the ML model was completed. </p>
    pub training_execution_end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>If the training of the ML model failed, this indicates the reason for that failure. </p>
    pub failed_reason: std::option::Option<std::string::String>,
    /// <p>The Model Metrics show an aggregated summary of the model's performance within the evaluation time range. This is the JSON content of the metrics created when evaluating the model. </p>
    pub model_metrics: std::option::Option<std::string::String>,
    /// <p>Indicates the last time the ML model was updated. The type of update is not specified. </p>
    pub last_updated_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates the time and date at which the ML model was created. </p>
    pub created_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>
    pub server_side_kms_key_id: std::option::Option<std::string::String>,
    /// <p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>
    pub off_condition: std::option::Option<std::string::String>,
}
impl DescribeModelOutput {
    /// <p>The name of the ML model being described. </p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the ML model being described. </p>
    pub fn model_arn(&self) -> std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>The name of the dataset being used by the ML being described. </p>
    pub fn dataset_name(&self) -> std::option::Option<&str> {
        self.dataset_name.as_deref()
    }
    /// <p>The Amazon Resouce Name (ARN) of the dataset used to create the ML model being described. </p>
    pub fn dataset_arn(&self) -> std::option::Option<&str> {
        self.dataset_arn.as_deref()
    }
    /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
    pub fn schema(&self) -> std::option::Option<&str> {
        self.schema.as_deref()
    }
    /// <p>Specifies configuration information about the labels input, including its S3 location. </p>
    pub fn labels_input_configuration(
        &self,
    ) -> std::option::Option<&crate::model::LabelsInputConfiguration> {
        self.labels_input_configuration.as_ref()
    }
    /// <p> Indicates the time reference in the dataset that was used to begin the subset of training data for the ML model. </p>
    pub fn training_data_start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.training_data_start_time.as_ref()
    }
    /// <p> Indicates the time reference in the dataset that was used to end the subset of training data for the ML model. </p>
    pub fn training_data_end_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.training_data_end_time.as_ref()
    }
    /// <p> Indicates the time reference in the dataset that was used to begin the subset of evaluation data for the ML model. </p>
    pub fn evaluation_data_start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.evaluation_data_start_time.as_ref()
    }
    /// <p> Indicates the time reference in the dataset that was used to end the subset of evaluation data for the ML model. </p>
    pub fn evaluation_data_end_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.evaluation_data_end_time.as_ref()
    }
    /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the ML model being described. </p>
    pub fn role_arn(&self) -> std::option::Option<&str> {
        self.role_arn.as_deref()
    }
    /// <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p>
    /// <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix "PT" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>
    pub fn data_pre_processing_configuration(
        &self,
    ) -> std::option::Option<&crate::model::DataPreProcessingConfiguration> {
        self.data_pre_processing_configuration.as_ref()
    }
    /// <p>Specifies the current status of the model being described. Status describes the status of the most recent action of the model. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::ModelStatus> {
        self.status.as_ref()
    }
    /// <p>Indicates the time at which the training of the ML model began. </p>
    pub fn training_execution_start_time(
        &self,
    ) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.training_execution_start_time.as_ref()
    }
    /// <p>Indicates the time at which the training of the ML model was completed. </p>
    pub fn training_execution_end_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.training_execution_end_time.as_ref()
    }
    /// <p>If the training of the ML model failed, this indicates the reason for that failure. </p>
    pub fn failed_reason(&self) -> std::option::Option<&str> {
        self.failed_reason.as_deref()
    }
    /// <p>The Model Metrics show an aggregated summary of the model's performance within the evaluation time range. This is the JSON content of the metrics created when evaluating the model. </p>
    pub fn model_metrics(&self) -> std::option::Option<&str> {
        self.model_metrics.as_deref()
    }
    /// <p>Indicates the last time the ML model was updated. The type of update is not specified. </p>
    pub fn last_updated_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.last_updated_time.as_ref()
    }
    /// <p>Indicates the time and date at which the ML model was created. </p>
    pub fn created_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.created_at.as_ref()
    }
    /// <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>
    pub fn server_side_kms_key_id(&self) -> std::option::Option<&str> {
        self.server_side_kms_key_id.as_deref()
    }
    /// <p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>
    pub fn off_condition(&self) -> std::option::Option<&str> {
        self.off_condition.as_deref()
    }
}
impl std::fmt::Debug for DescribeModelOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("DescribeModelOutput");
        formatter.field("model_name", &self.model_name);
        formatter.field("model_arn", &self.model_arn);
        formatter.field("dataset_name", &self.dataset_name);
        formatter.field("dataset_arn", &self.dataset_arn);
        formatter.field("schema", &self.schema);
        formatter.field(
            "labels_input_configuration",
            &self.labels_input_configuration,
        );
        formatter.field("training_data_start_time", &self.training_data_start_time);
        formatter.field("training_data_end_time", &self.training_data_end_time);
        formatter.field(
            "evaluation_data_start_time",
            &self.evaluation_data_start_time,
        );
        formatter.field("evaluation_data_end_time", &self.evaluation_data_end_time);
        formatter.field("role_arn", &self.role_arn);
        formatter.field(
            "data_pre_processing_configuration",
            &self.data_pre_processing_configuration,
        );
        formatter.field("status", &self.status);
        formatter.field(
            "training_execution_start_time",
            &self.training_execution_start_time,
        );
        formatter.field(
            "training_execution_end_time",
            &self.training_execution_end_time,
        );
        formatter.field("failed_reason", &self.failed_reason);
        formatter.field("model_metrics", &self.model_metrics);
        formatter.field("last_updated_time", &self.last_updated_time);
        formatter.field("created_at", &self.created_at);
        formatter.field("server_side_kms_key_id", &self.server_side_kms_key_id);
        formatter.field("off_condition", &self.off_condition);
        formatter.finish()
    }
}
/// See [`DescribeModelOutput`](crate::output::DescribeModelOutput)
pub mod describe_model_output {

    /// A builder for [`DescribeModelOutput`](crate::output::DescribeModelOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) model_name: std::option::Option<std::string::String>,
        pub(crate) model_arn: std::option::Option<std::string::String>,
        pub(crate) dataset_name: std::option::Option<std::string::String>,
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
        pub(crate) schema: std::option::Option<std::string::String>,
        pub(crate) labels_input_configuration:
            std::option::Option<crate::model::LabelsInputConfiguration>,
        pub(crate) training_data_start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) training_data_end_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) evaluation_data_start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) evaluation_data_end_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) role_arn: std::option::Option<std::string::String>,
        pub(crate) data_pre_processing_configuration:
            std::option::Option<crate::model::DataPreProcessingConfiguration>,
        pub(crate) status: std::option::Option<crate::model::ModelStatus>,
        pub(crate) training_execution_start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) training_execution_end_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) failed_reason: std::option::Option<std::string::String>,
        pub(crate) model_metrics: std::option::Option<std::string::String>,
        pub(crate) last_updated_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) created_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) server_side_kms_key_id: std::option::Option<std::string::String>,
        pub(crate) off_condition: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the ML model being described. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_name = Some(input.into());
            self
        }
        /// <p>The name of the ML model being described. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_name = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the ML model being described. </p>
        pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the ML model being described. </p>
        pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_arn = input;
            self
        }
        /// <p>The name of the dataset being used by the ML being described. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_name = Some(input.into());
            self
        }
        /// <p>The name of the dataset being used by the ML being described. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_name = input;
            self
        }
        /// <p>The Amazon Resouce Name (ARN) of the dataset used to create the ML model being described. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resouce Name (ARN) of the dataset used to create the ML model being described. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input;
            self
        }
        /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
        pub fn schema(mut self, input: impl Into<std::string::String>) -> Self {
            self.schema = Some(input.into());
            self
        }
        /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
        pub fn set_schema(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.schema = input;
            self
        }
        /// <p>Specifies configuration information about the labels input, including its S3 location. </p>
        pub fn labels_input_configuration(
            mut self,
            input: crate::model::LabelsInputConfiguration,
        ) -> Self {
            self.labels_input_configuration = Some(input);
            self
        }
        /// <p>Specifies configuration information about the labels input, including its S3 location. </p>
        pub fn set_labels_input_configuration(
            mut self,
            input: std::option::Option<crate::model::LabelsInputConfiguration>,
        ) -> Self {
            self.labels_input_configuration = input;
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to begin the subset of training data for the ML model. </p>
        pub fn training_data_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.training_data_start_time = Some(input);
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to begin the subset of training data for the ML model. </p>
        pub fn set_training_data_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.training_data_start_time = input;
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to end the subset of training data for the ML model. </p>
        pub fn training_data_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.training_data_end_time = Some(input);
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to end the subset of training data for the ML model. </p>
        pub fn set_training_data_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.training_data_end_time = input;
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to begin the subset of evaluation data for the ML model. </p>
        pub fn evaluation_data_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.evaluation_data_start_time = Some(input);
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to begin the subset of evaluation data for the ML model. </p>
        pub fn set_evaluation_data_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.evaluation_data_start_time = input;
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to end the subset of evaluation data for the ML model. </p>
        pub fn evaluation_data_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.evaluation_data_end_time = Some(input);
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to end the subset of evaluation data for the ML model. </p>
        pub fn set_evaluation_data_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.evaluation_data_end_time = input;
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the ML model being described. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.role_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the ML model being described. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.role_arn = input;
            self
        }
        /// <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p>
        /// <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix "PT" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>
        pub fn data_pre_processing_configuration(
            mut self,
            input: crate::model::DataPreProcessingConfiguration,
        ) -> Self {
            self.data_pre_processing_configuration = Some(input);
            self
        }
        /// <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p>
        /// <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix "PT" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>
        pub fn set_data_pre_processing_configuration(
            mut self,
            input: std::option::Option<crate::model::DataPreProcessingConfiguration>,
        ) -> Self {
            self.data_pre_processing_configuration = input;
            self
        }
        /// <p>Specifies the current status of the model being described. Status describes the status of the most recent action of the model. </p>
        pub fn status(mut self, input: crate::model::ModelStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Specifies the current status of the model being described. Status describes the status of the most recent action of the model. </p>
        pub fn set_status(mut self, input: std::option::Option<crate::model::ModelStatus>) -> Self {
            self.status = input;
            self
        }
        /// <p>Indicates the time at which the training of the ML model began. </p>
        pub fn training_execution_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.training_execution_start_time = Some(input);
            self
        }
        /// <p>Indicates the time at which the training of the ML model began. </p>
        pub fn set_training_execution_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.training_execution_start_time = input;
            self
        }
        /// <p>Indicates the time at which the training of the ML model was completed. </p>
        pub fn training_execution_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.training_execution_end_time = Some(input);
            self
        }
        /// <p>Indicates the time at which the training of the ML model was completed. </p>
        pub fn set_training_execution_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.training_execution_end_time = input;
            self
        }
        /// <p>If the training of the ML model failed, this indicates the reason for that failure. </p>
        pub fn failed_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.failed_reason = Some(input.into());
            self
        }
        /// <p>If the training of the ML model failed, this indicates the reason for that failure. </p>
        pub fn set_failed_reason(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.failed_reason = input;
            self
        }
        /// <p>The Model Metrics show an aggregated summary of the model's performance within the evaluation time range. This is the JSON content of the metrics created when evaluating the model. </p>
        pub fn model_metrics(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_metrics = Some(input.into());
            self
        }
        /// <p>The Model Metrics show an aggregated summary of the model's performance within the evaluation time range. This is the JSON content of the metrics created when evaluating the model. </p>
        pub fn set_model_metrics(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.model_metrics = input;
            self
        }
        /// <p>Indicates the last time the ML model was updated. The type of update is not specified. </p>
        pub fn last_updated_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.last_updated_time = Some(input);
            self
        }
        /// <p>Indicates the last time the ML model was updated. The type of update is not specified. </p>
        pub fn set_last_updated_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.last_updated_time = input;
            self
        }
        /// <p>Indicates the time and date at which the ML model was created. </p>
        pub fn created_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_at = Some(input);
            self
        }
        /// <p>Indicates the time and date at which the ML model was created. </p>
        pub fn set_created_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.created_at = input;
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.server_side_kms_key_id = Some(input.into());
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.server_side_kms_key_id = input;
            self
        }
        /// <p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>
        pub fn off_condition(mut self, input: impl Into<std::string::String>) -> Self {
            self.off_condition = Some(input.into());
            self
        }
        /// <p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>
        pub fn set_off_condition(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.off_condition = input;
            self
        }
        /// Consumes the builder and constructs a [`DescribeModelOutput`](crate::output::DescribeModelOutput)
        pub fn build(self) -> crate::output::DescribeModelOutput {
            crate::output::DescribeModelOutput {
                model_name: self.model_name,
                model_arn: self.model_arn,
                dataset_name: self.dataset_name,
                dataset_arn: self.dataset_arn,
                schema: self.schema,
                labels_input_configuration: self.labels_input_configuration,
                training_data_start_time: self.training_data_start_time,
                training_data_end_time: self.training_data_end_time,
                evaluation_data_start_time: self.evaluation_data_start_time,
                evaluation_data_end_time: self.evaluation_data_end_time,
                role_arn: self.role_arn,
                data_pre_processing_configuration: self.data_pre_processing_configuration,
                status: self.status,
                training_execution_start_time: self.training_execution_start_time,
                training_execution_end_time: self.training_execution_end_time,
                failed_reason: self.failed_reason,
                model_metrics: self.model_metrics,
                last_updated_time: self.last_updated_time,
                created_at: self.created_at,
                server_side_kms_key_id: self.server_side_kms_key_id,
                off_condition: self.off_condition,
            }
        }
    }
}
impl DescribeModelOutput {
    /// Creates a new builder-style object to manufacture [`DescribeModelOutput`](crate::output::DescribeModelOutput)
    pub fn builder() -> crate::output::describe_model_output::Builder {
        crate::output::describe_model_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct DescribeInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model of the inference scheduler being described. </p>
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>The name of the ML model of the inference scheduler being described. </p>
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The name of the inference scheduler being described. </p>
    pub inference_scheduler_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being described. </p>
    pub inference_scheduler_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the inference scheduler. </p>
    pub status: std::option::Option<crate::model::InferenceSchedulerStatus>,
    /// <p> A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if you select an offset delay time of five minutes, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>
    pub data_delay_offset_in_minutes: std::option::Option<i64>,
    /// <p>Specifies how often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes. </p>
    pub data_upload_frequency: std::option::Option<crate::model::DataUploadFrequency>,
    /// <p>Specifies the time at which the inference scheduler was created. </p>
    pub created_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Specifies the time at which the inference scheduler was last updated, if it was. </p>
    pub updated_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>
    pub data_input_configuration: std::option::Option<crate::model::InferenceInputConfiguration>,
    /// <p> Specifies information for the output results for the inference scheduler, including the output S3 location. </p>
    pub data_output_configuration: std::option::Option<crate::model::InferenceOutputConfiguration>,
    /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the inference scheduler being described. </p>
    pub role_arn: std::option::Option<std::string::String>,
    /// <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
    pub server_side_kms_key_id: std::option::Option<std::string::String>,
}
impl DescribeInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model of the inference scheduler being described. </p>
    pub fn model_arn(&self) -> std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>The name of the ML model of the inference scheduler being described. </p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>The name of the inference scheduler being described. </p>
    pub fn inference_scheduler_name(&self) -> std::option::Option<&str> {
        self.inference_scheduler_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being described. </p>
    pub fn inference_scheduler_arn(&self) -> std::option::Option<&str> {
        self.inference_scheduler_arn.as_deref()
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::InferenceSchedulerStatus> {
        self.status.as_ref()
    }
    /// <p> A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if you select an offset delay time of five minutes, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>
    pub fn data_delay_offset_in_minutes(&self) -> std::option::Option<i64> {
        self.data_delay_offset_in_minutes
    }
    /// <p>Specifies how often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes. </p>
    pub fn data_upload_frequency(&self) -> std::option::Option<&crate::model::DataUploadFrequency> {
        self.data_upload_frequency.as_ref()
    }
    /// <p>Specifies the time at which the inference scheduler was created. </p>
    pub fn created_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.created_at.as_ref()
    }
    /// <p>Specifies the time at which the inference scheduler was last updated, if it was. </p>
    pub fn updated_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.updated_at.as_ref()
    }
    /// <p> Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>
    pub fn data_input_configuration(
        &self,
    ) -> std::option::Option<&crate::model::InferenceInputConfiguration> {
        self.data_input_configuration.as_ref()
    }
    /// <p> Specifies information for the output results for the inference scheduler, including the output S3 location. </p>
    pub fn data_output_configuration(
        &self,
    ) -> std::option::Option<&crate::model::InferenceOutputConfiguration> {
        self.data_output_configuration.as_ref()
    }
    /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the inference scheduler being described. </p>
    pub fn role_arn(&self) -> std::option::Option<&str> {
        self.role_arn.as_deref()
    }
    /// <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
    pub fn server_side_kms_key_id(&self) -> std::option::Option<&str> {
        self.server_side_kms_key_id.as_deref()
    }
}
impl std::fmt::Debug for DescribeInferenceSchedulerOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("DescribeInferenceSchedulerOutput");
        formatter.field("model_arn", &self.model_arn);
        formatter.field("model_name", &self.model_name);
        formatter.field("inference_scheduler_name", &self.inference_scheduler_name);
        formatter.field("inference_scheduler_arn", &self.inference_scheduler_arn);
        formatter.field("status", &self.status);
        formatter.field(
            "data_delay_offset_in_minutes",
            &self.data_delay_offset_in_minutes,
        );
        formatter.field("data_upload_frequency", &self.data_upload_frequency);
        formatter.field("created_at", &self.created_at);
        formatter.field("updated_at", &self.updated_at);
        formatter.field("data_input_configuration", &self.data_input_configuration);
        formatter.field("data_output_configuration", &self.data_output_configuration);
        formatter.field("role_arn", &self.role_arn);
        formatter.field("server_side_kms_key_id", &self.server_side_kms_key_id);
        formatter.finish()
    }
}
/// See [`DescribeInferenceSchedulerOutput`](crate::output::DescribeInferenceSchedulerOutput)
pub mod describe_inference_scheduler_output {

    /// A builder for [`DescribeInferenceSchedulerOutput`](crate::output::DescribeInferenceSchedulerOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) model_arn: std::option::Option<std::string::String>,
        pub(crate) model_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_arn: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::InferenceSchedulerStatus>,
        pub(crate) data_delay_offset_in_minutes: std::option::Option<i64>,
        pub(crate) data_upload_frequency: std::option::Option<crate::model::DataUploadFrequency>,
        pub(crate) created_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) updated_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) data_input_configuration:
            std::option::Option<crate::model::InferenceInputConfiguration>,
        pub(crate) data_output_configuration:
            std::option::Option<crate::model::InferenceOutputConfiguration>,
        pub(crate) role_arn: std::option::Option<std::string::String>,
        pub(crate) server_side_kms_key_id: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the ML model of the inference scheduler being described. </p>
        pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the ML model of the inference scheduler being described. </p>
        pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_arn = input;
            self
        }
        /// <p>The name of the ML model of the inference scheduler being described. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_name = Some(input.into());
            self
        }
        /// <p>The name of the ML model of the inference scheduler being described. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_name = input;
            self
        }
        /// <p>The name of the inference scheduler being described. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_name = Some(input.into());
            self
        }
        /// <p>The name of the inference scheduler being described. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_name = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being described. </p>
        pub fn inference_scheduler_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being described. </p>
        pub fn set_inference_scheduler_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_arn = input;
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn status(mut self, input: crate::model::InferenceSchedulerStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::InferenceSchedulerStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        /// <p> A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if you select an offset delay time of five minutes, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>
        pub fn data_delay_offset_in_minutes(mut self, input: i64) -> Self {
            self.data_delay_offset_in_minutes = Some(input);
            self
        }
        /// <p> A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if you select an offset delay time of five minutes, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>
        pub fn set_data_delay_offset_in_minutes(mut self, input: std::option::Option<i64>) -> Self {
            self.data_delay_offset_in_minutes = input;
            self
        }
        /// <p>Specifies how often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes. </p>
        pub fn data_upload_frequency(mut self, input: crate::model::DataUploadFrequency) -> Self {
            self.data_upload_frequency = Some(input);
            self
        }
        /// <p>Specifies how often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes. </p>
        pub fn set_data_upload_frequency(
            mut self,
            input: std::option::Option<crate::model::DataUploadFrequency>,
        ) -> Self {
            self.data_upload_frequency = input;
            self
        }
        /// <p>Specifies the time at which the inference scheduler was created. </p>
        pub fn created_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_at = Some(input);
            self
        }
        /// <p>Specifies the time at which the inference scheduler was created. </p>
        pub fn set_created_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.created_at = input;
            self
        }
        /// <p>Specifies the time at which the inference scheduler was last updated, if it was. </p>
        pub fn updated_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.updated_at = Some(input);
            self
        }
        /// <p>Specifies the time at which the inference scheduler was last updated, if it was. </p>
        pub fn set_updated_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.updated_at = input;
            self
        }
        /// <p> Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>
        pub fn data_input_configuration(
            mut self,
            input: crate::model::InferenceInputConfiguration,
        ) -> Self {
            self.data_input_configuration = Some(input);
            self
        }
        /// <p> Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>
        pub fn set_data_input_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceInputConfiguration>,
        ) -> Self {
            self.data_input_configuration = input;
            self
        }
        /// <p> Specifies information for the output results for the inference scheduler, including the output S3 location. </p>
        pub fn data_output_configuration(
            mut self,
            input: crate::model::InferenceOutputConfiguration,
        ) -> Self {
            self.data_output_configuration = Some(input);
            self
        }
        /// <p> Specifies information for the output results for the inference scheduler, including the output S3 location. </p>
        pub fn set_data_output_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceOutputConfiguration>,
        ) -> Self {
            self.data_output_configuration = input;
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the inference scheduler being described. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.role_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the inference scheduler being described. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.role_arn = input;
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.server_side_kms_key_id = Some(input.into());
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.server_side_kms_key_id = input;
            self
        }
        /// Consumes the builder and constructs a [`DescribeInferenceSchedulerOutput`](crate::output::DescribeInferenceSchedulerOutput)
        pub fn build(self) -> crate::output::DescribeInferenceSchedulerOutput {
            crate::output::DescribeInferenceSchedulerOutput {
                model_arn: self.model_arn,
                model_name: self.model_name,
                inference_scheduler_name: self.inference_scheduler_name,
                inference_scheduler_arn: self.inference_scheduler_arn,
                status: self.status,
                data_delay_offset_in_minutes: self.data_delay_offset_in_minutes,
                data_upload_frequency: self.data_upload_frequency,
                created_at: self.created_at,
                updated_at: self.updated_at,
                data_input_configuration: self.data_input_configuration,
                data_output_configuration: self.data_output_configuration,
                role_arn: self.role_arn,
                server_side_kms_key_id: self.server_side_kms_key_id,
            }
        }
    }
}
impl DescribeInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`DescribeInferenceSchedulerOutput`](crate::output::DescribeInferenceSchedulerOutput)
    pub fn builder() -> crate::output::describe_inference_scheduler_output::Builder {
        crate::output::describe_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct DescribeDatasetOutput {
    /// <p>The name of the dataset being described. </p>
    pub dataset_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the dataset being described. </p>
    pub dataset_arn: std::option::Option<std::string::String>,
    /// <p>Specifies the time the dataset was created in Amazon Lookout for Equipment. </p>
    pub created_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Specifies the time the dataset was last updated, if it was. </p>
    pub last_updated_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates the status of the dataset. </p>
    pub status: std::option::Option<crate::model::DatasetStatus>,
    /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
    pub schema: std::option::Option<std::string::String>,
    /// <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>
    pub server_side_kms_key_id: std::option::Option<std::string::String>,
    /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
    pub ingestion_input_configuration:
        std::option::Option<crate::model::IngestionInputConfiguration>,
    /// <p> Gives statistics associated with the given dataset for the latest successful associated ingestion job id. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
    pub data_quality_summary: std::option::Option<crate::model::DataQualitySummary>,
    /// <p> IngestedFilesSummary associated with the given dataset for the latest successful associated ingestion job id. </p>
    pub ingested_files_summary: std::option::Option<crate::model::IngestedFilesSummary>,
    /// <p> The Amazon Resource Name (ARN) of the IAM role that you are using for this the data ingestion job. </p>
    pub role_arn: std::option::Option<std::string::String>,
    /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
    pub data_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
    pub data_end_time: std::option::Option<aws_smithy_types::DateTime>,
}
impl DescribeDatasetOutput {
    /// <p>The name of the dataset being described. </p>
    pub fn dataset_name(&self) -> std::option::Option<&str> {
        self.dataset_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the dataset being described. </p>
    pub fn dataset_arn(&self) -> std::option::Option<&str> {
        self.dataset_arn.as_deref()
    }
    /// <p>Specifies the time the dataset was created in Amazon Lookout for Equipment. </p>
    pub fn created_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.created_at.as_ref()
    }
    /// <p>Specifies the time the dataset was last updated, if it was. </p>
    pub fn last_updated_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.last_updated_at.as_ref()
    }
    /// <p>Indicates the status of the dataset. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::DatasetStatus> {
        self.status.as_ref()
    }
    /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
    pub fn schema(&self) -> std::option::Option<&str> {
        self.schema.as_deref()
    }
    /// <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>
    pub fn server_side_kms_key_id(&self) -> std::option::Option<&str> {
        self.server_side_kms_key_id.as_deref()
    }
    /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
    pub fn ingestion_input_configuration(
        &self,
    ) -> std::option::Option<&crate::model::IngestionInputConfiguration> {
        self.ingestion_input_configuration.as_ref()
    }
    /// <p> Gives statistics associated with the given dataset for the latest successful associated ingestion job id. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
    pub fn data_quality_summary(&self) -> std::option::Option<&crate::model::DataQualitySummary> {
        self.data_quality_summary.as_ref()
    }
    /// <p> IngestedFilesSummary associated with the given dataset for the latest successful associated ingestion job id. </p>
    pub fn ingested_files_summary(
        &self,
    ) -> std::option::Option<&crate::model::IngestedFilesSummary> {
        self.ingested_files_summary.as_ref()
    }
    /// <p> The Amazon Resource Name (ARN) of the IAM role that you are using for this the data ingestion job. </p>
    pub fn role_arn(&self) -> std::option::Option<&str> {
        self.role_arn.as_deref()
    }
    /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
    pub fn data_start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.data_start_time.as_ref()
    }
    /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
    pub fn data_end_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.data_end_time.as_ref()
    }
}
impl std::fmt::Debug for DescribeDatasetOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("DescribeDatasetOutput");
        formatter.field("dataset_name", &self.dataset_name);
        formatter.field("dataset_arn", &self.dataset_arn);
        formatter.field("created_at", &self.created_at);
        formatter.field("last_updated_at", &self.last_updated_at);
        formatter.field("status", &self.status);
        formatter.field("schema", &self.schema);
        formatter.field("server_side_kms_key_id", &self.server_side_kms_key_id);
        formatter.field(
            "ingestion_input_configuration",
            &self.ingestion_input_configuration,
        );
        formatter.field("data_quality_summary", &self.data_quality_summary);
        formatter.field("ingested_files_summary", &self.ingested_files_summary);
        formatter.field("role_arn", &self.role_arn);
        formatter.field("data_start_time", &self.data_start_time);
        formatter.field("data_end_time", &self.data_end_time);
        formatter.finish()
    }
}
/// See [`DescribeDatasetOutput`](crate::output::DescribeDatasetOutput)
pub mod describe_dataset_output {

    /// A builder for [`DescribeDatasetOutput`](crate::output::DescribeDatasetOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) dataset_name: std::option::Option<std::string::String>,
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
        pub(crate) created_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) last_updated_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) status: std::option::Option<crate::model::DatasetStatus>,
        pub(crate) schema: std::option::Option<std::string::String>,
        pub(crate) server_side_kms_key_id: std::option::Option<std::string::String>,
        pub(crate) ingestion_input_configuration:
            std::option::Option<crate::model::IngestionInputConfiguration>,
        pub(crate) data_quality_summary: std::option::Option<crate::model::DataQualitySummary>,
        pub(crate) ingested_files_summary: std::option::Option<crate::model::IngestedFilesSummary>,
        pub(crate) role_arn: std::option::Option<std::string::String>,
        pub(crate) data_start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) data_end_time: std::option::Option<aws_smithy_types::DateTime>,
    }
    impl Builder {
        /// <p>The name of the dataset being described. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_name = Some(input.into());
            self
        }
        /// <p>The name of the dataset being described. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_name = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the dataset being described. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the dataset being described. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input;
            self
        }
        /// <p>Specifies the time the dataset was created in Amazon Lookout for Equipment. </p>
        pub fn created_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_at = Some(input);
            self
        }
        /// <p>Specifies the time the dataset was created in Amazon Lookout for Equipment. </p>
        pub fn set_created_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.created_at = input;
            self
        }
        /// <p>Specifies the time the dataset was last updated, if it was. </p>
        pub fn last_updated_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.last_updated_at = Some(input);
            self
        }
        /// <p>Specifies the time the dataset was last updated, if it was. </p>
        pub fn set_last_updated_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.last_updated_at = input;
            self
        }
        /// <p>Indicates the status of the dataset. </p>
        pub fn status(mut self, input: crate::model::DatasetStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the dataset. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::DatasetStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
        pub fn schema(mut self, input: impl Into<std::string::String>) -> Self {
            self.schema = Some(input.into());
            self
        }
        /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
        pub fn set_schema(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.schema = input;
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.server_side_kms_key_id = Some(input.into());
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.server_side_kms_key_id = input;
            self
        }
        /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
        pub fn ingestion_input_configuration(
            mut self,
            input: crate::model::IngestionInputConfiguration,
        ) -> Self {
            self.ingestion_input_configuration = Some(input);
            self
        }
        /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
        pub fn set_ingestion_input_configuration(
            mut self,
            input: std::option::Option<crate::model::IngestionInputConfiguration>,
        ) -> Self {
            self.ingestion_input_configuration = input;
            self
        }
        /// <p> Gives statistics associated with the given dataset for the latest successful associated ingestion job id. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
        pub fn data_quality_summary(mut self, input: crate::model::DataQualitySummary) -> Self {
            self.data_quality_summary = Some(input);
            self
        }
        /// <p> Gives statistics associated with the given dataset for the latest successful associated ingestion job id. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
        pub fn set_data_quality_summary(
            mut self,
            input: std::option::Option<crate::model::DataQualitySummary>,
        ) -> Self {
            self.data_quality_summary = input;
            self
        }
        /// <p> IngestedFilesSummary associated with the given dataset for the latest successful associated ingestion job id. </p>
        pub fn ingested_files_summary(mut self, input: crate::model::IngestedFilesSummary) -> Self {
            self.ingested_files_summary = Some(input);
            self
        }
        /// <p> IngestedFilesSummary associated with the given dataset for the latest successful associated ingestion job id. </p>
        pub fn set_ingested_files_summary(
            mut self,
            input: std::option::Option<crate::model::IngestedFilesSummary>,
        ) -> Self {
            self.ingested_files_summary = input;
            self
        }
        /// <p> The Amazon Resource Name (ARN) of the IAM role that you are using for this the data ingestion job. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.role_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) of the IAM role that you are using for this the data ingestion job. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.role_arn = input;
            self
        }
        /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
        pub fn data_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.data_start_time = Some(input);
            self
        }
        /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
        pub fn set_data_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.data_start_time = input;
            self
        }
        /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
        pub fn data_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.data_end_time = Some(input);
            self
        }
        /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
        pub fn set_data_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.data_end_time = input;
            self
        }
        /// Consumes the builder and constructs a [`DescribeDatasetOutput`](crate::output::DescribeDatasetOutput)
        pub fn build(self) -> crate::output::DescribeDatasetOutput {
            crate::output::DescribeDatasetOutput {
                dataset_name: self.dataset_name,
                dataset_arn: self.dataset_arn,
                created_at: self.created_at,
                last_updated_at: self.last_updated_at,
                status: self.status,
                schema: self.schema,
                server_side_kms_key_id: self.server_side_kms_key_id,
                ingestion_input_configuration: self.ingestion_input_configuration,
                data_quality_summary: self.data_quality_summary,
                ingested_files_summary: self.ingested_files_summary,
                role_arn: self.role_arn,
                data_start_time: self.data_start_time,
                data_end_time: self.data_end_time,
            }
        }
    }
}
impl DescribeDatasetOutput {
    /// Creates a new builder-style object to manufacture [`DescribeDatasetOutput`](crate::output::DescribeDatasetOutput)
    pub fn builder() -> crate::output::describe_dataset_output::Builder {
        crate::output::describe_dataset_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct DescribeDataIngestionJobOutput {
    /// <p>Indicates the job ID of the data ingestion job. </p>
    pub job_id: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the dataset being used in the data ingestion job. </p>
    pub dataset_arn: std::option::Option<std::string::String>,
    /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
    pub ingestion_input_configuration:
        std::option::Option<crate::model::IngestionInputConfiguration>,
    /// <p>The Amazon Resource Name (ARN) of an IAM role with permission to access the data source being ingested. </p>
    pub role_arn: std::option::Option<std::string::String>,
    /// <p>The time at which the data ingestion job was created. </p>
    pub created_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates the status of the <code>DataIngestionJob</code> operation. </p>
    pub status: std::option::Option<crate::model::IngestionJobStatus>,
    /// <p>Specifies the reason for failure when a data ingestion job has failed. </p>
    pub failed_reason: std::option::Option<std::string::String>,
    /// <p> Gives statistics about a completed ingestion job. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
    pub data_quality_summary: std::option::Option<crate::model::DataQualitySummary>,
    /// <p>Gives statistics about how many files have been ingested, and which files have not been ingested, for a particular ingestion job.</p>
    pub ingested_files_summary: std::option::Option<crate::model::IngestedFilesSummary>,
    /// <p> Provides details about status of the ingestion job that is currently in progress. </p>
    pub status_detail: std::option::Option<std::string::String>,
    /// <p> Indicates the size of the ingested dataset. </p>
    pub ingested_data_size: std::option::Option<i64>,
    /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
    pub data_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
    pub data_end_time: std::option::Option<aws_smithy_types::DateTime>,
}
impl DescribeDataIngestionJobOutput {
    /// <p>Indicates the job ID of the data ingestion job. </p>
    pub fn job_id(&self) -> std::option::Option<&str> {
        self.job_id.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the dataset being used in the data ingestion job. </p>
    pub fn dataset_arn(&self) -> std::option::Option<&str> {
        self.dataset_arn.as_deref()
    }
    /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
    pub fn ingestion_input_configuration(
        &self,
    ) -> std::option::Option<&crate::model::IngestionInputConfiguration> {
        self.ingestion_input_configuration.as_ref()
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role with permission to access the data source being ingested. </p>
    pub fn role_arn(&self) -> std::option::Option<&str> {
        self.role_arn.as_deref()
    }
    /// <p>The time at which the data ingestion job was created. </p>
    pub fn created_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.created_at.as_ref()
    }
    /// <p>Indicates the status of the <code>DataIngestionJob</code> operation. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::IngestionJobStatus> {
        self.status.as_ref()
    }
    /// <p>Specifies the reason for failure when a data ingestion job has failed. </p>
    pub fn failed_reason(&self) -> std::option::Option<&str> {
        self.failed_reason.as_deref()
    }
    /// <p> Gives statistics about a completed ingestion job. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
    pub fn data_quality_summary(&self) -> std::option::Option<&crate::model::DataQualitySummary> {
        self.data_quality_summary.as_ref()
    }
    /// <p>Gives statistics about how many files have been ingested, and which files have not been ingested, for a particular ingestion job.</p>
    pub fn ingested_files_summary(
        &self,
    ) -> std::option::Option<&crate::model::IngestedFilesSummary> {
        self.ingested_files_summary.as_ref()
    }
    /// <p> Provides details about status of the ingestion job that is currently in progress. </p>
    pub fn status_detail(&self) -> std::option::Option<&str> {
        self.status_detail.as_deref()
    }
    /// <p> Indicates the size of the ingested dataset. </p>
    pub fn ingested_data_size(&self) -> std::option::Option<i64> {
        self.ingested_data_size
    }
    /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
    pub fn data_start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.data_start_time.as_ref()
    }
    /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
    pub fn data_end_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.data_end_time.as_ref()
    }
}
impl std::fmt::Debug for DescribeDataIngestionJobOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("DescribeDataIngestionJobOutput");
        formatter.field("job_id", &self.job_id);
        formatter.field("dataset_arn", &self.dataset_arn);
        formatter.field(
            "ingestion_input_configuration",
            &self.ingestion_input_configuration,
        );
        formatter.field("role_arn", &self.role_arn);
        formatter.field("created_at", &self.created_at);
        formatter.field("status", &self.status);
        formatter.field("failed_reason", &self.failed_reason);
        formatter.field("data_quality_summary", &self.data_quality_summary);
        formatter.field("ingested_files_summary", &self.ingested_files_summary);
        formatter.field("status_detail", &self.status_detail);
        formatter.field("ingested_data_size", &self.ingested_data_size);
        formatter.field("data_start_time", &self.data_start_time);
        formatter.field("data_end_time", &self.data_end_time);
        formatter.finish()
    }
}
/// See [`DescribeDataIngestionJobOutput`](crate::output::DescribeDataIngestionJobOutput)
pub mod describe_data_ingestion_job_output {

    /// A builder for [`DescribeDataIngestionJobOutput`](crate::output::DescribeDataIngestionJobOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
        pub(crate) ingestion_input_configuration:
            std::option::Option<crate::model::IngestionInputConfiguration>,
        pub(crate) role_arn: std::option::Option<std::string::String>,
        pub(crate) created_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) status: std::option::Option<crate::model::IngestionJobStatus>,
        pub(crate) failed_reason: std::option::Option<std::string::String>,
        pub(crate) data_quality_summary: std::option::Option<crate::model::DataQualitySummary>,
        pub(crate) ingested_files_summary: std::option::Option<crate::model::IngestedFilesSummary>,
        pub(crate) status_detail: std::option::Option<std::string::String>,
        pub(crate) ingested_data_size: std::option::Option<i64>,
        pub(crate) data_start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) data_end_time: std::option::Option<aws_smithy_types::DateTime>,
    }
    impl Builder {
        /// <p>Indicates the job ID of the data ingestion job. </p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>Indicates the job ID of the data ingestion job. </p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the dataset being used in the data ingestion job. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the dataset being used in the data ingestion job. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input;
            self
        }
        /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
        pub fn ingestion_input_configuration(
            mut self,
            input: crate::model::IngestionInputConfiguration,
        ) -> Self {
            self.ingestion_input_configuration = Some(input);
            self
        }
        /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
        pub fn set_ingestion_input_configuration(
            mut self,
            input: std::option::Option<crate::model::IngestionInputConfiguration>,
        ) -> Self {
            self.ingestion_input_configuration = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of an IAM role with permission to access the data source being ingested. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.role_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of an IAM role with permission to access the data source being ingested. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.role_arn = input;
            self
        }
        /// <p>The time at which the data ingestion job was created. </p>
        pub fn created_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_at = Some(input);
            self
        }
        /// <p>The time at which the data ingestion job was created. </p>
        pub fn set_created_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.created_at = input;
            self
        }
        /// <p>Indicates the status of the <code>DataIngestionJob</code> operation. </p>
        pub fn status(mut self, input: crate::model::IngestionJobStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the <code>DataIngestionJob</code> operation. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::IngestionJobStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        /// <p>Specifies the reason for failure when a data ingestion job has failed. </p>
        pub fn failed_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.failed_reason = Some(input.into());
            self
        }
        /// <p>Specifies the reason for failure when a data ingestion job has failed. </p>
        pub fn set_failed_reason(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.failed_reason = input;
            self
        }
        /// <p> Gives statistics about a completed ingestion job. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
        pub fn data_quality_summary(mut self, input: crate::model::DataQualitySummary) -> Self {
            self.data_quality_summary = Some(input);
            self
        }
        /// <p> Gives statistics about a completed ingestion job. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
        pub fn set_data_quality_summary(
            mut self,
            input: std::option::Option<crate::model::DataQualitySummary>,
        ) -> Self {
            self.data_quality_summary = input;
            self
        }
        /// <p>Gives statistics about how many files have been ingested, and which files have not been ingested, for a particular ingestion job.</p>
        pub fn ingested_files_summary(mut self, input: crate::model::IngestedFilesSummary) -> Self {
            self.ingested_files_summary = Some(input);
            self
        }
        /// <p>Gives statistics about how many files have been ingested, and which files have not been ingested, for a particular ingestion job.</p>
        pub fn set_ingested_files_summary(
            mut self,
            input: std::option::Option<crate::model::IngestedFilesSummary>,
        ) -> Self {
            self.ingested_files_summary = input;
            self
        }
        /// <p> Provides details about status of the ingestion job that is currently in progress. </p>
        pub fn status_detail(mut self, input: impl Into<std::string::String>) -> Self {
            self.status_detail = Some(input.into());
            self
        }
        /// <p> Provides details about status of the ingestion job that is currently in progress. </p>
        pub fn set_status_detail(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.status_detail = input;
            self
        }
        /// <p> Indicates the size of the ingested dataset. </p>
        pub fn ingested_data_size(mut self, input: i64) -> Self {
            self.ingested_data_size = Some(input);
            self
        }
        /// <p> Indicates the size of the ingested dataset. </p>
        pub fn set_ingested_data_size(mut self, input: std::option::Option<i64>) -> Self {
            self.ingested_data_size = input;
            self
        }
        /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
        pub fn data_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.data_start_time = Some(input);
            self
        }
        /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
        pub fn set_data_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.data_start_time = input;
            self
        }
        /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
        pub fn data_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.data_end_time = Some(input);
            self
        }
        /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
        pub fn set_data_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.data_end_time = input;
            self
        }
        /// Consumes the builder and constructs a [`DescribeDataIngestionJobOutput`](crate::output::DescribeDataIngestionJobOutput)
        pub fn build(self) -> crate::output::DescribeDataIngestionJobOutput {
            crate::output::DescribeDataIngestionJobOutput {
                job_id: self.job_id,
                dataset_arn: self.dataset_arn,
                ingestion_input_configuration: self.ingestion_input_configuration,
                role_arn: self.role_arn,
                created_at: self.created_at,
                status: self.status,
                failed_reason: self.failed_reason,
                data_quality_summary: self.data_quality_summary,
                ingested_files_summary: self.ingested_files_summary,
                status_detail: self.status_detail,
                ingested_data_size: self.ingested_data_size,
                data_start_time: self.data_start_time,
                data_end_time: self.data_end_time,
            }
        }
    }
}
impl DescribeDataIngestionJobOutput {
    /// Creates a new builder-style object to manufacture [`DescribeDataIngestionJobOutput`](crate::output::DescribeDataIngestionJobOutput)
    pub fn builder() -> crate::output::describe_data_ingestion_job_output::Builder {
        crate::output::describe_data_ingestion_job_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct DeleteModelOutput {}
impl std::fmt::Debug for DeleteModelOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("DeleteModelOutput");
        formatter.finish()
    }
}
/// See [`DeleteModelOutput`](crate::output::DeleteModelOutput)
pub mod delete_model_output {

    /// A builder for [`DeleteModelOutput`](crate::output::DeleteModelOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {}
    impl Builder {
        /// Consumes the builder and constructs a [`DeleteModelOutput`](crate::output::DeleteModelOutput)
        pub fn build(self) -> crate::output::DeleteModelOutput {
            crate::output::DeleteModelOutput {}
        }
    }
}
impl DeleteModelOutput {
    /// Creates a new builder-style object to manufacture [`DeleteModelOutput`](crate::output::DeleteModelOutput)
    pub fn builder() -> crate::output::delete_model_output::Builder {
        crate::output::delete_model_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct DeleteInferenceSchedulerOutput {}
impl std::fmt::Debug for DeleteInferenceSchedulerOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("DeleteInferenceSchedulerOutput");
        formatter.finish()
    }
}
/// See [`DeleteInferenceSchedulerOutput`](crate::output::DeleteInferenceSchedulerOutput)
pub mod delete_inference_scheduler_output {

    /// A builder for [`DeleteInferenceSchedulerOutput`](crate::output::DeleteInferenceSchedulerOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {}
    impl Builder {
        /// Consumes the builder and constructs a [`DeleteInferenceSchedulerOutput`](crate::output::DeleteInferenceSchedulerOutput)
        pub fn build(self) -> crate::output::DeleteInferenceSchedulerOutput {
            crate::output::DeleteInferenceSchedulerOutput {}
        }
    }
}
impl DeleteInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`DeleteInferenceSchedulerOutput`](crate::output::DeleteInferenceSchedulerOutput)
    pub fn builder() -> crate::output::delete_inference_scheduler_output::Builder {
        crate::output::delete_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct DeleteDatasetOutput {}
impl std::fmt::Debug for DeleteDatasetOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("DeleteDatasetOutput");
        formatter.finish()
    }
}
/// See [`DeleteDatasetOutput`](crate::output::DeleteDatasetOutput)
pub mod delete_dataset_output {

    /// A builder for [`DeleteDatasetOutput`](crate::output::DeleteDatasetOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {}
    impl Builder {
        /// Consumes the builder and constructs a [`DeleteDatasetOutput`](crate::output::DeleteDatasetOutput)
        pub fn build(self) -> crate::output::DeleteDatasetOutput {
            crate::output::DeleteDatasetOutput {}
        }
    }
}
impl DeleteDatasetOutput {
    /// Creates a new builder-style object to manufacture [`DeleteDatasetOutput`](crate::output::DeleteDatasetOutput)
    pub fn builder() -> crate::output::delete_dataset_output::Builder {
        crate::output::delete_dataset_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct CreateModelOutput {
    /// <p>The Amazon Resource Name (ARN) of the model being created. </p>
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the <code>CreateModel</code> operation. </p>
    pub status: std::option::Option<crate::model::ModelStatus>,
}
impl CreateModelOutput {
    /// <p>The Amazon Resource Name (ARN) of the model being created. </p>
    pub fn model_arn(&self) -> std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>Indicates the status of the <code>CreateModel</code> operation. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::ModelStatus> {
        self.status.as_ref()
    }
}
impl std::fmt::Debug for CreateModelOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("CreateModelOutput");
        formatter.field("model_arn", &self.model_arn);
        formatter.field("status", &self.status);
        formatter.finish()
    }
}
/// See [`CreateModelOutput`](crate::output::CreateModelOutput)
pub mod create_model_output {

    /// A builder for [`CreateModelOutput`](crate::output::CreateModelOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) model_arn: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::ModelStatus>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the model being created. </p>
        pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the model being created. </p>
        pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_arn = input;
            self
        }
        /// <p>Indicates the status of the <code>CreateModel</code> operation. </p>
        pub fn status(mut self, input: crate::model::ModelStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the <code>CreateModel</code> operation. </p>
        pub fn set_status(mut self, input: std::option::Option<crate::model::ModelStatus>) -> Self {
            self.status = input;
            self
        }
        /// Consumes the builder and constructs a [`CreateModelOutput`](crate::output::CreateModelOutput)
        pub fn build(self) -> crate::output::CreateModelOutput {
            crate::output::CreateModelOutput {
                model_arn: self.model_arn,
                status: self.status,
            }
        }
    }
}
impl CreateModelOutput {
    /// Creates a new builder-style object to manufacture [`CreateModelOutput`](crate::output::CreateModelOutput)
    pub fn builder() -> crate::output::create_model_output::Builder {
        crate::output::create_model_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct CreateInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being created. </p>
    pub inference_scheduler_arn: std::option::Option<std::string::String>,
    /// <p>The name of inference scheduler being created. </p>
    pub inference_scheduler_name: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the <code>CreateInferenceScheduler</code> operation. </p>
    pub status: std::option::Option<crate::model::InferenceSchedulerStatus>,
}
impl CreateInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being created. </p>
    pub fn inference_scheduler_arn(&self) -> std::option::Option<&str> {
        self.inference_scheduler_arn.as_deref()
    }
    /// <p>The name of inference scheduler being created. </p>
    pub fn inference_scheduler_name(&self) -> std::option::Option<&str> {
        self.inference_scheduler_name.as_deref()
    }
    /// <p>Indicates the status of the <code>CreateInferenceScheduler</code> operation. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::InferenceSchedulerStatus> {
        self.status.as_ref()
    }
}
impl std::fmt::Debug for CreateInferenceSchedulerOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("CreateInferenceSchedulerOutput");
        formatter.field("inference_scheduler_arn", &self.inference_scheduler_arn);
        formatter.field("inference_scheduler_name", &self.inference_scheduler_name);
        formatter.field("status", &self.status);
        formatter.finish()
    }
}
/// See [`CreateInferenceSchedulerOutput`](crate::output::CreateInferenceSchedulerOutput)
pub mod create_inference_scheduler_output {

    /// A builder for [`CreateInferenceSchedulerOutput`](crate::output::CreateInferenceSchedulerOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) inference_scheduler_arn: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_name: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::InferenceSchedulerStatus>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being created. </p>
        pub fn inference_scheduler_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being created. </p>
        pub fn set_inference_scheduler_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_arn = input;
            self
        }
        /// <p>The name of inference scheduler being created. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_name = Some(input.into());
            self
        }
        /// <p>The name of inference scheduler being created. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_name = input;
            self
        }
        /// <p>Indicates the status of the <code>CreateInferenceScheduler</code> operation. </p>
        pub fn status(mut self, input: crate::model::InferenceSchedulerStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the <code>CreateInferenceScheduler</code> operation. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::InferenceSchedulerStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        /// Consumes the builder and constructs a [`CreateInferenceSchedulerOutput`](crate::output::CreateInferenceSchedulerOutput)
        pub fn build(self) -> crate::output::CreateInferenceSchedulerOutput {
            crate::output::CreateInferenceSchedulerOutput {
                inference_scheduler_arn: self.inference_scheduler_arn,
                inference_scheduler_name: self.inference_scheduler_name,
                status: self.status,
            }
        }
    }
}
impl CreateInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`CreateInferenceSchedulerOutput`](crate::output::CreateInferenceSchedulerOutput)
    pub fn builder() -> crate::output::create_inference_scheduler_output::Builder {
        crate::output::create_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct CreateDatasetOutput {
    /// <p>The name of the dataset being created. </p>
    pub dataset_name: std::option::Option<std::string::String>,
    /// <p> The Amazon Resource Name (ARN) of the dataset being created. </p>
    pub dataset_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the <code>CreateDataset</code> operation. </p>
    pub status: std::option::Option<crate::model::DatasetStatus>,
}
impl CreateDatasetOutput {
    /// <p>The name of the dataset being created. </p>
    pub fn dataset_name(&self) -> std::option::Option<&str> {
        self.dataset_name.as_deref()
    }
    /// <p> The Amazon Resource Name (ARN) of the dataset being created. </p>
    pub fn dataset_arn(&self) -> std::option::Option<&str> {
        self.dataset_arn.as_deref()
    }
    /// <p>Indicates the status of the <code>CreateDataset</code> operation. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::DatasetStatus> {
        self.status.as_ref()
    }
}
impl std::fmt::Debug for CreateDatasetOutput {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let mut formatter = f.debug_struct("CreateDatasetOutput");
        formatter.field("dataset_name", &self.dataset_name);
        formatter.field("dataset_arn", &self.dataset_arn);
        formatter.field("status", &self.status);
        formatter.finish()
    }
}
/// See [`CreateDatasetOutput`](crate::output::CreateDatasetOutput)
pub mod create_dataset_output {

    /// A builder for [`CreateDatasetOutput`](crate::output::CreateDatasetOutput)
    #[non_exhaustive]
    #[derive(std::default::Default, std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) dataset_name: std::option::Option<std::string::String>,
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::DatasetStatus>,
    }
    impl Builder {
        /// <p>The name of the dataset being created. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_name = Some(input.into());
            self
        }
        /// <p>The name of the dataset being created. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_name = input;
            self
        }
        /// <p> The Amazon Resource Name (ARN) of the dataset being created. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) of the dataset being created. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input;
            self
        }
        /// <p>Indicates the status of the <code>CreateDataset</code> operation. </p>
        pub fn status(mut self, input: crate::model::DatasetStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the <code>CreateDataset</code> operation. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::DatasetStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        /// Consumes the builder and constructs a [`CreateDatasetOutput`](crate::output::CreateDatasetOutput)
        pub fn build(self) -> crate::output::CreateDatasetOutput {
            crate::output::CreateDatasetOutput {
                dataset_name: self.dataset_name,
                dataset_arn: self.dataset_arn,
                status: self.status,
            }
        }
    }
}
impl CreateDatasetOutput {
    /// Creates a new builder-style object to manufacture [`CreateDatasetOutput`](crate::output::CreateDatasetOutput)
    pub fn builder() -> crate::output::create_dataset_output::Builder {
        crate::output::create_dataset_output::Builder::default()
    }
}
