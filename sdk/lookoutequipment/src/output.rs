// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct UpdateLabelGroupOutput {
    _request_id: Option<String>,
}
impl aws_http::request_id::RequestId for UpdateLabelGroupOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`UpdateLabelGroupOutput`](crate::output::UpdateLabelGroupOutput).
pub mod update_label_group_output {

    /// A builder for [`UpdateLabelGroupOutput`](crate::output::UpdateLabelGroupOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        _request_id: Option<String>,
    }
    impl Builder {
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`UpdateLabelGroupOutput`](crate::output::UpdateLabelGroupOutput).
        pub fn build(self) -> crate::output::UpdateLabelGroupOutput {
            crate::output::UpdateLabelGroupOutput {
                _request_id: self._request_id,
            }
        }
    }
}
impl UpdateLabelGroupOutput {
    /// Creates a new builder-style object to manufacture [`UpdateLabelGroupOutput`](crate::output::UpdateLabelGroupOutput).
    pub fn builder() -> crate::output::update_label_group_output::Builder {
        crate::output::update_label_group_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct UpdateInferenceSchedulerOutput {
    _request_id: Option<String>,
}
impl aws_http::request_id::RequestId for UpdateInferenceSchedulerOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`UpdateInferenceSchedulerOutput`](crate::output::UpdateInferenceSchedulerOutput).
pub mod update_inference_scheduler_output {

    /// A builder for [`UpdateInferenceSchedulerOutput`](crate::output::UpdateInferenceSchedulerOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        _request_id: Option<String>,
    }
    impl Builder {
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`UpdateInferenceSchedulerOutput`](crate::output::UpdateInferenceSchedulerOutput).
        pub fn build(self) -> crate::output::UpdateInferenceSchedulerOutput {
            crate::output::UpdateInferenceSchedulerOutput {
                _request_id: self._request_id,
            }
        }
    }
}
impl UpdateInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`UpdateInferenceSchedulerOutput`](crate::output::UpdateInferenceSchedulerOutput).
    pub fn builder() -> crate::output::update_inference_scheduler_output::Builder {
        crate::output::update_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct UntagResourceOutput {
    _request_id: Option<String>,
}
impl aws_http::request_id::RequestId for UntagResourceOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`UntagResourceOutput`](crate::output::UntagResourceOutput).
pub mod untag_resource_output {

    /// A builder for [`UntagResourceOutput`](crate::output::UntagResourceOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        _request_id: Option<String>,
    }
    impl Builder {
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`UntagResourceOutput`](crate::output::UntagResourceOutput).
        pub fn build(self) -> crate::output::UntagResourceOutput {
            crate::output::UntagResourceOutput {
                _request_id: self._request_id,
            }
        }
    }
}
impl UntagResourceOutput {
    /// Creates a new builder-style object to manufacture [`UntagResourceOutput`](crate::output::UntagResourceOutput).
    pub fn builder() -> crate::output::untag_resource_output::Builder {
        crate::output::untag_resource_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct TagResourceOutput {
    _request_id: Option<String>,
}
impl aws_http::request_id::RequestId for TagResourceOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`TagResourceOutput`](crate::output::TagResourceOutput).
pub mod tag_resource_output {

    /// A builder for [`TagResourceOutput`](crate::output::TagResourceOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        _request_id: Option<String>,
    }
    impl Builder {
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`TagResourceOutput`](crate::output::TagResourceOutput).
        pub fn build(self) -> crate::output::TagResourceOutput {
            crate::output::TagResourceOutput {
                _request_id: self._request_id,
            }
        }
    }
}
impl TagResourceOutput {
    /// Creates a new builder-style object to manufacture [`TagResourceOutput`](crate::output::TagResourceOutput).
    pub fn builder() -> crate::output::tag_resource_output::Builder {
        crate::output::tag_resource_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StopInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
    #[doc(hidden)]
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
    #[doc(hidden)]
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The name of the inference scheduler being stopped. </p>
    #[doc(hidden)]
    pub inference_scheduler_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
    #[doc(hidden)]
    pub inference_scheduler_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the inference scheduler. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::InferenceSchedulerStatus>,
    _request_id: Option<String>,
}
impl StopInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
    pub fn model_arn(&self) -> std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>The name of the inference scheduler being stopped. </p>
    pub fn inference_scheduler_name(&self) -> std::option::Option<&str> {
        self.inference_scheduler_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
    pub fn inference_scheduler_arn(&self) -> std::option::Option<&str> {
        self.inference_scheduler_arn.as_deref()
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::InferenceSchedulerStatus> {
        self.status.as_ref()
    }
}
impl aws_http::request_id::RequestId for StopInferenceSchedulerOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`StopInferenceSchedulerOutput`](crate::output::StopInferenceSchedulerOutput).
pub mod stop_inference_scheduler_output {

    /// A builder for [`StopInferenceSchedulerOutput`](crate::output::StopInferenceSchedulerOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) model_arn: std::option::Option<std::string::String>,
        pub(crate) model_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_arn: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::InferenceSchedulerStatus>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
        pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>
        pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_arn = input;
            self
        }
        /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_name = Some(input.into());
            self
        }
        /// <p>The name of the ML model used by the inference scheduler being stopped. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_name = input;
            self
        }
        /// <p>The name of the inference scheduler being stopped. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_name = Some(input.into());
            self
        }
        /// <p>The name of the inference scheduler being stopped. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_name = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
        pub fn inference_scheduler_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
        pub fn set_inference_scheduler_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_arn = input;
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn status(mut self, input: crate::model::InferenceSchedulerStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::InferenceSchedulerStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`StopInferenceSchedulerOutput`](crate::output::StopInferenceSchedulerOutput).
        pub fn build(self) -> crate::output::StopInferenceSchedulerOutput {
            crate::output::StopInferenceSchedulerOutput {
                model_arn: self.model_arn,
                model_name: self.model_name,
                inference_scheduler_name: self.inference_scheduler_name,
                inference_scheduler_arn: self.inference_scheduler_arn,
                status: self.status,
                _request_id: self._request_id,
            }
        }
    }
}
impl StopInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`StopInferenceSchedulerOutput`](crate::output::StopInferenceSchedulerOutput).
    pub fn builder() -> crate::output::stop_inference_scheduler_output::Builder {
        crate::output::stop_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
    #[doc(hidden)]
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>The name of the ML model being used by the inference scheduler. </p>
    #[doc(hidden)]
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The name of the inference scheduler being started. </p>
    #[doc(hidden)]
    pub inference_scheduler_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
    #[doc(hidden)]
    pub inference_scheduler_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the inference scheduler. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::InferenceSchedulerStatus>,
    _request_id: Option<String>,
}
impl StartInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
    pub fn model_arn(&self) -> std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>The name of the ML model being used by the inference scheduler. </p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>The name of the inference scheduler being started. </p>
    pub fn inference_scheduler_name(&self) -> std::option::Option<&str> {
        self.inference_scheduler_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
    pub fn inference_scheduler_arn(&self) -> std::option::Option<&str> {
        self.inference_scheduler_arn.as_deref()
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::InferenceSchedulerStatus> {
        self.status.as_ref()
    }
}
impl aws_http::request_id::RequestId for StartInferenceSchedulerOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`StartInferenceSchedulerOutput`](crate::output::StartInferenceSchedulerOutput).
pub mod start_inference_scheduler_output {

    /// A builder for [`StartInferenceSchedulerOutput`](crate::output::StartInferenceSchedulerOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) model_arn: std::option::Option<std::string::String>,
        pub(crate) model_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_arn: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::InferenceSchedulerStatus>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
        pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>
        pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_arn = input;
            self
        }
        /// <p>The name of the ML model being used by the inference scheduler. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_name = Some(input.into());
            self
        }
        /// <p>The name of the ML model being used by the inference scheduler. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_name = input;
            self
        }
        /// <p>The name of the inference scheduler being started. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_name = Some(input.into());
            self
        }
        /// <p>The name of the inference scheduler being started. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_name = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
        pub fn inference_scheduler_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
        pub fn set_inference_scheduler_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_arn = input;
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn status(mut self, input: crate::model::InferenceSchedulerStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::InferenceSchedulerStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`StartInferenceSchedulerOutput`](crate::output::StartInferenceSchedulerOutput).
        pub fn build(self) -> crate::output::StartInferenceSchedulerOutput {
            crate::output::StartInferenceSchedulerOutput {
                model_arn: self.model_arn,
                model_name: self.model_name,
                inference_scheduler_name: self.inference_scheduler_name,
                inference_scheduler_arn: self.inference_scheduler_arn,
                status: self.status,
                _request_id: self._request_id,
            }
        }
    }
}
impl StartInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`StartInferenceSchedulerOutput`](crate::output::StartInferenceSchedulerOutput).
    pub fn builder() -> crate::output::start_inference_scheduler_output::Builder {
        crate::output::start_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StartDataIngestionJobOutput {
    /// <p>Indicates the job ID of the data ingestion job. </p>
    #[doc(hidden)]
    pub job_id: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the <code>StartDataIngestionJob</code> operation. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::IngestionJobStatus>,
    _request_id: Option<String>,
}
impl StartDataIngestionJobOutput {
    /// <p>Indicates the job ID of the data ingestion job. </p>
    pub fn job_id(&self) -> std::option::Option<&str> {
        self.job_id.as_deref()
    }
    /// <p>Indicates the status of the <code>StartDataIngestionJob</code> operation. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::IngestionJobStatus> {
        self.status.as_ref()
    }
}
impl aws_http::request_id::RequestId for StartDataIngestionJobOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`StartDataIngestionJobOutput`](crate::output::StartDataIngestionJobOutput).
pub mod start_data_ingestion_job_output {

    /// A builder for [`StartDataIngestionJobOutput`](crate::output::StartDataIngestionJobOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::IngestionJobStatus>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p>Indicates the job ID of the data ingestion job. </p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>Indicates the job ID of the data ingestion job. </p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input;
            self
        }
        /// <p>Indicates the status of the <code>StartDataIngestionJob</code> operation. </p>
        pub fn status(mut self, input: crate::model::IngestionJobStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the <code>StartDataIngestionJob</code> operation. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::IngestionJobStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`StartDataIngestionJobOutput`](crate::output::StartDataIngestionJobOutput).
        pub fn build(self) -> crate::output::StartDataIngestionJobOutput {
            crate::output::StartDataIngestionJobOutput {
                job_id: self.job_id,
                status: self.status,
                _request_id: self._request_id,
            }
        }
    }
}
impl StartDataIngestionJobOutput {
    /// Creates a new builder-style object to manufacture [`StartDataIngestionJobOutput`](crate::output::StartDataIngestionJobOutput).
    pub fn builder() -> crate::output::start_data_ingestion_job_output::Builder {
        crate::output::start_data_ingestion_job_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListTagsForResourceOutput {
    /// <p> Any tags associated with the resource. </p>
    #[doc(hidden)]
    pub tags: std::option::Option<std::vec::Vec<crate::model::Tag>>,
    _request_id: Option<String>,
}
impl ListTagsForResourceOutput {
    /// <p> Any tags associated with the resource. </p>
    pub fn tags(&self) -> std::option::Option<&[crate::model::Tag]> {
        self.tags.as_deref()
    }
}
impl aws_http::request_id::RequestId for ListTagsForResourceOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`ListTagsForResourceOutput`](crate::output::ListTagsForResourceOutput).
pub mod list_tags_for_resource_output {

    /// A builder for [`ListTagsForResourceOutput`](crate::output::ListTagsForResourceOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) tags: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// Appends an item to `tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p> Any tags associated with the resource. </p>
        pub fn tags(mut self, input: crate::model::Tag) -> Self {
            let mut v = self.tags.unwrap_or_default();
            v.push(input);
            self.tags = Some(v);
            self
        }
        /// <p> Any tags associated with the resource. </p>
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.tags = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`ListTagsForResourceOutput`](crate::output::ListTagsForResourceOutput).
        pub fn build(self) -> crate::output::ListTagsForResourceOutput {
            crate::output::ListTagsForResourceOutput {
                tags: self.tags,
                _request_id: self._request_id,
            }
        }
    }
}
impl ListTagsForResourceOutput {
    /// Creates a new builder-style object to manufacture [`ListTagsForResourceOutput`](crate::output::ListTagsForResourceOutput).
    pub fn builder() -> crate::output::list_tags_for_resource_output::Builder {
        crate::output::list_tags_for_resource_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListSensorStatisticsOutput {
    /// <p>Provides ingestion-based statistics regarding the specified sensor with respect to various validation types, such as whether data exists, the number and percentage of missing values, and the number and percentage of duplicate timestamps. </p>
    #[doc(hidden)]
    pub sensor_statistics_summaries:
        std::option::Option<std::vec::Vec<crate::model::SensorStatisticsSummary>>,
    /// <p>An opaque pagination token indicating where to continue the listing of sensor statistics. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    _request_id: Option<String>,
}
impl ListSensorStatisticsOutput {
    /// <p>Provides ingestion-based statistics regarding the specified sensor with respect to various validation types, such as whether data exists, the number and percentage of missing values, and the number and percentage of duplicate timestamps. </p>
    pub fn sensor_statistics_summaries(
        &self,
    ) -> std::option::Option<&[crate::model::SensorStatisticsSummary]> {
        self.sensor_statistics_summaries.as_deref()
    }
    /// <p>An opaque pagination token indicating where to continue the listing of sensor statistics. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
}
impl aws_http::request_id::RequestId for ListSensorStatisticsOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`ListSensorStatisticsOutput`](crate::output::ListSensorStatisticsOutput).
pub mod list_sensor_statistics_output {

    /// A builder for [`ListSensorStatisticsOutput`](crate::output::ListSensorStatisticsOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) sensor_statistics_summaries:
            std::option::Option<std::vec::Vec<crate::model::SensorStatisticsSummary>>,
        pub(crate) next_token: std::option::Option<std::string::String>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// Appends an item to `sensor_statistics_summaries`.
        ///
        /// To override the contents of this collection use [`set_sensor_statistics_summaries`](Self::set_sensor_statistics_summaries).
        ///
        /// <p>Provides ingestion-based statistics regarding the specified sensor with respect to various validation types, such as whether data exists, the number and percentage of missing values, and the number and percentage of duplicate timestamps. </p>
        pub fn sensor_statistics_summaries(
            mut self,
            input: crate::model::SensorStatisticsSummary,
        ) -> Self {
            let mut v = self.sensor_statistics_summaries.unwrap_or_default();
            v.push(input);
            self.sensor_statistics_summaries = Some(v);
            self
        }
        /// <p>Provides ingestion-based statistics regarding the specified sensor with respect to various validation types, such as whether data exists, the number and percentage of missing values, and the number and percentage of duplicate timestamps. </p>
        pub fn set_sensor_statistics_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::SensorStatisticsSummary>>,
        ) -> Self {
            self.sensor_statistics_summaries = input;
            self
        }
        /// <p>An opaque pagination token indicating where to continue the listing of sensor statistics. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>An opaque pagination token indicating where to continue the listing of sensor statistics. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`ListSensorStatisticsOutput`](crate::output::ListSensorStatisticsOutput).
        pub fn build(self) -> crate::output::ListSensorStatisticsOutput {
            crate::output::ListSensorStatisticsOutput {
                sensor_statistics_summaries: self.sensor_statistics_summaries,
                next_token: self.next_token,
                _request_id: self._request_id,
            }
        }
    }
}
impl ListSensorStatisticsOutput {
    /// Creates a new builder-style object to manufacture [`ListSensorStatisticsOutput`](crate::output::ListSensorStatisticsOutput).
    pub fn builder() -> crate::output::list_sensor_statistics_output::Builder {
        crate::output::list_sensor_statistics_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListModelsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of ML models. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Provides information on the specified model, including created time, model and dataset ARNs, and status. </p>
    #[doc(hidden)]
    pub model_summaries: std::option::Option<std::vec::Vec<crate::model::ModelSummary>>,
    _request_id: Option<String>,
}
impl ListModelsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of ML models. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Provides information on the specified model, including created time, model and dataset ARNs, and status. </p>
    pub fn model_summaries(&self) -> std::option::Option<&[crate::model::ModelSummary]> {
        self.model_summaries.as_deref()
    }
}
impl aws_http::request_id::RequestId for ListModelsOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`ListModelsOutput`](crate::output::ListModelsOutput).
pub mod list_models_output {

    /// A builder for [`ListModelsOutput`](crate::output::ListModelsOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) model_summaries: std::option::Option<std::vec::Vec<crate::model::ModelSummary>>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of ML models. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of ML models. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `model_summaries`.
        ///
        /// To override the contents of this collection use [`set_model_summaries`](Self::set_model_summaries).
        ///
        /// <p>Provides information on the specified model, including created time, model and dataset ARNs, and status. </p>
        pub fn model_summaries(mut self, input: crate::model::ModelSummary) -> Self {
            let mut v = self.model_summaries.unwrap_or_default();
            v.push(input);
            self.model_summaries = Some(v);
            self
        }
        /// <p>Provides information on the specified model, including created time, model and dataset ARNs, and status. </p>
        pub fn set_model_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::ModelSummary>>,
        ) -> Self {
            self.model_summaries = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`ListModelsOutput`](crate::output::ListModelsOutput).
        pub fn build(self) -> crate::output::ListModelsOutput {
            crate::output::ListModelsOutput {
                next_token: self.next_token,
                model_summaries: self.model_summaries,
                _request_id: self._request_id,
            }
        }
    }
}
impl ListModelsOutput {
    /// Creates a new builder-style object to manufacture [`ListModelsOutput`](crate::output::ListModelsOutput).
    pub fn builder() -> crate::output::list_models_output::Builder {
        crate::output::list_models_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListLabelsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p> A summary of the items in the label group. </p>
    #[doc(hidden)]
    pub label_summaries: std::option::Option<std::vec::Vec<crate::model::LabelSummary>>,
    _request_id: Option<String>,
}
impl ListLabelsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p> A summary of the items in the label group. </p>
    pub fn label_summaries(&self) -> std::option::Option<&[crate::model::LabelSummary]> {
        self.label_summaries.as_deref()
    }
}
impl aws_http::request_id::RequestId for ListLabelsOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`ListLabelsOutput`](crate::output::ListLabelsOutput).
pub mod list_labels_output {

    /// A builder for [`ListLabelsOutput`](crate::output::ListLabelsOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) label_summaries: std::option::Option<std::vec::Vec<crate::model::LabelSummary>>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `label_summaries`.
        ///
        /// To override the contents of this collection use [`set_label_summaries`](Self::set_label_summaries).
        ///
        /// <p> A summary of the items in the label group. </p>
        pub fn label_summaries(mut self, input: crate::model::LabelSummary) -> Self {
            let mut v = self.label_summaries.unwrap_or_default();
            v.push(input);
            self.label_summaries = Some(v);
            self
        }
        /// <p> A summary of the items in the label group. </p>
        pub fn set_label_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::LabelSummary>>,
        ) -> Self {
            self.label_summaries = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`ListLabelsOutput`](crate::output::ListLabelsOutput).
        pub fn build(self) -> crate::output::ListLabelsOutput {
            crate::output::ListLabelsOutput {
                next_token: self.next_token,
                label_summaries: self.label_summaries,
                _request_id: self._request_id,
            }
        }
    }
}
impl ListLabelsOutput {
    /// Creates a new builder-style object to manufacture [`ListLabelsOutput`](crate::output::ListLabelsOutput).
    pub fn builder() -> crate::output::list_labels_output::Builder {
        crate::output::list_labels_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListLabelGroupsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of label groups. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p> A summary of the label groups. </p>
    #[doc(hidden)]
    pub label_group_summaries: std::option::Option<std::vec::Vec<crate::model::LabelGroupSummary>>,
    _request_id: Option<String>,
}
impl ListLabelGroupsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of label groups. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p> A summary of the label groups. </p>
    pub fn label_group_summaries(&self) -> std::option::Option<&[crate::model::LabelGroupSummary]> {
        self.label_group_summaries.as_deref()
    }
}
impl aws_http::request_id::RequestId for ListLabelGroupsOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`ListLabelGroupsOutput`](crate::output::ListLabelGroupsOutput).
pub mod list_label_groups_output {

    /// A builder for [`ListLabelGroupsOutput`](crate::output::ListLabelGroupsOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) label_group_summaries:
            std::option::Option<std::vec::Vec<crate::model::LabelGroupSummary>>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of label groups. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of label groups. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `label_group_summaries`.
        ///
        /// To override the contents of this collection use [`set_label_group_summaries`](Self::set_label_group_summaries).
        ///
        /// <p> A summary of the label groups. </p>
        pub fn label_group_summaries(mut self, input: crate::model::LabelGroupSummary) -> Self {
            let mut v = self.label_group_summaries.unwrap_or_default();
            v.push(input);
            self.label_group_summaries = Some(v);
            self
        }
        /// <p> A summary of the label groups. </p>
        pub fn set_label_group_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::LabelGroupSummary>>,
        ) -> Self {
            self.label_group_summaries = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`ListLabelGroupsOutput`](crate::output::ListLabelGroupsOutput).
        pub fn build(self) -> crate::output::ListLabelGroupsOutput {
            crate::output::ListLabelGroupsOutput {
                next_token: self.next_token,
                label_group_summaries: self.label_group_summaries,
                _request_id: self._request_id,
            }
        }
    }
}
impl ListLabelGroupsOutput {
    /// Creates a new builder-style object to manufacture [`ListLabelGroupsOutput`](crate::output::ListLabelGroupsOutput).
    pub fn builder() -> crate::output::list_label_groups_output::Builder {
        crate::output::list_label_groups_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListInferenceSchedulersOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Provides information about the specified inference scheduler, including data upload frequency, model name and ARN, and status. </p>
    #[doc(hidden)]
    pub inference_scheduler_summaries:
        std::option::Option<std::vec::Vec<crate::model::InferenceSchedulerSummary>>,
    _request_id: Option<String>,
}
impl ListInferenceSchedulersOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Provides information about the specified inference scheduler, including data upload frequency, model name and ARN, and status. </p>
    pub fn inference_scheduler_summaries(
        &self,
    ) -> std::option::Option<&[crate::model::InferenceSchedulerSummary]> {
        self.inference_scheduler_summaries.as_deref()
    }
}
impl aws_http::request_id::RequestId for ListInferenceSchedulersOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`ListInferenceSchedulersOutput`](crate::output::ListInferenceSchedulersOutput).
pub mod list_inference_schedulers_output {

    /// A builder for [`ListInferenceSchedulersOutput`](crate::output::ListInferenceSchedulersOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_summaries:
            std::option::Option<std::vec::Vec<crate::model::InferenceSchedulerSummary>>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `inference_scheduler_summaries`.
        ///
        /// To override the contents of this collection use [`set_inference_scheduler_summaries`](Self::set_inference_scheduler_summaries).
        ///
        /// <p>Provides information about the specified inference scheduler, including data upload frequency, model name and ARN, and status. </p>
        pub fn inference_scheduler_summaries(
            mut self,
            input: crate::model::InferenceSchedulerSummary,
        ) -> Self {
            let mut v = self.inference_scheduler_summaries.unwrap_or_default();
            v.push(input);
            self.inference_scheduler_summaries = Some(v);
            self
        }
        /// <p>Provides information about the specified inference scheduler, including data upload frequency, model name and ARN, and status. </p>
        pub fn set_inference_scheduler_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::InferenceSchedulerSummary>>,
        ) -> Self {
            self.inference_scheduler_summaries = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`ListInferenceSchedulersOutput`](crate::output::ListInferenceSchedulersOutput).
        pub fn build(self) -> crate::output::ListInferenceSchedulersOutput {
            crate::output::ListInferenceSchedulersOutput {
                next_token: self.next_token,
                inference_scheduler_summaries: self.inference_scheduler_summaries,
                _request_id: self._request_id,
            }
        }
    }
}
impl ListInferenceSchedulersOutput {
    /// Creates a new builder-style object to manufacture [`ListInferenceSchedulersOutput`](crate::output::ListInferenceSchedulersOutput).
    pub fn builder() -> crate::output::list_inference_schedulers_output::Builder {
        crate::output::list_inference_schedulers_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListInferenceExecutionsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of inference executions. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Provides an array of information about the individual inference executions returned from the <code>ListInferenceExecutions</code> operation, including model used, inference scheduler, data configuration, and so on. </p>
    #[doc(hidden)]
    pub inference_execution_summaries:
        std::option::Option<std::vec::Vec<crate::model::InferenceExecutionSummary>>,
    _request_id: Option<String>,
}
impl ListInferenceExecutionsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of inference executions. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Provides an array of information about the individual inference executions returned from the <code>ListInferenceExecutions</code> operation, including model used, inference scheduler, data configuration, and so on. </p>
    pub fn inference_execution_summaries(
        &self,
    ) -> std::option::Option<&[crate::model::InferenceExecutionSummary]> {
        self.inference_execution_summaries.as_deref()
    }
}
impl aws_http::request_id::RequestId for ListInferenceExecutionsOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`ListInferenceExecutionsOutput`](crate::output::ListInferenceExecutionsOutput).
pub mod list_inference_executions_output {

    /// A builder for [`ListInferenceExecutionsOutput`](crate::output::ListInferenceExecutionsOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) inference_execution_summaries:
            std::option::Option<std::vec::Vec<crate::model::InferenceExecutionSummary>>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of inference executions. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of inference executions. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `inference_execution_summaries`.
        ///
        /// To override the contents of this collection use [`set_inference_execution_summaries`](Self::set_inference_execution_summaries).
        ///
        /// <p>Provides an array of information about the individual inference executions returned from the <code>ListInferenceExecutions</code> operation, including model used, inference scheduler, data configuration, and so on. </p>
        pub fn inference_execution_summaries(
            mut self,
            input: crate::model::InferenceExecutionSummary,
        ) -> Self {
            let mut v = self.inference_execution_summaries.unwrap_or_default();
            v.push(input);
            self.inference_execution_summaries = Some(v);
            self
        }
        /// <p>Provides an array of information about the individual inference executions returned from the <code>ListInferenceExecutions</code> operation, including model used, inference scheduler, data configuration, and so on. </p>
        pub fn set_inference_execution_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::InferenceExecutionSummary>>,
        ) -> Self {
            self.inference_execution_summaries = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`ListInferenceExecutionsOutput`](crate::output::ListInferenceExecutionsOutput).
        pub fn build(self) -> crate::output::ListInferenceExecutionsOutput {
            crate::output::ListInferenceExecutionsOutput {
                next_token: self.next_token,
                inference_execution_summaries: self.inference_execution_summaries,
                _request_id: self._request_id,
            }
        }
    }
}
impl ListInferenceExecutionsOutput {
    /// Creates a new builder-style object to manufacture [`ListInferenceExecutionsOutput`](crate::output::ListInferenceExecutionsOutput).
    pub fn builder() -> crate::output::list_inference_executions_output::Builder {
        crate::output::list_inference_executions_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListInferenceEventsOutput {
    /// <p>An opaque pagination token indicating where to continue the listing of inference executions. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Provides an array of information about the individual inference events returned from the <code>ListInferenceEvents</code> operation, including scheduler used, event start time, event end time, diagnostics, and so on. </p>
    #[doc(hidden)]
    pub inference_event_summaries:
        std::option::Option<std::vec::Vec<crate::model::InferenceEventSummary>>,
    _request_id: Option<String>,
}
impl ListInferenceEventsOutput {
    /// <p>An opaque pagination token indicating where to continue the listing of inference executions. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Provides an array of information about the individual inference events returned from the <code>ListInferenceEvents</code> operation, including scheduler used, event start time, event end time, diagnostics, and so on. </p>
    pub fn inference_event_summaries(
        &self,
    ) -> std::option::Option<&[crate::model::InferenceEventSummary]> {
        self.inference_event_summaries.as_deref()
    }
}
impl aws_http::request_id::RequestId for ListInferenceEventsOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`ListInferenceEventsOutput`](crate::output::ListInferenceEventsOutput).
pub mod list_inference_events_output {

    /// A builder for [`ListInferenceEventsOutput`](crate::output::ListInferenceEventsOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) inference_event_summaries:
            std::option::Option<std::vec::Vec<crate::model::InferenceEventSummary>>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p>An opaque pagination token indicating where to continue the listing of inference executions. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p>An opaque pagination token indicating where to continue the listing of inference executions. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `inference_event_summaries`.
        ///
        /// To override the contents of this collection use [`set_inference_event_summaries`](Self::set_inference_event_summaries).
        ///
        /// <p>Provides an array of information about the individual inference events returned from the <code>ListInferenceEvents</code> operation, including scheduler used, event start time, event end time, diagnostics, and so on. </p>
        pub fn inference_event_summaries(
            mut self,
            input: crate::model::InferenceEventSummary,
        ) -> Self {
            let mut v = self.inference_event_summaries.unwrap_or_default();
            v.push(input);
            self.inference_event_summaries = Some(v);
            self
        }
        /// <p>Provides an array of information about the individual inference events returned from the <code>ListInferenceEvents</code> operation, including scheduler used, event start time, event end time, diagnostics, and so on. </p>
        pub fn set_inference_event_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::InferenceEventSummary>>,
        ) -> Self {
            self.inference_event_summaries = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`ListInferenceEventsOutput`](crate::output::ListInferenceEventsOutput).
        pub fn build(self) -> crate::output::ListInferenceEventsOutput {
            crate::output::ListInferenceEventsOutput {
                next_token: self.next_token,
                inference_event_summaries: self.inference_event_summaries,
                _request_id: self._request_id,
            }
        }
    }
}
impl ListInferenceEventsOutput {
    /// Creates a new builder-style object to manufacture [`ListInferenceEventsOutput`](crate::output::ListInferenceEventsOutput).
    pub fn builder() -> crate::output::list_inference_events_output::Builder {
        crate::output::list_inference_events_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListDatasetsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Provides information about the specified dataset, including creation time, dataset ARN, and status. </p>
    #[doc(hidden)]
    pub dataset_summaries: std::option::Option<std::vec::Vec<crate::model::DatasetSummary>>,
    _request_id: Option<String>,
}
impl ListDatasetsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Provides information about the specified dataset, including creation time, dataset ARN, and status. </p>
    pub fn dataset_summaries(&self) -> std::option::Option<&[crate::model::DatasetSummary]> {
        self.dataset_summaries.as_deref()
    }
}
impl aws_http::request_id::RequestId for ListDatasetsOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`ListDatasetsOutput`](crate::output::ListDatasetsOutput).
pub mod list_datasets_output {

    /// A builder for [`ListDatasetsOutput`](crate::output::ListDatasetsOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) dataset_summaries:
            std::option::Option<std::vec::Vec<crate::model::DatasetSummary>>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of datasets. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `dataset_summaries`.
        ///
        /// To override the contents of this collection use [`set_dataset_summaries`](Self::set_dataset_summaries).
        ///
        /// <p>Provides information about the specified dataset, including creation time, dataset ARN, and status. </p>
        pub fn dataset_summaries(mut self, input: crate::model::DatasetSummary) -> Self {
            let mut v = self.dataset_summaries.unwrap_or_default();
            v.push(input);
            self.dataset_summaries = Some(v);
            self
        }
        /// <p>Provides information about the specified dataset, including creation time, dataset ARN, and status. </p>
        pub fn set_dataset_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::DatasetSummary>>,
        ) -> Self {
            self.dataset_summaries = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`ListDatasetsOutput`](crate::output::ListDatasetsOutput).
        pub fn build(self) -> crate::output::ListDatasetsOutput {
            crate::output::ListDatasetsOutput {
                next_token: self.next_token,
                dataset_summaries: self.dataset_summaries,
                _request_id: self._request_id,
            }
        }
    }
}
impl ListDatasetsOutput {
    /// Creates a new builder-style object to manufacture [`ListDatasetsOutput`](crate::output::ListDatasetsOutput).
    pub fn builder() -> crate::output::list_datasets_output::Builder {
        crate::output::list_datasets_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ListDataIngestionJobsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of data ingestion jobs. </p>
    #[doc(hidden)]
    pub next_token: std::option::Option<std::string::String>,
    /// <p>Specifies information about the specific data ingestion job, including dataset name and status. </p>
    #[doc(hidden)]
    pub data_ingestion_job_summaries:
        std::option::Option<std::vec::Vec<crate::model::DataIngestionJobSummary>>,
    _request_id: Option<String>,
}
impl ListDataIngestionJobsOutput {
    /// <p> An opaque pagination token indicating where to continue the listing of data ingestion jobs. </p>
    pub fn next_token(&self) -> std::option::Option<&str> {
        self.next_token.as_deref()
    }
    /// <p>Specifies information about the specific data ingestion job, including dataset name and status. </p>
    pub fn data_ingestion_job_summaries(
        &self,
    ) -> std::option::Option<&[crate::model::DataIngestionJobSummary]> {
        self.data_ingestion_job_summaries.as_deref()
    }
}
impl aws_http::request_id::RequestId for ListDataIngestionJobsOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`ListDataIngestionJobsOutput`](crate::output::ListDataIngestionJobsOutput).
pub mod list_data_ingestion_jobs_output {

    /// A builder for [`ListDataIngestionJobsOutput`](crate::output::ListDataIngestionJobsOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) next_token: std::option::Option<std::string::String>,
        pub(crate) data_ingestion_job_summaries:
            std::option::Option<std::vec::Vec<crate::model::DataIngestionJobSummary>>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p> An opaque pagination token indicating where to continue the listing of data ingestion jobs. </p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.next_token = Some(input.into());
            self
        }
        /// <p> An opaque pagination token indicating where to continue the listing of data ingestion jobs. </p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.next_token = input;
            self
        }
        /// Appends an item to `data_ingestion_job_summaries`.
        ///
        /// To override the contents of this collection use [`set_data_ingestion_job_summaries`](Self::set_data_ingestion_job_summaries).
        ///
        /// <p>Specifies information about the specific data ingestion job, including dataset name and status. </p>
        pub fn data_ingestion_job_summaries(
            mut self,
            input: crate::model::DataIngestionJobSummary,
        ) -> Self {
            let mut v = self.data_ingestion_job_summaries.unwrap_or_default();
            v.push(input);
            self.data_ingestion_job_summaries = Some(v);
            self
        }
        /// <p>Specifies information about the specific data ingestion job, including dataset name and status. </p>
        pub fn set_data_ingestion_job_summaries(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::DataIngestionJobSummary>>,
        ) -> Self {
            self.data_ingestion_job_summaries = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`ListDataIngestionJobsOutput`](crate::output::ListDataIngestionJobsOutput).
        pub fn build(self) -> crate::output::ListDataIngestionJobsOutput {
            crate::output::ListDataIngestionJobsOutput {
                next_token: self.next_token,
                data_ingestion_job_summaries: self.data_ingestion_job_summaries,
                _request_id: self._request_id,
            }
        }
    }
}
impl ListDataIngestionJobsOutput {
    /// Creates a new builder-style object to manufacture [`ListDataIngestionJobsOutput`](crate::output::ListDataIngestionJobsOutput).
    pub fn builder() -> crate::output::list_data_ingestion_jobs_output::Builder {
        crate::output::list_data_ingestion_jobs_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeModelOutput {
    /// <p>The name of the ML model being described. </p>
    #[doc(hidden)]
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the ML model being described. </p>
    #[doc(hidden)]
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>The name of the dataset being used by the ML being described. </p>
    #[doc(hidden)]
    pub dataset_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resouce Name (ARN) of the dataset used to create the ML model being described. </p>
    #[doc(hidden)]
    pub dataset_arn: std::option::Option<std::string::String>,
    /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
    #[doc(hidden)]
    pub schema: std::option::Option<std::string::String>,
    /// <p>Specifies configuration information about the labels input, including its S3 location. </p>
    #[doc(hidden)]
    pub labels_input_configuration: std::option::Option<crate::model::LabelsInputConfiguration>,
    /// <p> Indicates the time reference in the dataset that was used to begin the subset of training data for the ML model. </p>
    #[doc(hidden)]
    pub training_data_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Indicates the time reference in the dataset that was used to end the subset of training data for the ML model. </p>
    #[doc(hidden)]
    pub training_data_end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Indicates the time reference in the dataset that was used to begin the subset of evaluation data for the ML model. </p>
    #[doc(hidden)]
    pub evaluation_data_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Indicates the time reference in the dataset that was used to end the subset of evaluation data for the ML model. </p>
    #[doc(hidden)]
    pub evaluation_data_end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the ML model being described. </p>
    #[doc(hidden)]
    pub role_arn: std::option::Option<std::string::String>,
    /// <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p>
    /// <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix "PT" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>
    #[doc(hidden)]
    pub data_pre_processing_configuration:
        std::option::Option<crate::model::DataPreProcessingConfiguration>,
    /// <p>Specifies the current status of the model being described. Status describes the status of the most recent action of the model. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::ModelStatus>,
    /// <p>Indicates the time at which the training of the ML model began. </p>
    #[doc(hidden)]
    pub training_execution_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates the time at which the training of the ML model was completed. </p>
    #[doc(hidden)]
    pub training_execution_end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>If the training of the ML model failed, this indicates the reason for that failure. </p>
    #[doc(hidden)]
    pub failed_reason: std::option::Option<std::string::String>,
    /// <p>The Model Metrics show an aggregated summary of the model's performance within the evaluation time range. This is the JSON content of the metrics created when evaluating the model. </p>
    #[doc(hidden)]
    pub model_metrics: std::option::Option<std::string::String>,
    /// <p>Indicates the last time the ML model was updated. The type of update is not specified. </p>
    #[doc(hidden)]
    pub last_updated_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates the time and date at which the ML model was created. </p>
    #[doc(hidden)]
    pub created_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>
    #[doc(hidden)]
    pub server_side_kms_key_id: std::option::Option<std::string::String>,
    /// <p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>
    #[doc(hidden)]
    pub off_condition: std::option::Option<std::string::String>,
    _request_id: Option<String>,
}
impl DescribeModelOutput {
    /// <p>The name of the ML model being described. </p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the ML model being described. </p>
    pub fn model_arn(&self) -> std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>The name of the dataset being used by the ML being described. </p>
    pub fn dataset_name(&self) -> std::option::Option<&str> {
        self.dataset_name.as_deref()
    }
    /// <p>The Amazon Resouce Name (ARN) of the dataset used to create the ML model being described. </p>
    pub fn dataset_arn(&self) -> std::option::Option<&str> {
        self.dataset_arn.as_deref()
    }
    /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
    pub fn schema(&self) -> std::option::Option<&str> {
        self.schema.as_deref()
    }
    /// <p>Specifies configuration information about the labels input, including its S3 location. </p>
    pub fn labels_input_configuration(
        &self,
    ) -> std::option::Option<&crate::model::LabelsInputConfiguration> {
        self.labels_input_configuration.as_ref()
    }
    /// <p> Indicates the time reference in the dataset that was used to begin the subset of training data for the ML model. </p>
    pub fn training_data_start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.training_data_start_time.as_ref()
    }
    /// <p> Indicates the time reference in the dataset that was used to end the subset of training data for the ML model. </p>
    pub fn training_data_end_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.training_data_end_time.as_ref()
    }
    /// <p> Indicates the time reference in the dataset that was used to begin the subset of evaluation data for the ML model. </p>
    pub fn evaluation_data_start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.evaluation_data_start_time.as_ref()
    }
    /// <p> Indicates the time reference in the dataset that was used to end the subset of evaluation data for the ML model. </p>
    pub fn evaluation_data_end_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.evaluation_data_end_time.as_ref()
    }
    /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the ML model being described. </p>
    pub fn role_arn(&self) -> std::option::Option<&str> {
        self.role_arn.as_deref()
    }
    /// <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p>
    /// <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix "PT" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>
    pub fn data_pre_processing_configuration(
        &self,
    ) -> std::option::Option<&crate::model::DataPreProcessingConfiguration> {
        self.data_pre_processing_configuration.as_ref()
    }
    /// <p>Specifies the current status of the model being described. Status describes the status of the most recent action of the model. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::ModelStatus> {
        self.status.as_ref()
    }
    /// <p>Indicates the time at which the training of the ML model began. </p>
    pub fn training_execution_start_time(
        &self,
    ) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.training_execution_start_time.as_ref()
    }
    /// <p>Indicates the time at which the training of the ML model was completed. </p>
    pub fn training_execution_end_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.training_execution_end_time.as_ref()
    }
    /// <p>If the training of the ML model failed, this indicates the reason for that failure. </p>
    pub fn failed_reason(&self) -> std::option::Option<&str> {
        self.failed_reason.as_deref()
    }
    /// <p>The Model Metrics show an aggregated summary of the model's performance within the evaluation time range. This is the JSON content of the metrics created when evaluating the model. </p>
    pub fn model_metrics(&self) -> std::option::Option<&str> {
        self.model_metrics.as_deref()
    }
    /// <p>Indicates the last time the ML model was updated. The type of update is not specified. </p>
    pub fn last_updated_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.last_updated_time.as_ref()
    }
    /// <p>Indicates the time and date at which the ML model was created. </p>
    pub fn created_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.created_at.as_ref()
    }
    /// <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>
    pub fn server_side_kms_key_id(&self) -> std::option::Option<&str> {
        self.server_side_kms_key_id.as_deref()
    }
    /// <p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>
    pub fn off_condition(&self) -> std::option::Option<&str> {
        self.off_condition.as_deref()
    }
}
impl aws_http::request_id::RequestId for DescribeModelOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`DescribeModelOutput`](crate::output::DescribeModelOutput).
pub mod describe_model_output {

    /// A builder for [`DescribeModelOutput`](crate::output::DescribeModelOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) model_name: std::option::Option<std::string::String>,
        pub(crate) model_arn: std::option::Option<std::string::String>,
        pub(crate) dataset_name: std::option::Option<std::string::String>,
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
        pub(crate) schema: std::option::Option<std::string::String>,
        pub(crate) labels_input_configuration:
            std::option::Option<crate::model::LabelsInputConfiguration>,
        pub(crate) training_data_start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) training_data_end_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) evaluation_data_start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) evaluation_data_end_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) role_arn: std::option::Option<std::string::String>,
        pub(crate) data_pre_processing_configuration:
            std::option::Option<crate::model::DataPreProcessingConfiguration>,
        pub(crate) status: std::option::Option<crate::model::ModelStatus>,
        pub(crate) training_execution_start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) training_execution_end_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) failed_reason: std::option::Option<std::string::String>,
        pub(crate) model_metrics: std::option::Option<std::string::String>,
        pub(crate) last_updated_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) created_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) server_side_kms_key_id: std::option::Option<std::string::String>,
        pub(crate) off_condition: std::option::Option<std::string::String>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p>The name of the ML model being described. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_name = Some(input.into());
            self
        }
        /// <p>The name of the ML model being described. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_name = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the ML model being described. </p>
        pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the ML model being described. </p>
        pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_arn = input;
            self
        }
        /// <p>The name of the dataset being used by the ML being described. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_name = Some(input.into());
            self
        }
        /// <p>The name of the dataset being used by the ML being described. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_name = input;
            self
        }
        /// <p>The Amazon Resouce Name (ARN) of the dataset used to create the ML model being described. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resouce Name (ARN) of the dataset used to create the ML model being described. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input;
            self
        }
        /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
        pub fn schema(mut self, input: impl Into<std::string::String>) -> Self {
            self.schema = Some(input.into());
            self
        }
        /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
        pub fn set_schema(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.schema = input;
            self
        }
        /// <p>Specifies configuration information about the labels input, including its S3 location. </p>
        pub fn labels_input_configuration(
            mut self,
            input: crate::model::LabelsInputConfiguration,
        ) -> Self {
            self.labels_input_configuration = Some(input);
            self
        }
        /// <p>Specifies configuration information about the labels input, including its S3 location. </p>
        pub fn set_labels_input_configuration(
            mut self,
            input: std::option::Option<crate::model::LabelsInputConfiguration>,
        ) -> Self {
            self.labels_input_configuration = input;
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to begin the subset of training data for the ML model. </p>
        pub fn training_data_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.training_data_start_time = Some(input);
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to begin the subset of training data for the ML model. </p>
        pub fn set_training_data_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.training_data_start_time = input;
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to end the subset of training data for the ML model. </p>
        pub fn training_data_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.training_data_end_time = Some(input);
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to end the subset of training data for the ML model. </p>
        pub fn set_training_data_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.training_data_end_time = input;
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to begin the subset of evaluation data for the ML model. </p>
        pub fn evaluation_data_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.evaluation_data_start_time = Some(input);
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to begin the subset of evaluation data for the ML model. </p>
        pub fn set_evaluation_data_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.evaluation_data_start_time = input;
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to end the subset of evaluation data for the ML model. </p>
        pub fn evaluation_data_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.evaluation_data_end_time = Some(input);
            self
        }
        /// <p> Indicates the time reference in the dataset that was used to end the subset of evaluation data for the ML model. </p>
        pub fn set_evaluation_data_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.evaluation_data_end_time = input;
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the ML model being described. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.role_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the ML model being described. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.role_arn = input;
            self
        }
        /// <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p>
        /// <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix "PT" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>
        pub fn data_pre_processing_configuration(
            mut self,
            input: crate::model::DataPreProcessingConfiguration,
        ) -> Self {
            self.data_pre_processing_configuration = Some(input);
            self
        }
        /// <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p>
        /// <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix "PT" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>
        pub fn set_data_pre_processing_configuration(
            mut self,
            input: std::option::Option<crate::model::DataPreProcessingConfiguration>,
        ) -> Self {
            self.data_pre_processing_configuration = input;
            self
        }
        /// <p>Specifies the current status of the model being described. Status describes the status of the most recent action of the model. </p>
        pub fn status(mut self, input: crate::model::ModelStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Specifies the current status of the model being described. Status describes the status of the most recent action of the model. </p>
        pub fn set_status(mut self, input: std::option::Option<crate::model::ModelStatus>) -> Self {
            self.status = input;
            self
        }
        /// <p>Indicates the time at which the training of the ML model began. </p>
        pub fn training_execution_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.training_execution_start_time = Some(input);
            self
        }
        /// <p>Indicates the time at which the training of the ML model began. </p>
        pub fn set_training_execution_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.training_execution_start_time = input;
            self
        }
        /// <p>Indicates the time at which the training of the ML model was completed. </p>
        pub fn training_execution_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.training_execution_end_time = Some(input);
            self
        }
        /// <p>Indicates the time at which the training of the ML model was completed. </p>
        pub fn set_training_execution_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.training_execution_end_time = input;
            self
        }
        /// <p>If the training of the ML model failed, this indicates the reason for that failure. </p>
        pub fn failed_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.failed_reason = Some(input.into());
            self
        }
        /// <p>If the training of the ML model failed, this indicates the reason for that failure. </p>
        pub fn set_failed_reason(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.failed_reason = input;
            self
        }
        /// <p>The Model Metrics show an aggregated summary of the model's performance within the evaluation time range. This is the JSON content of the metrics created when evaluating the model. </p>
        pub fn model_metrics(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_metrics = Some(input.into());
            self
        }
        /// <p>The Model Metrics show an aggregated summary of the model's performance within the evaluation time range. This is the JSON content of the metrics created when evaluating the model. </p>
        pub fn set_model_metrics(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.model_metrics = input;
            self
        }
        /// <p>Indicates the last time the ML model was updated. The type of update is not specified. </p>
        pub fn last_updated_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.last_updated_time = Some(input);
            self
        }
        /// <p>Indicates the last time the ML model was updated. The type of update is not specified. </p>
        pub fn set_last_updated_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.last_updated_time = input;
            self
        }
        /// <p>Indicates the time and date at which the ML model was created. </p>
        pub fn created_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_at = Some(input);
            self
        }
        /// <p>Indicates the time and date at which the ML model was created. </p>
        pub fn set_created_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.created_at = input;
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.server_side_kms_key_id = Some(input.into());
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.server_side_kms_key_id = input;
            self
        }
        /// <p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>
        pub fn off_condition(mut self, input: impl Into<std::string::String>) -> Self {
            self.off_condition = Some(input.into());
            self
        }
        /// <p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>
        pub fn set_off_condition(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.off_condition = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`DescribeModelOutput`](crate::output::DescribeModelOutput).
        pub fn build(self) -> crate::output::DescribeModelOutput {
            crate::output::DescribeModelOutput {
                model_name: self.model_name,
                model_arn: self.model_arn,
                dataset_name: self.dataset_name,
                dataset_arn: self.dataset_arn,
                schema: self.schema,
                labels_input_configuration: self.labels_input_configuration,
                training_data_start_time: self.training_data_start_time,
                training_data_end_time: self.training_data_end_time,
                evaluation_data_start_time: self.evaluation_data_start_time,
                evaluation_data_end_time: self.evaluation_data_end_time,
                role_arn: self.role_arn,
                data_pre_processing_configuration: self.data_pre_processing_configuration,
                status: self.status,
                training_execution_start_time: self.training_execution_start_time,
                training_execution_end_time: self.training_execution_end_time,
                failed_reason: self.failed_reason,
                model_metrics: self.model_metrics,
                last_updated_time: self.last_updated_time,
                created_at: self.created_at,
                server_side_kms_key_id: self.server_side_kms_key_id,
                off_condition: self.off_condition,
                _request_id: self._request_id,
            }
        }
    }
}
impl DescribeModelOutput {
    /// Creates a new builder-style object to manufacture [`DescribeModelOutput`](crate::output::DescribeModelOutput).
    pub fn builder() -> crate::output::describe_model_output::Builder {
        crate::output::describe_model_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeLabelGroupOutput {
    /// <p> The name of the label group. </p>
    #[doc(hidden)]
    pub label_group_name: std::option::Option<std::string::String>,
    /// <p> The ARN of the label group. </p>
    #[doc(hidden)]
    pub label_group_arn: std::option::Option<std::string::String>,
    /// <p> Codes indicating the type of anomaly associated with the labels in the lagbel group. </p>
    #[doc(hidden)]
    pub fault_codes: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p> The time at which the label group was created. </p>
    #[doc(hidden)]
    pub created_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> The time at which the label group was updated. </p>
    #[doc(hidden)]
    pub updated_at: std::option::Option<aws_smithy_types::DateTime>,
    _request_id: Option<String>,
}
impl DescribeLabelGroupOutput {
    /// <p> The name of the label group. </p>
    pub fn label_group_name(&self) -> std::option::Option<&str> {
        self.label_group_name.as_deref()
    }
    /// <p> The ARN of the label group. </p>
    pub fn label_group_arn(&self) -> std::option::Option<&str> {
        self.label_group_arn.as_deref()
    }
    /// <p> Codes indicating the type of anomaly associated with the labels in the lagbel group. </p>
    pub fn fault_codes(&self) -> std::option::Option<&[std::string::String]> {
        self.fault_codes.as_deref()
    }
    /// <p> The time at which the label group was created. </p>
    pub fn created_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.created_at.as_ref()
    }
    /// <p> The time at which the label group was updated. </p>
    pub fn updated_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.updated_at.as_ref()
    }
}
impl aws_http::request_id::RequestId for DescribeLabelGroupOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`DescribeLabelGroupOutput`](crate::output::DescribeLabelGroupOutput).
pub mod describe_label_group_output {

    /// A builder for [`DescribeLabelGroupOutput`](crate::output::DescribeLabelGroupOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) label_group_name: std::option::Option<std::string::String>,
        pub(crate) label_group_arn: std::option::Option<std::string::String>,
        pub(crate) fault_codes: std::option::Option<std::vec::Vec<std::string::String>>,
        pub(crate) created_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) updated_at: std::option::Option<aws_smithy_types::DateTime>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p> The name of the label group. </p>
        pub fn label_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.label_group_name = Some(input.into());
            self
        }
        /// <p> The name of the label group. </p>
        pub fn set_label_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.label_group_name = input;
            self
        }
        /// <p> The ARN of the label group. </p>
        pub fn label_group_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.label_group_arn = Some(input.into());
            self
        }
        /// <p> The ARN of the label group. </p>
        pub fn set_label_group_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.label_group_arn = input;
            self
        }
        /// Appends an item to `fault_codes`.
        ///
        /// To override the contents of this collection use [`set_fault_codes`](Self::set_fault_codes).
        ///
        /// <p> Codes indicating the type of anomaly associated with the labels in the lagbel group. </p>
        pub fn fault_codes(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.fault_codes.unwrap_or_default();
            v.push(input.into());
            self.fault_codes = Some(v);
            self
        }
        /// <p> Codes indicating the type of anomaly associated with the labels in the lagbel group. </p>
        pub fn set_fault_codes(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.fault_codes = input;
            self
        }
        /// <p> The time at which the label group was created. </p>
        pub fn created_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_at = Some(input);
            self
        }
        /// <p> The time at which the label group was created. </p>
        pub fn set_created_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.created_at = input;
            self
        }
        /// <p> The time at which the label group was updated. </p>
        pub fn updated_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.updated_at = Some(input);
            self
        }
        /// <p> The time at which the label group was updated. </p>
        pub fn set_updated_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.updated_at = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`DescribeLabelGroupOutput`](crate::output::DescribeLabelGroupOutput).
        pub fn build(self) -> crate::output::DescribeLabelGroupOutput {
            crate::output::DescribeLabelGroupOutput {
                label_group_name: self.label_group_name,
                label_group_arn: self.label_group_arn,
                fault_codes: self.fault_codes,
                created_at: self.created_at,
                updated_at: self.updated_at,
                _request_id: self._request_id,
            }
        }
    }
}
impl DescribeLabelGroupOutput {
    /// Creates a new builder-style object to manufacture [`DescribeLabelGroupOutput`](crate::output::DescribeLabelGroupOutput).
    pub fn builder() -> crate::output::describe_label_group_output::Builder {
        crate::output::describe_label_group_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeLabelOutput {
    /// <p> The name of the requested label group. </p>
    #[doc(hidden)]
    pub label_group_name: std::option::Option<std::string::String>,
    /// <p> The ARN of the requested label group. </p>
    #[doc(hidden)]
    pub label_group_arn: std::option::Option<std::string::String>,
    /// <p> The ID of the requested label. </p>
    #[doc(hidden)]
    pub label_id: std::option::Option<std::string::String>,
    /// <p> The start time of the requested label. </p>
    #[doc(hidden)]
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> The end time of the requested label. </p>
    #[doc(hidden)]
    pub end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Indicates whether a labeled event represents an anomaly. </p>
    #[doc(hidden)]
    pub rating: std::option::Option<crate::model::LabelRating>,
    /// <p> Indicates the type of anomaly associated with the label. </p>
    /// <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>
    #[doc(hidden)]
    pub fault_code: std::option::Option<std::string::String>,
    /// <p>Metadata providing additional information about the label.</p>
    /// <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>
    #[doc(hidden)]
    pub notes: std::option::Option<std::string::String>,
    /// <p> Indicates that a label pertains to a particular piece of equipment. </p>
    #[doc(hidden)]
    pub equipment: std::option::Option<std::string::String>,
    /// <p> The time at which the label was created. </p>
    #[doc(hidden)]
    pub created_at: std::option::Option<aws_smithy_types::DateTime>,
    _request_id: Option<String>,
}
impl DescribeLabelOutput {
    /// <p> The name of the requested label group. </p>
    pub fn label_group_name(&self) -> std::option::Option<&str> {
        self.label_group_name.as_deref()
    }
    /// <p> The ARN of the requested label group. </p>
    pub fn label_group_arn(&self) -> std::option::Option<&str> {
        self.label_group_arn.as_deref()
    }
    /// <p> The ID of the requested label. </p>
    pub fn label_id(&self) -> std::option::Option<&str> {
        self.label_id.as_deref()
    }
    /// <p> The start time of the requested label. </p>
    pub fn start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p> The end time of the requested label. </p>
    pub fn end_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.end_time.as_ref()
    }
    /// <p> Indicates whether a labeled event represents an anomaly. </p>
    pub fn rating(&self) -> std::option::Option<&crate::model::LabelRating> {
        self.rating.as_ref()
    }
    /// <p> Indicates the type of anomaly associated with the label. </p>
    /// <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>
    pub fn fault_code(&self) -> std::option::Option<&str> {
        self.fault_code.as_deref()
    }
    /// <p>Metadata providing additional information about the label.</p>
    /// <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>
    pub fn notes(&self) -> std::option::Option<&str> {
        self.notes.as_deref()
    }
    /// <p> Indicates that a label pertains to a particular piece of equipment. </p>
    pub fn equipment(&self) -> std::option::Option<&str> {
        self.equipment.as_deref()
    }
    /// <p> The time at which the label was created. </p>
    pub fn created_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.created_at.as_ref()
    }
}
impl aws_http::request_id::RequestId for DescribeLabelOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`DescribeLabelOutput`](crate::output::DescribeLabelOutput).
pub mod describe_label_output {

    /// A builder for [`DescribeLabelOutput`](crate::output::DescribeLabelOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) label_group_name: std::option::Option<std::string::String>,
        pub(crate) label_group_arn: std::option::Option<std::string::String>,
        pub(crate) label_id: std::option::Option<std::string::String>,
        pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) end_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) rating: std::option::Option<crate::model::LabelRating>,
        pub(crate) fault_code: std::option::Option<std::string::String>,
        pub(crate) notes: std::option::Option<std::string::String>,
        pub(crate) equipment: std::option::Option<std::string::String>,
        pub(crate) created_at: std::option::Option<aws_smithy_types::DateTime>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p> The name of the requested label group. </p>
        pub fn label_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.label_group_name = Some(input.into());
            self
        }
        /// <p> The name of the requested label group. </p>
        pub fn set_label_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.label_group_name = input;
            self
        }
        /// <p> The ARN of the requested label group. </p>
        pub fn label_group_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.label_group_arn = Some(input.into());
            self
        }
        /// <p> The ARN of the requested label group. </p>
        pub fn set_label_group_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.label_group_arn = input;
            self
        }
        /// <p> The ID of the requested label. </p>
        pub fn label_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.label_id = Some(input.into());
            self
        }
        /// <p> The ID of the requested label. </p>
        pub fn set_label_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.label_id = input;
            self
        }
        /// <p> The start time of the requested label. </p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p> The start time of the requested label. </p>
        pub fn set_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.start_time = input;
            self
        }
        /// <p> The end time of the requested label. </p>
        pub fn end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.end_time = Some(input);
            self
        }
        /// <p> The end time of the requested label. </p>
        pub fn set_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.end_time = input;
            self
        }
        /// <p> Indicates whether a labeled event represents an anomaly. </p>
        pub fn rating(mut self, input: crate::model::LabelRating) -> Self {
            self.rating = Some(input);
            self
        }
        /// <p> Indicates whether a labeled event represents an anomaly. </p>
        pub fn set_rating(mut self, input: std::option::Option<crate::model::LabelRating>) -> Self {
            self.rating = input;
            self
        }
        /// <p> Indicates the type of anomaly associated with the label. </p>
        /// <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>
        pub fn fault_code(mut self, input: impl Into<std::string::String>) -> Self {
            self.fault_code = Some(input.into());
            self
        }
        /// <p> Indicates the type of anomaly associated with the label. </p>
        /// <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>
        pub fn set_fault_code(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.fault_code = input;
            self
        }
        /// <p>Metadata providing additional information about the label.</p>
        /// <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>
        pub fn notes(mut self, input: impl Into<std::string::String>) -> Self {
            self.notes = Some(input.into());
            self
        }
        /// <p>Metadata providing additional information about the label.</p>
        /// <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>
        pub fn set_notes(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.notes = input;
            self
        }
        /// <p> Indicates that a label pertains to a particular piece of equipment. </p>
        pub fn equipment(mut self, input: impl Into<std::string::String>) -> Self {
            self.equipment = Some(input.into());
            self
        }
        /// <p> Indicates that a label pertains to a particular piece of equipment. </p>
        pub fn set_equipment(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.equipment = input;
            self
        }
        /// <p> The time at which the label was created. </p>
        pub fn created_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_at = Some(input);
            self
        }
        /// <p> The time at which the label was created. </p>
        pub fn set_created_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.created_at = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`DescribeLabelOutput`](crate::output::DescribeLabelOutput).
        pub fn build(self) -> crate::output::DescribeLabelOutput {
            crate::output::DescribeLabelOutput {
                label_group_name: self.label_group_name,
                label_group_arn: self.label_group_arn,
                label_id: self.label_id,
                start_time: self.start_time,
                end_time: self.end_time,
                rating: self.rating,
                fault_code: self.fault_code,
                notes: self.notes,
                equipment: self.equipment,
                created_at: self.created_at,
                _request_id: self._request_id,
            }
        }
    }
}
impl DescribeLabelOutput {
    /// Creates a new builder-style object to manufacture [`DescribeLabelOutput`](crate::output::DescribeLabelOutput).
    pub fn builder() -> crate::output::describe_label_output::Builder {
        crate::output::describe_label_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model of the inference scheduler being described. </p>
    #[doc(hidden)]
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>The name of the ML model of the inference scheduler being described. </p>
    #[doc(hidden)]
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The name of the inference scheduler being described. </p>
    #[doc(hidden)]
    pub inference_scheduler_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being described. </p>
    #[doc(hidden)]
    pub inference_scheduler_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the inference scheduler. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::InferenceSchedulerStatus>,
    /// <p> A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if you select an offset delay time of five minutes, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>
    #[doc(hidden)]
    pub data_delay_offset_in_minutes: std::option::Option<i64>,
    /// <p>Specifies how often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes. </p>
    #[doc(hidden)]
    pub data_upload_frequency: std::option::Option<crate::model::DataUploadFrequency>,
    /// <p>Specifies the time at which the inference scheduler was created. </p>
    #[doc(hidden)]
    pub created_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Specifies the time at which the inference scheduler was last updated, if it was. </p>
    #[doc(hidden)]
    pub updated_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>
    #[doc(hidden)]
    pub data_input_configuration: std::option::Option<crate::model::InferenceInputConfiguration>,
    /// <p> Specifies information for the output results for the inference scheduler, including the output S3 location. </p>
    #[doc(hidden)]
    pub data_output_configuration: std::option::Option<crate::model::InferenceOutputConfiguration>,
    /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the inference scheduler being described. </p>
    #[doc(hidden)]
    pub role_arn: std::option::Option<std::string::String>,
    /// <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
    #[doc(hidden)]
    pub server_side_kms_key_id: std::option::Option<std::string::String>,
    /// <p>Indicates whether the latest execution for the inference scheduler was Anomalous (anomalous events found) or Normal (no anomalous events found).</p>
    #[doc(hidden)]
    pub latest_inference_result: std::option::Option<crate::model::LatestInferenceResult>,
    _request_id: Option<String>,
}
impl DescribeInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the ML model of the inference scheduler being described. </p>
    pub fn model_arn(&self) -> std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>The name of the ML model of the inference scheduler being described. </p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>The name of the inference scheduler being described. </p>
    pub fn inference_scheduler_name(&self) -> std::option::Option<&str> {
        self.inference_scheduler_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being described. </p>
    pub fn inference_scheduler_arn(&self) -> std::option::Option<&str> {
        self.inference_scheduler_arn.as_deref()
    }
    /// <p>Indicates the status of the inference scheduler. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::InferenceSchedulerStatus> {
        self.status.as_ref()
    }
    /// <p> A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if you select an offset delay time of five minutes, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>
    pub fn data_delay_offset_in_minutes(&self) -> std::option::Option<i64> {
        self.data_delay_offset_in_minutes
    }
    /// <p>Specifies how often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes. </p>
    pub fn data_upload_frequency(&self) -> std::option::Option<&crate::model::DataUploadFrequency> {
        self.data_upload_frequency.as_ref()
    }
    /// <p>Specifies the time at which the inference scheduler was created. </p>
    pub fn created_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.created_at.as_ref()
    }
    /// <p>Specifies the time at which the inference scheduler was last updated, if it was. </p>
    pub fn updated_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.updated_at.as_ref()
    }
    /// <p> Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>
    pub fn data_input_configuration(
        &self,
    ) -> std::option::Option<&crate::model::InferenceInputConfiguration> {
        self.data_input_configuration.as_ref()
    }
    /// <p> Specifies information for the output results for the inference scheduler, including the output S3 location. </p>
    pub fn data_output_configuration(
        &self,
    ) -> std::option::Option<&crate::model::InferenceOutputConfiguration> {
        self.data_output_configuration.as_ref()
    }
    /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the inference scheduler being described. </p>
    pub fn role_arn(&self) -> std::option::Option<&str> {
        self.role_arn.as_deref()
    }
    /// <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
    pub fn server_side_kms_key_id(&self) -> std::option::Option<&str> {
        self.server_side_kms_key_id.as_deref()
    }
    /// <p>Indicates whether the latest execution for the inference scheduler was Anomalous (anomalous events found) or Normal (no anomalous events found).</p>
    pub fn latest_inference_result(
        &self,
    ) -> std::option::Option<&crate::model::LatestInferenceResult> {
        self.latest_inference_result.as_ref()
    }
}
impl aws_http::request_id::RequestId for DescribeInferenceSchedulerOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`DescribeInferenceSchedulerOutput`](crate::output::DescribeInferenceSchedulerOutput).
pub mod describe_inference_scheduler_output {

    /// A builder for [`DescribeInferenceSchedulerOutput`](crate::output::DescribeInferenceSchedulerOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) model_arn: std::option::Option<std::string::String>,
        pub(crate) model_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_name: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_arn: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::InferenceSchedulerStatus>,
        pub(crate) data_delay_offset_in_minutes: std::option::Option<i64>,
        pub(crate) data_upload_frequency: std::option::Option<crate::model::DataUploadFrequency>,
        pub(crate) created_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) updated_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) data_input_configuration:
            std::option::Option<crate::model::InferenceInputConfiguration>,
        pub(crate) data_output_configuration:
            std::option::Option<crate::model::InferenceOutputConfiguration>,
        pub(crate) role_arn: std::option::Option<std::string::String>,
        pub(crate) server_side_kms_key_id: std::option::Option<std::string::String>,
        pub(crate) latest_inference_result:
            std::option::Option<crate::model::LatestInferenceResult>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the ML model of the inference scheduler being described. </p>
        pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the ML model of the inference scheduler being described. </p>
        pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_arn = input;
            self
        }
        /// <p>The name of the ML model of the inference scheduler being described. </p>
        pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_name = Some(input.into());
            self
        }
        /// <p>The name of the ML model of the inference scheduler being described. </p>
        pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_name = input;
            self
        }
        /// <p>The name of the inference scheduler being described. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_name = Some(input.into());
            self
        }
        /// <p>The name of the inference scheduler being described. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_name = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being described. </p>
        pub fn inference_scheduler_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being described. </p>
        pub fn set_inference_scheduler_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_arn = input;
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn status(mut self, input: crate::model::InferenceSchedulerStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the inference scheduler. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::InferenceSchedulerStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        /// <p> A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if you select an offset delay time of five minutes, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>
        pub fn data_delay_offset_in_minutes(mut self, input: i64) -> Self {
            self.data_delay_offset_in_minutes = Some(input);
            self
        }
        /// <p> A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if you select an offset delay time of five minutes, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>
        pub fn set_data_delay_offset_in_minutes(mut self, input: std::option::Option<i64>) -> Self {
            self.data_delay_offset_in_minutes = input;
            self
        }
        /// <p>Specifies how often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes. </p>
        pub fn data_upload_frequency(mut self, input: crate::model::DataUploadFrequency) -> Self {
            self.data_upload_frequency = Some(input);
            self
        }
        /// <p>Specifies how often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes. </p>
        pub fn set_data_upload_frequency(
            mut self,
            input: std::option::Option<crate::model::DataUploadFrequency>,
        ) -> Self {
            self.data_upload_frequency = input;
            self
        }
        /// <p>Specifies the time at which the inference scheduler was created. </p>
        pub fn created_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_at = Some(input);
            self
        }
        /// <p>Specifies the time at which the inference scheduler was created. </p>
        pub fn set_created_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.created_at = input;
            self
        }
        /// <p>Specifies the time at which the inference scheduler was last updated, if it was. </p>
        pub fn updated_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.updated_at = Some(input);
            self
        }
        /// <p>Specifies the time at which the inference scheduler was last updated, if it was. </p>
        pub fn set_updated_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.updated_at = input;
            self
        }
        /// <p> Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>
        pub fn data_input_configuration(
            mut self,
            input: crate::model::InferenceInputConfiguration,
        ) -> Self {
            self.data_input_configuration = Some(input);
            self
        }
        /// <p> Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>
        pub fn set_data_input_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceInputConfiguration>,
        ) -> Self {
            self.data_input_configuration = input;
            self
        }
        /// <p> Specifies information for the output results for the inference scheduler, including the output S3 location. </p>
        pub fn data_output_configuration(
            mut self,
            input: crate::model::InferenceOutputConfiguration,
        ) -> Self {
            self.data_output_configuration = Some(input);
            self
        }
        /// <p> Specifies information for the output results for the inference scheduler, including the output S3 location. </p>
        pub fn set_data_output_configuration(
            mut self,
            input: std::option::Option<crate::model::InferenceOutputConfiguration>,
        ) -> Self {
            self.data_output_configuration = input;
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the inference scheduler being described. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.role_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the inference scheduler being described. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.role_arn = input;
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.server_side_kms_key_id = Some(input.into());
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.server_side_kms_key_id = input;
            self
        }
        /// <p>Indicates whether the latest execution for the inference scheduler was Anomalous (anomalous events found) or Normal (no anomalous events found).</p>
        pub fn latest_inference_result(
            mut self,
            input: crate::model::LatestInferenceResult,
        ) -> Self {
            self.latest_inference_result = Some(input);
            self
        }
        /// <p>Indicates whether the latest execution for the inference scheduler was Anomalous (anomalous events found) or Normal (no anomalous events found).</p>
        pub fn set_latest_inference_result(
            mut self,
            input: std::option::Option<crate::model::LatestInferenceResult>,
        ) -> Self {
            self.latest_inference_result = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`DescribeInferenceSchedulerOutput`](crate::output::DescribeInferenceSchedulerOutput).
        pub fn build(self) -> crate::output::DescribeInferenceSchedulerOutput {
            crate::output::DescribeInferenceSchedulerOutput {
                model_arn: self.model_arn,
                model_name: self.model_name,
                inference_scheduler_name: self.inference_scheduler_name,
                inference_scheduler_arn: self.inference_scheduler_arn,
                status: self.status,
                data_delay_offset_in_minutes: self.data_delay_offset_in_minutes,
                data_upload_frequency: self.data_upload_frequency,
                created_at: self.created_at,
                updated_at: self.updated_at,
                data_input_configuration: self.data_input_configuration,
                data_output_configuration: self.data_output_configuration,
                role_arn: self.role_arn,
                server_side_kms_key_id: self.server_side_kms_key_id,
                latest_inference_result: self.latest_inference_result,
                _request_id: self._request_id,
            }
        }
    }
}
impl DescribeInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`DescribeInferenceSchedulerOutput`](crate::output::DescribeInferenceSchedulerOutput).
    pub fn builder() -> crate::output::describe_inference_scheduler_output::Builder {
        crate::output::describe_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeDatasetOutput {
    /// <p>The name of the dataset being described. </p>
    #[doc(hidden)]
    pub dataset_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the dataset being described. </p>
    #[doc(hidden)]
    pub dataset_arn: std::option::Option<std::string::String>,
    /// <p>Specifies the time the dataset was created in Lookout for Equipment. </p>
    #[doc(hidden)]
    pub created_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Specifies the time the dataset was last updated, if it was. </p>
    #[doc(hidden)]
    pub last_updated_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates the status of the dataset. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::DatasetStatus>,
    /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
    #[doc(hidden)]
    pub schema: std::option::Option<std::string::String>,
    /// <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>
    #[doc(hidden)]
    pub server_side_kms_key_id: std::option::Option<std::string::String>,
    /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
    #[doc(hidden)]
    pub ingestion_input_configuration:
        std::option::Option<crate::model::IngestionInputConfiguration>,
    /// <p> Gives statistics associated with the given dataset for the latest successful associated ingestion job id. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
    #[doc(hidden)]
    pub data_quality_summary: std::option::Option<crate::model::DataQualitySummary>,
    /// <p> IngestedFilesSummary associated with the given dataset for the latest successful associated ingestion job id. </p>
    #[doc(hidden)]
    pub ingested_files_summary: std::option::Option<crate::model::IngestedFilesSummary>,
    /// <p> The Amazon Resource Name (ARN) of the IAM role that you are using for this the data ingestion job. </p>
    #[doc(hidden)]
    pub role_arn: std::option::Option<std::string::String>,
    /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
    #[doc(hidden)]
    pub data_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
    #[doc(hidden)]
    pub data_end_time: std::option::Option<aws_smithy_types::DateTime>,
    _request_id: Option<String>,
}
impl DescribeDatasetOutput {
    /// <p>The name of the dataset being described. </p>
    pub fn dataset_name(&self) -> std::option::Option<&str> {
        self.dataset_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the dataset being described. </p>
    pub fn dataset_arn(&self) -> std::option::Option<&str> {
        self.dataset_arn.as_deref()
    }
    /// <p>Specifies the time the dataset was created in Lookout for Equipment. </p>
    pub fn created_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.created_at.as_ref()
    }
    /// <p>Specifies the time the dataset was last updated, if it was. </p>
    pub fn last_updated_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.last_updated_at.as_ref()
    }
    /// <p>Indicates the status of the dataset. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::DatasetStatus> {
        self.status.as_ref()
    }
    /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
    pub fn schema(&self) -> std::option::Option<&str> {
        self.schema.as_deref()
    }
    /// <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>
    pub fn server_side_kms_key_id(&self) -> std::option::Option<&str> {
        self.server_side_kms_key_id.as_deref()
    }
    /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
    pub fn ingestion_input_configuration(
        &self,
    ) -> std::option::Option<&crate::model::IngestionInputConfiguration> {
        self.ingestion_input_configuration.as_ref()
    }
    /// <p> Gives statistics associated with the given dataset for the latest successful associated ingestion job id. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
    pub fn data_quality_summary(&self) -> std::option::Option<&crate::model::DataQualitySummary> {
        self.data_quality_summary.as_ref()
    }
    /// <p> IngestedFilesSummary associated with the given dataset for the latest successful associated ingestion job id. </p>
    pub fn ingested_files_summary(
        &self,
    ) -> std::option::Option<&crate::model::IngestedFilesSummary> {
        self.ingested_files_summary.as_ref()
    }
    /// <p> The Amazon Resource Name (ARN) of the IAM role that you are using for this the data ingestion job. </p>
    pub fn role_arn(&self) -> std::option::Option<&str> {
        self.role_arn.as_deref()
    }
    /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
    pub fn data_start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.data_start_time.as_ref()
    }
    /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
    pub fn data_end_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.data_end_time.as_ref()
    }
}
impl aws_http::request_id::RequestId for DescribeDatasetOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`DescribeDatasetOutput`](crate::output::DescribeDatasetOutput).
pub mod describe_dataset_output {

    /// A builder for [`DescribeDatasetOutput`](crate::output::DescribeDatasetOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) dataset_name: std::option::Option<std::string::String>,
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
        pub(crate) created_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) last_updated_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) status: std::option::Option<crate::model::DatasetStatus>,
        pub(crate) schema: std::option::Option<std::string::String>,
        pub(crate) server_side_kms_key_id: std::option::Option<std::string::String>,
        pub(crate) ingestion_input_configuration:
            std::option::Option<crate::model::IngestionInputConfiguration>,
        pub(crate) data_quality_summary: std::option::Option<crate::model::DataQualitySummary>,
        pub(crate) ingested_files_summary: std::option::Option<crate::model::IngestedFilesSummary>,
        pub(crate) role_arn: std::option::Option<std::string::String>,
        pub(crate) data_start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) data_end_time: std::option::Option<aws_smithy_types::DateTime>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p>The name of the dataset being described. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_name = Some(input.into());
            self
        }
        /// <p>The name of the dataset being described. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_name = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the dataset being described. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the dataset being described. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input;
            self
        }
        /// <p>Specifies the time the dataset was created in Lookout for Equipment. </p>
        pub fn created_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_at = Some(input);
            self
        }
        /// <p>Specifies the time the dataset was created in Lookout for Equipment. </p>
        pub fn set_created_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.created_at = input;
            self
        }
        /// <p>Specifies the time the dataset was last updated, if it was. </p>
        pub fn last_updated_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.last_updated_at = Some(input);
            self
        }
        /// <p>Specifies the time the dataset was last updated, if it was. </p>
        pub fn set_last_updated_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.last_updated_at = input;
            self
        }
        /// <p>Indicates the status of the dataset. </p>
        pub fn status(mut self, input: crate::model::DatasetStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the dataset. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::DatasetStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
        pub fn schema(mut self, input: impl Into<std::string::String>) -> Self {
            self.schema = Some(input.into());
            self
        }
        /// <p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>
        pub fn set_schema(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.schema = input;
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>
        pub fn server_side_kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.server_side_kms_key_id = Some(input.into());
            self
        }
        /// <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>
        pub fn set_server_side_kms_key_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.server_side_kms_key_id = input;
            self
        }
        /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
        pub fn ingestion_input_configuration(
            mut self,
            input: crate::model::IngestionInputConfiguration,
        ) -> Self {
            self.ingestion_input_configuration = Some(input);
            self
        }
        /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
        pub fn set_ingestion_input_configuration(
            mut self,
            input: std::option::Option<crate::model::IngestionInputConfiguration>,
        ) -> Self {
            self.ingestion_input_configuration = input;
            self
        }
        /// <p> Gives statistics associated with the given dataset for the latest successful associated ingestion job id. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
        pub fn data_quality_summary(mut self, input: crate::model::DataQualitySummary) -> Self {
            self.data_quality_summary = Some(input);
            self
        }
        /// <p> Gives statistics associated with the given dataset for the latest successful associated ingestion job id. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
        pub fn set_data_quality_summary(
            mut self,
            input: std::option::Option<crate::model::DataQualitySummary>,
        ) -> Self {
            self.data_quality_summary = input;
            self
        }
        /// <p> IngestedFilesSummary associated with the given dataset for the latest successful associated ingestion job id. </p>
        pub fn ingested_files_summary(mut self, input: crate::model::IngestedFilesSummary) -> Self {
            self.ingested_files_summary = Some(input);
            self
        }
        /// <p> IngestedFilesSummary associated with the given dataset for the latest successful associated ingestion job id. </p>
        pub fn set_ingested_files_summary(
            mut self,
            input: std::option::Option<crate::model::IngestedFilesSummary>,
        ) -> Self {
            self.ingested_files_summary = input;
            self
        }
        /// <p> The Amazon Resource Name (ARN) of the IAM role that you are using for this the data ingestion job. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.role_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) of the IAM role that you are using for this the data ingestion job. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.role_arn = input;
            self
        }
        /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
        pub fn data_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.data_start_time = Some(input);
            self
        }
        /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
        pub fn set_data_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.data_start_time = input;
            self
        }
        /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
        pub fn data_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.data_end_time = Some(input);
            self
        }
        /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>
        pub fn set_data_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.data_end_time = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`DescribeDatasetOutput`](crate::output::DescribeDatasetOutput).
        pub fn build(self) -> crate::output::DescribeDatasetOutput {
            crate::output::DescribeDatasetOutput {
                dataset_name: self.dataset_name,
                dataset_arn: self.dataset_arn,
                created_at: self.created_at,
                last_updated_at: self.last_updated_at,
                status: self.status,
                schema: self.schema,
                server_side_kms_key_id: self.server_side_kms_key_id,
                ingestion_input_configuration: self.ingestion_input_configuration,
                data_quality_summary: self.data_quality_summary,
                ingested_files_summary: self.ingested_files_summary,
                role_arn: self.role_arn,
                data_start_time: self.data_start_time,
                data_end_time: self.data_end_time,
                _request_id: self._request_id,
            }
        }
    }
}
impl DescribeDatasetOutput {
    /// Creates a new builder-style object to manufacture [`DescribeDatasetOutput`](crate::output::DescribeDatasetOutput).
    pub fn builder() -> crate::output::describe_dataset_output::Builder {
        crate::output::describe_dataset_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeDataIngestionJobOutput {
    /// <p>Indicates the job ID of the data ingestion job. </p>
    #[doc(hidden)]
    pub job_id: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the dataset being used in the data ingestion job. </p>
    #[doc(hidden)]
    pub dataset_arn: std::option::Option<std::string::String>,
    /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
    #[doc(hidden)]
    pub ingestion_input_configuration:
        std::option::Option<crate::model::IngestionInputConfiguration>,
    /// <p>The Amazon Resource Name (ARN) of an IAM role with permission to access the data source being ingested. </p>
    #[doc(hidden)]
    pub role_arn: std::option::Option<std::string::String>,
    /// <p>The time at which the data ingestion job was created. </p>
    #[doc(hidden)]
    pub created_at: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates the status of the <code>DataIngestionJob</code> operation. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::IngestionJobStatus>,
    /// <p>Specifies the reason for failure when a data ingestion job has failed. </p>
    #[doc(hidden)]
    pub failed_reason: std::option::Option<std::string::String>,
    /// <p> Gives statistics about a completed ingestion job. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
    #[doc(hidden)]
    pub data_quality_summary: std::option::Option<crate::model::DataQualitySummary>,
    /// <p>Gives statistics about how many files have been ingested, and which files have not been ingested, for a particular ingestion job.</p>
    #[doc(hidden)]
    pub ingested_files_summary: std::option::Option<crate::model::IngestedFilesSummary>,
    /// <p> Provides details about status of the ingestion job that is currently in progress. </p>
    #[doc(hidden)]
    pub status_detail: std::option::Option<std::string::String>,
    /// <p> Indicates the size of the ingested dataset. </p>
    #[doc(hidden)]
    pub ingested_data_size: std::option::Option<i64>,
    /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
    #[doc(hidden)]
    pub data_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
    #[doc(hidden)]
    pub data_end_time: std::option::Option<aws_smithy_types::DateTime>,
    _request_id: Option<String>,
}
impl DescribeDataIngestionJobOutput {
    /// <p>Indicates the job ID of the data ingestion job. </p>
    pub fn job_id(&self) -> std::option::Option<&str> {
        self.job_id.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the dataset being used in the data ingestion job. </p>
    pub fn dataset_arn(&self) -> std::option::Option<&str> {
        self.dataset_arn.as_deref()
    }
    /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
    pub fn ingestion_input_configuration(
        &self,
    ) -> std::option::Option<&crate::model::IngestionInputConfiguration> {
        self.ingestion_input_configuration.as_ref()
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role with permission to access the data source being ingested. </p>
    pub fn role_arn(&self) -> std::option::Option<&str> {
        self.role_arn.as_deref()
    }
    /// <p>The time at which the data ingestion job was created. </p>
    pub fn created_at(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.created_at.as_ref()
    }
    /// <p>Indicates the status of the <code>DataIngestionJob</code> operation. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::IngestionJobStatus> {
        self.status.as_ref()
    }
    /// <p>Specifies the reason for failure when a data ingestion job has failed. </p>
    pub fn failed_reason(&self) -> std::option::Option<&str> {
        self.failed_reason.as_deref()
    }
    /// <p> Gives statistics about a completed ingestion job. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
    pub fn data_quality_summary(&self) -> std::option::Option<&crate::model::DataQualitySummary> {
        self.data_quality_summary.as_ref()
    }
    /// <p>Gives statistics about how many files have been ingested, and which files have not been ingested, for a particular ingestion job.</p>
    pub fn ingested_files_summary(
        &self,
    ) -> std::option::Option<&crate::model::IngestedFilesSummary> {
        self.ingested_files_summary.as_ref()
    }
    /// <p> Provides details about status of the ingestion job that is currently in progress. </p>
    pub fn status_detail(&self) -> std::option::Option<&str> {
        self.status_detail.as_deref()
    }
    /// <p> Indicates the size of the ingested dataset. </p>
    pub fn ingested_data_size(&self) -> std::option::Option<i64> {
        self.ingested_data_size
    }
    /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
    pub fn data_start_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.data_start_time.as_ref()
    }
    /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
    pub fn data_end_time(&self) -> std::option::Option<&aws_smithy_types::DateTime> {
        self.data_end_time.as_ref()
    }
}
impl aws_http::request_id::RequestId for DescribeDataIngestionJobOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`DescribeDataIngestionJobOutput`](crate::output::DescribeDataIngestionJobOutput).
pub mod describe_data_ingestion_job_output {

    /// A builder for [`DescribeDataIngestionJobOutput`](crate::output::DescribeDataIngestionJobOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) job_id: std::option::Option<std::string::String>,
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
        pub(crate) ingestion_input_configuration:
            std::option::Option<crate::model::IngestionInputConfiguration>,
        pub(crate) role_arn: std::option::Option<std::string::String>,
        pub(crate) created_at: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) status: std::option::Option<crate::model::IngestionJobStatus>,
        pub(crate) failed_reason: std::option::Option<std::string::String>,
        pub(crate) data_quality_summary: std::option::Option<crate::model::DataQualitySummary>,
        pub(crate) ingested_files_summary: std::option::Option<crate::model::IngestedFilesSummary>,
        pub(crate) status_detail: std::option::Option<std::string::String>,
        pub(crate) ingested_data_size: std::option::Option<i64>,
        pub(crate) data_start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) data_end_time: std::option::Option<aws_smithy_types::DateTime>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p>Indicates the job ID of the data ingestion job. </p>
        pub fn job_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.job_id = Some(input.into());
            self
        }
        /// <p>Indicates the job ID of the data ingestion job. </p>
        pub fn set_job_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.job_id = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the dataset being used in the data ingestion job. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the dataset being used in the data ingestion job. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input;
            self
        }
        /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
        pub fn ingestion_input_configuration(
            mut self,
            input: crate::model::IngestionInputConfiguration,
        ) -> Self {
            self.ingestion_input_configuration = Some(input);
            self
        }
        /// <p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>
        pub fn set_ingestion_input_configuration(
            mut self,
            input: std::option::Option<crate::model::IngestionInputConfiguration>,
        ) -> Self {
            self.ingestion_input_configuration = input;
            self
        }
        /// <p>The Amazon Resource Name (ARN) of an IAM role with permission to access the data source being ingested. </p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.role_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of an IAM role with permission to access the data source being ingested. </p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.role_arn = input;
            self
        }
        /// <p>The time at which the data ingestion job was created. </p>
        pub fn created_at(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_at = Some(input);
            self
        }
        /// <p>The time at which the data ingestion job was created. </p>
        pub fn set_created_at(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.created_at = input;
            self
        }
        /// <p>Indicates the status of the <code>DataIngestionJob</code> operation. </p>
        pub fn status(mut self, input: crate::model::IngestionJobStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the <code>DataIngestionJob</code> operation. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::IngestionJobStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        /// <p>Specifies the reason for failure when a data ingestion job has failed. </p>
        pub fn failed_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.failed_reason = Some(input.into());
            self
        }
        /// <p>Specifies the reason for failure when a data ingestion job has failed. </p>
        pub fn set_failed_reason(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.failed_reason = input;
            self
        }
        /// <p> Gives statistics about a completed ingestion job. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
        pub fn data_quality_summary(mut self, input: crate::model::DataQualitySummary) -> Self {
            self.data_quality_summary = Some(input);
            self
        }
        /// <p> Gives statistics about a completed ingestion job. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
        pub fn set_data_quality_summary(
            mut self,
            input: std::option::Option<crate::model::DataQualitySummary>,
        ) -> Self {
            self.data_quality_summary = input;
            self
        }
        /// <p>Gives statistics about how many files have been ingested, and which files have not been ingested, for a particular ingestion job.</p>
        pub fn ingested_files_summary(mut self, input: crate::model::IngestedFilesSummary) -> Self {
            self.ingested_files_summary = Some(input);
            self
        }
        /// <p>Gives statistics about how many files have been ingested, and which files have not been ingested, for a particular ingestion job.</p>
        pub fn set_ingested_files_summary(
            mut self,
            input: std::option::Option<crate::model::IngestedFilesSummary>,
        ) -> Self {
            self.ingested_files_summary = input;
            self
        }
        /// <p> Provides details about status of the ingestion job that is currently in progress. </p>
        pub fn status_detail(mut self, input: impl Into<std::string::String>) -> Self {
            self.status_detail = Some(input.into());
            self
        }
        /// <p> Provides details about status of the ingestion job that is currently in progress. </p>
        pub fn set_status_detail(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.status_detail = input;
            self
        }
        /// <p> Indicates the size of the ingested dataset. </p>
        pub fn ingested_data_size(mut self, input: i64) -> Self {
            self.ingested_data_size = Some(input);
            self
        }
        /// <p> Indicates the size of the ingested dataset. </p>
        pub fn set_ingested_data_size(mut self, input: std::option::Option<i64>) -> Self {
            self.ingested_data_size = input;
            self
        }
        /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
        pub fn data_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.data_start_time = Some(input);
            self
        }
        /// <p> Indicates the earliest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
        pub fn set_data_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.data_start_time = input;
            self
        }
        /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
        pub fn data_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.data_end_time = Some(input);
            self
        }
        /// <p> Indicates the latest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>
        pub fn set_data_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.data_end_time = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`DescribeDataIngestionJobOutput`](crate::output::DescribeDataIngestionJobOutput).
        pub fn build(self) -> crate::output::DescribeDataIngestionJobOutput {
            crate::output::DescribeDataIngestionJobOutput {
                job_id: self.job_id,
                dataset_arn: self.dataset_arn,
                ingestion_input_configuration: self.ingestion_input_configuration,
                role_arn: self.role_arn,
                created_at: self.created_at,
                status: self.status,
                failed_reason: self.failed_reason,
                data_quality_summary: self.data_quality_summary,
                ingested_files_summary: self.ingested_files_summary,
                status_detail: self.status_detail,
                ingested_data_size: self.ingested_data_size,
                data_start_time: self.data_start_time,
                data_end_time: self.data_end_time,
                _request_id: self._request_id,
            }
        }
    }
}
impl DescribeDataIngestionJobOutput {
    /// Creates a new builder-style object to manufacture [`DescribeDataIngestionJobOutput`](crate::output::DescribeDataIngestionJobOutput).
    pub fn builder() -> crate::output::describe_data_ingestion_job_output::Builder {
        crate::output::describe_data_ingestion_job_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteModelOutput {
    _request_id: Option<String>,
}
impl aws_http::request_id::RequestId for DeleteModelOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`DeleteModelOutput`](crate::output::DeleteModelOutput).
pub mod delete_model_output {

    /// A builder for [`DeleteModelOutput`](crate::output::DeleteModelOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        _request_id: Option<String>,
    }
    impl Builder {
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`DeleteModelOutput`](crate::output::DeleteModelOutput).
        pub fn build(self) -> crate::output::DeleteModelOutput {
            crate::output::DeleteModelOutput {
                _request_id: self._request_id,
            }
        }
    }
}
impl DeleteModelOutput {
    /// Creates a new builder-style object to manufacture [`DeleteModelOutput`](crate::output::DeleteModelOutput).
    pub fn builder() -> crate::output::delete_model_output::Builder {
        crate::output::delete_model_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteLabelGroupOutput {
    _request_id: Option<String>,
}
impl aws_http::request_id::RequestId for DeleteLabelGroupOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`DeleteLabelGroupOutput`](crate::output::DeleteLabelGroupOutput).
pub mod delete_label_group_output {

    /// A builder for [`DeleteLabelGroupOutput`](crate::output::DeleteLabelGroupOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        _request_id: Option<String>,
    }
    impl Builder {
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`DeleteLabelGroupOutput`](crate::output::DeleteLabelGroupOutput).
        pub fn build(self) -> crate::output::DeleteLabelGroupOutput {
            crate::output::DeleteLabelGroupOutput {
                _request_id: self._request_id,
            }
        }
    }
}
impl DeleteLabelGroupOutput {
    /// Creates a new builder-style object to manufacture [`DeleteLabelGroupOutput`](crate::output::DeleteLabelGroupOutput).
    pub fn builder() -> crate::output::delete_label_group_output::Builder {
        crate::output::delete_label_group_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteLabelOutput {
    _request_id: Option<String>,
}
impl aws_http::request_id::RequestId for DeleteLabelOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`DeleteLabelOutput`](crate::output::DeleteLabelOutput).
pub mod delete_label_output {

    /// A builder for [`DeleteLabelOutput`](crate::output::DeleteLabelOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        _request_id: Option<String>,
    }
    impl Builder {
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`DeleteLabelOutput`](crate::output::DeleteLabelOutput).
        pub fn build(self) -> crate::output::DeleteLabelOutput {
            crate::output::DeleteLabelOutput {
                _request_id: self._request_id,
            }
        }
    }
}
impl DeleteLabelOutput {
    /// Creates a new builder-style object to manufacture [`DeleteLabelOutput`](crate::output::DeleteLabelOutput).
    pub fn builder() -> crate::output::delete_label_output::Builder {
        crate::output::delete_label_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteInferenceSchedulerOutput {
    _request_id: Option<String>,
}
impl aws_http::request_id::RequestId for DeleteInferenceSchedulerOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`DeleteInferenceSchedulerOutput`](crate::output::DeleteInferenceSchedulerOutput).
pub mod delete_inference_scheduler_output {

    /// A builder for [`DeleteInferenceSchedulerOutput`](crate::output::DeleteInferenceSchedulerOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        _request_id: Option<String>,
    }
    impl Builder {
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`DeleteInferenceSchedulerOutput`](crate::output::DeleteInferenceSchedulerOutput).
        pub fn build(self) -> crate::output::DeleteInferenceSchedulerOutput {
            crate::output::DeleteInferenceSchedulerOutput {
                _request_id: self._request_id,
            }
        }
    }
}
impl DeleteInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`DeleteInferenceSchedulerOutput`](crate::output::DeleteInferenceSchedulerOutput).
    pub fn builder() -> crate::output::delete_inference_scheduler_output::Builder {
        crate::output::delete_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DeleteDatasetOutput {
    _request_id: Option<String>,
}
impl aws_http::request_id::RequestId for DeleteDatasetOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`DeleteDatasetOutput`](crate::output::DeleteDatasetOutput).
pub mod delete_dataset_output {

    /// A builder for [`DeleteDatasetOutput`](crate::output::DeleteDatasetOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        _request_id: Option<String>,
    }
    impl Builder {
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`DeleteDatasetOutput`](crate::output::DeleteDatasetOutput).
        pub fn build(self) -> crate::output::DeleteDatasetOutput {
            crate::output::DeleteDatasetOutput {
                _request_id: self._request_id,
            }
        }
    }
}
impl DeleteDatasetOutput {
    /// Creates a new builder-style object to manufacture [`DeleteDatasetOutput`](crate::output::DeleteDatasetOutput).
    pub fn builder() -> crate::output::delete_dataset_output::Builder {
        crate::output::delete_dataset_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateModelOutput {
    /// <p>The Amazon Resource Name (ARN) of the model being created. </p>
    #[doc(hidden)]
    pub model_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the <code>CreateModel</code> operation. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::ModelStatus>,
    _request_id: Option<String>,
}
impl CreateModelOutput {
    /// <p>The Amazon Resource Name (ARN) of the model being created. </p>
    pub fn model_arn(&self) -> std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>Indicates the status of the <code>CreateModel</code> operation. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::ModelStatus> {
        self.status.as_ref()
    }
}
impl aws_http::request_id::RequestId for CreateModelOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`CreateModelOutput`](crate::output::CreateModelOutput).
pub mod create_model_output {

    /// A builder for [`CreateModelOutput`](crate::output::CreateModelOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) model_arn: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::ModelStatus>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the model being created. </p>
        pub fn model_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.model_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the model being created. </p>
        pub fn set_model_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.model_arn = input;
            self
        }
        /// <p>Indicates the status of the <code>CreateModel</code> operation. </p>
        pub fn status(mut self, input: crate::model::ModelStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the <code>CreateModel</code> operation. </p>
        pub fn set_status(mut self, input: std::option::Option<crate::model::ModelStatus>) -> Self {
            self.status = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`CreateModelOutput`](crate::output::CreateModelOutput).
        pub fn build(self) -> crate::output::CreateModelOutput {
            crate::output::CreateModelOutput {
                model_arn: self.model_arn,
                status: self.status,
                _request_id: self._request_id,
            }
        }
    }
}
impl CreateModelOutput {
    /// Creates a new builder-style object to manufacture [`CreateModelOutput`](crate::output::CreateModelOutput).
    pub fn builder() -> crate::output::create_model_output::Builder {
        crate::output::create_model_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateLabelGroupOutput {
    /// <p> The name of the label group that you have created. Data in this field will be retained for service usage. Follow best practices for the security of your data. </p>
    #[doc(hidden)]
    pub label_group_name: std::option::Option<std::string::String>,
    /// <p> The ARN of the label group that you have created. </p>
    #[doc(hidden)]
    pub label_group_arn: std::option::Option<std::string::String>,
    _request_id: Option<String>,
}
impl CreateLabelGroupOutput {
    /// <p> The name of the label group that you have created. Data in this field will be retained for service usage. Follow best practices for the security of your data. </p>
    pub fn label_group_name(&self) -> std::option::Option<&str> {
        self.label_group_name.as_deref()
    }
    /// <p> The ARN of the label group that you have created. </p>
    pub fn label_group_arn(&self) -> std::option::Option<&str> {
        self.label_group_arn.as_deref()
    }
}
impl aws_http::request_id::RequestId for CreateLabelGroupOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`CreateLabelGroupOutput`](crate::output::CreateLabelGroupOutput).
pub mod create_label_group_output {

    /// A builder for [`CreateLabelGroupOutput`](crate::output::CreateLabelGroupOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) label_group_name: std::option::Option<std::string::String>,
        pub(crate) label_group_arn: std::option::Option<std::string::String>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p> The name of the label group that you have created. Data in this field will be retained for service usage. Follow best practices for the security of your data. </p>
        pub fn label_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.label_group_name = Some(input.into());
            self
        }
        /// <p> The name of the label group that you have created. Data in this field will be retained for service usage. Follow best practices for the security of your data. </p>
        pub fn set_label_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.label_group_name = input;
            self
        }
        /// <p> The ARN of the label group that you have created. </p>
        pub fn label_group_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.label_group_arn = Some(input.into());
            self
        }
        /// <p> The ARN of the label group that you have created. </p>
        pub fn set_label_group_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.label_group_arn = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`CreateLabelGroupOutput`](crate::output::CreateLabelGroupOutput).
        pub fn build(self) -> crate::output::CreateLabelGroupOutput {
            crate::output::CreateLabelGroupOutput {
                label_group_name: self.label_group_name,
                label_group_arn: self.label_group_arn,
                _request_id: self._request_id,
            }
        }
    }
}
impl CreateLabelGroupOutput {
    /// Creates a new builder-style object to manufacture [`CreateLabelGroupOutput`](crate::output::CreateLabelGroupOutput).
    pub fn builder() -> crate::output::create_label_group_output::Builder {
        crate::output::create_label_group_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateLabelOutput {
    /// <p> The ID of the label that you have created. </p>
    #[doc(hidden)]
    pub label_id: std::option::Option<std::string::String>,
    _request_id: Option<String>,
}
impl CreateLabelOutput {
    /// <p> The ID of the label that you have created. </p>
    pub fn label_id(&self) -> std::option::Option<&str> {
        self.label_id.as_deref()
    }
}
impl aws_http::request_id::RequestId for CreateLabelOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`CreateLabelOutput`](crate::output::CreateLabelOutput).
pub mod create_label_output {

    /// A builder for [`CreateLabelOutput`](crate::output::CreateLabelOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) label_id: std::option::Option<std::string::String>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p> The ID of the label that you have created. </p>
        pub fn label_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.label_id = Some(input.into());
            self
        }
        /// <p> The ID of the label that you have created. </p>
        pub fn set_label_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.label_id = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`CreateLabelOutput`](crate::output::CreateLabelOutput).
        pub fn build(self) -> crate::output::CreateLabelOutput {
            crate::output::CreateLabelOutput {
                label_id: self.label_id,
                _request_id: self._request_id,
            }
        }
    }
}
impl CreateLabelOutput {
    /// Creates a new builder-style object to manufacture [`CreateLabelOutput`](crate::output::CreateLabelOutput).
    pub fn builder() -> crate::output::create_label_output::Builder {
        crate::output::create_label_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being created. </p>
    #[doc(hidden)]
    pub inference_scheduler_arn: std::option::Option<std::string::String>,
    /// <p>The name of inference scheduler being created. </p>
    #[doc(hidden)]
    pub inference_scheduler_name: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the <code>CreateInferenceScheduler</code> operation. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::InferenceSchedulerStatus>,
    _request_id: Option<String>,
}
impl CreateInferenceSchedulerOutput {
    /// <p>The Amazon Resource Name (ARN) of the inference scheduler being created. </p>
    pub fn inference_scheduler_arn(&self) -> std::option::Option<&str> {
        self.inference_scheduler_arn.as_deref()
    }
    /// <p>The name of inference scheduler being created. </p>
    pub fn inference_scheduler_name(&self) -> std::option::Option<&str> {
        self.inference_scheduler_name.as_deref()
    }
    /// <p>Indicates the status of the <code>CreateInferenceScheduler</code> operation. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::InferenceSchedulerStatus> {
        self.status.as_ref()
    }
}
impl aws_http::request_id::RequestId for CreateInferenceSchedulerOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`CreateInferenceSchedulerOutput`](crate::output::CreateInferenceSchedulerOutput).
pub mod create_inference_scheduler_output {

    /// A builder for [`CreateInferenceSchedulerOutput`](crate::output::CreateInferenceSchedulerOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) inference_scheduler_arn: std::option::Option<std::string::String>,
        pub(crate) inference_scheduler_name: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::InferenceSchedulerStatus>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being created. </p>
        pub fn inference_scheduler_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the inference scheduler being created. </p>
        pub fn set_inference_scheduler_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_arn = input;
            self
        }
        /// <p>The name of inference scheduler being created. </p>
        pub fn inference_scheduler_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inference_scheduler_name = Some(input.into());
            self
        }
        /// <p>The name of inference scheduler being created. </p>
        pub fn set_inference_scheduler_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inference_scheduler_name = input;
            self
        }
        /// <p>Indicates the status of the <code>CreateInferenceScheduler</code> operation. </p>
        pub fn status(mut self, input: crate::model::InferenceSchedulerStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the <code>CreateInferenceScheduler</code> operation. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::InferenceSchedulerStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`CreateInferenceSchedulerOutput`](crate::output::CreateInferenceSchedulerOutput).
        pub fn build(self) -> crate::output::CreateInferenceSchedulerOutput {
            crate::output::CreateInferenceSchedulerOutput {
                inference_scheduler_arn: self.inference_scheduler_arn,
                inference_scheduler_name: self.inference_scheduler_name,
                status: self.status,
                _request_id: self._request_id,
            }
        }
    }
}
impl CreateInferenceSchedulerOutput {
    /// Creates a new builder-style object to manufacture [`CreateInferenceSchedulerOutput`](crate::output::CreateInferenceSchedulerOutput).
    pub fn builder() -> crate::output::create_inference_scheduler_output::Builder {
        crate::output::create_inference_scheduler_output::Builder::default()
    }
}

#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CreateDatasetOutput {
    /// <p>The name of the dataset being created. </p>
    #[doc(hidden)]
    pub dataset_name: std::option::Option<std::string::String>,
    /// <p> The Amazon Resource Name (ARN) of the dataset being created. </p>
    #[doc(hidden)]
    pub dataset_arn: std::option::Option<std::string::String>,
    /// <p>Indicates the status of the <code>CreateDataset</code> operation. </p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::DatasetStatus>,
    _request_id: Option<String>,
}
impl CreateDatasetOutput {
    /// <p>The name of the dataset being created. </p>
    pub fn dataset_name(&self) -> std::option::Option<&str> {
        self.dataset_name.as_deref()
    }
    /// <p> The Amazon Resource Name (ARN) of the dataset being created. </p>
    pub fn dataset_arn(&self) -> std::option::Option<&str> {
        self.dataset_arn.as_deref()
    }
    /// <p>Indicates the status of the <code>CreateDataset</code> operation. </p>
    pub fn status(&self) -> std::option::Option<&crate::model::DatasetStatus> {
        self.status.as_ref()
    }
}
impl aws_http::request_id::RequestId for CreateDatasetOutput {
    fn request_id(&self) -> Option<&str> {
        self._request_id.as_deref()
    }
}
/// See [`CreateDatasetOutput`](crate::output::CreateDatasetOutput).
pub mod create_dataset_output {

    /// A builder for [`CreateDatasetOutput`](crate::output::CreateDatasetOutput).
    #[non_exhaustive]
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) dataset_name: std::option::Option<std::string::String>,
        pub(crate) dataset_arn: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::DatasetStatus>,
        _request_id: Option<String>,
    }
    impl Builder {
        /// <p>The name of the dataset being created. </p>
        pub fn dataset_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_name = Some(input.into());
            self
        }
        /// <p>The name of the dataset being created. </p>
        pub fn set_dataset_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_name = input;
            self
        }
        /// <p> The Amazon Resource Name (ARN) of the dataset being created. </p>
        pub fn dataset_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.dataset_arn = Some(input.into());
            self
        }
        /// <p> The Amazon Resource Name (ARN) of the dataset being created. </p>
        pub fn set_dataset_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.dataset_arn = input;
            self
        }
        /// <p>Indicates the status of the <code>CreateDataset</code> operation. </p>
        pub fn status(mut self, input: crate::model::DatasetStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>Indicates the status of the <code>CreateDataset</code> operation. </p>
        pub fn set_status(
            mut self,
            input: std::option::Option<crate::model::DatasetStatus>,
        ) -> Self {
            self.status = input;
            self
        }
        pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
            self._request_id = Some(request_id.into());
            self
        }

        pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
            self._request_id = request_id;
            self
        }
        /// Consumes the builder and constructs a [`CreateDatasetOutput`](crate::output::CreateDatasetOutput).
        pub fn build(self) -> crate::output::CreateDatasetOutput {
            crate::output::CreateDatasetOutput {
                dataset_name: self.dataset_name,
                dataset_arn: self.dataset_arn,
                status: self.status,
                _request_id: self._request_id,
            }
        }
    }
}
impl CreateDatasetOutput {
    /// Creates a new builder-style object to manufacture [`CreateDatasetOutput`](crate::output::CreateDatasetOutput).
    pub fn builder() -> crate::output::create_dataset_output::Builder {
        crate::output::create_dataset_output::Builder::default()
    }
}
