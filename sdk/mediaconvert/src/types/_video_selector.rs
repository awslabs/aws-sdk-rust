// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// Input video selectors contain the video settings for the input. Each of your inputs can have up to one video selector.
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct VideoSelector {
    /// Ignore this setting unless this input is a QuickTime animation with an alpha channel. Use this setting to create separate Key and Fill outputs. In each output, specify which part of the input MediaConvert uses. Leave this setting at the default value DISCARD to delete the alpha channel and preserve the video. Set it to REMAP_TO_LUMA to delete the video and map the alpha channel to the luma channel of your outputs.
    pub alpha_behavior: ::std::option::Option<crate::types::AlphaBehavior>,
    /// If your input video has accurate color space metadata, or if you don't know about color space: Keep the default value, Follow. MediaConvert will automatically detect your input color space. If your input video has metadata indicating the wrong color space, or has missing metadata: Specify the accurate color space here. If your input video is HDR 10 and the SMPTE ST 2086 Mastering Display Color Volume static metadata isn't present in your video stream, or if that metadata is present but not accurate: Choose Force HDR 10. Specify correct values in the input HDR 10 metadata settings. For more information about HDR jobs, see https://docs.aws.amazon.com/console/mediaconvert/hdr. When you specify an input color space, MediaConvert uses the following color space metadata, which includes color primaries, transfer characteristics, and matrix coefficients: * HDR 10: BT.2020, PQ, BT.2020 non-constant * HLG 2020: BT.2020, HLG, BT.2020 non-constant * P3DCI (Theater): DCIP3, SMPTE 428M, BT.709 * P3D65 (SDR): Display P3, sRGB, BT.709 * P3D65 (HDR): Display P3, PQ, BT.709
    pub color_space: ::std::option::Option<crate::types::ColorSpace>,
    /// There are two sources for color metadata, the input file and the job input settings Color space and HDR master display information settings. The Color space usage setting determines which takes precedence. Choose Force to use color metadata from the input job settings. If you don't specify values for those settings, the service defaults to using metadata from your input. FALLBACK - Choose Fallback to use color metadata from the source when it is present. If there's no color metadata in your input file, the service defaults to using values you specify in the input settings.
    pub color_space_usage: ::std::option::Option<crate::types::ColorSpaceUsage>,
    /// Set Embedded timecode override to Use MDPM when your AVCHD input contains timecode tag data in the Modified Digital Video Pack Metadata. When you do, we recommend you also set Timecode source to Embedded. Leave Embedded timecode override blank, or set to None, when your input does not contain MDPM timecode.
    pub embedded_timecode_override: ::std::option::Option<crate::types::EmbeddedTimecodeOverride>,
    /// Use these settings to provide HDR 10 metadata that is missing or inaccurate in your input video. Appropriate values vary depending on the input video and must be provided by a color grader. The color grader generates these values during the HDR 10 mastering process. The valid range for each of these settings is 0 to 50,000. Each increment represents 0.00002 in CIE1931 color coordinate. Related settings - When you specify these values, you must also set Color space to HDR 10. To specify whether the the values you specify here take precedence over the values in the metadata of your input file, set Color space usage. To specify whether color metadata is included in an output, set Color metadata. For more information about MediaConvert HDR jobs, see https://docs.aws.amazon.com/console/mediaconvert/hdr.
    pub hdr10_metadata: ::std::option::Option<crate::types::Hdr10Metadata>,
    /// Specify the maximum mastering display luminance. Enter an integer from 0 to 2147483647, in units of 0.0001 nits. For example, enter 10000000 for 1000 nits.
    pub max_luminance: ::std::option::Option<i32>,
    /// Use this setting if your input has video and audio durations that don't align, and your output or player has strict alignment requirements. Examples: Input audio track has a delayed start. Input video track ends before audio ends. When you set Pad video to Black, MediaConvert generates black video frames so that output video and audio durations match. Black video frames are added at the beginning or end, depending on your input. To keep the default behavior and not generate black video, set Pad video to Disabled or leave blank.
    pub pad_video: ::std::option::Option<crate::types::PadVideo>,
    /// Use PID to select specific video data from an input file. Specify this value as an integer; the system automatically converts it to the hexidecimal value. For example, 257 selects PID 0x101. A PID, or packet identifier, is an identifier for a set of data in an MPEG-2 transport stream container.
    pub pid: ::std::option::Option<i32>,
    /// Selects a specific program from within a multi-program transport stream. Note that Quad 4K is not currently supported.
    pub program_number: ::std::option::Option<i32>,
    /// Use Rotate to specify how the service rotates your video. You can choose automatic rotation or specify a rotation. You can specify a clockwise rotation of 0, 90, 180, or 270 degrees. If your input video container is .mov or .mp4 and your input has rotation metadata, you can choose Automatic to have the service rotate your video according to the rotation specified in the metadata. The rotation must be within one degree of 90, 180, or 270 degrees. If the rotation metadata specifies any other rotation, the service will default to no rotation. By default, the service does no rotation, even if your input video has rotation metadata. The service doesn't pass through rotation metadata.
    pub rotate: ::std::option::Option<crate::types::InputRotate>,
    /// If the sample range metadata in your input video is accurate, or if you don't know about sample range, keep the default value, Follow, for this setting. When you do, the service automatically detects your input sample range. If your input video has metadata indicating the wrong sample range, specify the accurate sample range here. When you do, MediaConvert ignores any sample range information in the input metadata. Regardless of whether MediaConvert uses the input sample range or the sample range that you specify, MediaConvert uses the sample range for transcoding and also writes it to the output metadata.
    pub sample_range: ::std::option::Option<crate::types::InputSampleRange>,
    /// Choose the video selector type for your HLS input. Use to specify which video rendition MediaConvert uses from your HLS input. To have MediaConvert automatically use the highest bitrate rendition from your HLS input: Keep the default value, Auto. To manually specify a rendition: Choose Stream. Then enter the unique stream number in the Streams array, starting at 1, corresponding to the stream order in the manifest.
    pub selector_type: ::std::option::Option<crate::types::VideoSelectorType>,
    /// Specify one or more video streams for MediaConvert to use from your HLS input. Enter an integer corresponding to the stream number, with the first stream in your HLS multivariant playlist starting at 1.For re-encoding workflows, MediaConvert uses the video stream that you select with the highest bitrate as the input.For video passthrough workflows, you specify whether to passthrough a single video stream or multiple video streams under Video selector source in the output video encoding settings.
    pub streams: ::std::option::Option<::std::vec::Vec<i32>>,
}
impl VideoSelector {
    /// Ignore this setting unless this input is a QuickTime animation with an alpha channel. Use this setting to create separate Key and Fill outputs. In each output, specify which part of the input MediaConvert uses. Leave this setting at the default value DISCARD to delete the alpha channel and preserve the video. Set it to REMAP_TO_LUMA to delete the video and map the alpha channel to the luma channel of your outputs.
    pub fn alpha_behavior(&self) -> ::std::option::Option<&crate::types::AlphaBehavior> {
        self.alpha_behavior.as_ref()
    }
    /// If your input video has accurate color space metadata, or if you don't know about color space: Keep the default value, Follow. MediaConvert will automatically detect your input color space. If your input video has metadata indicating the wrong color space, or has missing metadata: Specify the accurate color space here. If your input video is HDR 10 and the SMPTE ST 2086 Mastering Display Color Volume static metadata isn't present in your video stream, or if that metadata is present but not accurate: Choose Force HDR 10. Specify correct values in the input HDR 10 metadata settings. For more information about HDR jobs, see https://docs.aws.amazon.com/console/mediaconvert/hdr. When you specify an input color space, MediaConvert uses the following color space metadata, which includes color primaries, transfer characteristics, and matrix coefficients: * HDR 10: BT.2020, PQ, BT.2020 non-constant * HLG 2020: BT.2020, HLG, BT.2020 non-constant * P3DCI (Theater): DCIP3, SMPTE 428M, BT.709 * P3D65 (SDR): Display P3, sRGB, BT.709 * P3D65 (HDR): Display P3, PQ, BT.709
    pub fn color_space(&self) -> ::std::option::Option<&crate::types::ColorSpace> {
        self.color_space.as_ref()
    }
    /// There are two sources for color metadata, the input file and the job input settings Color space and HDR master display information settings. The Color space usage setting determines which takes precedence. Choose Force to use color metadata from the input job settings. If you don't specify values for those settings, the service defaults to using metadata from your input. FALLBACK - Choose Fallback to use color metadata from the source when it is present. If there's no color metadata in your input file, the service defaults to using values you specify in the input settings.
    pub fn color_space_usage(&self) -> ::std::option::Option<&crate::types::ColorSpaceUsage> {
        self.color_space_usage.as_ref()
    }
    /// Set Embedded timecode override to Use MDPM when your AVCHD input contains timecode tag data in the Modified Digital Video Pack Metadata. When you do, we recommend you also set Timecode source to Embedded. Leave Embedded timecode override blank, or set to None, when your input does not contain MDPM timecode.
    pub fn embedded_timecode_override(&self) -> ::std::option::Option<&crate::types::EmbeddedTimecodeOverride> {
        self.embedded_timecode_override.as_ref()
    }
    /// Use these settings to provide HDR 10 metadata that is missing or inaccurate in your input video. Appropriate values vary depending on the input video and must be provided by a color grader. The color grader generates these values during the HDR 10 mastering process. The valid range for each of these settings is 0 to 50,000. Each increment represents 0.00002 in CIE1931 color coordinate. Related settings - When you specify these values, you must also set Color space to HDR 10. To specify whether the the values you specify here take precedence over the values in the metadata of your input file, set Color space usage. To specify whether color metadata is included in an output, set Color metadata. For more information about MediaConvert HDR jobs, see https://docs.aws.amazon.com/console/mediaconvert/hdr.
    pub fn hdr10_metadata(&self) -> ::std::option::Option<&crate::types::Hdr10Metadata> {
        self.hdr10_metadata.as_ref()
    }
    /// Specify the maximum mastering display luminance. Enter an integer from 0 to 2147483647, in units of 0.0001 nits. For example, enter 10000000 for 1000 nits.
    pub fn max_luminance(&self) -> ::std::option::Option<i32> {
        self.max_luminance
    }
    /// Use this setting if your input has video and audio durations that don't align, and your output or player has strict alignment requirements. Examples: Input audio track has a delayed start. Input video track ends before audio ends. When you set Pad video to Black, MediaConvert generates black video frames so that output video and audio durations match. Black video frames are added at the beginning or end, depending on your input. To keep the default behavior and not generate black video, set Pad video to Disabled or leave blank.
    pub fn pad_video(&self) -> ::std::option::Option<&crate::types::PadVideo> {
        self.pad_video.as_ref()
    }
    /// Use PID to select specific video data from an input file. Specify this value as an integer; the system automatically converts it to the hexidecimal value. For example, 257 selects PID 0x101. A PID, or packet identifier, is an identifier for a set of data in an MPEG-2 transport stream container.
    pub fn pid(&self) -> ::std::option::Option<i32> {
        self.pid
    }
    /// Selects a specific program from within a multi-program transport stream. Note that Quad 4K is not currently supported.
    pub fn program_number(&self) -> ::std::option::Option<i32> {
        self.program_number
    }
    /// Use Rotate to specify how the service rotates your video. You can choose automatic rotation or specify a rotation. You can specify a clockwise rotation of 0, 90, 180, or 270 degrees. If your input video container is .mov or .mp4 and your input has rotation metadata, you can choose Automatic to have the service rotate your video according to the rotation specified in the metadata. The rotation must be within one degree of 90, 180, or 270 degrees. If the rotation metadata specifies any other rotation, the service will default to no rotation. By default, the service does no rotation, even if your input video has rotation metadata. The service doesn't pass through rotation metadata.
    pub fn rotate(&self) -> ::std::option::Option<&crate::types::InputRotate> {
        self.rotate.as_ref()
    }
    /// If the sample range metadata in your input video is accurate, or if you don't know about sample range, keep the default value, Follow, for this setting. When you do, the service automatically detects your input sample range. If your input video has metadata indicating the wrong sample range, specify the accurate sample range here. When you do, MediaConvert ignores any sample range information in the input metadata. Regardless of whether MediaConvert uses the input sample range or the sample range that you specify, MediaConvert uses the sample range for transcoding and also writes it to the output metadata.
    pub fn sample_range(&self) -> ::std::option::Option<&crate::types::InputSampleRange> {
        self.sample_range.as_ref()
    }
    /// Choose the video selector type for your HLS input. Use to specify which video rendition MediaConvert uses from your HLS input. To have MediaConvert automatically use the highest bitrate rendition from your HLS input: Keep the default value, Auto. To manually specify a rendition: Choose Stream. Then enter the unique stream number in the Streams array, starting at 1, corresponding to the stream order in the manifest.
    pub fn selector_type(&self) -> ::std::option::Option<&crate::types::VideoSelectorType> {
        self.selector_type.as_ref()
    }
    /// Specify one or more video streams for MediaConvert to use from your HLS input. Enter an integer corresponding to the stream number, with the first stream in your HLS multivariant playlist starting at 1.For re-encoding workflows, MediaConvert uses the video stream that you select with the highest bitrate as the input.For video passthrough workflows, you specify whether to passthrough a single video stream or multiple video streams under Video selector source in the output video encoding settings.
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.streams.is_none()`.
    pub fn streams(&self) -> &[i32] {
        self.streams.as_deref().unwrap_or_default()
    }
}
impl VideoSelector {
    /// Creates a new builder-style object to manufacture [`VideoSelector`](crate::types::VideoSelector).
    pub fn builder() -> crate::types::builders::VideoSelectorBuilder {
        crate::types::builders::VideoSelectorBuilder::default()
    }
}

/// A builder for [`VideoSelector`](crate::types::VideoSelector).
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
#[non_exhaustive]
pub struct VideoSelectorBuilder {
    pub(crate) alpha_behavior: ::std::option::Option<crate::types::AlphaBehavior>,
    pub(crate) color_space: ::std::option::Option<crate::types::ColorSpace>,
    pub(crate) color_space_usage: ::std::option::Option<crate::types::ColorSpaceUsage>,
    pub(crate) embedded_timecode_override: ::std::option::Option<crate::types::EmbeddedTimecodeOverride>,
    pub(crate) hdr10_metadata: ::std::option::Option<crate::types::Hdr10Metadata>,
    pub(crate) max_luminance: ::std::option::Option<i32>,
    pub(crate) pad_video: ::std::option::Option<crate::types::PadVideo>,
    pub(crate) pid: ::std::option::Option<i32>,
    pub(crate) program_number: ::std::option::Option<i32>,
    pub(crate) rotate: ::std::option::Option<crate::types::InputRotate>,
    pub(crate) sample_range: ::std::option::Option<crate::types::InputSampleRange>,
    pub(crate) selector_type: ::std::option::Option<crate::types::VideoSelectorType>,
    pub(crate) streams: ::std::option::Option<::std::vec::Vec<i32>>,
}
impl VideoSelectorBuilder {
    /// Ignore this setting unless this input is a QuickTime animation with an alpha channel. Use this setting to create separate Key and Fill outputs. In each output, specify which part of the input MediaConvert uses. Leave this setting at the default value DISCARD to delete the alpha channel and preserve the video. Set it to REMAP_TO_LUMA to delete the video and map the alpha channel to the luma channel of your outputs.
    pub fn alpha_behavior(mut self, input: crate::types::AlphaBehavior) -> Self {
        self.alpha_behavior = ::std::option::Option::Some(input);
        self
    }
    /// Ignore this setting unless this input is a QuickTime animation with an alpha channel. Use this setting to create separate Key and Fill outputs. In each output, specify which part of the input MediaConvert uses. Leave this setting at the default value DISCARD to delete the alpha channel and preserve the video. Set it to REMAP_TO_LUMA to delete the video and map the alpha channel to the luma channel of your outputs.
    pub fn set_alpha_behavior(mut self, input: ::std::option::Option<crate::types::AlphaBehavior>) -> Self {
        self.alpha_behavior = input;
        self
    }
    /// Ignore this setting unless this input is a QuickTime animation with an alpha channel. Use this setting to create separate Key and Fill outputs. In each output, specify which part of the input MediaConvert uses. Leave this setting at the default value DISCARD to delete the alpha channel and preserve the video. Set it to REMAP_TO_LUMA to delete the video and map the alpha channel to the luma channel of your outputs.
    pub fn get_alpha_behavior(&self) -> &::std::option::Option<crate::types::AlphaBehavior> {
        &self.alpha_behavior
    }
    /// If your input video has accurate color space metadata, or if you don't know about color space: Keep the default value, Follow. MediaConvert will automatically detect your input color space. If your input video has metadata indicating the wrong color space, or has missing metadata: Specify the accurate color space here. If your input video is HDR 10 and the SMPTE ST 2086 Mastering Display Color Volume static metadata isn't present in your video stream, or if that metadata is present but not accurate: Choose Force HDR 10. Specify correct values in the input HDR 10 metadata settings. For more information about HDR jobs, see https://docs.aws.amazon.com/console/mediaconvert/hdr. When you specify an input color space, MediaConvert uses the following color space metadata, which includes color primaries, transfer characteristics, and matrix coefficients: * HDR 10: BT.2020, PQ, BT.2020 non-constant * HLG 2020: BT.2020, HLG, BT.2020 non-constant * P3DCI (Theater): DCIP3, SMPTE 428M, BT.709 * P3D65 (SDR): Display P3, sRGB, BT.709 * P3D65 (HDR): Display P3, PQ, BT.709
    pub fn color_space(mut self, input: crate::types::ColorSpace) -> Self {
        self.color_space = ::std::option::Option::Some(input);
        self
    }
    /// If your input video has accurate color space metadata, or if you don't know about color space: Keep the default value, Follow. MediaConvert will automatically detect your input color space. If your input video has metadata indicating the wrong color space, or has missing metadata: Specify the accurate color space here. If your input video is HDR 10 and the SMPTE ST 2086 Mastering Display Color Volume static metadata isn't present in your video stream, or if that metadata is present but not accurate: Choose Force HDR 10. Specify correct values in the input HDR 10 metadata settings. For more information about HDR jobs, see https://docs.aws.amazon.com/console/mediaconvert/hdr. When you specify an input color space, MediaConvert uses the following color space metadata, which includes color primaries, transfer characteristics, and matrix coefficients: * HDR 10: BT.2020, PQ, BT.2020 non-constant * HLG 2020: BT.2020, HLG, BT.2020 non-constant * P3DCI (Theater): DCIP3, SMPTE 428M, BT.709 * P3D65 (SDR): Display P3, sRGB, BT.709 * P3D65 (HDR): Display P3, PQ, BT.709
    pub fn set_color_space(mut self, input: ::std::option::Option<crate::types::ColorSpace>) -> Self {
        self.color_space = input;
        self
    }
    /// If your input video has accurate color space metadata, or if you don't know about color space: Keep the default value, Follow. MediaConvert will automatically detect your input color space. If your input video has metadata indicating the wrong color space, or has missing metadata: Specify the accurate color space here. If your input video is HDR 10 and the SMPTE ST 2086 Mastering Display Color Volume static metadata isn't present in your video stream, or if that metadata is present but not accurate: Choose Force HDR 10. Specify correct values in the input HDR 10 metadata settings. For more information about HDR jobs, see https://docs.aws.amazon.com/console/mediaconvert/hdr. When you specify an input color space, MediaConvert uses the following color space metadata, which includes color primaries, transfer characteristics, and matrix coefficients: * HDR 10: BT.2020, PQ, BT.2020 non-constant * HLG 2020: BT.2020, HLG, BT.2020 non-constant * P3DCI (Theater): DCIP3, SMPTE 428M, BT.709 * P3D65 (SDR): Display P3, sRGB, BT.709 * P3D65 (HDR): Display P3, PQ, BT.709
    pub fn get_color_space(&self) -> &::std::option::Option<crate::types::ColorSpace> {
        &self.color_space
    }
    /// There are two sources for color metadata, the input file and the job input settings Color space and HDR master display information settings. The Color space usage setting determines which takes precedence. Choose Force to use color metadata from the input job settings. If you don't specify values for those settings, the service defaults to using metadata from your input. FALLBACK - Choose Fallback to use color metadata from the source when it is present. If there's no color metadata in your input file, the service defaults to using values you specify in the input settings.
    pub fn color_space_usage(mut self, input: crate::types::ColorSpaceUsage) -> Self {
        self.color_space_usage = ::std::option::Option::Some(input);
        self
    }
    /// There are two sources for color metadata, the input file and the job input settings Color space and HDR master display information settings. The Color space usage setting determines which takes precedence. Choose Force to use color metadata from the input job settings. If you don't specify values for those settings, the service defaults to using metadata from your input. FALLBACK - Choose Fallback to use color metadata from the source when it is present. If there's no color metadata in your input file, the service defaults to using values you specify in the input settings.
    pub fn set_color_space_usage(mut self, input: ::std::option::Option<crate::types::ColorSpaceUsage>) -> Self {
        self.color_space_usage = input;
        self
    }
    /// There are two sources for color metadata, the input file and the job input settings Color space and HDR master display information settings. The Color space usage setting determines which takes precedence. Choose Force to use color metadata from the input job settings. If you don't specify values for those settings, the service defaults to using metadata from your input. FALLBACK - Choose Fallback to use color metadata from the source when it is present. If there's no color metadata in your input file, the service defaults to using values you specify in the input settings.
    pub fn get_color_space_usage(&self) -> &::std::option::Option<crate::types::ColorSpaceUsage> {
        &self.color_space_usage
    }
    /// Set Embedded timecode override to Use MDPM when your AVCHD input contains timecode tag data in the Modified Digital Video Pack Metadata. When you do, we recommend you also set Timecode source to Embedded. Leave Embedded timecode override blank, or set to None, when your input does not contain MDPM timecode.
    pub fn embedded_timecode_override(mut self, input: crate::types::EmbeddedTimecodeOverride) -> Self {
        self.embedded_timecode_override = ::std::option::Option::Some(input);
        self
    }
    /// Set Embedded timecode override to Use MDPM when your AVCHD input contains timecode tag data in the Modified Digital Video Pack Metadata. When you do, we recommend you also set Timecode source to Embedded. Leave Embedded timecode override blank, or set to None, when your input does not contain MDPM timecode.
    pub fn set_embedded_timecode_override(mut self, input: ::std::option::Option<crate::types::EmbeddedTimecodeOverride>) -> Self {
        self.embedded_timecode_override = input;
        self
    }
    /// Set Embedded timecode override to Use MDPM when your AVCHD input contains timecode tag data in the Modified Digital Video Pack Metadata. When you do, we recommend you also set Timecode source to Embedded. Leave Embedded timecode override blank, or set to None, when your input does not contain MDPM timecode.
    pub fn get_embedded_timecode_override(&self) -> &::std::option::Option<crate::types::EmbeddedTimecodeOverride> {
        &self.embedded_timecode_override
    }
    /// Use these settings to provide HDR 10 metadata that is missing or inaccurate in your input video. Appropriate values vary depending on the input video and must be provided by a color grader. The color grader generates these values during the HDR 10 mastering process. The valid range for each of these settings is 0 to 50,000. Each increment represents 0.00002 in CIE1931 color coordinate. Related settings - When you specify these values, you must also set Color space to HDR 10. To specify whether the the values you specify here take precedence over the values in the metadata of your input file, set Color space usage. To specify whether color metadata is included in an output, set Color metadata. For more information about MediaConvert HDR jobs, see https://docs.aws.amazon.com/console/mediaconvert/hdr.
    pub fn hdr10_metadata(mut self, input: crate::types::Hdr10Metadata) -> Self {
        self.hdr10_metadata = ::std::option::Option::Some(input);
        self
    }
    /// Use these settings to provide HDR 10 metadata that is missing or inaccurate in your input video. Appropriate values vary depending on the input video and must be provided by a color grader. The color grader generates these values during the HDR 10 mastering process. The valid range for each of these settings is 0 to 50,000. Each increment represents 0.00002 in CIE1931 color coordinate. Related settings - When you specify these values, you must also set Color space to HDR 10. To specify whether the the values you specify here take precedence over the values in the metadata of your input file, set Color space usage. To specify whether color metadata is included in an output, set Color metadata. For more information about MediaConvert HDR jobs, see https://docs.aws.amazon.com/console/mediaconvert/hdr.
    pub fn set_hdr10_metadata(mut self, input: ::std::option::Option<crate::types::Hdr10Metadata>) -> Self {
        self.hdr10_metadata = input;
        self
    }
    /// Use these settings to provide HDR 10 metadata that is missing or inaccurate in your input video. Appropriate values vary depending on the input video and must be provided by a color grader. The color grader generates these values during the HDR 10 mastering process. The valid range for each of these settings is 0 to 50,000. Each increment represents 0.00002 in CIE1931 color coordinate. Related settings - When you specify these values, you must also set Color space to HDR 10. To specify whether the the values you specify here take precedence over the values in the metadata of your input file, set Color space usage. To specify whether color metadata is included in an output, set Color metadata. For more information about MediaConvert HDR jobs, see https://docs.aws.amazon.com/console/mediaconvert/hdr.
    pub fn get_hdr10_metadata(&self) -> &::std::option::Option<crate::types::Hdr10Metadata> {
        &self.hdr10_metadata
    }
    /// Specify the maximum mastering display luminance. Enter an integer from 0 to 2147483647, in units of 0.0001 nits. For example, enter 10000000 for 1000 nits.
    pub fn max_luminance(mut self, input: i32) -> Self {
        self.max_luminance = ::std::option::Option::Some(input);
        self
    }
    /// Specify the maximum mastering display luminance. Enter an integer from 0 to 2147483647, in units of 0.0001 nits. For example, enter 10000000 for 1000 nits.
    pub fn set_max_luminance(mut self, input: ::std::option::Option<i32>) -> Self {
        self.max_luminance = input;
        self
    }
    /// Specify the maximum mastering display luminance. Enter an integer from 0 to 2147483647, in units of 0.0001 nits. For example, enter 10000000 for 1000 nits.
    pub fn get_max_luminance(&self) -> &::std::option::Option<i32> {
        &self.max_luminance
    }
    /// Use this setting if your input has video and audio durations that don't align, and your output or player has strict alignment requirements. Examples: Input audio track has a delayed start. Input video track ends before audio ends. When you set Pad video to Black, MediaConvert generates black video frames so that output video and audio durations match. Black video frames are added at the beginning or end, depending on your input. To keep the default behavior and not generate black video, set Pad video to Disabled or leave blank.
    pub fn pad_video(mut self, input: crate::types::PadVideo) -> Self {
        self.pad_video = ::std::option::Option::Some(input);
        self
    }
    /// Use this setting if your input has video and audio durations that don't align, and your output or player has strict alignment requirements. Examples: Input audio track has a delayed start. Input video track ends before audio ends. When you set Pad video to Black, MediaConvert generates black video frames so that output video and audio durations match. Black video frames are added at the beginning or end, depending on your input. To keep the default behavior and not generate black video, set Pad video to Disabled or leave blank.
    pub fn set_pad_video(mut self, input: ::std::option::Option<crate::types::PadVideo>) -> Self {
        self.pad_video = input;
        self
    }
    /// Use this setting if your input has video and audio durations that don't align, and your output or player has strict alignment requirements. Examples: Input audio track has a delayed start. Input video track ends before audio ends. When you set Pad video to Black, MediaConvert generates black video frames so that output video and audio durations match. Black video frames are added at the beginning or end, depending on your input. To keep the default behavior and not generate black video, set Pad video to Disabled or leave blank.
    pub fn get_pad_video(&self) -> &::std::option::Option<crate::types::PadVideo> {
        &self.pad_video
    }
    /// Use PID to select specific video data from an input file. Specify this value as an integer; the system automatically converts it to the hexidecimal value. For example, 257 selects PID 0x101. A PID, or packet identifier, is an identifier for a set of data in an MPEG-2 transport stream container.
    pub fn pid(mut self, input: i32) -> Self {
        self.pid = ::std::option::Option::Some(input);
        self
    }
    /// Use PID to select specific video data from an input file. Specify this value as an integer; the system automatically converts it to the hexidecimal value. For example, 257 selects PID 0x101. A PID, or packet identifier, is an identifier for a set of data in an MPEG-2 transport stream container.
    pub fn set_pid(mut self, input: ::std::option::Option<i32>) -> Self {
        self.pid = input;
        self
    }
    /// Use PID to select specific video data from an input file. Specify this value as an integer; the system automatically converts it to the hexidecimal value. For example, 257 selects PID 0x101. A PID, or packet identifier, is an identifier for a set of data in an MPEG-2 transport stream container.
    pub fn get_pid(&self) -> &::std::option::Option<i32> {
        &self.pid
    }
    /// Selects a specific program from within a multi-program transport stream. Note that Quad 4K is not currently supported.
    pub fn program_number(mut self, input: i32) -> Self {
        self.program_number = ::std::option::Option::Some(input);
        self
    }
    /// Selects a specific program from within a multi-program transport stream. Note that Quad 4K is not currently supported.
    pub fn set_program_number(mut self, input: ::std::option::Option<i32>) -> Self {
        self.program_number = input;
        self
    }
    /// Selects a specific program from within a multi-program transport stream. Note that Quad 4K is not currently supported.
    pub fn get_program_number(&self) -> &::std::option::Option<i32> {
        &self.program_number
    }
    /// Use Rotate to specify how the service rotates your video. You can choose automatic rotation or specify a rotation. You can specify a clockwise rotation of 0, 90, 180, or 270 degrees. If your input video container is .mov or .mp4 and your input has rotation metadata, you can choose Automatic to have the service rotate your video according to the rotation specified in the metadata. The rotation must be within one degree of 90, 180, or 270 degrees. If the rotation metadata specifies any other rotation, the service will default to no rotation. By default, the service does no rotation, even if your input video has rotation metadata. The service doesn't pass through rotation metadata.
    pub fn rotate(mut self, input: crate::types::InputRotate) -> Self {
        self.rotate = ::std::option::Option::Some(input);
        self
    }
    /// Use Rotate to specify how the service rotates your video. You can choose automatic rotation or specify a rotation. You can specify a clockwise rotation of 0, 90, 180, or 270 degrees. If your input video container is .mov or .mp4 and your input has rotation metadata, you can choose Automatic to have the service rotate your video according to the rotation specified in the metadata. The rotation must be within one degree of 90, 180, or 270 degrees. If the rotation metadata specifies any other rotation, the service will default to no rotation. By default, the service does no rotation, even if your input video has rotation metadata. The service doesn't pass through rotation metadata.
    pub fn set_rotate(mut self, input: ::std::option::Option<crate::types::InputRotate>) -> Self {
        self.rotate = input;
        self
    }
    /// Use Rotate to specify how the service rotates your video. You can choose automatic rotation or specify a rotation. You can specify a clockwise rotation of 0, 90, 180, or 270 degrees. If your input video container is .mov or .mp4 and your input has rotation metadata, you can choose Automatic to have the service rotate your video according to the rotation specified in the metadata. The rotation must be within one degree of 90, 180, or 270 degrees. If the rotation metadata specifies any other rotation, the service will default to no rotation. By default, the service does no rotation, even if your input video has rotation metadata. The service doesn't pass through rotation metadata.
    pub fn get_rotate(&self) -> &::std::option::Option<crate::types::InputRotate> {
        &self.rotate
    }
    /// If the sample range metadata in your input video is accurate, or if you don't know about sample range, keep the default value, Follow, for this setting. When you do, the service automatically detects your input sample range. If your input video has metadata indicating the wrong sample range, specify the accurate sample range here. When you do, MediaConvert ignores any sample range information in the input metadata. Regardless of whether MediaConvert uses the input sample range or the sample range that you specify, MediaConvert uses the sample range for transcoding and also writes it to the output metadata.
    pub fn sample_range(mut self, input: crate::types::InputSampleRange) -> Self {
        self.sample_range = ::std::option::Option::Some(input);
        self
    }
    /// If the sample range metadata in your input video is accurate, or if you don't know about sample range, keep the default value, Follow, for this setting. When you do, the service automatically detects your input sample range. If your input video has metadata indicating the wrong sample range, specify the accurate sample range here. When you do, MediaConvert ignores any sample range information in the input metadata. Regardless of whether MediaConvert uses the input sample range or the sample range that you specify, MediaConvert uses the sample range for transcoding and also writes it to the output metadata.
    pub fn set_sample_range(mut self, input: ::std::option::Option<crate::types::InputSampleRange>) -> Self {
        self.sample_range = input;
        self
    }
    /// If the sample range metadata in your input video is accurate, or if you don't know about sample range, keep the default value, Follow, for this setting. When you do, the service automatically detects your input sample range. If your input video has metadata indicating the wrong sample range, specify the accurate sample range here. When you do, MediaConvert ignores any sample range information in the input metadata. Regardless of whether MediaConvert uses the input sample range or the sample range that you specify, MediaConvert uses the sample range for transcoding and also writes it to the output metadata.
    pub fn get_sample_range(&self) -> &::std::option::Option<crate::types::InputSampleRange> {
        &self.sample_range
    }
    /// Choose the video selector type for your HLS input. Use to specify which video rendition MediaConvert uses from your HLS input. To have MediaConvert automatically use the highest bitrate rendition from your HLS input: Keep the default value, Auto. To manually specify a rendition: Choose Stream. Then enter the unique stream number in the Streams array, starting at 1, corresponding to the stream order in the manifest.
    pub fn selector_type(mut self, input: crate::types::VideoSelectorType) -> Self {
        self.selector_type = ::std::option::Option::Some(input);
        self
    }
    /// Choose the video selector type for your HLS input. Use to specify which video rendition MediaConvert uses from your HLS input. To have MediaConvert automatically use the highest bitrate rendition from your HLS input: Keep the default value, Auto. To manually specify a rendition: Choose Stream. Then enter the unique stream number in the Streams array, starting at 1, corresponding to the stream order in the manifest.
    pub fn set_selector_type(mut self, input: ::std::option::Option<crate::types::VideoSelectorType>) -> Self {
        self.selector_type = input;
        self
    }
    /// Choose the video selector type for your HLS input. Use to specify which video rendition MediaConvert uses from your HLS input. To have MediaConvert automatically use the highest bitrate rendition from your HLS input: Keep the default value, Auto. To manually specify a rendition: Choose Stream. Then enter the unique stream number in the Streams array, starting at 1, corresponding to the stream order in the manifest.
    pub fn get_selector_type(&self) -> &::std::option::Option<crate::types::VideoSelectorType> {
        &self.selector_type
    }
    /// Appends an item to `streams`.
    ///
    /// To override the contents of this collection use [`set_streams`](Self::set_streams).
    ///
    /// Specify one or more video streams for MediaConvert to use from your HLS input. Enter an integer corresponding to the stream number, with the first stream in your HLS multivariant playlist starting at 1.For re-encoding workflows, MediaConvert uses the video stream that you select with the highest bitrate as the input.For video passthrough workflows, you specify whether to passthrough a single video stream or multiple video streams under Video selector source in the output video encoding settings.
    pub fn streams(mut self, input: i32) -> Self {
        let mut v = self.streams.unwrap_or_default();
        v.push(input);
        self.streams = ::std::option::Option::Some(v);
        self
    }
    /// Specify one or more video streams for MediaConvert to use from your HLS input. Enter an integer corresponding to the stream number, with the first stream in your HLS multivariant playlist starting at 1.For re-encoding workflows, MediaConvert uses the video stream that you select with the highest bitrate as the input.For video passthrough workflows, you specify whether to passthrough a single video stream or multiple video streams under Video selector source in the output video encoding settings.
    pub fn set_streams(mut self, input: ::std::option::Option<::std::vec::Vec<i32>>) -> Self {
        self.streams = input;
        self
    }
    /// Specify one or more video streams for MediaConvert to use from your HLS input. Enter an integer corresponding to the stream number, with the first stream in your HLS multivariant playlist starting at 1.For re-encoding workflows, MediaConvert uses the video stream that you select with the highest bitrate as the input.For video passthrough workflows, you specify whether to passthrough a single video stream or multiple video streams under Video selector source in the output video encoding settings.
    pub fn get_streams(&self) -> &::std::option::Option<::std::vec::Vec<i32>> {
        &self.streams
    }
    /// Consumes the builder and constructs a [`VideoSelector`](crate::types::VideoSelector).
    pub fn build(self) -> crate::types::VideoSelector {
        crate::types::VideoSelector {
            alpha_behavior: self.alpha_behavior,
            color_space: self.color_space,
            color_space_usage: self.color_space_usage,
            embedded_timecode_override: self.embedded_timecode_override,
            hdr10_metadata: self.hdr10_metadata,
            max_luminance: self.max_luminance,
            pad_video: self.pad_video,
            pid: self.pid,
            program_number: self.program_number,
            rotate: self.rotate,
            sample_range: self.sample_range,
            selector_type: self.selector_type,
            streams: self.streams,
        }
    }
}
