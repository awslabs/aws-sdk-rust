// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// Required when you set (Codec) under (VideoDescription)&gt;(CodecSettings) to the value MPEG2.
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct Mpeg2Settings {
    /// Specify the strength of any adaptive quantization filters that you enable. The value that you choose here applies to the following settings: Spatial adaptive quantization (spatialAdaptiveQuantization), and Temporal adaptive quantization (temporalAdaptiveQuantization).
    #[doc(hidden)]
    pub adaptive_quantization: std::option::Option<crate::types::Mpeg2AdaptiveQuantization>,
    /// Specify the average bitrate in bits per second. Required for VBR and CBR. For MS Smooth outputs, bitrates must be unique when rounded down to the nearest multiple of 1000.
    #[doc(hidden)]
    pub bitrate: i32,
    /// Use Level (Mpeg2CodecLevel) to set the MPEG-2 level for the video output.
    #[doc(hidden)]
    pub codec_level: std::option::Option<crate::types::Mpeg2CodecLevel>,
    /// Use Profile (Mpeg2CodecProfile) to set the MPEG-2 profile for the video output.
    #[doc(hidden)]
    pub codec_profile: std::option::Option<crate::types::Mpeg2CodecProfile>,
    /// Choose Adaptive to improve subjective video quality for high-motion content. This will cause the service to use fewer B-frames (which infer information based on other frames) for high-motion portions of the video and more B-frames for low-motion portions. The maximum number of B-frames is limited by the value you provide for the setting B frames between reference frames (numberBFramesBetweenReferenceFrames).
    #[doc(hidden)]
    pub dynamic_sub_gop: std::option::Option<crate::types::Mpeg2DynamicSubGop>,
    /// If you are using the console, use the Framerate setting to specify the frame rate for this output. If you want to keep the same frame rate as the input video, choose Follow source. If you want to do frame rate conversion, choose a frame rate from the dropdown list or choose Custom. The framerates shown in the dropdown list are decimal approximations of fractions. If you choose Custom, specify your frame rate as a fraction. If you are creating your transcoding job specification as a JSON file without the console, use FramerateControl to specify which value the service uses for the frame rate for this output. Choose INITIALIZE_FROM_SOURCE if you want the service to use the frame rate from the input. Choose SPECIFIED if you want the service to use the frame rate you specify in the settings FramerateNumerator and FramerateDenominator.
    #[doc(hidden)]
    pub framerate_control: std::option::Option<crate::types::Mpeg2FramerateControl>,
    /// Choose the method that you want MediaConvert to use when increasing or decreasing the frame rate. We recommend using drop duplicate (DUPLICATE_DROP) for numerically simple conversions, such as 60 fps to 30 fps. For numerically complex conversions, you can use interpolate (INTERPOLATE) to avoid stutter. This results in a smooth picture, but might introduce undesirable video artifacts. For complex frame rate conversions, especially if your source video has already been converted from its original cadence, use FrameFormer (FRAMEFORMER) to do motion-compensated interpolation. FrameFormer chooses the best conversion method frame by frame. Note that using FrameFormer increases the transcoding time and incurs a significant add-on cost.
    #[doc(hidden)]
    pub framerate_conversion_algorithm:
        std::option::Option<crate::types::Mpeg2FramerateConversionAlgorithm>,
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateDenominator to specify the denominator of this fraction. In this example, use 1001 for the value of FramerateDenominator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    #[doc(hidden)]
    pub framerate_denominator: i32,
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateNumerator to specify the numerator of this fraction. In this example, use 24000 for the value of FramerateNumerator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    #[doc(hidden)]
    pub framerate_numerator: i32,
    /// Specify the relative frequency of open to closed GOPs in this output. For example, if you want to allow four open GOPs and then require a closed GOP, set this value to 5. When you create a streaming output, we recommend that you keep the default value, 1, so that players starting mid-stream receive an IDR frame as quickly as possible. Don't set this value to 0; that would break output segmenting.
    #[doc(hidden)]
    pub gop_closed_cadence: i32,
    /// Specify the interval between keyframes, in seconds or frames, for this output. Default: 12 Related settings: When you specify the GOP size in seconds, set GOP mode control (GopSizeUnits) to Specified, seconds (SECONDS). The default value for GOP mode control (GopSizeUnits) is Frames (FRAMES).
    #[doc(hidden)]
    pub gop_size: f64,
    /// Specify the units for GOP size (GopSize). If you don't specify a value here, by default the encoder measures GOP size in frames.
    #[doc(hidden)]
    pub gop_size_units: std::option::Option<crate::types::Mpeg2GopSizeUnits>,
    /// If your downstream systems have strict buffer requirements: Specify the minimum percentage of the HRD buffer that's available at the end of each encoded video segment. For the best video quality: Set to 0 or leave blank to automatically determine the final buffer fill percentage.
    #[doc(hidden)]
    pub hrd_buffer_final_fill_percentage: i32,
    /// Percentage of the buffer that should initially be filled (HRD buffer model).
    #[doc(hidden)]
    pub hrd_buffer_initial_fill_percentage: i32,
    /// Size of buffer (HRD buffer model) in bits. For example, enter five megabits as 5000000.
    #[doc(hidden)]
    pub hrd_buffer_size: i32,
    /// Choose the scan line type for the output. Keep the default value, Progressive (PROGRESSIVE) to create a progressive output, regardless of the scan type of your input. Use Top field first (TOP_FIELD) or Bottom field first (BOTTOM_FIELD) to create an output that's interlaced with the same field polarity throughout. Use Follow, default top (FOLLOW_TOP_FIELD) or Follow, default bottom (FOLLOW_BOTTOM_FIELD) to produce outputs with the same field polarity as the source. For jobs that have multiple inputs, the output field polarity might change over the course of the output. Follow behavior depends on the input scan type. If the source is interlaced, the output will be interlaced with the same polarity as the source. If the source is progressive, the output will be interlaced with top field bottom field first, depending on which of the Follow options you choose.
    #[doc(hidden)]
    pub interlace_mode: std::option::Option<crate::types::Mpeg2InterlaceMode>,
    /// Use Intra DC precision (Mpeg2IntraDcPrecision) to set quantization precision for intra-block DC coefficients. If you choose the value auto, the service will automatically select the precision based on the per-frame compression ratio.
    #[doc(hidden)]
    pub intra_dc_precision: std::option::Option<crate::types::Mpeg2IntraDcPrecision>,
    /// Maximum bitrate in bits/second. For example, enter five megabits per second as 5000000.
    #[doc(hidden)]
    pub max_bitrate: i32,
    /// Use this setting only when you also enable Scene change detection (SceneChangeDetect). This setting determines how the encoder manages the spacing between I-frames that it inserts as part of the I-frame cadence and the I-frames that it inserts for Scene change detection. When you specify a value for this setting, the encoder determines whether to skip a cadence-driven I-frame by the value you set. For example, if you set Min I interval (minIInterval) to 5 and a cadence-driven I-frame would fall within 5 frames of a scene-change I-frame, then the encoder skips the cadence-driven I-frame. In this way, one GOP is shrunk slightly and one GOP is stretched slightly. When the cadence-driven I-frames are farther from the scene-change I-frame than the value you set, then the encoder leaves all I-frames in place and the GOPs surrounding the scene change are smaller than the usual cadence GOPs.
    #[doc(hidden)]
    pub min_i_interval: i32,
    /// Specify the number of B-frames that MediaConvert puts between reference frames in this output. Valid values are whole numbers from 0 through 7. When you don't specify a value, MediaConvert defaults to 2.
    #[doc(hidden)]
    pub number_b_frames_between_reference_frames: i32,
    /// Optional. Specify how the service determines the pixel aspect ratio (PAR) for this output. The default behavior, Follow source (INITIALIZE_FROM_SOURCE), uses the PAR from your input video for your output. To specify a different PAR in the console, choose any value other than Follow source. To specify a different PAR by editing the JSON job specification, choose SPECIFIED. When you choose SPECIFIED for this setting, you must also specify values for the parNumerator and parDenominator settings.
    #[doc(hidden)]
    pub par_control: std::option::Option<crate::types::Mpeg2ParControl>,
    /// Required when you set Pixel aspect ratio (parControl) to SPECIFIED. On the console, this corresponds to any value other than Follow source. When you specify an output pixel aspect ratio (PAR) that is different from your input video PAR, provide your output PAR as a ratio. For example, for D1/DV NTSC widescreen, you would specify the ratio 40:33. In this example, the value for parDenominator is 33.
    #[doc(hidden)]
    pub par_denominator: i32,
    /// Required when you set Pixel aspect ratio (parControl) to SPECIFIED. On the console, this corresponds to any value other than Follow source. When you specify an output pixel aspect ratio (PAR) that is different from your input video PAR, provide your output PAR as a ratio. For example, for D1/DV NTSC widescreen, you would specify the ratio 40:33. In this example, the value for parNumerator is 40.
    #[doc(hidden)]
    pub par_numerator: i32,
    /// Optional. Use Quality tuning level (qualityTuningLevel) to choose how you want to trade off encoding speed for output video quality. The default behavior is faster, lower quality, single-pass encoding.
    #[doc(hidden)]
    pub quality_tuning_level: std::option::Option<crate::types::Mpeg2QualityTuningLevel>,
    /// Use Rate control mode (Mpeg2RateControlMode) to specify whether the bitrate is variable (vbr) or constant (cbr).
    #[doc(hidden)]
    pub rate_control_mode: std::option::Option<crate::types::Mpeg2RateControlMode>,
    /// Use this setting for interlaced outputs, when your output frame rate is half of your input frame rate. In this situation, choose Optimized interlacing (INTERLACED_OPTIMIZE) to create a better quality interlaced output. In this case, each progressive frame from the input corresponds to an interlaced field in the output. Keep the default value, Basic interlacing (INTERLACED), for all other output frame rates. With basic interlacing, MediaConvert performs any frame rate conversion first and then interlaces the frames. When you choose Optimized interlacing and you set your output frame rate to a value that isn't suitable for optimized interlacing, MediaConvert automatically falls back to basic interlacing. Required settings: To use optimized interlacing, you must set Telecine (telecine) to None (NONE) or Soft (SOFT). You can't use optimized interlacing for hard telecine outputs. You must also set Interlace mode (interlaceMode) to a value other than Progressive (PROGRESSIVE).
    #[doc(hidden)]
    pub scan_type_conversion_mode: std::option::Option<crate::types::Mpeg2ScanTypeConversionMode>,
    /// Enable this setting to insert I-frames at scene changes that the service automatically detects. This improves video quality and is enabled by default.
    #[doc(hidden)]
    pub scene_change_detect: std::option::Option<crate::types::Mpeg2SceneChangeDetect>,
    /// Ignore this setting unless your input frame rate is 23.976 or 24 frames per second (fps). Enable slow PAL to create a 25 fps output. When you enable slow PAL, MediaConvert relabels the video frames to 25 fps and resamples your audio to keep it synchronized with the video. Note that enabling this setting will slightly reduce the duration of your video. Required settings: You must also set Framerate to 25. In your JSON job specification, set (framerateControl) to (SPECIFIED), (framerateNumerator) to 25 and (framerateDenominator) to 1.
    #[doc(hidden)]
    pub slow_pal: std::option::Option<crate::types::Mpeg2SlowPal>,
    /// Ignore this setting unless you need to comply with a specification that requires a specific value. If you don't have a specification requirement, we recommend that you adjust the softness of your output by using a lower value for the setting Sharpness (sharpness) or by enabling a noise reducer filter (noiseReducerFilter). The Softness (softness) setting specifies the quantization matrices that the encoder uses. Keep the default value, 0, to use the AWS Elemental default matrices. Choose a value from 17 to 128 to use planar interpolation. Increasing values from 17 to 128 result in increasing reduction of high-frequency data. The value 128 results in the softest video.
    #[doc(hidden)]
    pub softness: i32,
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on spatial variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas that can sustain more distortion with no noticeable visual degradation and uses more bits on areas where any small distortion will be noticeable. For example, complex textured blocks are encoded with fewer bits and smooth textured blocks are encoded with more bits. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen with a lot of complex texture, you might choose to disable this feature. Related setting: When you enable spatial adaptive quantization, set the value for Adaptive quantization (adaptiveQuantization) depending on your content. For homogeneous content, such as cartoons and video games, set it to Low. For content with a wider variety of textures, set it to High or Higher.
    #[doc(hidden)]
    pub spatial_adaptive_quantization:
        std::option::Option<crate::types::Mpeg2SpatialAdaptiveQuantization>,
    /// Specify whether this output's video uses the D10 syntax. Keep the default value to not use the syntax. Related settings: When you choose D10 (D_10) for your MXF profile (profile), you must also set this value to D10 (D_10).
    #[doc(hidden)]
    pub syntax: std::option::Option<crate::types::Mpeg2Syntax>,
    /// When you do frame rate conversion from 23.976 frames per second (fps) to 29.97 fps, and your output scan type is interlaced, you can optionally enable hard or soft telecine to create a smoother picture. Hard telecine (HARD) produces a 29.97i output. Soft telecine (SOFT) produces an output with a 23.976 output that signals to the video player device to do the conversion during play back. When you keep the default value, None (NONE), MediaConvert does a standard frame rate conversion to 29.97 without doing anything with the field polarity to create a smoother picture.
    #[doc(hidden)]
    pub telecine: std::option::Option<crate::types::Mpeg2Telecine>,
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on temporal variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas of the frame that aren't moving and uses more bits on complex objects with sharp edges that move a lot. For example, this feature improves the readability of text tickers on newscasts and scoreboards on sports matches. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen that doesn't have moving objects with sharp edges, such as sports athletes' faces, you might choose to disable this feature. Related setting: When you enable temporal quantization, adjust the strength of the filter with the setting Adaptive quantization (adaptiveQuantization).
    #[doc(hidden)]
    pub temporal_adaptive_quantization:
        std::option::Option<crate::types::Mpeg2TemporalAdaptiveQuantization>,
}
impl Mpeg2Settings {
    /// Specify the strength of any adaptive quantization filters that you enable. The value that you choose here applies to the following settings: Spatial adaptive quantization (spatialAdaptiveQuantization), and Temporal adaptive quantization (temporalAdaptiveQuantization).
    pub fn adaptive_quantization(
        &self,
    ) -> std::option::Option<&crate::types::Mpeg2AdaptiveQuantization> {
        self.adaptive_quantization.as_ref()
    }
    /// Specify the average bitrate in bits per second. Required for VBR and CBR. For MS Smooth outputs, bitrates must be unique when rounded down to the nearest multiple of 1000.
    pub fn bitrate(&self) -> i32 {
        self.bitrate
    }
    /// Use Level (Mpeg2CodecLevel) to set the MPEG-2 level for the video output.
    pub fn codec_level(&self) -> std::option::Option<&crate::types::Mpeg2CodecLevel> {
        self.codec_level.as_ref()
    }
    /// Use Profile (Mpeg2CodecProfile) to set the MPEG-2 profile for the video output.
    pub fn codec_profile(&self) -> std::option::Option<&crate::types::Mpeg2CodecProfile> {
        self.codec_profile.as_ref()
    }
    /// Choose Adaptive to improve subjective video quality for high-motion content. This will cause the service to use fewer B-frames (which infer information based on other frames) for high-motion portions of the video and more B-frames for low-motion portions. The maximum number of B-frames is limited by the value you provide for the setting B frames between reference frames (numberBFramesBetweenReferenceFrames).
    pub fn dynamic_sub_gop(&self) -> std::option::Option<&crate::types::Mpeg2DynamicSubGop> {
        self.dynamic_sub_gop.as_ref()
    }
    /// If you are using the console, use the Framerate setting to specify the frame rate for this output. If you want to keep the same frame rate as the input video, choose Follow source. If you want to do frame rate conversion, choose a frame rate from the dropdown list or choose Custom. The framerates shown in the dropdown list are decimal approximations of fractions. If you choose Custom, specify your frame rate as a fraction. If you are creating your transcoding job specification as a JSON file without the console, use FramerateControl to specify which value the service uses for the frame rate for this output. Choose INITIALIZE_FROM_SOURCE if you want the service to use the frame rate from the input. Choose SPECIFIED if you want the service to use the frame rate you specify in the settings FramerateNumerator and FramerateDenominator.
    pub fn framerate_control(&self) -> std::option::Option<&crate::types::Mpeg2FramerateControl> {
        self.framerate_control.as_ref()
    }
    /// Choose the method that you want MediaConvert to use when increasing or decreasing the frame rate. We recommend using drop duplicate (DUPLICATE_DROP) for numerically simple conversions, such as 60 fps to 30 fps. For numerically complex conversions, you can use interpolate (INTERPOLATE) to avoid stutter. This results in a smooth picture, but might introduce undesirable video artifacts. For complex frame rate conversions, especially if your source video has already been converted from its original cadence, use FrameFormer (FRAMEFORMER) to do motion-compensated interpolation. FrameFormer chooses the best conversion method frame by frame. Note that using FrameFormer increases the transcoding time and incurs a significant add-on cost.
    pub fn framerate_conversion_algorithm(
        &self,
    ) -> std::option::Option<&crate::types::Mpeg2FramerateConversionAlgorithm> {
        self.framerate_conversion_algorithm.as_ref()
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateDenominator to specify the denominator of this fraction. In this example, use 1001 for the value of FramerateDenominator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn framerate_denominator(&self) -> i32 {
        self.framerate_denominator
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateNumerator to specify the numerator of this fraction. In this example, use 24000 for the value of FramerateNumerator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn framerate_numerator(&self) -> i32 {
        self.framerate_numerator
    }
    /// Specify the relative frequency of open to closed GOPs in this output. For example, if you want to allow four open GOPs and then require a closed GOP, set this value to 5. When you create a streaming output, we recommend that you keep the default value, 1, so that players starting mid-stream receive an IDR frame as quickly as possible. Don't set this value to 0; that would break output segmenting.
    pub fn gop_closed_cadence(&self) -> i32 {
        self.gop_closed_cadence
    }
    /// Specify the interval between keyframes, in seconds or frames, for this output. Default: 12 Related settings: When you specify the GOP size in seconds, set GOP mode control (GopSizeUnits) to Specified, seconds (SECONDS). The default value for GOP mode control (GopSizeUnits) is Frames (FRAMES).
    pub fn gop_size(&self) -> f64 {
        self.gop_size
    }
    /// Specify the units for GOP size (GopSize). If you don't specify a value here, by default the encoder measures GOP size in frames.
    pub fn gop_size_units(&self) -> std::option::Option<&crate::types::Mpeg2GopSizeUnits> {
        self.gop_size_units.as_ref()
    }
    /// If your downstream systems have strict buffer requirements: Specify the minimum percentage of the HRD buffer that's available at the end of each encoded video segment. For the best video quality: Set to 0 or leave blank to automatically determine the final buffer fill percentage.
    pub fn hrd_buffer_final_fill_percentage(&self) -> i32 {
        self.hrd_buffer_final_fill_percentage
    }
    /// Percentage of the buffer that should initially be filled (HRD buffer model).
    pub fn hrd_buffer_initial_fill_percentage(&self) -> i32 {
        self.hrd_buffer_initial_fill_percentage
    }
    /// Size of buffer (HRD buffer model) in bits. For example, enter five megabits as 5000000.
    pub fn hrd_buffer_size(&self) -> i32 {
        self.hrd_buffer_size
    }
    /// Choose the scan line type for the output. Keep the default value, Progressive (PROGRESSIVE) to create a progressive output, regardless of the scan type of your input. Use Top field first (TOP_FIELD) or Bottom field first (BOTTOM_FIELD) to create an output that's interlaced with the same field polarity throughout. Use Follow, default top (FOLLOW_TOP_FIELD) or Follow, default bottom (FOLLOW_BOTTOM_FIELD) to produce outputs with the same field polarity as the source. For jobs that have multiple inputs, the output field polarity might change over the course of the output. Follow behavior depends on the input scan type. If the source is interlaced, the output will be interlaced with the same polarity as the source. If the source is progressive, the output will be interlaced with top field bottom field first, depending on which of the Follow options you choose.
    pub fn interlace_mode(&self) -> std::option::Option<&crate::types::Mpeg2InterlaceMode> {
        self.interlace_mode.as_ref()
    }
    /// Use Intra DC precision (Mpeg2IntraDcPrecision) to set quantization precision for intra-block DC coefficients. If you choose the value auto, the service will automatically select the precision based on the per-frame compression ratio.
    pub fn intra_dc_precision(&self) -> std::option::Option<&crate::types::Mpeg2IntraDcPrecision> {
        self.intra_dc_precision.as_ref()
    }
    /// Maximum bitrate in bits/second. For example, enter five megabits per second as 5000000.
    pub fn max_bitrate(&self) -> i32 {
        self.max_bitrate
    }
    /// Use this setting only when you also enable Scene change detection (SceneChangeDetect). This setting determines how the encoder manages the spacing between I-frames that it inserts as part of the I-frame cadence and the I-frames that it inserts for Scene change detection. When you specify a value for this setting, the encoder determines whether to skip a cadence-driven I-frame by the value you set. For example, if you set Min I interval (minIInterval) to 5 and a cadence-driven I-frame would fall within 5 frames of a scene-change I-frame, then the encoder skips the cadence-driven I-frame. In this way, one GOP is shrunk slightly and one GOP is stretched slightly. When the cadence-driven I-frames are farther from the scene-change I-frame than the value you set, then the encoder leaves all I-frames in place and the GOPs surrounding the scene change are smaller than the usual cadence GOPs.
    pub fn min_i_interval(&self) -> i32 {
        self.min_i_interval
    }
    /// Specify the number of B-frames that MediaConvert puts between reference frames in this output. Valid values are whole numbers from 0 through 7. When you don't specify a value, MediaConvert defaults to 2.
    pub fn number_b_frames_between_reference_frames(&self) -> i32 {
        self.number_b_frames_between_reference_frames
    }
    /// Optional. Specify how the service determines the pixel aspect ratio (PAR) for this output. The default behavior, Follow source (INITIALIZE_FROM_SOURCE), uses the PAR from your input video for your output. To specify a different PAR in the console, choose any value other than Follow source. To specify a different PAR by editing the JSON job specification, choose SPECIFIED. When you choose SPECIFIED for this setting, you must also specify values for the parNumerator and parDenominator settings.
    pub fn par_control(&self) -> std::option::Option<&crate::types::Mpeg2ParControl> {
        self.par_control.as_ref()
    }
    /// Required when you set Pixel aspect ratio (parControl) to SPECIFIED. On the console, this corresponds to any value other than Follow source. When you specify an output pixel aspect ratio (PAR) that is different from your input video PAR, provide your output PAR as a ratio. For example, for D1/DV NTSC widescreen, you would specify the ratio 40:33. In this example, the value for parDenominator is 33.
    pub fn par_denominator(&self) -> i32 {
        self.par_denominator
    }
    /// Required when you set Pixel aspect ratio (parControl) to SPECIFIED. On the console, this corresponds to any value other than Follow source. When you specify an output pixel aspect ratio (PAR) that is different from your input video PAR, provide your output PAR as a ratio. For example, for D1/DV NTSC widescreen, you would specify the ratio 40:33. In this example, the value for parNumerator is 40.
    pub fn par_numerator(&self) -> i32 {
        self.par_numerator
    }
    /// Optional. Use Quality tuning level (qualityTuningLevel) to choose how you want to trade off encoding speed for output video quality. The default behavior is faster, lower quality, single-pass encoding.
    pub fn quality_tuning_level(
        &self,
    ) -> std::option::Option<&crate::types::Mpeg2QualityTuningLevel> {
        self.quality_tuning_level.as_ref()
    }
    /// Use Rate control mode (Mpeg2RateControlMode) to specify whether the bitrate is variable (vbr) or constant (cbr).
    pub fn rate_control_mode(&self) -> std::option::Option<&crate::types::Mpeg2RateControlMode> {
        self.rate_control_mode.as_ref()
    }
    /// Use this setting for interlaced outputs, when your output frame rate is half of your input frame rate. In this situation, choose Optimized interlacing (INTERLACED_OPTIMIZE) to create a better quality interlaced output. In this case, each progressive frame from the input corresponds to an interlaced field in the output. Keep the default value, Basic interlacing (INTERLACED), for all other output frame rates. With basic interlacing, MediaConvert performs any frame rate conversion first and then interlaces the frames. When you choose Optimized interlacing and you set your output frame rate to a value that isn't suitable for optimized interlacing, MediaConvert automatically falls back to basic interlacing. Required settings: To use optimized interlacing, you must set Telecine (telecine) to None (NONE) or Soft (SOFT). You can't use optimized interlacing for hard telecine outputs. You must also set Interlace mode (interlaceMode) to a value other than Progressive (PROGRESSIVE).
    pub fn scan_type_conversion_mode(
        &self,
    ) -> std::option::Option<&crate::types::Mpeg2ScanTypeConversionMode> {
        self.scan_type_conversion_mode.as_ref()
    }
    /// Enable this setting to insert I-frames at scene changes that the service automatically detects. This improves video quality and is enabled by default.
    pub fn scene_change_detect(
        &self,
    ) -> std::option::Option<&crate::types::Mpeg2SceneChangeDetect> {
        self.scene_change_detect.as_ref()
    }
    /// Ignore this setting unless your input frame rate is 23.976 or 24 frames per second (fps). Enable slow PAL to create a 25 fps output. When you enable slow PAL, MediaConvert relabels the video frames to 25 fps and resamples your audio to keep it synchronized with the video. Note that enabling this setting will slightly reduce the duration of your video. Required settings: You must also set Framerate to 25. In your JSON job specification, set (framerateControl) to (SPECIFIED), (framerateNumerator) to 25 and (framerateDenominator) to 1.
    pub fn slow_pal(&self) -> std::option::Option<&crate::types::Mpeg2SlowPal> {
        self.slow_pal.as_ref()
    }
    /// Ignore this setting unless you need to comply with a specification that requires a specific value. If you don't have a specification requirement, we recommend that you adjust the softness of your output by using a lower value for the setting Sharpness (sharpness) or by enabling a noise reducer filter (noiseReducerFilter). The Softness (softness) setting specifies the quantization matrices that the encoder uses. Keep the default value, 0, to use the AWS Elemental default matrices. Choose a value from 17 to 128 to use planar interpolation. Increasing values from 17 to 128 result in increasing reduction of high-frequency data. The value 128 results in the softest video.
    pub fn softness(&self) -> i32 {
        self.softness
    }
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on spatial variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas that can sustain more distortion with no noticeable visual degradation and uses more bits on areas where any small distortion will be noticeable. For example, complex textured blocks are encoded with fewer bits and smooth textured blocks are encoded with more bits. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen with a lot of complex texture, you might choose to disable this feature. Related setting: When you enable spatial adaptive quantization, set the value for Adaptive quantization (adaptiveQuantization) depending on your content. For homogeneous content, such as cartoons and video games, set it to Low. For content with a wider variety of textures, set it to High or Higher.
    pub fn spatial_adaptive_quantization(
        &self,
    ) -> std::option::Option<&crate::types::Mpeg2SpatialAdaptiveQuantization> {
        self.spatial_adaptive_quantization.as_ref()
    }
    /// Specify whether this output's video uses the D10 syntax. Keep the default value to not use the syntax. Related settings: When you choose D10 (D_10) for your MXF profile (profile), you must also set this value to D10 (D_10).
    pub fn syntax(&self) -> std::option::Option<&crate::types::Mpeg2Syntax> {
        self.syntax.as_ref()
    }
    /// When you do frame rate conversion from 23.976 frames per second (fps) to 29.97 fps, and your output scan type is interlaced, you can optionally enable hard or soft telecine to create a smoother picture. Hard telecine (HARD) produces a 29.97i output. Soft telecine (SOFT) produces an output with a 23.976 output that signals to the video player device to do the conversion during play back. When you keep the default value, None (NONE), MediaConvert does a standard frame rate conversion to 29.97 without doing anything with the field polarity to create a smoother picture.
    pub fn telecine(&self) -> std::option::Option<&crate::types::Mpeg2Telecine> {
        self.telecine.as_ref()
    }
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on temporal variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas of the frame that aren't moving and uses more bits on complex objects with sharp edges that move a lot. For example, this feature improves the readability of text tickers on newscasts and scoreboards on sports matches. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen that doesn't have moving objects with sharp edges, such as sports athletes' faces, you might choose to disable this feature. Related setting: When you enable temporal quantization, adjust the strength of the filter with the setting Adaptive quantization (adaptiveQuantization).
    pub fn temporal_adaptive_quantization(
        &self,
    ) -> std::option::Option<&crate::types::Mpeg2TemporalAdaptiveQuantization> {
        self.temporal_adaptive_quantization.as_ref()
    }
}
impl Mpeg2Settings {
    /// Creates a new builder-style object to manufacture [`Mpeg2Settings`](crate::types::Mpeg2Settings).
    pub fn builder() -> crate::types::builders::Mpeg2SettingsBuilder {
        crate::types::builders::Mpeg2SettingsBuilder::default()
    }
}

/// A builder for [`Mpeg2Settings`](crate::types::Mpeg2Settings).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct Mpeg2SettingsBuilder {
    pub(crate) adaptive_quantization: std::option::Option<crate::types::Mpeg2AdaptiveQuantization>,
    pub(crate) bitrate: std::option::Option<i32>,
    pub(crate) codec_level: std::option::Option<crate::types::Mpeg2CodecLevel>,
    pub(crate) codec_profile: std::option::Option<crate::types::Mpeg2CodecProfile>,
    pub(crate) dynamic_sub_gop: std::option::Option<crate::types::Mpeg2DynamicSubGop>,
    pub(crate) framerate_control: std::option::Option<crate::types::Mpeg2FramerateControl>,
    pub(crate) framerate_conversion_algorithm:
        std::option::Option<crate::types::Mpeg2FramerateConversionAlgorithm>,
    pub(crate) framerate_denominator: std::option::Option<i32>,
    pub(crate) framerate_numerator: std::option::Option<i32>,
    pub(crate) gop_closed_cadence: std::option::Option<i32>,
    pub(crate) gop_size: std::option::Option<f64>,
    pub(crate) gop_size_units: std::option::Option<crate::types::Mpeg2GopSizeUnits>,
    pub(crate) hrd_buffer_final_fill_percentage: std::option::Option<i32>,
    pub(crate) hrd_buffer_initial_fill_percentage: std::option::Option<i32>,
    pub(crate) hrd_buffer_size: std::option::Option<i32>,
    pub(crate) interlace_mode: std::option::Option<crate::types::Mpeg2InterlaceMode>,
    pub(crate) intra_dc_precision: std::option::Option<crate::types::Mpeg2IntraDcPrecision>,
    pub(crate) max_bitrate: std::option::Option<i32>,
    pub(crate) min_i_interval: std::option::Option<i32>,
    pub(crate) number_b_frames_between_reference_frames: std::option::Option<i32>,
    pub(crate) par_control: std::option::Option<crate::types::Mpeg2ParControl>,
    pub(crate) par_denominator: std::option::Option<i32>,
    pub(crate) par_numerator: std::option::Option<i32>,
    pub(crate) quality_tuning_level: std::option::Option<crate::types::Mpeg2QualityTuningLevel>,
    pub(crate) rate_control_mode: std::option::Option<crate::types::Mpeg2RateControlMode>,
    pub(crate) scan_type_conversion_mode:
        std::option::Option<crate::types::Mpeg2ScanTypeConversionMode>,
    pub(crate) scene_change_detect: std::option::Option<crate::types::Mpeg2SceneChangeDetect>,
    pub(crate) slow_pal: std::option::Option<crate::types::Mpeg2SlowPal>,
    pub(crate) softness: std::option::Option<i32>,
    pub(crate) spatial_adaptive_quantization:
        std::option::Option<crate::types::Mpeg2SpatialAdaptiveQuantization>,
    pub(crate) syntax: std::option::Option<crate::types::Mpeg2Syntax>,
    pub(crate) telecine: std::option::Option<crate::types::Mpeg2Telecine>,
    pub(crate) temporal_adaptive_quantization:
        std::option::Option<crate::types::Mpeg2TemporalAdaptiveQuantization>,
}
impl Mpeg2SettingsBuilder {
    /// Specify the strength of any adaptive quantization filters that you enable. The value that you choose here applies to the following settings: Spatial adaptive quantization (spatialAdaptiveQuantization), and Temporal adaptive quantization (temporalAdaptiveQuantization).
    pub fn adaptive_quantization(mut self, input: crate::types::Mpeg2AdaptiveQuantization) -> Self {
        self.adaptive_quantization = Some(input);
        self
    }
    /// Specify the strength of any adaptive quantization filters that you enable. The value that you choose here applies to the following settings: Spatial adaptive quantization (spatialAdaptiveQuantization), and Temporal adaptive quantization (temporalAdaptiveQuantization).
    pub fn set_adaptive_quantization(
        mut self,
        input: std::option::Option<crate::types::Mpeg2AdaptiveQuantization>,
    ) -> Self {
        self.adaptive_quantization = input;
        self
    }
    /// Specify the average bitrate in bits per second. Required for VBR and CBR. For MS Smooth outputs, bitrates must be unique when rounded down to the nearest multiple of 1000.
    pub fn bitrate(mut self, input: i32) -> Self {
        self.bitrate = Some(input);
        self
    }
    /// Specify the average bitrate in bits per second. Required for VBR and CBR. For MS Smooth outputs, bitrates must be unique when rounded down to the nearest multiple of 1000.
    pub fn set_bitrate(mut self, input: std::option::Option<i32>) -> Self {
        self.bitrate = input;
        self
    }
    /// Use Level (Mpeg2CodecLevel) to set the MPEG-2 level for the video output.
    pub fn codec_level(mut self, input: crate::types::Mpeg2CodecLevel) -> Self {
        self.codec_level = Some(input);
        self
    }
    /// Use Level (Mpeg2CodecLevel) to set the MPEG-2 level for the video output.
    pub fn set_codec_level(
        mut self,
        input: std::option::Option<crate::types::Mpeg2CodecLevel>,
    ) -> Self {
        self.codec_level = input;
        self
    }
    /// Use Profile (Mpeg2CodecProfile) to set the MPEG-2 profile for the video output.
    pub fn codec_profile(mut self, input: crate::types::Mpeg2CodecProfile) -> Self {
        self.codec_profile = Some(input);
        self
    }
    /// Use Profile (Mpeg2CodecProfile) to set the MPEG-2 profile for the video output.
    pub fn set_codec_profile(
        mut self,
        input: std::option::Option<crate::types::Mpeg2CodecProfile>,
    ) -> Self {
        self.codec_profile = input;
        self
    }
    /// Choose Adaptive to improve subjective video quality for high-motion content. This will cause the service to use fewer B-frames (which infer information based on other frames) for high-motion portions of the video and more B-frames for low-motion portions. The maximum number of B-frames is limited by the value you provide for the setting B frames between reference frames (numberBFramesBetweenReferenceFrames).
    pub fn dynamic_sub_gop(mut self, input: crate::types::Mpeg2DynamicSubGop) -> Self {
        self.dynamic_sub_gop = Some(input);
        self
    }
    /// Choose Adaptive to improve subjective video quality for high-motion content. This will cause the service to use fewer B-frames (which infer information based on other frames) for high-motion portions of the video and more B-frames for low-motion portions. The maximum number of B-frames is limited by the value you provide for the setting B frames between reference frames (numberBFramesBetweenReferenceFrames).
    pub fn set_dynamic_sub_gop(
        mut self,
        input: std::option::Option<crate::types::Mpeg2DynamicSubGop>,
    ) -> Self {
        self.dynamic_sub_gop = input;
        self
    }
    /// If you are using the console, use the Framerate setting to specify the frame rate for this output. If you want to keep the same frame rate as the input video, choose Follow source. If you want to do frame rate conversion, choose a frame rate from the dropdown list or choose Custom. The framerates shown in the dropdown list are decimal approximations of fractions. If you choose Custom, specify your frame rate as a fraction. If you are creating your transcoding job specification as a JSON file without the console, use FramerateControl to specify which value the service uses for the frame rate for this output. Choose INITIALIZE_FROM_SOURCE if you want the service to use the frame rate from the input. Choose SPECIFIED if you want the service to use the frame rate you specify in the settings FramerateNumerator and FramerateDenominator.
    pub fn framerate_control(mut self, input: crate::types::Mpeg2FramerateControl) -> Self {
        self.framerate_control = Some(input);
        self
    }
    /// If you are using the console, use the Framerate setting to specify the frame rate for this output. If you want to keep the same frame rate as the input video, choose Follow source. If you want to do frame rate conversion, choose a frame rate from the dropdown list or choose Custom. The framerates shown in the dropdown list are decimal approximations of fractions. If you choose Custom, specify your frame rate as a fraction. If you are creating your transcoding job specification as a JSON file without the console, use FramerateControl to specify which value the service uses for the frame rate for this output. Choose INITIALIZE_FROM_SOURCE if you want the service to use the frame rate from the input. Choose SPECIFIED if you want the service to use the frame rate you specify in the settings FramerateNumerator and FramerateDenominator.
    pub fn set_framerate_control(
        mut self,
        input: std::option::Option<crate::types::Mpeg2FramerateControl>,
    ) -> Self {
        self.framerate_control = input;
        self
    }
    /// Choose the method that you want MediaConvert to use when increasing or decreasing the frame rate. We recommend using drop duplicate (DUPLICATE_DROP) for numerically simple conversions, such as 60 fps to 30 fps. For numerically complex conversions, you can use interpolate (INTERPOLATE) to avoid stutter. This results in a smooth picture, but might introduce undesirable video artifacts. For complex frame rate conversions, especially if your source video has already been converted from its original cadence, use FrameFormer (FRAMEFORMER) to do motion-compensated interpolation. FrameFormer chooses the best conversion method frame by frame. Note that using FrameFormer increases the transcoding time and incurs a significant add-on cost.
    pub fn framerate_conversion_algorithm(
        mut self,
        input: crate::types::Mpeg2FramerateConversionAlgorithm,
    ) -> Self {
        self.framerate_conversion_algorithm = Some(input);
        self
    }
    /// Choose the method that you want MediaConvert to use when increasing or decreasing the frame rate. We recommend using drop duplicate (DUPLICATE_DROP) for numerically simple conversions, such as 60 fps to 30 fps. For numerically complex conversions, you can use interpolate (INTERPOLATE) to avoid stutter. This results in a smooth picture, but might introduce undesirable video artifacts. For complex frame rate conversions, especially if your source video has already been converted from its original cadence, use FrameFormer (FRAMEFORMER) to do motion-compensated interpolation. FrameFormer chooses the best conversion method frame by frame. Note that using FrameFormer increases the transcoding time and incurs a significant add-on cost.
    pub fn set_framerate_conversion_algorithm(
        mut self,
        input: std::option::Option<crate::types::Mpeg2FramerateConversionAlgorithm>,
    ) -> Self {
        self.framerate_conversion_algorithm = input;
        self
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateDenominator to specify the denominator of this fraction. In this example, use 1001 for the value of FramerateDenominator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn framerate_denominator(mut self, input: i32) -> Self {
        self.framerate_denominator = Some(input);
        self
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateDenominator to specify the denominator of this fraction. In this example, use 1001 for the value of FramerateDenominator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn set_framerate_denominator(mut self, input: std::option::Option<i32>) -> Self {
        self.framerate_denominator = input;
        self
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateNumerator to specify the numerator of this fraction. In this example, use 24000 for the value of FramerateNumerator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn framerate_numerator(mut self, input: i32) -> Self {
        self.framerate_numerator = Some(input);
        self
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateNumerator to specify the numerator of this fraction. In this example, use 24000 for the value of FramerateNumerator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn set_framerate_numerator(mut self, input: std::option::Option<i32>) -> Self {
        self.framerate_numerator = input;
        self
    }
    /// Specify the relative frequency of open to closed GOPs in this output. For example, if you want to allow four open GOPs and then require a closed GOP, set this value to 5. When you create a streaming output, we recommend that you keep the default value, 1, so that players starting mid-stream receive an IDR frame as quickly as possible. Don't set this value to 0; that would break output segmenting.
    pub fn gop_closed_cadence(mut self, input: i32) -> Self {
        self.gop_closed_cadence = Some(input);
        self
    }
    /// Specify the relative frequency of open to closed GOPs in this output. For example, if you want to allow four open GOPs and then require a closed GOP, set this value to 5. When you create a streaming output, we recommend that you keep the default value, 1, so that players starting mid-stream receive an IDR frame as quickly as possible. Don't set this value to 0; that would break output segmenting.
    pub fn set_gop_closed_cadence(mut self, input: std::option::Option<i32>) -> Self {
        self.gop_closed_cadence = input;
        self
    }
    /// Specify the interval between keyframes, in seconds or frames, for this output. Default: 12 Related settings: When you specify the GOP size in seconds, set GOP mode control (GopSizeUnits) to Specified, seconds (SECONDS). The default value for GOP mode control (GopSizeUnits) is Frames (FRAMES).
    pub fn gop_size(mut self, input: f64) -> Self {
        self.gop_size = Some(input);
        self
    }
    /// Specify the interval between keyframes, in seconds or frames, for this output. Default: 12 Related settings: When you specify the GOP size in seconds, set GOP mode control (GopSizeUnits) to Specified, seconds (SECONDS). The default value for GOP mode control (GopSizeUnits) is Frames (FRAMES).
    pub fn set_gop_size(mut self, input: std::option::Option<f64>) -> Self {
        self.gop_size = input;
        self
    }
    /// Specify the units for GOP size (GopSize). If you don't specify a value here, by default the encoder measures GOP size in frames.
    pub fn gop_size_units(mut self, input: crate::types::Mpeg2GopSizeUnits) -> Self {
        self.gop_size_units = Some(input);
        self
    }
    /// Specify the units for GOP size (GopSize). If you don't specify a value here, by default the encoder measures GOP size in frames.
    pub fn set_gop_size_units(
        mut self,
        input: std::option::Option<crate::types::Mpeg2GopSizeUnits>,
    ) -> Self {
        self.gop_size_units = input;
        self
    }
    /// If your downstream systems have strict buffer requirements: Specify the minimum percentage of the HRD buffer that's available at the end of each encoded video segment. For the best video quality: Set to 0 or leave blank to automatically determine the final buffer fill percentage.
    pub fn hrd_buffer_final_fill_percentage(mut self, input: i32) -> Self {
        self.hrd_buffer_final_fill_percentage = Some(input);
        self
    }
    /// If your downstream systems have strict buffer requirements: Specify the minimum percentage of the HRD buffer that's available at the end of each encoded video segment. For the best video quality: Set to 0 or leave blank to automatically determine the final buffer fill percentage.
    pub fn set_hrd_buffer_final_fill_percentage(mut self, input: std::option::Option<i32>) -> Self {
        self.hrd_buffer_final_fill_percentage = input;
        self
    }
    /// Percentage of the buffer that should initially be filled (HRD buffer model).
    pub fn hrd_buffer_initial_fill_percentage(mut self, input: i32) -> Self {
        self.hrd_buffer_initial_fill_percentage = Some(input);
        self
    }
    /// Percentage of the buffer that should initially be filled (HRD buffer model).
    pub fn set_hrd_buffer_initial_fill_percentage(
        mut self,
        input: std::option::Option<i32>,
    ) -> Self {
        self.hrd_buffer_initial_fill_percentage = input;
        self
    }
    /// Size of buffer (HRD buffer model) in bits. For example, enter five megabits as 5000000.
    pub fn hrd_buffer_size(mut self, input: i32) -> Self {
        self.hrd_buffer_size = Some(input);
        self
    }
    /// Size of buffer (HRD buffer model) in bits. For example, enter five megabits as 5000000.
    pub fn set_hrd_buffer_size(mut self, input: std::option::Option<i32>) -> Self {
        self.hrd_buffer_size = input;
        self
    }
    /// Choose the scan line type for the output. Keep the default value, Progressive (PROGRESSIVE) to create a progressive output, regardless of the scan type of your input. Use Top field first (TOP_FIELD) or Bottom field first (BOTTOM_FIELD) to create an output that's interlaced with the same field polarity throughout. Use Follow, default top (FOLLOW_TOP_FIELD) or Follow, default bottom (FOLLOW_BOTTOM_FIELD) to produce outputs with the same field polarity as the source. For jobs that have multiple inputs, the output field polarity might change over the course of the output. Follow behavior depends on the input scan type. If the source is interlaced, the output will be interlaced with the same polarity as the source. If the source is progressive, the output will be interlaced with top field bottom field first, depending on which of the Follow options you choose.
    pub fn interlace_mode(mut self, input: crate::types::Mpeg2InterlaceMode) -> Self {
        self.interlace_mode = Some(input);
        self
    }
    /// Choose the scan line type for the output. Keep the default value, Progressive (PROGRESSIVE) to create a progressive output, regardless of the scan type of your input. Use Top field first (TOP_FIELD) or Bottom field first (BOTTOM_FIELD) to create an output that's interlaced with the same field polarity throughout. Use Follow, default top (FOLLOW_TOP_FIELD) or Follow, default bottom (FOLLOW_BOTTOM_FIELD) to produce outputs with the same field polarity as the source. For jobs that have multiple inputs, the output field polarity might change over the course of the output. Follow behavior depends on the input scan type. If the source is interlaced, the output will be interlaced with the same polarity as the source. If the source is progressive, the output will be interlaced with top field bottom field first, depending on which of the Follow options you choose.
    pub fn set_interlace_mode(
        mut self,
        input: std::option::Option<crate::types::Mpeg2InterlaceMode>,
    ) -> Self {
        self.interlace_mode = input;
        self
    }
    /// Use Intra DC precision (Mpeg2IntraDcPrecision) to set quantization precision for intra-block DC coefficients. If you choose the value auto, the service will automatically select the precision based on the per-frame compression ratio.
    pub fn intra_dc_precision(mut self, input: crate::types::Mpeg2IntraDcPrecision) -> Self {
        self.intra_dc_precision = Some(input);
        self
    }
    /// Use Intra DC precision (Mpeg2IntraDcPrecision) to set quantization precision for intra-block DC coefficients. If you choose the value auto, the service will automatically select the precision based on the per-frame compression ratio.
    pub fn set_intra_dc_precision(
        mut self,
        input: std::option::Option<crate::types::Mpeg2IntraDcPrecision>,
    ) -> Self {
        self.intra_dc_precision = input;
        self
    }
    /// Maximum bitrate in bits/second. For example, enter five megabits per second as 5000000.
    pub fn max_bitrate(mut self, input: i32) -> Self {
        self.max_bitrate = Some(input);
        self
    }
    /// Maximum bitrate in bits/second. For example, enter five megabits per second as 5000000.
    pub fn set_max_bitrate(mut self, input: std::option::Option<i32>) -> Self {
        self.max_bitrate = input;
        self
    }
    /// Use this setting only when you also enable Scene change detection (SceneChangeDetect). This setting determines how the encoder manages the spacing between I-frames that it inserts as part of the I-frame cadence and the I-frames that it inserts for Scene change detection. When you specify a value for this setting, the encoder determines whether to skip a cadence-driven I-frame by the value you set. For example, if you set Min I interval (minIInterval) to 5 and a cadence-driven I-frame would fall within 5 frames of a scene-change I-frame, then the encoder skips the cadence-driven I-frame. In this way, one GOP is shrunk slightly and one GOP is stretched slightly. When the cadence-driven I-frames are farther from the scene-change I-frame than the value you set, then the encoder leaves all I-frames in place and the GOPs surrounding the scene change are smaller than the usual cadence GOPs.
    pub fn min_i_interval(mut self, input: i32) -> Self {
        self.min_i_interval = Some(input);
        self
    }
    /// Use this setting only when you also enable Scene change detection (SceneChangeDetect). This setting determines how the encoder manages the spacing between I-frames that it inserts as part of the I-frame cadence and the I-frames that it inserts for Scene change detection. When you specify a value for this setting, the encoder determines whether to skip a cadence-driven I-frame by the value you set. For example, if you set Min I interval (minIInterval) to 5 and a cadence-driven I-frame would fall within 5 frames of a scene-change I-frame, then the encoder skips the cadence-driven I-frame. In this way, one GOP is shrunk slightly and one GOP is stretched slightly. When the cadence-driven I-frames are farther from the scene-change I-frame than the value you set, then the encoder leaves all I-frames in place and the GOPs surrounding the scene change are smaller than the usual cadence GOPs.
    pub fn set_min_i_interval(mut self, input: std::option::Option<i32>) -> Self {
        self.min_i_interval = input;
        self
    }
    /// Specify the number of B-frames that MediaConvert puts between reference frames in this output. Valid values are whole numbers from 0 through 7. When you don't specify a value, MediaConvert defaults to 2.
    pub fn number_b_frames_between_reference_frames(mut self, input: i32) -> Self {
        self.number_b_frames_between_reference_frames = Some(input);
        self
    }
    /// Specify the number of B-frames that MediaConvert puts between reference frames in this output. Valid values are whole numbers from 0 through 7. When you don't specify a value, MediaConvert defaults to 2.
    pub fn set_number_b_frames_between_reference_frames(
        mut self,
        input: std::option::Option<i32>,
    ) -> Self {
        self.number_b_frames_between_reference_frames = input;
        self
    }
    /// Optional. Specify how the service determines the pixel aspect ratio (PAR) for this output. The default behavior, Follow source (INITIALIZE_FROM_SOURCE), uses the PAR from your input video for your output. To specify a different PAR in the console, choose any value other than Follow source. To specify a different PAR by editing the JSON job specification, choose SPECIFIED. When you choose SPECIFIED for this setting, you must also specify values for the parNumerator and parDenominator settings.
    pub fn par_control(mut self, input: crate::types::Mpeg2ParControl) -> Self {
        self.par_control = Some(input);
        self
    }
    /// Optional. Specify how the service determines the pixel aspect ratio (PAR) for this output. The default behavior, Follow source (INITIALIZE_FROM_SOURCE), uses the PAR from your input video for your output. To specify a different PAR in the console, choose any value other than Follow source. To specify a different PAR by editing the JSON job specification, choose SPECIFIED. When you choose SPECIFIED for this setting, you must also specify values for the parNumerator and parDenominator settings.
    pub fn set_par_control(
        mut self,
        input: std::option::Option<crate::types::Mpeg2ParControl>,
    ) -> Self {
        self.par_control = input;
        self
    }
    /// Required when you set Pixel aspect ratio (parControl) to SPECIFIED. On the console, this corresponds to any value other than Follow source. When you specify an output pixel aspect ratio (PAR) that is different from your input video PAR, provide your output PAR as a ratio. For example, for D1/DV NTSC widescreen, you would specify the ratio 40:33. In this example, the value for parDenominator is 33.
    pub fn par_denominator(mut self, input: i32) -> Self {
        self.par_denominator = Some(input);
        self
    }
    /// Required when you set Pixel aspect ratio (parControl) to SPECIFIED. On the console, this corresponds to any value other than Follow source. When you specify an output pixel aspect ratio (PAR) that is different from your input video PAR, provide your output PAR as a ratio. For example, for D1/DV NTSC widescreen, you would specify the ratio 40:33. In this example, the value for parDenominator is 33.
    pub fn set_par_denominator(mut self, input: std::option::Option<i32>) -> Self {
        self.par_denominator = input;
        self
    }
    /// Required when you set Pixel aspect ratio (parControl) to SPECIFIED. On the console, this corresponds to any value other than Follow source. When you specify an output pixel aspect ratio (PAR) that is different from your input video PAR, provide your output PAR as a ratio. For example, for D1/DV NTSC widescreen, you would specify the ratio 40:33. In this example, the value for parNumerator is 40.
    pub fn par_numerator(mut self, input: i32) -> Self {
        self.par_numerator = Some(input);
        self
    }
    /// Required when you set Pixel aspect ratio (parControl) to SPECIFIED. On the console, this corresponds to any value other than Follow source. When you specify an output pixel aspect ratio (PAR) that is different from your input video PAR, provide your output PAR as a ratio. For example, for D1/DV NTSC widescreen, you would specify the ratio 40:33. In this example, the value for parNumerator is 40.
    pub fn set_par_numerator(mut self, input: std::option::Option<i32>) -> Self {
        self.par_numerator = input;
        self
    }
    /// Optional. Use Quality tuning level (qualityTuningLevel) to choose how you want to trade off encoding speed for output video quality. The default behavior is faster, lower quality, single-pass encoding.
    pub fn quality_tuning_level(mut self, input: crate::types::Mpeg2QualityTuningLevel) -> Self {
        self.quality_tuning_level = Some(input);
        self
    }
    /// Optional. Use Quality tuning level (qualityTuningLevel) to choose how you want to trade off encoding speed for output video quality. The default behavior is faster, lower quality, single-pass encoding.
    pub fn set_quality_tuning_level(
        mut self,
        input: std::option::Option<crate::types::Mpeg2QualityTuningLevel>,
    ) -> Self {
        self.quality_tuning_level = input;
        self
    }
    /// Use Rate control mode (Mpeg2RateControlMode) to specify whether the bitrate is variable (vbr) or constant (cbr).
    pub fn rate_control_mode(mut self, input: crate::types::Mpeg2RateControlMode) -> Self {
        self.rate_control_mode = Some(input);
        self
    }
    /// Use Rate control mode (Mpeg2RateControlMode) to specify whether the bitrate is variable (vbr) or constant (cbr).
    pub fn set_rate_control_mode(
        mut self,
        input: std::option::Option<crate::types::Mpeg2RateControlMode>,
    ) -> Self {
        self.rate_control_mode = input;
        self
    }
    /// Use this setting for interlaced outputs, when your output frame rate is half of your input frame rate. In this situation, choose Optimized interlacing (INTERLACED_OPTIMIZE) to create a better quality interlaced output. In this case, each progressive frame from the input corresponds to an interlaced field in the output. Keep the default value, Basic interlacing (INTERLACED), for all other output frame rates. With basic interlacing, MediaConvert performs any frame rate conversion first and then interlaces the frames. When you choose Optimized interlacing and you set your output frame rate to a value that isn't suitable for optimized interlacing, MediaConvert automatically falls back to basic interlacing. Required settings: To use optimized interlacing, you must set Telecine (telecine) to None (NONE) or Soft (SOFT). You can't use optimized interlacing for hard telecine outputs. You must also set Interlace mode (interlaceMode) to a value other than Progressive (PROGRESSIVE).
    pub fn scan_type_conversion_mode(
        mut self,
        input: crate::types::Mpeg2ScanTypeConversionMode,
    ) -> Self {
        self.scan_type_conversion_mode = Some(input);
        self
    }
    /// Use this setting for interlaced outputs, when your output frame rate is half of your input frame rate. In this situation, choose Optimized interlacing (INTERLACED_OPTIMIZE) to create a better quality interlaced output. In this case, each progressive frame from the input corresponds to an interlaced field in the output. Keep the default value, Basic interlacing (INTERLACED), for all other output frame rates. With basic interlacing, MediaConvert performs any frame rate conversion first and then interlaces the frames. When you choose Optimized interlacing and you set your output frame rate to a value that isn't suitable for optimized interlacing, MediaConvert automatically falls back to basic interlacing. Required settings: To use optimized interlacing, you must set Telecine (telecine) to None (NONE) or Soft (SOFT). You can't use optimized interlacing for hard telecine outputs. You must also set Interlace mode (interlaceMode) to a value other than Progressive (PROGRESSIVE).
    pub fn set_scan_type_conversion_mode(
        mut self,
        input: std::option::Option<crate::types::Mpeg2ScanTypeConversionMode>,
    ) -> Self {
        self.scan_type_conversion_mode = input;
        self
    }
    /// Enable this setting to insert I-frames at scene changes that the service automatically detects. This improves video quality and is enabled by default.
    pub fn scene_change_detect(mut self, input: crate::types::Mpeg2SceneChangeDetect) -> Self {
        self.scene_change_detect = Some(input);
        self
    }
    /// Enable this setting to insert I-frames at scene changes that the service automatically detects. This improves video quality and is enabled by default.
    pub fn set_scene_change_detect(
        mut self,
        input: std::option::Option<crate::types::Mpeg2SceneChangeDetect>,
    ) -> Self {
        self.scene_change_detect = input;
        self
    }
    /// Ignore this setting unless your input frame rate is 23.976 or 24 frames per second (fps). Enable slow PAL to create a 25 fps output. When you enable slow PAL, MediaConvert relabels the video frames to 25 fps and resamples your audio to keep it synchronized with the video. Note that enabling this setting will slightly reduce the duration of your video. Required settings: You must also set Framerate to 25. In your JSON job specification, set (framerateControl) to (SPECIFIED), (framerateNumerator) to 25 and (framerateDenominator) to 1.
    pub fn slow_pal(mut self, input: crate::types::Mpeg2SlowPal) -> Self {
        self.slow_pal = Some(input);
        self
    }
    /// Ignore this setting unless your input frame rate is 23.976 or 24 frames per second (fps). Enable slow PAL to create a 25 fps output. When you enable slow PAL, MediaConvert relabels the video frames to 25 fps and resamples your audio to keep it synchronized with the video. Note that enabling this setting will slightly reduce the duration of your video. Required settings: You must also set Framerate to 25. In your JSON job specification, set (framerateControl) to (SPECIFIED), (framerateNumerator) to 25 and (framerateDenominator) to 1.
    pub fn set_slow_pal(mut self, input: std::option::Option<crate::types::Mpeg2SlowPal>) -> Self {
        self.slow_pal = input;
        self
    }
    /// Ignore this setting unless you need to comply with a specification that requires a specific value. If you don't have a specification requirement, we recommend that you adjust the softness of your output by using a lower value for the setting Sharpness (sharpness) or by enabling a noise reducer filter (noiseReducerFilter). The Softness (softness) setting specifies the quantization matrices that the encoder uses. Keep the default value, 0, to use the AWS Elemental default matrices. Choose a value from 17 to 128 to use planar interpolation. Increasing values from 17 to 128 result in increasing reduction of high-frequency data. The value 128 results in the softest video.
    pub fn softness(mut self, input: i32) -> Self {
        self.softness = Some(input);
        self
    }
    /// Ignore this setting unless you need to comply with a specification that requires a specific value. If you don't have a specification requirement, we recommend that you adjust the softness of your output by using a lower value for the setting Sharpness (sharpness) or by enabling a noise reducer filter (noiseReducerFilter). The Softness (softness) setting specifies the quantization matrices that the encoder uses. Keep the default value, 0, to use the AWS Elemental default matrices. Choose a value from 17 to 128 to use planar interpolation. Increasing values from 17 to 128 result in increasing reduction of high-frequency data. The value 128 results in the softest video.
    pub fn set_softness(mut self, input: std::option::Option<i32>) -> Self {
        self.softness = input;
        self
    }
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on spatial variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas that can sustain more distortion with no noticeable visual degradation and uses more bits on areas where any small distortion will be noticeable. For example, complex textured blocks are encoded with fewer bits and smooth textured blocks are encoded with more bits. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen with a lot of complex texture, you might choose to disable this feature. Related setting: When you enable spatial adaptive quantization, set the value for Adaptive quantization (adaptiveQuantization) depending on your content. For homogeneous content, such as cartoons and video games, set it to Low. For content with a wider variety of textures, set it to High or Higher.
    pub fn spatial_adaptive_quantization(
        mut self,
        input: crate::types::Mpeg2SpatialAdaptiveQuantization,
    ) -> Self {
        self.spatial_adaptive_quantization = Some(input);
        self
    }
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on spatial variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas that can sustain more distortion with no noticeable visual degradation and uses more bits on areas where any small distortion will be noticeable. For example, complex textured blocks are encoded with fewer bits and smooth textured blocks are encoded with more bits. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen with a lot of complex texture, you might choose to disable this feature. Related setting: When you enable spatial adaptive quantization, set the value for Adaptive quantization (adaptiveQuantization) depending on your content. For homogeneous content, such as cartoons and video games, set it to Low. For content with a wider variety of textures, set it to High or Higher.
    pub fn set_spatial_adaptive_quantization(
        mut self,
        input: std::option::Option<crate::types::Mpeg2SpatialAdaptiveQuantization>,
    ) -> Self {
        self.spatial_adaptive_quantization = input;
        self
    }
    /// Specify whether this output's video uses the D10 syntax. Keep the default value to not use the syntax. Related settings: When you choose D10 (D_10) for your MXF profile (profile), you must also set this value to D10 (D_10).
    pub fn syntax(mut self, input: crate::types::Mpeg2Syntax) -> Self {
        self.syntax = Some(input);
        self
    }
    /// Specify whether this output's video uses the D10 syntax. Keep the default value to not use the syntax. Related settings: When you choose D10 (D_10) for your MXF profile (profile), you must also set this value to D10 (D_10).
    pub fn set_syntax(mut self, input: std::option::Option<crate::types::Mpeg2Syntax>) -> Self {
        self.syntax = input;
        self
    }
    /// When you do frame rate conversion from 23.976 frames per second (fps) to 29.97 fps, and your output scan type is interlaced, you can optionally enable hard or soft telecine to create a smoother picture. Hard telecine (HARD) produces a 29.97i output. Soft telecine (SOFT) produces an output with a 23.976 output that signals to the video player device to do the conversion during play back. When you keep the default value, None (NONE), MediaConvert does a standard frame rate conversion to 29.97 without doing anything with the field polarity to create a smoother picture.
    pub fn telecine(mut self, input: crate::types::Mpeg2Telecine) -> Self {
        self.telecine = Some(input);
        self
    }
    /// When you do frame rate conversion from 23.976 frames per second (fps) to 29.97 fps, and your output scan type is interlaced, you can optionally enable hard or soft telecine to create a smoother picture. Hard telecine (HARD) produces a 29.97i output. Soft telecine (SOFT) produces an output with a 23.976 output that signals to the video player device to do the conversion during play back. When you keep the default value, None (NONE), MediaConvert does a standard frame rate conversion to 29.97 without doing anything with the field polarity to create a smoother picture.
    pub fn set_telecine(mut self, input: std::option::Option<crate::types::Mpeg2Telecine>) -> Self {
        self.telecine = input;
        self
    }
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on temporal variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas of the frame that aren't moving and uses more bits on complex objects with sharp edges that move a lot. For example, this feature improves the readability of text tickers on newscasts and scoreboards on sports matches. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen that doesn't have moving objects with sharp edges, such as sports athletes' faces, you might choose to disable this feature. Related setting: When you enable temporal quantization, adjust the strength of the filter with the setting Adaptive quantization (adaptiveQuantization).
    pub fn temporal_adaptive_quantization(
        mut self,
        input: crate::types::Mpeg2TemporalAdaptiveQuantization,
    ) -> Self {
        self.temporal_adaptive_quantization = Some(input);
        self
    }
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on temporal variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas of the frame that aren't moving and uses more bits on complex objects with sharp edges that move a lot. For example, this feature improves the readability of text tickers on newscasts and scoreboards on sports matches. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen that doesn't have moving objects with sharp edges, such as sports athletes' faces, you might choose to disable this feature. Related setting: When you enable temporal quantization, adjust the strength of the filter with the setting Adaptive quantization (adaptiveQuantization).
    pub fn set_temporal_adaptive_quantization(
        mut self,
        input: std::option::Option<crate::types::Mpeg2TemporalAdaptiveQuantization>,
    ) -> Self {
        self.temporal_adaptive_quantization = input;
        self
    }
    /// Consumes the builder and constructs a [`Mpeg2Settings`](crate::types::Mpeg2Settings).
    pub fn build(self) -> crate::types::Mpeg2Settings {
        crate::types::Mpeg2Settings {
            adaptive_quantization: self.adaptive_quantization,
            bitrate: self.bitrate.unwrap_or_default(),
            codec_level: self.codec_level,
            codec_profile: self.codec_profile,
            dynamic_sub_gop: self.dynamic_sub_gop,
            framerate_control: self.framerate_control,
            framerate_conversion_algorithm: self.framerate_conversion_algorithm,
            framerate_denominator: self.framerate_denominator.unwrap_or_default(),
            framerate_numerator: self.framerate_numerator.unwrap_or_default(),
            gop_closed_cadence: self.gop_closed_cadence.unwrap_or_default(),
            gop_size: self.gop_size.unwrap_or_default(),
            gop_size_units: self.gop_size_units,
            hrd_buffer_final_fill_percentage: self
                .hrd_buffer_final_fill_percentage
                .unwrap_or_default(),
            hrd_buffer_initial_fill_percentage: self
                .hrd_buffer_initial_fill_percentage
                .unwrap_or_default(),
            hrd_buffer_size: self.hrd_buffer_size.unwrap_or_default(),
            interlace_mode: self.interlace_mode,
            intra_dc_precision: self.intra_dc_precision,
            max_bitrate: self.max_bitrate.unwrap_or_default(),
            min_i_interval: self.min_i_interval.unwrap_or_default(),
            number_b_frames_between_reference_frames: self
                .number_b_frames_between_reference_frames
                .unwrap_or_default(),
            par_control: self.par_control,
            par_denominator: self.par_denominator.unwrap_or_default(),
            par_numerator: self.par_numerator.unwrap_or_default(),
            quality_tuning_level: self.quality_tuning_level,
            rate_control_mode: self.rate_control_mode,
            scan_type_conversion_mode: self.scan_type_conversion_mode,
            scene_change_detect: self.scene_change_detect,
            slow_pal: self.slow_pal,
            softness: self.softness.unwrap_or_default(),
            spatial_adaptive_quantization: self.spatial_adaptive_quantization,
            syntax: self.syntax,
            telecine: self.telecine,
            temporal_adaptive_quantization: self.temporal_adaptive_quantization,
        }
    }
}
