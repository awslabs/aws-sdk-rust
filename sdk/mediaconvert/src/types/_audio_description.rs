// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// Settings related to one audio tab on the MediaConvert console. In your job JSON, an instance of AudioDescription is equivalent to one audio tab in the console. Usually, one audio tab corresponds to one output audio track. Depending on how you set up your input audio selectors and whether you use audio selector groups, one audio tab can correspond to a group of output audio tracks.
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct AudioDescription {
    /// When you mimic a multi-channel audio layout with multiple mono-channel tracks, you can tag each channel layout manually. For example, you would tag the tracks that contain your left, right, and center audio with Left (L), Right (R), and Center (C), respectively. When you don't specify a value, MediaConvert labels your track as Center (C) by default. To use audio layout tagging, your output must be in a QuickTime (.mov) container; your audio codec must be AAC, WAV, or AIFF; and you must set up your audio track to have only one channel.
    #[doc(hidden)]
    pub audio_channel_tagging_settings:
        std::option::Option<crate::types::AudioChannelTaggingSettings>,
    /// Advanced audio normalization settings. Ignore these settings unless you need to comply with a loudness standard.
    #[doc(hidden)]
    pub audio_normalization_settings: std::option::Option<crate::types::AudioNormalizationSettings>,
    /// Specifies which audio data to use from each input. In the simplest case, specify an "Audio Selector":#inputs-audio_selector by name based on its order within each input. For example if you specify "Audio Selector 3", then the third audio selector will be used from each input. If an input does not have an "Audio Selector 3", then the audio selector marked as "default" in that input will be used. If there is no audio selector marked as "default", silence will be inserted for the duration of that input. Alternatively, an "Audio Selector Group":#inputs-audio_selector_group name may be specified, with similar default/silence behavior. If no audio_source_name is specified, then "Audio Selector 1" will be chosen automatically.
    #[doc(hidden)]
    pub audio_source_name: std::option::Option<std::string::String>,
    /// Applies only if Follow Input Audio Type is unchecked (false). A number between 0 and 255. The following are defined in ISO-IEC 13818-1: 0 = Undefined, 1 = Clean Effects, 2 = Hearing Impaired, 3 = Visually Impaired Commentary, 4-255 = Reserved.
    #[doc(hidden)]
    pub audio_type: i32,
    /// When set to FOLLOW_INPUT, if the input contains an ISO 639 audio_type, then that value is passed through to the output. If the input contains no ISO 639 audio_type, the value in Audio Type is included in the output. Otherwise the value in Audio Type is included in the output. Note that this field and audioType are both ignored if audioDescriptionBroadcasterMix is set to BROADCASTER_MIXED_AD.
    #[doc(hidden)]
    pub audio_type_control: std::option::Option<crate::types::AudioTypeControl>,
    /// Settings related to audio encoding. The settings in this group vary depending on the value that you choose for your audio codec.
    #[doc(hidden)]
    pub codec_settings: std::option::Option<crate::types::AudioCodecSettings>,
    /// Specify the language for this audio output track. The service puts this language code into your output audio track when you set Language code control (AudioLanguageCodeControl) to Use configured (USE_CONFIGURED). The service also uses your specified custom language code when you set Language code control (AudioLanguageCodeControl) to Follow input (FOLLOW_INPUT), but your input file doesn't specify a language code. For all outputs, you can use an ISO 639-2 or ISO 639-3 code. For streaming outputs, you can also use any other code in the full RFC-5646 specification. Streaming outputs are those that are in one of the following output groups: CMAF, DASH ISO, Apple HLS, or Microsoft Smooth Streaming.
    #[doc(hidden)]
    pub custom_language_code: std::option::Option<std::string::String>,
    /// Indicates the language of the audio output track. The ISO 639 language specified in the 'Language Code' drop down will be used when 'Follow Input Language Code' is not selected or when 'Follow Input Language Code' is selected but there is no ISO 639 language code specified by the input.
    #[doc(hidden)]
    pub language_code: std::option::Option<crate::types::LanguageCode>,
    /// Specify which source for language code takes precedence for this audio track. When you choose Follow input (FOLLOW_INPUT), the service uses the language code from the input track if it's present. If there's no languge code on the input track, the service uses the code that you specify in the setting Language code (languageCode or customLanguageCode). When you choose Use configured (USE_CONFIGURED), the service uses the language code that you specify.
    #[doc(hidden)]
    pub language_code_control: std::option::Option<crate::types::AudioLanguageCodeControl>,
    /// Advanced audio remixing settings.
    #[doc(hidden)]
    pub remix_settings: std::option::Option<crate::types::RemixSettings>,
    /// Specify a label for this output audio stream. For example, "English", "Director commentary", or "track_2". For streaming outputs, MediaConvert passes this information into destination manifests for display on the end-viewer's player device. For outputs in other output groups, the service ignores this setting.
    #[doc(hidden)]
    pub stream_name: std::option::Option<std::string::String>,
}
impl AudioDescription {
    /// When you mimic a multi-channel audio layout with multiple mono-channel tracks, you can tag each channel layout manually. For example, you would tag the tracks that contain your left, right, and center audio with Left (L), Right (R), and Center (C), respectively. When you don't specify a value, MediaConvert labels your track as Center (C) by default. To use audio layout tagging, your output must be in a QuickTime (.mov) container; your audio codec must be AAC, WAV, or AIFF; and you must set up your audio track to have only one channel.
    pub fn audio_channel_tagging_settings(
        &self,
    ) -> std::option::Option<&crate::types::AudioChannelTaggingSettings> {
        self.audio_channel_tagging_settings.as_ref()
    }
    /// Advanced audio normalization settings. Ignore these settings unless you need to comply with a loudness standard.
    pub fn audio_normalization_settings(
        &self,
    ) -> std::option::Option<&crate::types::AudioNormalizationSettings> {
        self.audio_normalization_settings.as_ref()
    }
    /// Specifies which audio data to use from each input. In the simplest case, specify an "Audio Selector":#inputs-audio_selector by name based on its order within each input. For example if you specify "Audio Selector 3", then the third audio selector will be used from each input. If an input does not have an "Audio Selector 3", then the audio selector marked as "default" in that input will be used. If there is no audio selector marked as "default", silence will be inserted for the duration of that input. Alternatively, an "Audio Selector Group":#inputs-audio_selector_group name may be specified, with similar default/silence behavior. If no audio_source_name is specified, then "Audio Selector 1" will be chosen automatically.
    pub fn audio_source_name(&self) -> std::option::Option<&str> {
        self.audio_source_name.as_deref()
    }
    /// Applies only if Follow Input Audio Type is unchecked (false). A number between 0 and 255. The following are defined in ISO-IEC 13818-1: 0 = Undefined, 1 = Clean Effects, 2 = Hearing Impaired, 3 = Visually Impaired Commentary, 4-255 = Reserved.
    pub fn audio_type(&self) -> i32 {
        self.audio_type
    }
    /// When set to FOLLOW_INPUT, if the input contains an ISO 639 audio_type, then that value is passed through to the output. If the input contains no ISO 639 audio_type, the value in Audio Type is included in the output. Otherwise the value in Audio Type is included in the output. Note that this field and audioType are both ignored if audioDescriptionBroadcasterMix is set to BROADCASTER_MIXED_AD.
    pub fn audio_type_control(&self) -> std::option::Option<&crate::types::AudioTypeControl> {
        self.audio_type_control.as_ref()
    }
    /// Settings related to audio encoding. The settings in this group vary depending on the value that you choose for your audio codec.
    pub fn codec_settings(&self) -> std::option::Option<&crate::types::AudioCodecSettings> {
        self.codec_settings.as_ref()
    }
    /// Specify the language for this audio output track. The service puts this language code into your output audio track when you set Language code control (AudioLanguageCodeControl) to Use configured (USE_CONFIGURED). The service also uses your specified custom language code when you set Language code control (AudioLanguageCodeControl) to Follow input (FOLLOW_INPUT), but your input file doesn't specify a language code. For all outputs, you can use an ISO 639-2 or ISO 639-3 code. For streaming outputs, you can also use any other code in the full RFC-5646 specification. Streaming outputs are those that are in one of the following output groups: CMAF, DASH ISO, Apple HLS, or Microsoft Smooth Streaming.
    pub fn custom_language_code(&self) -> std::option::Option<&str> {
        self.custom_language_code.as_deref()
    }
    /// Indicates the language of the audio output track. The ISO 639 language specified in the 'Language Code' drop down will be used when 'Follow Input Language Code' is not selected or when 'Follow Input Language Code' is selected but there is no ISO 639 language code specified by the input.
    pub fn language_code(&self) -> std::option::Option<&crate::types::LanguageCode> {
        self.language_code.as_ref()
    }
    /// Specify which source for language code takes precedence for this audio track. When you choose Follow input (FOLLOW_INPUT), the service uses the language code from the input track if it's present. If there's no languge code on the input track, the service uses the code that you specify in the setting Language code (languageCode or customLanguageCode). When you choose Use configured (USE_CONFIGURED), the service uses the language code that you specify.
    pub fn language_code_control(
        &self,
    ) -> std::option::Option<&crate::types::AudioLanguageCodeControl> {
        self.language_code_control.as_ref()
    }
    /// Advanced audio remixing settings.
    pub fn remix_settings(&self) -> std::option::Option<&crate::types::RemixSettings> {
        self.remix_settings.as_ref()
    }
    /// Specify a label for this output audio stream. For example, "English", "Director commentary", or "track_2". For streaming outputs, MediaConvert passes this information into destination manifests for display on the end-viewer's player device. For outputs in other output groups, the service ignores this setting.
    pub fn stream_name(&self) -> std::option::Option<&str> {
        self.stream_name.as_deref()
    }
}
impl AudioDescription {
    /// Creates a new builder-style object to manufacture [`AudioDescription`](crate::types::AudioDescription).
    pub fn builder() -> crate::types::builders::AudioDescriptionBuilder {
        crate::types::builders::AudioDescriptionBuilder::default()
    }
}

/// A builder for [`AudioDescription`](crate::types::AudioDescription).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct AudioDescriptionBuilder {
    pub(crate) audio_channel_tagging_settings:
        std::option::Option<crate::types::AudioChannelTaggingSettings>,
    pub(crate) audio_normalization_settings:
        std::option::Option<crate::types::AudioNormalizationSettings>,
    pub(crate) audio_source_name: std::option::Option<std::string::String>,
    pub(crate) audio_type: std::option::Option<i32>,
    pub(crate) audio_type_control: std::option::Option<crate::types::AudioTypeControl>,
    pub(crate) codec_settings: std::option::Option<crate::types::AudioCodecSettings>,
    pub(crate) custom_language_code: std::option::Option<std::string::String>,
    pub(crate) language_code: std::option::Option<crate::types::LanguageCode>,
    pub(crate) language_code_control: std::option::Option<crate::types::AudioLanguageCodeControl>,
    pub(crate) remix_settings: std::option::Option<crate::types::RemixSettings>,
    pub(crate) stream_name: std::option::Option<std::string::String>,
}
impl AudioDescriptionBuilder {
    /// When you mimic a multi-channel audio layout with multiple mono-channel tracks, you can tag each channel layout manually. For example, you would tag the tracks that contain your left, right, and center audio with Left (L), Right (R), and Center (C), respectively. When you don't specify a value, MediaConvert labels your track as Center (C) by default. To use audio layout tagging, your output must be in a QuickTime (.mov) container; your audio codec must be AAC, WAV, or AIFF; and you must set up your audio track to have only one channel.
    pub fn audio_channel_tagging_settings(
        mut self,
        input: crate::types::AudioChannelTaggingSettings,
    ) -> Self {
        self.audio_channel_tagging_settings = Some(input);
        self
    }
    /// When you mimic a multi-channel audio layout with multiple mono-channel tracks, you can tag each channel layout manually. For example, you would tag the tracks that contain your left, right, and center audio with Left (L), Right (R), and Center (C), respectively. When you don't specify a value, MediaConvert labels your track as Center (C) by default. To use audio layout tagging, your output must be in a QuickTime (.mov) container; your audio codec must be AAC, WAV, or AIFF; and you must set up your audio track to have only one channel.
    pub fn set_audio_channel_tagging_settings(
        mut self,
        input: std::option::Option<crate::types::AudioChannelTaggingSettings>,
    ) -> Self {
        self.audio_channel_tagging_settings = input;
        self
    }
    /// Advanced audio normalization settings. Ignore these settings unless you need to comply with a loudness standard.
    pub fn audio_normalization_settings(
        mut self,
        input: crate::types::AudioNormalizationSettings,
    ) -> Self {
        self.audio_normalization_settings = Some(input);
        self
    }
    /// Advanced audio normalization settings. Ignore these settings unless you need to comply with a loudness standard.
    pub fn set_audio_normalization_settings(
        mut self,
        input: std::option::Option<crate::types::AudioNormalizationSettings>,
    ) -> Self {
        self.audio_normalization_settings = input;
        self
    }
    /// Specifies which audio data to use from each input. In the simplest case, specify an "Audio Selector":#inputs-audio_selector by name based on its order within each input. For example if you specify "Audio Selector 3", then the third audio selector will be used from each input. If an input does not have an "Audio Selector 3", then the audio selector marked as "default" in that input will be used. If there is no audio selector marked as "default", silence will be inserted for the duration of that input. Alternatively, an "Audio Selector Group":#inputs-audio_selector_group name may be specified, with similar default/silence behavior. If no audio_source_name is specified, then "Audio Selector 1" will be chosen automatically.
    pub fn audio_source_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.audio_source_name = Some(input.into());
        self
    }
    /// Specifies which audio data to use from each input. In the simplest case, specify an "Audio Selector":#inputs-audio_selector by name based on its order within each input. For example if you specify "Audio Selector 3", then the third audio selector will be used from each input. If an input does not have an "Audio Selector 3", then the audio selector marked as "default" in that input will be used. If there is no audio selector marked as "default", silence will be inserted for the duration of that input. Alternatively, an "Audio Selector Group":#inputs-audio_selector_group name may be specified, with similar default/silence behavior. If no audio_source_name is specified, then "Audio Selector 1" will be chosen automatically.
    pub fn set_audio_source_name(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.audio_source_name = input;
        self
    }
    /// Applies only if Follow Input Audio Type is unchecked (false). A number between 0 and 255. The following are defined in ISO-IEC 13818-1: 0 = Undefined, 1 = Clean Effects, 2 = Hearing Impaired, 3 = Visually Impaired Commentary, 4-255 = Reserved.
    pub fn audio_type(mut self, input: i32) -> Self {
        self.audio_type = Some(input);
        self
    }
    /// Applies only if Follow Input Audio Type is unchecked (false). A number between 0 and 255. The following are defined in ISO-IEC 13818-1: 0 = Undefined, 1 = Clean Effects, 2 = Hearing Impaired, 3 = Visually Impaired Commentary, 4-255 = Reserved.
    pub fn set_audio_type(mut self, input: std::option::Option<i32>) -> Self {
        self.audio_type = input;
        self
    }
    /// When set to FOLLOW_INPUT, if the input contains an ISO 639 audio_type, then that value is passed through to the output. If the input contains no ISO 639 audio_type, the value in Audio Type is included in the output. Otherwise the value in Audio Type is included in the output. Note that this field and audioType are both ignored if audioDescriptionBroadcasterMix is set to BROADCASTER_MIXED_AD.
    pub fn audio_type_control(mut self, input: crate::types::AudioTypeControl) -> Self {
        self.audio_type_control = Some(input);
        self
    }
    /// When set to FOLLOW_INPUT, if the input contains an ISO 639 audio_type, then that value is passed through to the output. If the input contains no ISO 639 audio_type, the value in Audio Type is included in the output. Otherwise the value in Audio Type is included in the output. Note that this field and audioType are both ignored if audioDescriptionBroadcasterMix is set to BROADCASTER_MIXED_AD.
    pub fn set_audio_type_control(
        mut self,
        input: std::option::Option<crate::types::AudioTypeControl>,
    ) -> Self {
        self.audio_type_control = input;
        self
    }
    /// Settings related to audio encoding. The settings in this group vary depending on the value that you choose for your audio codec.
    pub fn codec_settings(mut self, input: crate::types::AudioCodecSettings) -> Self {
        self.codec_settings = Some(input);
        self
    }
    /// Settings related to audio encoding. The settings in this group vary depending on the value that you choose for your audio codec.
    pub fn set_codec_settings(
        mut self,
        input: std::option::Option<crate::types::AudioCodecSettings>,
    ) -> Self {
        self.codec_settings = input;
        self
    }
    /// Specify the language for this audio output track. The service puts this language code into your output audio track when you set Language code control (AudioLanguageCodeControl) to Use configured (USE_CONFIGURED). The service also uses your specified custom language code when you set Language code control (AudioLanguageCodeControl) to Follow input (FOLLOW_INPUT), but your input file doesn't specify a language code. For all outputs, you can use an ISO 639-2 or ISO 639-3 code. For streaming outputs, you can also use any other code in the full RFC-5646 specification. Streaming outputs are those that are in one of the following output groups: CMAF, DASH ISO, Apple HLS, or Microsoft Smooth Streaming.
    pub fn custom_language_code(mut self, input: impl Into<std::string::String>) -> Self {
        self.custom_language_code = Some(input.into());
        self
    }
    /// Specify the language for this audio output track. The service puts this language code into your output audio track when you set Language code control (AudioLanguageCodeControl) to Use configured (USE_CONFIGURED). The service also uses your specified custom language code when you set Language code control (AudioLanguageCodeControl) to Follow input (FOLLOW_INPUT), but your input file doesn't specify a language code. For all outputs, you can use an ISO 639-2 or ISO 639-3 code. For streaming outputs, you can also use any other code in the full RFC-5646 specification. Streaming outputs are those that are in one of the following output groups: CMAF, DASH ISO, Apple HLS, or Microsoft Smooth Streaming.
    pub fn set_custom_language_code(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.custom_language_code = input;
        self
    }
    /// Indicates the language of the audio output track. The ISO 639 language specified in the 'Language Code' drop down will be used when 'Follow Input Language Code' is not selected or when 'Follow Input Language Code' is selected but there is no ISO 639 language code specified by the input.
    pub fn language_code(mut self, input: crate::types::LanguageCode) -> Self {
        self.language_code = Some(input);
        self
    }
    /// Indicates the language of the audio output track. The ISO 639 language specified in the 'Language Code' drop down will be used when 'Follow Input Language Code' is not selected or when 'Follow Input Language Code' is selected but there is no ISO 639 language code specified by the input.
    pub fn set_language_code(
        mut self,
        input: std::option::Option<crate::types::LanguageCode>,
    ) -> Self {
        self.language_code = input;
        self
    }
    /// Specify which source for language code takes precedence for this audio track. When you choose Follow input (FOLLOW_INPUT), the service uses the language code from the input track if it's present. If there's no languge code on the input track, the service uses the code that you specify in the setting Language code (languageCode or customLanguageCode). When you choose Use configured (USE_CONFIGURED), the service uses the language code that you specify.
    pub fn language_code_control(mut self, input: crate::types::AudioLanguageCodeControl) -> Self {
        self.language_code_control = Some(input);
        self
    }
    /// Specify which source for language code takes precedence for this audio track. When you choose Follow input (FOLLOW_INPUT), the service uses the language code from the input track if it's present. If there's no languge code on the input track, the service uses the code that you specify in the setting Language code (languageCode or customLanguageCode). When you choose Use configured (USE_CONFIGURED), the service uses the language code that you specify.
    pub fn set_language_code_control(
        mut self,
        input: std::option::Option<crate::types::AudioLanguageCodeControl>,
    ) -> Self {
        self.language_code_control = input;
        self
    }
    /// Advanced audio remixing settings.
    pub fn remix_settings(mut self, input: crate::types::RemixSettings) -> Self {
        self.remix_settings = Some(input);
        self
    }
    /// Advanced audio remixing settings.
    pub fn set_remix_settings(
        mut self,
        input: std::option::Option<crate::types::RemixSettings>,
    ) -> Self {
        self.remix_settings = input;
        self
    }
    /// Specify a label for this output audio stream. For example, "English", "Director commentary", or "track_2". For streaming outputs, MediaConvert passes this information into destination manifests for display on the end-viewer's player device. For outputs in other output groups, the service ignores this setting.
    pub fn stream_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.stream_name = Some(input.into());
        self
    }
    /// Specify a label for this output audio stream. For example, "English", "Director commentary", or "track_2". For streaming outputs, MediaConvert passes this information into destination manifests for display on the end-viewer's player device. For outputs in other output groups, the service ignores this setting.
    pub fn set_stream_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.stream_name = input;
        self
    }
    /// Consumes the builder and constructs a [`AudioDescription`](crate::types::AudioDescription).
    pub fn build(self) -> crate::types::AudioDescription {
        crate::types::AudioDescription {
            audio_channel_tagging_settings: self.audio_channel_tagging_settings,
            audio_normalization_settings: self.audio_normalization_settings,
            audio_source_name: self.audio_source_name,
            audio_type: self.audio_type.unwrap_or_default(),
            audio_type_control: self.audio_type_control,
            codec_settings: self.codec_settings,
            custom_language_code: self.custom_language_code,
            language_code: self.language_code,
            language_code_control: self.language_code_control,
            remix_settings: self.remix_settings,
            stream_name: self.stream_name,
        }
    }
}
