// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// Required when you set Codec, under VideoDescription&gt;CodecSettings to the value AV1.
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct Av1Settings {
    /// Specify the strength of any adaptive quantization filters that you enable. The value that you choose here applies to Spatial adaptive quantization (spatialAdaptiveQuantization).
    #[doc(hidden)]
    pub adaptive_quantization: std::option::Option<crate::types::Av1AdaptiveQuantization>,
    /// Specify the Bit depth (Av1BitDepth). You can choose 8-bit (BIT_8) or 10-bit (BIT_10).
    #[doc(hidden)]
    pub bit_depth: std::option::Option<crate::types::Av1BitDepth>,
    /// If you are using the console, use the Framerate setting to specify the frame rate for this output. If you want to keep the same frame rate as the input video, choose Follow source. If you want to do frame rate conversion, choose a frame rate from the dropdown list or choose Custom. The framerates shown in the dropdown list are decimal approximations of fractions. If you choose Custom, specify your frame rate as a fraction. If you are creating your transcoding job specification as a JSON file without the console, use FramerateControl to specify which value the service uses for the frame rate for this output. Choose INITIALIZE_FROM_SOURCE if you want the service to use the frame rate from the input. Choose SPECIFIED if you want the service to use the frame rate you specify in the settings FramerateNumerator and FramerateDenominator.
    #[doc(hidden)]
    pub framerate_control: std::option::Option<crate::types::Av1FramerateControl>,
    /// Choose the method that you want MediaConvert to use when increasing or decreasing the frame rate. We recommend using drop duplicate (DUPLICATE_DROP) for numerically simple conversions, such as 60 fps to 30 fps. For numerically complex conversions, you can use interpolate (INTERPOLATE) to avoid stutter. This results in a smooth picture, but might introduce undesirable video artifacts. For complex frame rate conversions, especially if your source video has already been converted from its original cadence, use FrameFormer (FRAMEFORMER) to do motion-compensated interpolation. FrameFormer chooses the best conversion method frame by frame. Note that using FrameFormer increases the transcoding time and incurs a significant add-on cost.
    #[doc(hidden)]
    pub framerate_conversion_algorithm:
        std::option::Option<crate::types::Av1FramerateConversionAlgorithm>,
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateDenominator to specify the denominator of this fraction. In this example, use 1001 for the value of FramerateDenominator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    #[doc(hidden)]
    pub framerate_denominator: i32,
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateNumerator to specify the numerator of this fraction. In this example, use 24000 for the value of FramerateNumerator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    #[doc(hidden)]
    pub framerate_numerator: i32,
    /// Specify the GOP length (keyframe interval) in frames. With AV1, MediaConvert doesn't support GOP length in seconds. This value must be greater than zero and preferably equal to 1 + ((numberBFrames + 1) * x), where x is an integer value.
    #[doc(hidden)]
    pub gop_size: f64,
    /// Maximum bitrate in bits/second. For example, enter five megabits per second as 5000000. Required when Rate control mode is QVBR.
    #[doc(hidden)]
    pub max_bitrate: i32,
    /// Specify from the number of B-frames, in the range of 0-15. For AV1 encoding, we recommend using 7 or 15. Choose a larger number for a lower bitrate and smaller file size; choose a smaller number for better video quality.
    #[doc(hidden)]
    pub number_b_frames_between_reference_frames: i32,
    /// Settings for quality-defined variable bitrate encoding with the H.265 codec. Use these settings only when you set QVBR for Rate control mode (RateControlMode).
    #[doc(hidden)]
    pub qvbr_settings: std::option::Option<crate::types::Av1QvbrSettings>,
    /// 'With AV1 outputs, for rate control mode, MediaConvert supports only quality-defined variable bitrate (QVBR). You can''t use CBR or VBR.'
    #[doc(hidden)]
    pub rate_control_mode: std::option::Option<crate::types::Av1RateControlMode>,
    /// Specify the number of slices per picture. This value must be 1, 2, 4, 8, 16, or 32. For progressive pictures, this value must be less than or equal to the number of macroblock rows. For interlaced pictures, this value must be less than or equal to half the number of macroblock rows.
    #[doc(hidden)]
    pub slices: i32,
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on spatial variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas that can sustain more distortion with no noticeable visual degradation and uses more bits on areas where any small distortion will be noticeable. For example, complex textured blocks are encoded with fewer bits and smooth textured blocks are encoded with more bits. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen with a lot of complex texture, you might choose to disable this feature. Related setting: When you enable spatial adaptive quantization, set the value for Adaptive quantization (adaptiveQuantization) depending on your content. For homogeneous content, such as cartoons and video games, set it to Low. For content with a wider variety of textures, set it to High or Higher.
    #[doc(hidden)]
    pub spatial_adaptive_quantization:
        std::option::Option<crate::types::Av1SpatialAdaptiveQuantization>,
}
impl Av1Settings {
    /// Specify the strength of any adaptive quantization filters that you enable. The value that you choose here applies to Spatial adaptive quantization (spatialAdaptiveQuantization).
    pub fn adaptive_quantization(
        &self,
    ) -> std::option::Option<&crate::types::Av1AdaptiveQuantization> {
        self.adaptive_quantization.as_ref()
    }
    /// Specify the Bit depth (Av1BitDepth). You can choose 8-bit (BIT_8) or 10-bit (BIT_10).
    pub fn bit_depth(&self) -> std::option::Option<&crate::types::Av1BitDepth> {
        self.bit_depth.as_ref()
    }
    /// If you are using the console, use the Framerate setting to specify the frame rate for this output. If you want to keep the same frame rate as the input video, choose Follow source. If you want to do frame rate conversion, choose a frame rate from the dropdown list or choose Custom. The framerates shown in the dropdown list are decimal approximations of fractions. If you choose Custom, specify your frame rate as a fraction. If you are creating your transcoding job specification as a JSON file without the console, use FramerateControl to specify which value the service uses for the frame rate for this output. Choose INITIALIZE_FROM_SOURCE if you want the service to use the frame rate from the input. Choose SPECIFIED if you want the service to use the frame rate you specify in the settings FramerateNumerator and FramerateDenominator.
    pub fn framerate_control(&self) -> std::option::Option<&crate::types::Av1FramerateControl> {
        self.framerate_control.as_ref()
    }
    /// Choose the method that you want MediaConvert to use when increasing or decreasing the frame rate. We recommend using drop duplicate (DUPLICATE_DROP) for numerically simple conversions, such as 60 fps to 30 fps. For numerically complex conversions, you can use interpolate (INTERPOLATE) to avoid stutter. This results in a smooth picture, but might introduce undesirable video artifacts. For complex frame rate conversions, especially if your source video has already been converted from its original cadence, use FrameFormer (FRAMEFORMER) to do motion-compensated interpolation. FrameFormer chooses the best conversion method frame by frame. Note that using FrameFormer increases the transcoding time and incurs a significant add-on cost.
    pub fn framerate_conversion_algorithm(
        &self,
    ) -> std::option::Option<&crate::types::Av1FramerateConversionAlgorithm> {
        self.framerate_conversion_algorithm.as_ref()
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateDenominator to specify the denominator of this fraction. In this example, use 1001 for the value of FramerateDenominator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn framerate_denominator(&self) -> i32 {
        self.framerate_denominator
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateNumerator to specify the numerator of this fraction. In this example, use 24000 for the value of FramerateNumerator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn framerate_numerator(&self) -> i32 {
        self.framerate_numerator
    }
    /// Specify the GOP length (keyframe interval) in frames. With AV1, MediaConvert doesn't support GOP length in seconds. This value must be greater than zero and preferably equal to 1 + ((numberBFrames + 1) * x), where x is an integer value.
    pub fn gop_size(&self) -> f64 {
        self.gop_size
    }
    /// Maximum bitrate in bits/second. For example, enter five megabits per second as 5000000. Required when Rate control mode is QVBR.
    pub fn max_bitrate(&self) -> i32 {
        self.max_bitrate
    }
    /// Specify from the number of B-frames, in the range of 0-15. For AV1 encoding, we recommend using 7 or 15. Choose a larger number for a lower bitrate and smaller file size; choose a smaller number for better video quality.
    pub fn number_b_frames_between_reference_frames(&self) -> i32 {
        self.number_b_frames_between_reference_frames
    }
    /// Settings for quality-defined variable bitrate encoding with the H.265 codec. Use these settings only when you set QVBR for Rate control mode (RateControlMode).
    pub fn qvbr_settings(&self) -> std::option::Option<&crate::types::Av1QvbrSettings> {
        self.qvbr_settings.as_ref()
    }
    /// 'With AV1 outputs, for rate control mode, MediaConvert supports only quality-defined variable bitrate (QVBR). You can''t use CBR or VBR.'
    pub fn rate_control_mode(&self) -> std::option::Option<&crate::types::Av1RateControlMode> {
        self.rate_control_mode.as_ref()
    }
    /// Specify the number of slices per picture. This value must be 1, 2, 4, 8, 16, or 32. For progressive pictures, this value must be less than or equal to the number of macroblock rows. For interlaced pictures, this value must be less than or equal to half the number of macroblock rows.
    pub fn slices(&self) -> i32 {
        self.slices
    }
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on spatial variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas that can sustain more distortion with no noticeable visual degradation and uses more bits on areas where any small distortion will be noticeable. For example, complex textured blocks are encoded with fewer bits and smooth textured blocks are encoded with more bits. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen with a lot of complex texture, you might choose to disable this feature. Related setting: When you enable spatial adaptive quantization, set the value for Adaptive quantization (adaptiveQuantization) depending on your content. For homogeneous content, such as cartoons and video games, set it to Low. For content with a wider variety of textures, set it to High or Higher.
    pub fn spatial_adaptive_quantization(
        &self,
    ) -> std::option::Option<&crate::types::Av1SpatialAdaptiveQuantization> {
        self.spatial_adaptive_quantization.as_ref()
    }
}
impl Av1Settings {
    /// Creates a new builder-style object to manufacture [`Av1Settings`](crate::types::Av1Settings).
    pub fn builder() -> crate::types::builders::Av1SettingsBuilder {
        crate::types::builders::Av1SettingsBuilder::default()
    }
}

/// A builder for [`Av1Settings`](crate::types::Av1Settings).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct Av1SettingsBuilder {
    pub(crate) adaptive_quantization: std::option::Option<crate::types::Av1AdaptiveQuantization>,
    pub(crate) bit_depth: std::option::Option<crate::types::Av1BitDepth>,
    pub(crate) framerate_control: std::option::Option<crate::types::Av1FramerateControl>,
    pub(crate) framerate_conversion_algorithm:
        std::option::Option<crate::types::Av1FramerateConversionAlgorithm>,
    pub(crate) framerate_denominator: std::option::Option<i32>,
    pub(crate) framerate_numerator: std::option::Option<i32>,
    pub(crate) gop_size: std::option::Option<f64>,
    pub(crate) max_bitrate: std::option::Option<i32>,
    pub(crate) number_b_frames_between_reference_frames: std::option::Option<i32>,
    pub(crate) qvbr_settings: std::option::Option<crate::types::Av1QvbrSettings>,
    pub(crate) rate_control_mode: std::option::Option<crate::types::Av1RateControlMode>,
    pub(crate) slices: std::option::Option<i32>,
    pub(crate) spatial_adaptive_quantization:
        std::option::Option<crate::types::Av1SpatialAdaptiveQuantization>,
}
impl Av1SettingsBuilder {
    /// Specify the strength of any adaptive quantization filters that you enable. The value that you choose here applies to Spatial adaptive quantization (spatialAdaptiveQuantization).
    pub fn adaptive_quantization(mut self, input: crate::types::Av1AdaptiveQuantization) -> Self {
        self.adaptive_quantization = Some(input);
        self
    }
    /// Specify the strength of any adaptive quantization filters that you enable. The value that you choose here applies to Spatial adaptive quantization (spatialAdaptiveQuantization).
    pub fn set_adaptive_quantization(
        mut self,
        input: std::option::Option<crate::types::Av1AdaptiveQuantization>,
    ) -> Self {
        self.adaptive_quantization = input;
        self
    }
    /// Specify the Bit depth (Av1BitDepth). You can choose 8-bit (BIT_8) or 10-bit (BIT_10).
    pub fn bit_depth(mut self, input: crate::types::Av1BitDepth) -> Self {
        self.bit_depth = Some(input);
        self
    }
    /// Specify the Bit depth (Av1BitDepth). You can choose 8-bit (BIT_8) or 10-bit (BIT_10).
    pub fn set_bit_depth(mut self, input: std::option::Option<crate::types::Av1BitDepth>) -> Self {
        self.bit_depth = input;
        self
    }
    /// If you are using the console, use the Framerate setting to specify the frame rate for this output. If you want to keep the same frame rate as the input video, choose Follow source. If you want to do frame rate conversion, choose a frame rate from the dropdown list or choose Custom. The framerates shown in the dropdown list are decimal approximations of fractions. If you choose Custom, specify your frame rate as a fraction. If you are creating your transcoding job specification as a JSON file without the console, use FramerateControl to specify which value the service uses for the frame rate for this output. Choose INITIALIZE_FROM_SOURCE if you want the service to use the frame rate from the input. Choose SPECIFIED if you want the service to use the frame rate you specify in the settings FramerateNumerator and FramerateDenominator.
    pub fn framerate_control(mut self, input: crate::types::Av1FramerateControl) -> Self {
        self.framerate_control = Some(input);
        self
    }
    /// If you are using the console, use the Framerate setting to specify the frame rate for this output. If you want to keep the same frame rate as the input video, choose Follow source. If you want to do frame rate conversion, choose a frame rate from the dropdown list or choose Custom. The framerates shown in the dropdown list are decimal approximations of fractions. If you choose Custom, specify your frame rate as a fraction. If you are creating your transcoding job specification as a JSON file without the console, use FramerateControl to specify which value the service uses for the frame rate for this output. Choose INITIALIZE_FROM_SOURCE if you want the service to use the frame rate from the input. Choose SPECIFIED if you want the service to use the frame rate you specify in the settings FramerateNumerator and FramerateDenominator.
    pub fn set_framerate_control(
        mut self,
        input: std::option::Option<crate::types::Av1FramerateControl>,
    ) -> Self {
        self.framerate_control = input;
        self
    }
    /// Choose the method that you want MediaConvert to use when increasing or decreasing the frame rate. We recommend using drop duplicate (DUPLICATE_DROP) for numerically simple conversions, such as 60 fps to 30 fps. For numerically complex conversions, you can use interpolate (INTERPOLATE) to avoid stutter. This results in a smooth picture, but might introduce undesirable video artifacts. For complex frame rate conversions, especially if your source video has already been converted from its original cadence, use FrameFormer (FRAMEFORMER) to do motion-compensated interpolation. FrameFormer chooses the best conversion method frame by frame. Note that using FrameFormer increases the transcoding time and incurs a significant add-on cost.
    pub fn framerate_conversion_algorithm(
        mut self,
        input: crate::types::Av1FramerateConversionAlgorithm,
    ) -> Self {
        self.framerate_conversion_algorithm = Some(input);
        self
    }
    /// Choose the method that you want MediaConvert to use when increasing or decreasing the frame rate. We recommend using drop duplicate (DUPLICATE_DROP) for numerically simple conversions, such as 60 fps to 30 fps. For numerically complex conversions, you can use interpolate (INTERPOLATE) to avoid stutter. This results in a smooth picture, but might introduce undesirable video artifacts. For complex frame rate conversions, especially if your source video has already been converted from its original cadence, use FrameFormer (FRAMEFORMER) to do motion-compensated interpolation. FrameFormer chooses the best conversion method frame by frame. Note that using FrameFormer increases the transcoding time and incurs a significant add-on cost.
    pub fn set_framerate_conversion_algorithm(
        mut self,
        input: std::option::Option<crate::types::Av1FramerateConversionAlgorithm>,
    ) -> Self {
        self.framerate_conversion_algorithm = input;
        self
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateDenominator to specify the denominator of this fraction. In this example, use 1001 for the value of FramerateDenominator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn framerate_denominator(mut self, input: i32) -> Self {
        self.framerate_denominator = Some(input);
        self
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateDenominator to specify the denominator of this fraction. In this example, use 1001 for the value of FramerateDenominator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn set_framerate_denominator(mut self, input: std::option::Option<i32>) -> Self {
        self.framerate_denominator = input;
        self
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateNumerator to specify the numerator of this fraction. In this example, use 24000 for the value of FramerateNumerator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn framerate_numerator(mut self, input: i32) -> Self {
        self.framerate_numerator = Some(input);
        self
    }
    /// When you use the API for transcode jobs that use frame rate conversion, specify the frame rate as a fraction. For example, 24000 / 1001 = 23.976 fps. Use FramerateNumerator to specify the numerator of this fraction. In this example, use 24000 for the value of FramerateNumerator. When you use the console for transcode jobs that use frame rate conversion, provide the value as a decimal number for Framerate. In this example, specify 23.976.
    pub fn set_framerate_numerator(mut self, input: std::option::Option<i32>) -> Self {
        self.framerate_numerator = input;
        self
    }
    /// Specify the GOP length (keyframe interval) in frames. With AV1, MediaConvert doesn't support GOP length in seconds. This value must be greater than zero and preferably equal to 1 + ((numberBFrames + 1) * x), where x is an integer value.
    pub fn gop_size(mut self, input: f64) -> Self {
        self.gop_size = Some(input);
        self
    }
    /// Specify the GOP length (keyframe interval) in frames. With AV1, MediaConvert doesn't support GOP length in seconds. This value must be greater than zero and preferably equal to 1 + ((numberBFrames + 1) * x), where x is an integer value.
    pub fn set_gop_size(mut self, input: std::option::Option<f64>) -> Self {
        self.gop_size = input;
        self
    }
    /// Maximum bitrate in bits/second. For example, enter five megabits per second as 5000000. Required when Rate control mode is QVBR.
    pub fn max_bitrate(mut self, input: i32) -> Self {
        self.max_bitrate = Some(input);
        self
    }
    /// Maximum bitrate in bits/second. For example, enter five megabits per second as 5000000. Required when Rate control mode is QVBR.
    pub fn set_max_bitrate(mut self, input: std::option::Option<i32>) -> Self {
        self.max_bitrate = input;
        self
    }
    /// Specify from the number of B-frames, in the range of 0-15. For AV1 encoding, we recommend using 7 or 15. Choose a larger number for a lower bitrate and smaller file size; choose a smaller number for better video quality.
    pub fn number_b_frames_between_reference_frames(mut self, input: i32) -> Self {
        self.number_b_frames_between_reference_frames = Some(input);
        self
    }
    /// Specify from the number of B-frames, in the range of 0-15. For AV1 encoding, we recommend using 7 or 15. Choose a larger number for a lower bitrate and smaller file size; choose a smaller number for better video quality.
    pub fn set_number_b_frames_between_reference_frames(
        mut self,
        input: std::option::Option<i32>,
    ) -> Self {
        self.number_b_frames_between_reference_frames = input;
        self
    }
    /// Settings for quality-defined variable bitrate encoding with the H.265 codec. Use these settings only when you set QVBR for Rate control mode (RateControlMode).
    pub fn qvbr_settings(mut self, input: crate::types::Av1QvbrSettings) -> Self {
        self.qvbr_settings = Some(input);
        self
    }
    /// Settings for quality-defined variable bitrate encoding with the H.265 codec. Use these settings only when you set QVBR for Rate control mode (RateControlMode).
    pub fn set_qvbr_settings(
        mut self,
        input: std::option::Option<crate::types::Av1QvbrSettings>,
    ) -> Self {
        self.qvbr_settings = input;
        self
    }
    /// 'With AV1 outputs, for rate control mode, MediaConvert supports only quality-defined variable bitrate (QVBR). You can''t use CBR or VBR.'
    pub fn rate_control_mode(mut self, input: crate::types::Av1RateControlMode) -> Self {
        self.rate_control_mode = Some(input);
        self
    }
    /// 'With AV1 outputs, for rate control mode, MediaConvert supports only quality-defined variable bitrate (QVBR). You can''t use CBR or VBR.'
    pub fn set_rate_control_mode(
        mut self,
        input: std::option::Option<crate::types::Av1RateControlMode>,
    ) -> Self {
        self.rate_control_mode = input;
        self
    }
    /// Specify the number of slices per picture. This value must be 1, 2, 4, 8, 16, or 32. For progressive pictures, this value must be less than or equal to the number of macroblock rows. For interlaced pictures, this value must be less than or equal to half the number of macroblock rows.
    pub fn slices(mut self, input: i32) -> Self {
        self.slices = Some(input);
        self
    }
    /// Specify the number of slices per picture. This value must be 1, 2, 4, 8, 16, or 32. For progressive pictures, this value must be less than or equal to the number of macroblock rows. For interlaced pictures, this value must be less than or equal to half the number of macroblock rows.
    pub fn set_slices(mut self, input: std::option::Option<i32>) -> Self {
        self.slices = input;
        self
    }
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on spatial variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas that can sustain more distortion with no noticeable visual degradation and uses more bits on areas where any small distortion will be noticeable. For example, complex textured blocks are encoded with fewer bits and smooth textured blocks are encoded with more bits. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen with a lot of complex texture, you might choose to disable this feature. Related setting: When you enable spatial adaptive quantization, set the value for Adaptive quantization (adaptiveQuantization) depending on your content. For homogeneous content, such as cartoons and video games, set it to Low. For content with a wider variety of textures, set it to High or Higher.
    pub fn spatial_adaptive_quantization(
        mut self,
        input: crate::types::Av1SpatialAdaptiveQuantization,
    ) -> Self {
        self.spatial_adaptive_quantization = Some(input);
        self
    }
    /// Keep the default value, Enabled (ENABLED), to adjust quantization within each frame based on spatial variation of content complexity. When you enable this feature, the encoder uses fewer bits on areas that can sustain more distortion with no noticeable visual degradation and uses more bits on areas where any small distortion will be noticeable. For example, complex textured blocks are encoded with fewer bits and smooth textured blocks are encoded with more bits. Enabling this feature will almost always improve your video quality. Note, though, that this feature doesn't take into account where the viewer's attention is likely to be. If viewers are likely to be focusing their attention on a part of the screen with a lot of complex texture, you might choose to disable this feature. Related setting: When you enable spatial adaptive quantization, set the value for Adaptive quantization (adaptiveQuantization) depending on your content. For homogeneous content, such as cartoons and video games, set it to Low. For content with a wider variety of textures, set it to High or Higher.
    pub fn set_spatial_adaptive_quantization(
        mut self,
        input: std::option::Option<crate::types::Av1SpatialAdaptiveQuantization>,
    ) -> Self {
        self.spatial_adaptive_quantization = input;
        self
    }
    /// Consumes the builder and constructs a [`Av1Settings`](crate::types::Av1Settings).
    pub fn build(self) -> crate::types::Av1Settings {
        crate::types::Av1Settings {
            adaptive_quantization: self.adaptive_quantization,
            bit_depth: self.bit_depth,
            framerate_control: self.framerate_control,
            framerate_conversion_algorithm: self.framerate_conversion_algorithm,
            framerate_denominator: self.framerate_denominator.unwrap_or_default(),
            framerate_numerator: self.framerate_numerator.unwrap_or_default(),
            gop_size: self.gop_size.unwrap_or_default(),
            max_bitrate: self.max_bitrate.unwrap_or_default(),
            number_b_frames_between_reference_frames: self
                .number_b_frames_between_reference_frames
                .unwrap_or_default(),
            qvbr_settings: self.qvbr_settings,
            rate_control_mode: self.rate_control_mode,
            slices: self.slices.unwrap_or_default(),
            spatial_adaptive_quantization: self.spatial_adaptive_quantization,
        }
    }
}
