// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// Specified video input in a template.
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct InputTemplate {
    /// Use to remove noise, blocking, blurriness, or ringing from your input as a pre-filter step before encoding. The Advanced input filter removes more types of compression artifacts and is an improvement when compared to basic Deblock and Denoise filters. To remove video compression artifacts from your input and improve the video quality: Choose Enabled. Additionally, this filter can help increase the video quality of your output relative to its bitrate, since noisy inputs are more complex and require more bits to encode. To help restore loss of detail after applying the filter, you can optionally add texture or sharpening as an additional step. Jobs that use this feature incur pro-tier pricing. To not apply advanced input filtering: Choose Disabled. Note that you can still apply basic filtering with Deblock and Denoise.
    pub advanced_input_filter: ::std::option::Option<crate::types::AdvancedInputFilter>,
    /// Optional settings for Advanced input filter when you set Advanced input filter to Enabled.
    pub advanced_input_filter_settings: ::std::option::Option<crate::types::AdvancedInputFilterSettings>,
    /// Use audio selector groups to combine multiple sidecar audio inputs so that you can assign them to a single output audio tab. Note that, if you're working with embedded audio, it's simpler to assign multiple input tracks into a single audio selector rather than use an audio selector group.
    pub audio_selector_groups: ::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::AudioSelectorGroup>>,
    /// Use Audio selectors to specify a track or set of tracks from the input that you will use in your outputs. You can use multiple Audio selectors per input.
    pub audio_selectors: ::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::AudioSelector>>,
    /// Use captions selectors to specify the captions data from your input that you use in your outputs. You can use up to 100 captions selectors per input.
    pub caption_selectors: ::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::CaptionSelector>>,
    /// Use Cropping selection to specify the video area that the service will include in the output video frame. If you specify a value here, it will override any value that you specify in the output setting Cropping selection.
    pub crop: ::std::option::Option<crate::types::Rectangle>,
    /// Enable Deblock to produce smoother motion in the output. Default is disabled. Only manually controllable for MPEG2 and uncompressed video inputs.
    pub deblock_filter: ::std::option::Option<crate::types::InputDeblockFilter>,
    /// Enable Denoise to filter noise from the input. Default is disabled. Only applicable to MPEG2, H.264, H.265, and uncompressed video inputs.
    pub denoise_filter: ::std::option::Option<crate::types::InputDenoiseFilter>,
    /// Use this setting only when your video source has Dolby Vision studio mastering metadata that is carried in a separate XML file. Specify the Amazon S3 location for the metadata XML file. MediaConvert uses this file to provide global and frame-level metadata for Dolby Vision preprocessing. When you specify a file here and your input also has interleaved global and frame level metadata, MediaConvert ignores the interleaved metadata and uses only the the metadata from this external XML file. Note that your IAM service role must grant MediaConvert read permissions to this file. For more information, see https://docs.aws.amazon.com/mediaconvert/latest/ug/iam-role.html.
    pub dolby_vision_metadata_xml: ::std::option::Option<::std::string::String>,
    /// Specify whether to apply input filtering to improve the video quality of your input. To apply filtering depending on your input type and quality: Choose Auto. To apply no filtering: Choose Disable. To apply filtering regardless of your input type and quality: Choose Force. When you do, you must also specify a value for Filter strength.
    pub filter_enable: ::std::option::Option<crate::types::InputFilterEnable>,
    /// Specify the strength of the input filter. To apply an automatic amount of filtering based the compression artifacts measured in your input: We recommend that you leave Filter strength blank and set Filter enable to Auto. To manually apply filtering: Enter a value from 1 to 5, where 1 is the least amount of filtering and 5 is the most. The value that you enter applies to the strength of the Deblock or Denoise filters, or to the strength of the Advanced input filter.
    pub filter_strength: ::std::option::Option<i32>,
    /// Enable the image inserter feature to include a graphic overlay on your video. Enable or disable this feature for each input individually. This setting is disabled by default.
    pub image_inserter: ::std::option::Option<crate::types::ImageInserter>,
    /// Contains sets of start and end times that together specify a portion of the input to be used in the outputs. If you provide only a start time, the clip will be the entire input from that point to the end. If you provide only an end time, it will be the entire input up to that point. When you specify more than one input clip, the transcoding service creates the job outputs by stringing the clips together in the order you specify them.
    pub input_clippings: ::std::option::Option<::std::vec::Vec<crate::types::InputClipping>>,
    /// When you have a progressive segmented frame (PsF) input, use this setting to flag the input as PsF. MediaConvert doesn't automatically detect PsF. Therefore, flagging your input as PsF results in better preservation of video quality when you do deinterlacing and frame rate conversion. If you don't specify, the default value is Auto. Auto is the correct setting for all inputs that are not PsF. Don't set this value to PsF when your input is interlaced. Doing so creates horizontal interlacing artifacts.
    pub input_scan_type: ::std::option::Option<crate::types::InputScanType>,
    /// Use Selection placement to define the video area in your output frame. The area outside of the rectangle that you specify here is black. If you specify a value here, it will override any value that you specify in the output setting Selection placement. If you specify a value here, this will override any AFD values in your input, even if you set Respond to AFD to Respond. If you specify a value here, this will ignore anything that you specify for the setting Scaling Behavior.
    pub position: ::std::option::Option<crate::types::Rectangle>,
    /// Use Program to select a specific program from within a multi-program transport stream. Note that Quad 4K is not currently supported. Default is the first program within the transport stream. If the program you specify doesn't exist, the transcoding service will use this default.
    pub program_number: ::std::option::Option<i32>,
    /// Set PSI control for transport stream inputs to specify which data the demux process to scans. * Ignore PSI - Scan all PIDs for audio and video. * Use PSI - Scan only PSI data.
    pub psi_control: ::std::option::Option<crate::types::InputPsiControl>,
    /// Use this Timecode source setting, located under the input settings, to specify how the service counts input video frames. This input frame count affects only the behavior of features that apply to a single input at a time, such as input clipping and synchronizing some captions formats. Choose Embedded to use the timecodes in your input video. Choose Start at zero to start the first frame at zero. Choose Specified start to start the first frame at the timecode that you specify in the setting Start timecode. If you don't specify a value for Timecode source, the service will use Embedded by default. For more information about timecodes, see https://docs.aws.amazon.com/console/mediaconvert/timecode.
    pub timecode_source: ::std::option::Option<crate::types::InputTimecodeSource>,
    /// Specify the timecode that you want the service to use for this input's initial frame. To use this setting, you must set the Timecode source setting, located under the input settings, to Specified start. For more information about timecodes, see https://docs.aws.amazon.com/console/mediaconvert/timecode.
    pub timecode_start: ::std::option::Option<::std::string::String>,
    /// Contains an array of video overlays.
    pub video_overlays: ::std::option::Option<::std::vec::Vec<crate::types::VideoOverlay>>,
    /// Input video selectors contain the video settings for the input. Each of your inputs can have up to one video selector.
    pub video_selector: ::std::option::Option<crate::types::VideoSelector>,
}
impl InputTemplate {
    /// Use to remove noise, blocking, blurriness, or ringing from your input as a pre-filter step before encoding. The Advanced input filter removes more types of compression artifacts and is an improvement when compared to basic Deblock and Denoise filters. To remove video compression artifacts from your input and improve the video quality: Choose Enabled. Additionally, this filter can help increase the video quality of your output relative to its bitrate, since noisy inputs are more complex and require more bits to encode. To help restore loss of detail after applying the filter, you can optionally add texture or sharpening as an additional step. Jobs that use this feature incur pro-tier pricing. To not apply advanced input filtering: Choose Disabled. Note that you can still apply basic filtering with Deblock and Denoise.
    pub fn advanced_input_filter(&self) -> ::std::option::Option<&crate::types::AdvancedInputFilter> {
        self.advanced_input_filter.as_ref()
    }
    /// Optional settings for Advanced input filter when you set Advanced input filter to Enabled.
    pub fn advanced_input_filter_settings(&self) -> ::std::option::Option<&crate::types::AdvancedInputFilterSettings> {
        self.advanced_input_filter_settings.as_ref()
    }
    /// Use audio selector groups to combine multiple sidecar audio inputs so that you can assign them to a single output audio tab. Note that, if you're working with embedded audio, it's simpler to assign multiple input tracks into a single audio selector rather than use an audio selector group.
    pub fn audio_selector_groups(
        &self,
    ) -> ::std::option::Option<&::std::collections::HashMap<::std::string::String, crate::types::AudioSelectorGroup>> {
        self.audio_selector_groups.as_ref()
    }
    /// Use Audio selectors to specify a track or set of tracks from the input that you will use in your outputs. You can use multiple Audio selectors per input.
    pub fn audio_selectors(&self) -> ::std::option::Option<&::std::collections::HashMap<::std::string::String, crate::types::AudioSelector>> {
        self.audio_selectors.as_ref()
    }
    /// Use captions selectors to specify the captions data from your input that you use in your outputs. You can use up to 100 captions selectors per input.
    pub fn caption_selectors(&self) -> ::std::option::Option<&::std::collections::HashMap<::std::string::String, crate::types::CaptionSelector>> {
        self.caption_selectors.as_ref()
    }
    /// Use Cropping selection to specify the video area that the service will include in the output video frame. If you specify a value here, it will override any value that you specify in the output setting Cropping selection.
    pub fn crop(&self) -> ::std::option::Option<&crate::types::Rectangle> {
        self.crop.as_ref()
    }
    /// Enable Deblock to produce smoother motion in the output. Default is disabled. Only manually controllable for MPEG2 and uncompressed video inputs.
    pub fn deblock_filter(&self) -> ::std::option::Option<&crate::types::InputDeblockFilter> {
        self.deblock_filter.as_ref()
    }
    /// Enable Denoise to filter noise from the input. Default is disabled. Only applicable to MPEG2, H.264, H.265, and uncompressed video inputs.
    pub fn denoise_filter(&self) -> ::std::option::Option<&crate::types::InputDenoiseFilter> {
        self.denoise_filter.as_ref()
    }
    /// Use this setting only when your video source has Dolby Vision studio mastering metadata that is carried in a separate XML file. Specify the Amazon S3 location for the metadata XML file. MediaConvert uses this file to provide global and frame-level metadata for Dolby Vision preprocessing. When you specify a file here and your input also has interleaved global and frame level metadata, MediaConvert ignores the interleaved metadata and uses only the the metadata from this external XML file. Note that your IAM service role must grant MediaConvert read permissions to this file. For more information, see https://docs.aws.amazon.com/mediaconvert/latest/ug/iam-role.html.
    pub fn dolby_vision_metadata_xml(&self) -> ::std::option::Option<&str> {
        self.dolby_vision_metadata_xml.as_deref()
    }
    /// Specify whether to apply input filtering to improve the video quality of your input. To apply filtering depending on your input type and quality: Choose Auto. To apply no filtering: Choose Disable. To apply filtering regardless of your input type and quality: Choose Force. When you do, you must also specify a value for Filter strength.
    pub fn filter_enable(&self) -> ::std::option::Option<&crate::types::InputFilterEnable> {
        self.filter_enable.as_ref()
    }
    /// Specify the strength of the input filter. To apply an automatic amount of filtering based the compression artifacts measured in your input: We recommend that you leave Filter strength blank and set Filter enable to Auto. To manually apply filtering: Enter a value from 1 to 5, where 1 is the least amount of filtering and 5 is the most. The value that you enter applies to the strength of the Deblock or Denoise filters, or to the strength of the Advanced input filter.
    pub fn filter_strength(&self) -> ::std::option::Option<i32> {
        self.filter_strength
    }
    /// Enable the image inserter feature to include a graphic overlay on your video. Enable or disable this feature for each input individually. This setting is disabled by default.
    pub fn image_inserter(&self) -> ::std::option::Option<&crate::types::ImageInserter> {
        self.image_inserter.as_ref()
    }
    /// Contains sets of start and end times that together specify a portion of the input to be used in the outputs. If you provide only a start time, the clip will be the entire input from that point to the end. If you provide only an end time, it will be the entire input up to that point. When you specify more than one input clip, the transcoding service creates the job outputs by stringing the clips together in the order you specify them.
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.input_clippings.is_none()`.
    pub fn input_clippings(&self) -> &[crate::types::InputClipping] {
        self.input_clippings.as_deref().unwrap_or_default()
    }
    /// When you have a progressive segmented frame (PsF) input, use this setting to flag the input as PsF. MediaConvert doesn't automatically detect PsF. Therefore, flagging your input as PsF results in better preservation of video quality when you do deinterlacing and frame rate conversion. If you don't specify, the default value is Auto. Auto is the correct setting for all inputs that are not PsF. Don't set this value to PsF when your input is interlaced. Doing so creates horizontal interlacing artifacts.
    pub fn input_scan_type(&self) -> ::std::option::Option<&crate::types::InputScanType> {
        self.input_scan_type.as_ref()
    }
    /// Use Selection placement to define the video area in your output frame. The area outside of the rectangle that you specify here is black. If you specify a value here, it will override any value that you specify in the output setting Selection placement. If you specify a value here, this will override any AFD values in your input, even if you set Respond to AFD to Respond. If you specify a value here, this will ignore anything that you specify for the setting Scaling Behavior.
    pub fn position(&self) -> ::std::option::Option<&crate::types::Rectangle> {
        self.position.as_ref()
    }
    /// Use Program to select a specific program from within a multi-program transport stream. Note that Quad 4K is not currently supported. Default is the first program within the transport stream. If the program you specify doesn't exist, the transcoding service will use this default.
    pub fn program_number(&self) -> ::std::option::Option<i32> {
        self.program_number
    }
    /// Set PSI control for transport stream inputs to specify which data the demux process to scans. * Ignore PSI - Scan all PIDs for audio and video. * Use PSI - Scan only PSI data.
    pub fn psi_control(&self) -> ::std::option::Option<&crate::types::InputPsiControl> {
        self.psi_control.as_ref()
    }
    /// Use this Timecode source setting, located under the input settings, to specify how the service counts input video frames. This input frame count affects only the behavior of features that apply to a single input at a time, such as input clipping and synchronizing some captions formats. Choose Embedded to use the timecodes in your input video. Choose Start at zero to start the first frame at zero. Choose Specified start to start the first frame at the timecode that you specify in the setting Start timecode. If you don't specify a value for Timecode source, the service will use Embedded by default. For more information about timecodes, see https://docs.aws.amazon.com/console/mediaconvert/timecode.
    pub fn timecode_source(&self) -> ::std::option::Option<&crate::types::InputTimecodeSource> {
        self.timecode_source.as_ref()
    }
    /// Specify the timecode that you want the service to use for this input's initial frame. To use this setting, you must set the Timecode source setting, located under the input settings, to Specified start. For more information about timecodes, see https://docs.aws.amazon.com/console/mediaconvert/timecode.
    pub fn timecode_start(&self) -> ::std::option::Option<&str> {
        self.timecode_start.as_deref()
    }
    /// Contains an array of video overlays.
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.video_overlays.is_none()`.
    pub fn video_overlays(&self) -> &[crate::types::VideoOverlay] {
        self.video_overlays.as_deref().unwrap_or_default()
    }
    /// Input video selectors contain the video settings for the input. Each of your inputs can have up to one video selector.
    pub fn video_selector(&self) -> ::std::option::Option<&crate::types::VideoSelector> {
        self.video_selector.as_ref()
    }
}
impl InputTemplate {
    /// Creates a new builder-style object to manufacture [`InputTemplate`](crate::types::InputTemplate).
    pub fn builder() -> crate::types::builders::InputTemplateBuilder {
        crate::types::builders::InputTemplateBuilder::default()
    }
}

/// A builder for [`InputTemplate`](crate::types::InputTemplate).
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
pub struct InputTemplateBuilder {
    pub(crate) advanced_input_filter: ::std::option::Option<crate::types::AdvancedInputFilter>,
    pub(crate) advanced_input_filter_settings: ::std::option::Option<crate::types::AdvancedInputFilterSettings>,
    pub(crate) audio_selector_groups: ::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::AudioSelectorGroup>>,
    pub(crate) audio_selectors: ::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::AudioSelector>>,
    pub(crate) caption_selectors: ::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::CaptionSelector>>,
    pub(crate) crop: ::std::option::Option<crate::types::Rectangle>,
    pub(crate) deblock_filter: ::std::option::Option<crate::types::InputDeblockFilter>,
    pub(crate) denoise_filter: ::std::option::Option<crate::types::InputDenoiseFilter>,
    pub(crate) dolby_vision_metadata_xml: ::std::option::Option<::std::string::String>,
    pub(crate) filter_enable: ::std::option::Option<crate::types::InputFilterEnable>,
    pub(crate) filter_strength: ::std::option::Option<i32>,
    pub(crate) image_inserter: ::std::option::Option<crate::types::ImageInserter>,
    pub(crate) input_clippings: ::std::option::Option<::std::vec::Vec<crate::types::InputClipping>>,
    pub(crate) input_scan_type: ::std::option::Option<crate::types::InputScanType>,
    pub(crate) position: ::std::option::Option<crate::types::Rectangle>,
    pub(crate) program_number: ::std::option::Option<i32>,
    pub(crate) psi_control: ::std::option::Option<crate::types::InputPsiControl>,
    pub(crate) timecode_source: ::std::option::Option<crate::types::InputTimecodeSource>,
    pub(crate) timecode_start: ::std::option::Option<::std::string::String>,
    pub(crate) video_overlays: ::std::option::Option<::std::vec::Vec<crate::types::VideoOverlay>>,
    pub(crate) video_selector: ::std::option::Option<crate::types::VideoSelector>,
}
impl InputTemplateBuilder {
    /// Use to remove noise, blocking, blurriness, or ringing from your input as a pre-filter step before encoding. The Advanced input filter removes more types of compression artifacts and is an improvement when compared to basic Deblock and Denoise filters. To remove video compression artifacts from your input and improve the video quality: Choose Enabled. Additionally, this filter can help increase the video quality of your output relative to its bitrate, since noisy inputs are more complex and require more bits to encode. To help restore loss of detail after applying the filter, you can optionally add texture or sharpening as an additional step. Jobs that use this feature incur pro-tier pricing. To not apply advanced input filtering: Choose Disabled. Note that you can still apply basic filtering with Deblock and Denoise.
    pub fn advanced_input_filter(mut self, input: crate::types::AdvancedInputFilter) -> Self {
        self.advanced_input_filter = ::std::option::Option::Some(input);
        self
    }
    /// Use to remove noise, blocking, blurriness, or ringing from your input as a pre-filter step before encoding. The Advanced input filter removes more types of compression artifacts and is an improvement when compared to basic Deblock and Denoise filters. To remove video compression artifacts from your input and improve the video quality: Choose Enabled. Additionally, this filter can help increase the video quality of your output relative to its bitrate, since noisy inputs are more complex and require more bits to encode. To help restore loss of detail after applying the filter, you can optionally add texture or sharpening as an additional step. Jobs that use this feature incur pro-tier pricing. To not apply advanced input filtering: Choose Disabled. Note that you can still apply basic filtering with Deblock and Denoise.
    pub fn set_advanced_input_filter(mut self, input: ::std::option::Option<crate::types::AdvancedInputFilter>) -> Self {
        self.advanced_input_filter = input;
        self
    }
    /// Use to remove noise, blocking, blurriness, or ringing from your input as a pre-filter step before encoding. The Advanced input filter removes more types of compression artifacts and is an improvement when compared to basic Deblock and Denoise filters. To remove video compression artifacts from your input and improve the video quality: Choose Enabled. Additionally, this filter can help increase the video quality of your output relative to its bitrate, since noisy inputs are more complex and require more bits to encode. To help restore loss of detail after applying the filter, you can optionally add texture or sharpening as an additional step. Jobs that use this feature incur pro-tier pricing. To not apply advanced input filtering: Choose Disabled. Note that you can still apply basic filtering with Deblock and Denoise.
    pub fn get_advanced_input_filter(&self) -> &::std::option::Option<crate::types::AdvancedInputFilter> {
        &self.advanced_input_filter
    }
    /// Optional settings for Advanced input filter when you set Advanced input filter to Enabled.
    pub fn advanced_input_filter_settings(mut self, input: crate::types::AdvancedInputFilterSettings) -> Self {
        self.advanced_input_filter_settings = ::std::option::Option::Some(input);
        self
    }
    /// Optional settings for Advanced input filter when you set Advanced input filter to Enabled.
    pub fn set_advanced_input_filter_settings(mut self, input: ::std::option::Option<crate::types::AdvancedInputFilterSettings>) -> Self {
        self.advanced_input_filter_settings = input;
        self
    }
    /// Optional settings for Advanced input filter when you set Advanced input filter to Enabled.
    pub fn get_advanced_input_filter_settings(&self) -> &::std::option::Option<crate::types::AdvancedInputFilterSettings> {
        &self.advanced_input_filter_settings
    }
    /// Adds a key-value pair to `audio_selector_groups`.
    ///
    /// To override the contents of this collection use [`set_audio_selector_groups`](Self::set_audio_selector_groups).
    ///
    /// Use audio selector groups to combine multiple sidecar audio inputs so that you can assign them to a single output audio tab. Note that, if you're working with embedded audio, it's simpler to assign multiple input tracks into a single audio selector rather than use an audio selector group.
    pub fn audio_selector_groups(mut self, k: impl ::std::convert::Into<::std::string::String>, v: crate::types::AudioSelectorGroup) -> Self {
        let mut hash_map = self.audio_selector_groups.unwrap_or_default();
        hash_map.insert(k.into(), v);
        self.audio_selector_groups = ::std::option::Option::Some(hash_map);
        self
    }
    /// Use audio selector groups to combine multiple sidecar audio inputs so that you can assign them to a single output audio tab. Note that, if you're working with embedded audio, it's simpler to assign multiple input tracks into a single audio selector rather than use an audio selector group.
    pub fn set_audio_selector_groups(
        mut self,
        input: ::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::AudioSelectorGroup>>,
    ) -> Self {
        self.audio_selector_groups = input;
        self
    }
    /// Use audio selector groups to combine multiple sidecar audio inputs so that you can assign them to a single output audio tab. Note that, if you're working with embedded audio, it's simpler to assign multiple input tracks into a single audio selector rather than use an audio selector group.
    pub fn get_audio_selector_groups(
        &self,
    ) -> &::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::AudioSelectorGroup>> {
        &self.audio_selector_groups
    }
    /// Adds a key-value pair to `audio_selectors`.
    ///
    /// To override the contents of this collection use [`set_audio_selectors`](Self::set_audio_selectors).
    ///
    /// Use Audio selectors to specify a track or set of tracks from the input that you will use in your outputs. You can use multiple Audio selectors per input.
    pub fn audio_selectors(mut self, k: impl ::std::convert::Into<::std::string::String>, v: crate::types::AudioSelector) -> Self {
        let mut hash_map = self.audio_selectors.unwrap_or_default();
        hash_map.insert(k.into(), v);
        self.audio_selectors = ::std::option::Option::Some(hash_map);
        self
    }
    /// Use Audio selectors to specify a track or set of tracks from the input that you will use in your outputs. You can use multiple Audio selectors per input.
    pub fn set_audio_selectors(
        mut self,
        input: ::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::AudioSelector>>,
    ) -> Self {
        self.audio_selectors = input;
        self
    }
    /// Use Audio selectors to specify a track or set of tracks from the input that you will use in your outputs. You can use multiple Audio selectors per input.
    pub fn get_audio_selectors(&self) -> &::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::AudioSelector>> {
        &self.audio_selectors
    }
    /// Adds a key-value pair to `caption_selectors`.
    ///
    /// To override the contents of this collection use [`set_caption_selectors`](Self::set_caption_selectors).
    ///
    /// Use captions selectors to specify the captions data from your input that you use in your outputs. You can use up to 100 captions selectors per input.
    pub fn caption_selectors(mut self, k: impl ::std::convert::Into<::std::string::String>, v: crate::types::CaptionSelector) -> Self {
        let mut hash_map = self.caption_selectors.unwrap_or_default();
        hash_map.insert(k.into(), v);
        self.caption_selectors = ::std::option::Option::Some(hash_map);
        self
    }
    /// Use captions selectors to specify the captions data from your input that you use in your outputs. You can use up to 100 captions selectors per input.
    pub fn set_caption_selectors(
        mut self,
        input: ::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::CaptionSelector>>,
    ) -> Self {
        self.caption_selectors = input;
        self
    }
    /// Use captions selectors to specify the captions data from your input that you use in your outputs. You can use up to 100 captions selectors per input.
    pub fn get_caption_selectors(&self) -> &::std::option::Option<::std::collections::HashMap<::std::string::String, crate::types::CaptionSelector>> {
        &self.caption_selectors
    }
    /// Use Cropping selection to specify the video area that the service will include in the output video frame. If you specify a value here, it will override any value that you specify in the output setting Cropping selection.
    pub fn crop(mut self, input: crate::types::Rectangle) -> Self {
        self.crop = ::std::option::Option::Some(input);
        self
    }
    /// Use Cropping selection to specify the video area that the service will include in the output video frame. If you specify a value here, it will override any value that you specify in the output setting Cropping selection.
    pub fn set_crop(mut self, input: ::std::option::Option<crate::types::Rectangle>) -> Self {
        self.crop = input;
        self
    }
    /// Use Cropping selection to specify the video area that the service will include in the output video frame. If you specify a value here, it will override any value that you specify in the output setting Cropping selection.
    pub fn get_crop(&self) -> &::std::option::Option<crate::types::Rectangle> {
        &self.crop
    }
    /// Enable Deblock to produce smoother motion in the output. Default is disabled. Only manually controllable for MPEG2 and uncompressed video inputs.
    pub fn deblock_filter(mut self, input: crate::types::InputDeblockFilter) -> Self {
        self.deblock_filter = ::std::option::Option::Some(input);
        self
    }
    /// Enable Deblock to produce smoother motion in the output. Default is disabled. Only manually controllable for MPEG2 and uncompressed video inputs.
    pub fn set_deblock_filter(mut self, input: ::std::option::Option<crate::types::InputDeblockFilter>) -> Self {
        self.deblock_filter = input;
        self
    }
    /// Enable Deblock to produce smoother motion in the output. Default is disabled. Only manually controllable for MPEG2 and uncompressed video inputs.
    pub fn get_deblock_filter(&self) -> &::std::option::Option<crate::types::InputDeblockFilter> {
        &self.deblock_filter
    }
    /// Enable Denoise to filter noise from the input. Default is disabled. Only applicable to MPEG2, H.264, H.265, and uncompressed video inputs.
    pub fn denoise_filter(mut self, input: crate::types::InputDenoiseFilter) -> Self {
        self.denoise_filter = ::std::option::Option::Some(input);
        self
    }
    /// Enable Denoise to filter noise from the input. Default is disabled. Only applicable to MPEG2, H.264, H.265, and uncompressed video inputs.
    pub fn set_denoise_filter(mut self, input: ::std::option::Option<crate::types::InputDenoiseFilter>) -> Self {
        self.denoise_filter = input;
        self
    }
    /// Enable Denoise to filter noise from the input. Default is disabled. Only applicable to MPEG2, H.264, H.265, and uncompressed video inputs.
    pub fn get_denoise_filter(&self) -> &::std::option::Option<crate::types::InputDenoiseFilter> {
        &self.denoise_filter
    }
    /// Use this setting only when your video source has Dolby Vision studio mastering metadata that is carried in a separate XML file. Specify the Amazon S3 location for the metadata XML file. MediaConvert uses this file to provide global and frame-level metadata for Dolby Vision preprocessing. When you specify a file here and your input also has interleaved global and frame level metadata, MediaConvert ignores the interleaved metadata and uses only the the metadata from this external XML file. Note that your IAM service role must grant MediaConvert read permissions to this file. For more information, see https://docs.aws.amazon.com/mediaconvert/latest/ug/iam-role.html.
    pub fn dolby_vision_metadata_xml(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.dolby_vision_metadata_xml = ::std::option::Option::Some(input.into());
        self
    }
    /// Use this setting only when your video source has Dolby Vision studio mastering metadata that is carried in a separate XML file. Specify the Amazon S3 location for the metadata XML file. MediaConvert uses this file to provide global and frame-level metadata for Dolby Vision preprocessing. When you specify a file here and your input also has interleaved global and frame level metadata, MediaConvert ignores the interleaved metadata and uses only the the metadata from this external XML file. Note that your IAM service role must grant MediaConvert read permissions to this file. For more information, see https://docs.aws.amazon.com/mediaconvert/latest/ug/iam-role.html.
    pub fn set_dolby_vision_metadata_xml(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.dolby_vision_metadata_xml = input;
        self
    }
    /// Use this setting only when your video source has Dolby Vision studio mastering metadata that is carried in a separate XML file. Specify the Amazon S3 location for the metadata XML file. MediaConvert uses this file to provide global and frame-level metadata for Dolby Vision preprocessing. When you specify a file here and your input also has interleaved global and frame level metadata, MediaConvert ignores the interleaved metadata and uses only the the metadata from this external XML file. Note that your IAM service role must grant MediaConvert read permissions to this file. For more information, see https://docs.aws.amazon.com/mediaconvert/latest/ug/iam-role.html.
    pub fn get_dolby_vision_metadata_xml(&self) -> &::std::option::Option<::std::string::String> {
        &self.dolby_vision_metadata_xml
    }
    /// Specify whether to apply input filtering to improve the video quality of your input. To apply filtering depending on your input type and quality: Choose Auto. To apply no filtering: Choose Disable. To apply filtering regardless of your input type and quality: Choose Force. When you do, you must also specify a value for Filter strength.
    pub fn filter_enable(mut self, input: crate::types::InputFilterEnable) -> Self {
        self.filter_enable = ::std::option::Option::Some(input);
        self
    }
    /// Specify whether to apply input filtering to improve the video quality of your input. To apply filtering depending on your input type and quality: Choose Auto. To apply no filtering: Choose Disable. To apply filtering regardless of your input type and quality: Choose Force. When you do, you must also specify a value for Filter strength.
    pub fn set_filter_enable(mut self, input: ::std::option::Option<crate::types::InputFilterEnable>) -> Self {
        self.filter_enable = input;
        self
    }
    /// Specify whether to apply input filtering to improve the video quality of your input. To apply filtering depending on your input type and quality: Choose Auto. To apply no filtering: Choose Disable. To apply filtering regardless of your input type and quality: Choose Force. When you do, you must also specify a value for Filter strength.
    pub fn get_filter_enable(&self) -> &::std::option::Option<crate::types::InputFilterEnable> {
        &self.filter_enable
    }
    /// Specify the strength of the input filter. To apply an automatic amount of filtering based the compression artifacts measured in your input: We recommend that you leave Filter strength blank and set Filter enable to Auto. To manually apply filtering: Enter a value from 1 to 5, where 1 is the least amount of filtering and 5 is the most. The value that you enter applies to the strength of the Deblock or Denoise filters, or to the strength of the Advanced input filter.
    pub fn filter_strength(mut self, input: i32) -> Self {
        self.filter_strength = ::std::option::Option::Some(input);
        self
    }
    /// Specify the strength of the input filter. To apply an automatic amount of filtering based the compression artifacts measured in your input: We recommend that you leave Filter strength blank and set Filter enable to Auto. To manually apply filtering: Enter a value from 1 to 5, where 1 is the least amount of filtering and 5 is the most. The value that you enter applies to the strength of the Deblock or Denoise filters, or to the strength of the Advanced input filter.
    pub fn set_filter_strength(mut self, input: ::std::option::Option<i32>) -> Self {
        self.filter_strength = input;
        self
    }
    /// Specify the strength of the input filter. To apply an automatic amount of filtering based the compression artifacts measured in your input: We recommend that you leave Filter strength blank and set Filter enable to Auto. To manually apply filtering: Enter a value from 1 to 5, where 1 is the least amount of filtering and 5 is the most. The value that you enter applies to the strength of the Deblock or Denoise filters, or to the strength of the Advanced input filter.
    pub fn get_filter_strength(&self) -> &::std::option::Option<i32> {
        &self.filter_strength
    }
    /// Enable the image inserter feature to include a graphic overlay on your video. Enable or disable this feature for each input individually. This setting is disabled by default.
    pub fn image_inserter(mut self, input: crate::types::ImageInserter) -> Self {
        self.image_inserter = ::std::option::Option::Some(input);
        self
    }
    /// Enable the image inserter feature to include a graphic overlay on your video. Enable or disable this feature for each input individually. This setting is disabled by default.
    pub fn set_image_inserter(mut self, input: ::std::option::Option<crate::types::ImageInserter>) -> Self {
        self.image_inserter = input;
        self
    }
    /// Enable the image inserter feature to include a graphic overlay on your video. Enable or disable this feature for each input individually. This setting is disabled by default.
    pub fn get_image_inserter(&self) -> &::std::option::Option<crate::types::ImageInserter> {
        &self.image_inserter
    }
    /// Appends an item to `input_clippings`.
    ///
    /// To override the contents of this collection use [`set_input_clippings`](Self::set_input_clippings).
    ///
    /// Contains sets of start and end times that together specify a portion of the input to be used in the outputs. If you provide only a start time, the clip will be the entire input from that point to the end. If you provide only an end time, it will be the entire input up to that point. When you specify more than one input clip, the transcoding service creates the job outputs by stringing the clips together in the order you specify them.
    pub fn input_clippings(mut self, input: crate::types::InputClipping) -> Self {
        let mut v = self.input_clippings.unwrap_or_default();
        v.push(input);
        self.input_clippings = ::std::option::Option::Some(v);
        self
    }
    /// Contains sets of start and end times that together specify a portion of the input to be used in the outputs. If you provide only a start time, the clip will be the entire input from that point to the end. If you provide only an end time, it will be the entire input up to that point. When you specify more than one input clip, the transcoding service creates the job outputs by stringing the clips together in the order you specify them.
    pub fn set_input_clippings(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::InputClipping>>) -> Self {
        self.input_clippings = input;
        self
    }
    /// Contains sets of start and end times that together specify a portion of the input to be used in the outputs. If you provide only a start time, the clip will be the entire input from that point to the end. If you provide only an end time, it will be the entire input up to that point. When you specify more than one input clip, the transcoding service creates the job outputs by stringing the clips together in the order you specify them.
    pub fn get_input_clippings(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::InputClipping>> {
        &self.input_clippings
    }
    /// When you have a progressive segmented frame (PsF) input, use this setting to flag the input as PsF. MediaConvert doesn't automatically detect PsF. Therefore, flagging your input as PsF results in better preservation of video quality when you do deinterlacing and frame rate conversion. If you don't specify, the default value is Auto. Auto is the correct setting for all inputs that are not PsF. Don't set this value to PsF when your input is interlaced. Doing so creates horizontal interlacing artifacts.
    pub fn input_scan_type(mut self, input: crate::types::InputScanType) -> Self {
        self.input_scan_type = ::std::option::Option::Some(input);
        self
    }
    /// When you have a progressive segmented frame (PsF) input, use this setting to flag the input as PsF. MediaConvert doesn't automatically detect PsF. Therefore, flagging your input as PsF results in better preservation of video quality when you do deinterlacing and frame rate conversion. If you don't specify, the default value is Auto. Auto is the correct setting for all inputs that are not PsF. Don't set this value to PsF when your input is interlaced. Doing so creates horizontal interlacing artifacts.
    pub fn set_input_scan_type(mut self, input: ::std::option::Option<crate::types::InputScanType>) -> Self {
        self.input_scan_type = input;
        self
    }
    /// When you have a progressive segmented frame (PsF) input, use this setting to flag the input as PsF. MediaConvert doesn't automatically detect PsF. Therefore, flagging your input as PsF results in better preservation of video quality when you do deinterlacing and frame rate conversion. If you don't specify, the default value is Auto. Auto is the correct setting for all inputs that are not PsF. Don't set this value to PsF when your input is interlaced. Doing so creates horizontal interlacing artifacts.
    pub fn get_input_scan_type(&self) -> &::std::option::Option<crate::types::InputScanType> {
        &self.input_scan_type
    }
    /// Use Selection placement to define the video area in your output frame. The area outside of the rectangle that you specify here is black. If you specify a value here, it will override any value that you specify in the output setting Selection placement. If you specify a value here, this will override any AFD values in your input, even if you set Respond to AFD to Respond. If you specify a value here, this will ignore anything that you specify for the setting Scaling Behavior.
    pub fn position(mut self, input: crate::types::Rectangle) -> Self {
        self.position = ::std::option::Option::Some(input);
        self
    }
    /// Use Selection placement to define the video area in your output frame. The area outside of the rectangle that you specify here is black. If you specify a value here, it will override any value that you specify in the output setting Selection placement. If you specify a value here, this will override any AFD values in your input, even if you set Respond to AFD to Respond. If you specify a value here, this will ignore anything that you specify for the setting Scaling Behavior.
    pub fn set_position(mut self, input: ::std::option::Option<crate::types::Rectangle>) -> Self {
        self.position = input;
        self
    }
    /// Use Selection placement to define the video area in your output frame. The area outside of the rectangle that you specify here is black. If you specify a value here, it will override any value that you specify in the output setting Selection placement. If you specify a value here, this will override any AFD values in your input, even if you set Respond to AFD to Respond. If you specify a value here, this will ignore anything that you specify for the setting Scaling Behavior.
    pub fn get_position(&self) -> &::std::option::Option<crate::types::Rectangle> {
        &self.position
    }
    /// Use Program to select a specific program from within a multi-program transport stream. Note that Quad 4K is not currently supported. Default is the first program within the transport stream. If the program you specify doesn't exist, the transcoding service will use this default.
    pub fn program_number(mut self, input: i32) -> Self {
        self.program_number = ::std::option::Option::Some(input);
        self
    }
    /// Use Program to select a specific program from within a multi-program transport stream. Note that Quad 4K is not currently supported. Default is the first program within the transport stream. If the program you specify doesn't exist, the transcoding service will use this default.
    pub fn set_program_number(mut self, input: ::std::option::Option<i32>) -> Self {
        self.program_number = input;
        self
    }
    /// Use Program to select a specific program from within a multi-program transport stream. Note that Quad 4K is not currently supported. Default is the first program within the transport stream. If the program you specify doesn't exist, the transcoding service will use this default.
    pub fn get_program_number(&self) -> &::std::option::Option<i32> {
        &self.program_number
    }
    /// Set PSI control for transport stream inputs to specify which data the demux process to scans. * Ignore PSI - Scan all PIDs for audio and video. * Use PSI - Scan only PSI data.
    pub fn psi_control(mut self, input: crate::types::InputPsiControl) -> Self {
        self.psi_control = ::std::option::Option::Some(input);
        self
    }
    /// Set PSI control for transport stream inputs to specify which data the demux process to scans. * Ignore PSI - Scan all PIDs for audio and video. * Use PSI - Scan only PSI data.
    pub fn set_psi_control(mut self, input: ::std::option::Option<crate::types::InputPsiControl>) -> Self {
        self.psi_control = input;
        self
    }
    /// Set PSI control for transport stream inputs to specify which data the demux process to scans. * Ignore PSI - Scan all PIDs for audio and video. * Use PSI - Scan only PSI data.
    pub fn get_psi_control(&self) -> &::std::option::Option<crate::types::InputPsiControl> {
        &self.psi_control
    }
    /// Use this Timecode source setting, located under the input settings, to specify how the service counts input video frames. This input frame count affects only the behavior of features that apply to a single input at a time, such as input clipping and synchronizing some captions formats. Choose Embedded to use the timecodes in your input video. Choose Start at zero to start the first frame at zero. Choose Specified start to start the first frame at the timecode that you specify in the setting Start timecode. If you don't specify a value for Timecode source, the service will use Embedded by default. For more information about timecodes, see https://docs.aws.amazon.com/console/mediaconvert/timecode.
    pub fn timecode_source(mut self, input: crate::types::InputTimecodeSource) -> Self {
        self.timecode_source = ::std::option::Option::Some(input);
        self
    }
    /// Use this Timecode source setting, located under the input settings, to specify how the service counts input video frames. This input frame count affects only the behavior of features that apply to a single input at a time, such as input clipping and synchronizing some captions formats. Choose Embedded to use the timecodes in your input video. Choose Start at zero to start the first frame at zero. Choose Specified start to start the first frame at the timecode that you specify in the setting Start timecode. If you don't specify a value for Timecode source, the service will use Embedded by default. For more information about timecodes, see https://docs.aws.amazon.com/console/mediaconvert/timecode.
    pub fn set_timecode_source(mut self, input: ::std::option::Option<crate::types::InputTimecodeSource>) -> Self {
        self.timecode_source = input;
        self
    }
    /// Use this Timecode source setting, located under the input settings, to specify how the service counts input video frames. This input frame count affects only the behavior of features that apply to a single input at a time, such as input clipping and synchronizing some captions formats. Choose Embedded to use the timecodes in your input video. Choose Start at zero to start the first frame at zero. Choose Specified start to start the first frame at the timecode that you specify in the setting Start timecode. If you don't specify a value for Timecode source, the service will use Embedded by default. For more information about timecodes, see https://docs.aws.amazon.com/console/mediaconvert/timecode.
    pub fn get_timecode_source(&self) -> &::std::option::Option<crate::types::InputTimecodeSource> {
        &self.timecode_source
    }
    /// Specify the timecode that you want the service to use for this input's initial frame. To use this setting, you must set the Timecode source setting, located under the input settings, to Specified start. For more information about timecodes, see https://docs.aws.amazon.com/console/mediaconvert/timecode.
    pub fn timecode_start(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.timecode_start = ::std::option::Option::Some(input.into());
        self
    }
    /// Specify the timecode that you want the service to use for this input's initial frame. To use this setting, you must set the Timecode source setting, located under the input settings, to Specified start. For more information about timecodes, see https://docs.aws.amazon.com/console/mediaconvert/timecode.
    pub fn set_timecode_start(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.timecode_start = input;
        self
    }
    /// Specify the timecode that you want the service to use for this input's initial frame. To use this setting, you must set the Timecode source setting, located under the input settings, to Specified start. For more information about timecodes, see https://docs.aws.amazon.com/console/mediaconvert/timecode.
    pub fn get_timecode_start(&self) -> &::std::option::Option<::std::string::String> {
        &self.timecode_start
    }
    /// Appends an item to `video_overlays`.
    ///
    /// To override the contents of this collection use [`set_video_overlays`](Self::set_video_overlays).
    ///
    /// Contains an array of video overlays.
    pub fn video_overlays(mut self, input: crate::types::VideoOverlay) -> Self {
        let mut v = self.video_overlays.unwrap_or_default();
        v.push(input);
        self.video_overlays = ::std::option::Option::Some(v);
        self
    }
    /// Contains an array of video overlays.
    pub fn set_video_overlays(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::VideoOverlay>>) -> Self {
        self.video_overlays = input;
        self
    }
    /// Contains an array of video overlays.
    pub fn get_video_overlays(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::VideoOverlay>> {
        &self.video_overlays
    }
    /// Input video selectors contain the video settings for the input. Each of your inputs can have up to one video selector.
    pub fn video_selector(mut self, input: crate::types::VideoSelector) -> Self {
        self.video_selector = ::std::option::Option::Some(input);
        self
    }
    /// Input video selectors contain the video settings for the input. Each of your inputs can have up to one video selector.
    pub fn set_video_selector(mut self, input: ::std::option::Option<crate::types::VideoSelector>) -> Self {
        self.video_selector = input;
        self
    }
    /// Input video selectors contain the video settings for the input. Each of your inputs can have up to one video selector.
    pub fn get_video_selector(&self) -> &::std::option::Option<crate::types::VideoSelector> {
        &self.video_selector
    }
    /// Consumes the builder and constructs a [`InputTemplate`](crate::types::InputTemplate).
    pub fn build(self) -> crate::types::InputTemplate {
        crate::types::InputTemplate {
            advanced_input_filter: self.advanced_input_filter,
            advanced_input_filter_settings: self.advanced_input_filter_settings,
            audio_selector_groups: self.audio_selector_groups,
            audio_selectors: self.audio_selectors,
            caption_selectors: self.caption_selectors,
            crop: self.crop,
            deblock_filter: self.deblock_filter,
            denoise_filter: self.denoise_filter,
            dolby_vision_metadata_xml: self.dolby_vision_metadata_xml,
            filter_enable: self.filter_enable,
            filter_strength: self.filter_strength,
            image_inserter: self.image_inserter,
            input_clippings: self.input_clippings,
            input_scan_type: self.input_scan_type,
            position: self.position,
            program_number: self.program_number,
            psi_control: self.psi_control,
            timecode_source: self.timecode_source,
            timecode_start: self.timecode_start,
            video_overlays: self.video_overlays,
            video_selector: self.video_selector,
        }
    }
}
