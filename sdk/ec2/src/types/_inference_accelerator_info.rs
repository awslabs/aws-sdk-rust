// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Describes the Inference accelerators for the instance type.</p>
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct InferenceAcceleratorInfo  {
    /// <p>Describes the Inference accelerators for the instance type.</p>
    pub accelerators: ::std::option::Option<::std::vec::Vec::<crate::types::InferenceDeviceInfo>>,
    /// <p>The total size of the memory for the inference accelerators for the instance type, in MiB.</p>
    pub total_inference_memory_in_mib: ::std::option::Option<i32>,
}
impl  InferenceAcceleratorInfo  {
    /// <p>Describes the Inference accelerators for the instance type.</p>
    /// 
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.accelerators.is_none()`.
    pub fn accelerators(&self) -> & [crate::types::InferenceDeviceInfo] {
        self.accelerators.as_deref()
        .unwrap_or_default()
    }
    /// <p>The total size of the memory for the inference accelerators for the instance type, in MiB.</p>
    pub fn total_inference_memory_in_mib(&self) -> ::std::option::Option<i32> {
        self.total_inference_memory_in_mib
    }
}
impl InferenceAcceleratorInfo {
    /// Creates a new builder-style object to manufacture [`InferenceAcceleratorInfo`](crate::types::InferenceAcceleratorInfo).
    pub fn builder() -> crate::types::builders::InferenceAcceleratorInfoBuilder {
        crate::types::builders::InferenceAcceleratorInfoBuilder::default()
    }
}

/// A builder for [`InferenceAcceleratorInfo`](crate::types::InferenceAcceleratorInfo).
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
pub struct InferenceAcceleratorInfoBuilder {
    pub(crate) accelerators: ::std::option::Option<::std::vec::Vec::<crate::types::InferenceDeviceInfo>>,
    pub(crate) total_inference_memory_in_mib: ::std::option::Option<i32>,
}
impl InferenceAcceleratorInfoBuilder {
    /// Appends an item to `accelerators`.
    ///
    /// To override the contents of this collection use [`set_accelerators`](Self::set_accelerators).
    ///
    /// <p>Describes the Inference accelerators for the instance type.</p>
    pub fn accelerators(mut self, input: crate::types::InferenceDeviceInfo) -> Self {
        let mut v = self.accelerators.unwrap_or_default();
                        v.push(input);
                        self.accelerators = ::std::option::Option::Some(v);
                        self
    }
    /// <p>Describes the Inference accelerators for the instance type.</p>
    pub fn set_accelerators(mut self, input: ::std::option::Option<::std::vec::Vec::<crate::types::InferenceDeviceInfo>>) -> Self {
        self.accelerators = input; self
    }
    /// <p>Describes the Inference accelerators for the instance type.</p>
    pub fn get_accelerators(&self) -> &::std::option::Option<::std::vec::Vec::<crate::types::InferenceDeviceInfo>> {
        &self.accelerators
    }
    /// <p>The total size of the memory for the inference accelerators for the instance type, in MiB.</p>
    pub fn total_inference_memory_in_mib(mut self, input: i32) -> Self {
        self.total_inference_memory_in_mib = ::std::option::Option::Some(input);
        self
    }
    /// <p>The total size of the memory for the inference accelerators for the instance type, in MiB.</p>
    pub fn set_total_inference_memory_in_mib(mut self, input: ::std::option::Option<i32>) -> Self {
        self.total_inference_memory_in_mib = input; self
    }
    /// <p>The total size of the memory for the inference accelerators for the instance type, in MiB.</p>
    pub fn get_total_inference_memory_in_mib(&self) -> &::std::option::Option<i32> {
        &self.total_inference_memory_in_mib
    }
    /// Consumes the builder and constructs a [`InferenceAcceleratorInfo`](crate::types::InferenceAcceleratorInfo).
    pub fn build(self) -> crate::types::InferenceAcceleratorInfo {
        crate::types::InferenceAcceleratorInfo {
            accelerators: self.accelerators
            ,
            total_inference_memory_in_mib: self.total_inference_memory_in_mib
            ,
        }
    }
}

