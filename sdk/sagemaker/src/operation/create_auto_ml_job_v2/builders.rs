// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
pub use crate::operation::create_auto_ml_job_v2::_create_auto_ml_job_v2_output::CreateAutoMlJobV2OutputBuilder;

pub use crate::operation::create_auto_ml_job_v2::_create_auto_ml_job_v2_input::CreateAutoMlJobV2InputBuilder;

impl CreateAutoMlJobV2InputBuilder {
    /// Sends a request with this input using the given client.
    pub async fn send_with(
        self,
        client: &crate::Client,
    ) -> ::std::result::Result<
        crate::operation::create_auto_ml_job_v2::CreateAutoMlJobV2Output,
        ::aws_smithy_runtime_api::client::result::SdkError<
            crate::operation::create_auto_ml_job_v2::CreateAutoMLJobV2Error,
            ::aws_smithy_runtime_api::client::orchestrator::HttpResponse,
        >,
    > {
        let mut fluent_builder = client.create_auto_ml_job_v2();
        fluent_builder.inner = self;
        fluent_builder.send().await
    }
}
/// Fluent builder constructing a request to `CreateAutoMLJobV2`.
///
/// <p>Creates an Autopilot job also referred to as Autopilot experiment or AutoML job V2.</p><note>
/// <p><a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateAutoMLJobV2.html">CreateAutoMLJobV2</a> and <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeAutoMLJobV2.html">DescribeAutoMLJobV2</a> are new versions of <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateAutoMLJob.html">CreateAutoMLJob</a> and <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeAutoMLJob.html">DescribeAutoMLJob</a> which offer backward compatibility.</p>
/// <p><code>CreateAutoMLJobV2</code> can manage tabular problem types identical to those of its previous version <code>CreateAutoMLJob</code>, as well as time-series forecasting, non-tabular problem types such as image or text classification, and text generation (LLMs fine-tuning).</p>
/// <p>Find guidelines about how to migrate a <code>CreateAutoMLJob</code> to <code>CreateAutoMLJobV2</code> in <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development-create-experiment.html#autopilot-create-experiment-api-migrate-v1-v2">Migrate a CreateAutoMLJob to CreateAutoMLJobV2</a>.</p>
/// </note>
/// <p>For the list of available problem types supported by <code>CreateAutoMLJobV2</code>, see <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_AutoMLProblemTypeConfig.html">AutoMLProblemTypeConfig</a>.</p>
/// <p>You can find the best-performing model after you run an AutoML job V2 by calling <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeAutoMLJobV2.html">DescribeAutoMLJobV2</a>.</p>
#[derive(::std::clone::Clone, ::std::fmt::Debug)]
pub struct CreateAutoMLJobV2FluentBuilder {
    handle: ::std::sync::Arc<crate::client::Handle>,
    inner: crate::operation::create_auto_ml_job_v2::builders::CreateAutoMlJobV2InputBuilder,
    config_override: ::std::option::Option<crate::config::Builder>,
}
impl
    crate::client::customize::internal::CustomizableSend<
        crate::operation::create_auto_ml_job_v2::CreateAutoMlJobV2Output,
        crate::operation::create_auto_ml_job_v2::CreateAutoMLJobV2Error,
    > for CreateAutoMLJobV2FluentBuilder
{
    fn send(
        self,
        config_override: crate::config::Builder,
    ) -> crate::client::customize::internal::BoxFuture<
        crate::client::customize::internal::SendResult<
            crate::operation::create_auto_ml_job_v2::CreateAutoMlJobV2Output,
            crate::operation::create_auto_ml_job_v2::CreateAutoMLJobV2Error,
        >,
    > {
        ::std::boxed::Box::pin(async move { self.config_override(config_override).send().await })
    }
}
impl CreateAutoMLJobV2FluentBuilder {
    /// Creates a new `CreateAutoMLJobV2`.
    pub(crate) fn new(handle: ::std::sync::Arc<crate::client::Handle>) -> Self {
        Self {
            handle,
            inner: ::std::default::Default::default(),
            config_override: ::std::option::Option::None,
        }
    }
    /// Access the CreateAutoMLJobV2 as a reference.
    pub fn as_input(&self) -> &crate::operation::create_auto_ml_job_v2::builders::CreateAutoMlJobV2InputBuilder {
        &self.inner
    }
    /// Sends the request and returns the response.
    ///
    /// If an error occurs, an `SdkError` will be returned with additional details that
    /// can be matched against.
    ///
    /// By default, any retryable failures will be retried twice. Retry behavior
    /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
    /// set when configuring the client.
    pub async fn send(
        self,
    ) -> ::std::result::Result<
        crate::operation::create_auto_ml_job_v2::CreateAutoMlJobV2Output,
        ::aws_smithy_runtime_api::client::result::SdkError<
            crate::operation::create_auto_ml_job_v2::CreateAutoMLJobV2Error,
            ::aws_smithy_runtime_api::client::orchestrator::HttpResponse,
        >,
    > {
        let input = self
            .inner
            .build()
            .map_err(::aws_smithy_runtime_api::client::result::SdkError::construction_failure)?;
        let runtime_plugins = crate::operation::create_auto_ml_job_v2::CreateAutoMLJobV2::operation_runtime_plugins(
            self.handle.runtime_plugins.clone(),
            &self.handle.conf,
            self.config_override,
        );
        crate::operation::create_auto_ml_job_v2::CreateAutoMLJobV2::orchestrate(&runtime_plugins, input).await
    }

    /// Consumes this builder, creating a customizable operation that can be modified before being sent.
    pub fn customize(
        self,
    ) -> crate::client::customize::CustomizableOperation<
        crate::operation::create_auto_ml_job_v2::CreateAutoMlJobV2Output,
        crate::operation::create_auto_ml_job_v2::CreateAutoMLJobV2Error,
        Self,
    > {
        crate::client::customize::CustomizableOperation::new(self)
    }
    pub(crate) fn config_override(mut self, config_override: impl Into<crate::config::Builder>) -> Self {
        self.set_config_override(Some(config_override.into()));
        self
    }

    pub(crate) fn set_config_override(&mut self, config_override: Option<crate::config::Builder>) -> &mut Self {
        self.config_override = config_override;
        self
    }
    /// <p>Identifies an Autopilot job. The name must be unique to your account and is case insensitive.</p>
    pub fn auto_ml_job_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.inner = self.inner.auto_ml_job_name(input.into());
        self
    }
    /// <p>Identifies an Autopilot job. The name must be unique to your account and is case insensitive.</p>
    pub fn set_auto_ml_job_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.inner = self.inner.set_auto_ml_job_name(input);
        self
    }
    /// <p>Identifies an Autopilot job. The name must be unique to your account and is case insensitive.</p>
    pub fn get_auto_ml_job_name(&self) -> &::std::option::Option<::std::string::String> {
        self.inner.get_auto_ml_job_name()
    }
    /// Appends an item to `AutoMLJobInputDataConfig`.
    ///
    /// To override the contents of this collection use [`set_auto_ml_job_input_data_config`](Self::set_auto_ml_job_input_data_config).
    ///
    /// <p>An array of channel objects describing the input data and their location. Each channel is a named input source. Similar to the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateAutoMLJob.html#sagemaker-CreateAutoMLJob-request-InputDataConfig">InputDataConfig</a> attribute in the <code>CreateAutoMLJob</code> input parameters. The supported formats depend on the problem type:</p>
    /// <ul>
    /// <li>
    /// <p>For tabular problem types: <code>S3Prefix</code>, <code>ManifestFile</code>.</p></li>
    /// <li>
    /// <p>For image classification: <code>S3Prefix</code>, <code>ManifestFile</code>, <code>AugmentedManifestFile</code>.</p></li>
    /// <li>
    /// <p>For text classification: <code>S3Prefix</code>.</p></li>
    /// <li>
    /// <p>For time-series forecasting: <code>S3Prefix</code>.</p></li>
    /// <li>
    /// <p>For text generation (LLMs fine-tuning): <code>S3Prefix</code>.</p></li>
    /// </ul>
    pub fn auto_ml_job_input_data_config(mut self, input: crate::types::AutoMlJobChannel) -> Self {
        self.inner = self.inner.auto_ml_job_input_data_config(input);
        self
    }
    /// <p>An array of channel objects describing the input data and their location. Each channel is a named input source. Similar to the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateAutoMLJob.html#sagemaker-CreateAutoMLJob-request-InputDataConfig">InputDataConfig</a> attribute in the <code>CreateAutoMLJob</code> input parameters. The supported formats depend on the problem type:</p>
    /// <ul>
    /// <li>
    /// <p>For tabular problem types: <code>S3Prefix</code>, <code>ManifestFile</code>.</p></li>
    /// <li>
    /// <p>For image classification: <code>S3Prefix</code>, <code>ManifestFile</code>, <code>AugmentedManifestFile</code>.</p></li>
    /// <li>
    /// <p>For text classification: <code>S3Prefix</code>.</p></li>
    /// <li>
    /// <p>For time-series forecasting: <code>S3Prefix</code>.</p></li>
    /// <li>
    /// <p>For text generation (LLMs fine-tuning): <code>S3Prefix</code>.</p></li>
    /// </ul>
    pub fn set_auto_ml_job_input_data_config(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::AutoMlJobChannel>>) -> Self {
        self.inner = self.inner.set_auto_ml_job_input_data_config(input);
        self
    }
    /// <p>An array of channel objects describing the input data and their location. Each channel is a named input source. Similar to the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateAutoMLJob.html#sagemaker-CreateAutoMLJob-request-InputDataConfig">InputDataConfig</a> attribute in the <code>CreateAutoMLJob</code> input parameters. The supported formats depend on the problem type:</p>
    /// <ul>
    /// <li>
    /// <p>For tabular problem types: <code>S3Prefix</code>, <code>ManifestFile</code>.</p></li>
    /// <li>
    /// <p>For image classification: <code>S3Prefix</code>, <code>ManifestFile</code>, <code>AugmentedManifestFile</code>.</p></li>
    /// <li>
    /// <p>For text classification: <code>S3Prefix</code>.</p></li>
    /// <li>
    /// <p>For time-series forecasting: <code>S3Prefix</code>.</p></li>
    /// <li>
    /// <p>For text generation (LLMs fine-tuning): <code>S3Prefix</code>.</p></li>
    /// </ul>
    pub fn get_auto_ml_job_input_data_config(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::AutoMlJobChannel>> {
        self.inner.get_auto_ml_job_input_data_config()
    }
    /// <p>Provides information about encryption and the Amazon S3 output path needed to store artifacts from an AutoML job.</p>
    pub fn output_data_config(mut self, input: crate::types::AutoMlOutputDataConfig) -> Self {
        self.inner = self.inner.output_data_config(input);
        self
    }
    /// <p>Provides information about encryption and the Amazon S3 output path needed to store artifacts from an AutoML job.</p>
    pub fn set_output_data_config(mut self, input: ::std::option::Option<crate::types::AutoMlOutputDataConfig>) -> Self {
        self.inner = self.inner.set_output_data_config(input);
        self
    }
    /// <p>Provides information about encryption and the Amazon S3 output path needed to store artifacts from an AutoML job.</p>
    pub fn get_output_data_config(&self) -> &::std::option::Option<crate::types::AutoMlOutputDataConfig> {
        self.inner.get_output_data_config()
    }
    /// <p>Defines the configuration settings of one of the supported problem types.</p>
    pub fn auto_ml_problem_type_config(mut self, input: crate::types::AutoMlProblemTypeConfig) -> Self {
        self.inner = self.inner.auto_ml_problem_type_config(input);
        self
    }
    /// <p>Defines the configuration settings of one of the supported problem types.</p>
    pub fn set_auto_ml_problem_type_config(mut self, input: ::std::option::Option<crate::types::AutoMlProblemTypeConfig>) -> Self {
        self.inner = self.inner.set_auto_ml_problem_type_config(input);
        self
    }
    /// <p>Defines the configuration settings of one of the supported problem types.</p>
    pub fn get_auto_ml_problem_type_config(&self) -> &::std::option::Option<crate::types::AutoMlProblemTypeConfig> {
        self.inner.get_auto_ml_problem_type_config()
    }
    /// <p>The ARN of the role that is used to access the data.</p>
    pub fn role_arn(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.inner = self.inner.role_arn(input.into());
        self
    }
    /// <p>The ARN of the role that is used to access the data.</p>
    pub fn set_role_arn(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.inner = self.inner.set_role_arn(input);
        self
    }
    /// <p>The ARN of the role that is used to access the data.</p>
    pub fn get_role_arn(&self) -> &::std::option::Option<::std::string::String> {
        self.inner.get_role_arn()
    }
    /// Appends an item to `Tags`.
    ///
    /// To override the contents of this collection use [`set_tags`](Self::set_tags).
    ///
    /// <p>An array of key-value pairs. You can use tags to categorize your Amazon Web Services resources in different ways, such as by purpose, owner, or environment. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html">Tagging Amazon Web ServicesResources</a>. Tag keys must be unique per resource.</p>
    pub fn tags(mut self, input: crate::types::Tag) -> Self {
        self.inner = self.inner.tags(input);
        self
    }
    /// <p>An array of key-value pairs. You can use tags to categorize your Amazon Web Services resources in different ways, such as by purpose, owner, or environment. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html">Tagging Amazon Web ServicesResources</a>. Tag keys must be unique per resource.</p>
    pub fn set_tags(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::Tag>>) -> Self {
        self.inner = self.inner.set_tags(input);
        self
    }
    /// <p>An array of key-value pairs. You can use tags to categorize your Amazon Web Services resources in different ways, such as by purpose, owner, or environment. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html">Tagging Amazon Web ServicesResources</a>. Tag keys must be unique per resource.</p>
    pub fn get_tags(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::Tag>> {
        self.inner.get_tags()
    }
    /// <p>The security configuration for traffic encryption or Amazon VPC settings.</p>
    pub fn security_config(mut self, input: crate::types::AutoMlSecurityConfig) -> Self {
        self.inner = self.inner.security_config(input);
        self
    }
    /// <p>The security configuration for traffic encryption or Amazon VPC settings.</p>
    pub fn set_security_config(mut self, input: ::std::option::Option<crate::types::AutoMlSecurityConfig>) -> Self {
        self.inner = self.inner.set_security_config(input);
        self
    }
    /// <p>The security configuration for traffic encryption or Amazon VPC settings.</p>
    pub fn get_security_config(&self) -> &::std::option::Option<crate::types::AutoMlSecurityConfig> {
        self.inner.get_security_config()
    }
    /// <p>Specifies a metric to minimize or maximize as the objective of a job. If not specified, the default objective metric depends on the problem type. For the list of default values per problem type, see <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_AutoMLJobObjective.html">AutoMLJobObjective</a>.</p><note>
    /// <ul>
    /// <li>
    /// <p>For tabular problem types: You must either provide both the <code>AutoMLJobObjective</code> and indicate the type of supervised learning problem in <code>AutoMLProblemTypeConfig</code> (<code>TabularJobConfig.ProblemType</code>), or none at all.</p></li>
    /// <li>
    /// <p>For text generation problem types (LLMs fine-tuning): Fine-tuning language models in Autopilot does not require setting the <code>AutoMLJobObjective</code> field. Autopilot fine-tunes LLMs without requiring multiple candidates to be trained and evaluated. Instead, using your dataset, Autopilot directly fine-tunes your target model to enhance a default objective metric, the cross-entropy loss. After fine-tuning a language model, you can evaluate the quality of its generated text using different metrics. For a list of the available metrics, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-llms-finetuning-metrics.html">Metrics for fine-tuning LLMs in Autopilot</a>.</p></li>
    /// </ul>
    /// </note>
    pub fn auto_ml_job_objective(mut self, input: crate::types::AutoMlJobObjective) -> Self {
        self.inner = self.inner.auto_ml_job_objective(input);
        self
    }
    /// <p>Specifies a metric to minimize or maximize as the objective of a job. If not specified, the default objective metric depends on the problem type. For the list of default values per problem type, see <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_AutoMLJobObjective.html">AutoMLJobObjective</a>.</p><note>
    /// <ul>
    /// <li>
    /// <p>For tabular problem types: You must either provide both the <code>AutoMLJobObjective</code> and indicate the type of supervised learning problem in <code>AutoMLProblemTypeConfig</code> (<code>TabularJobConfig.ProblemType</code>), or none at all.</p></li>
    /// <li>
    /// <p>For text generation problem types (LLMs fine-tuning): Fine-tuning language models in Autopilot does not require setting the <code>AutoMLJobObjective</code> field. Autopilot fine-tunes LLMs without requiring multiple candidates to be trained and evaluated. Instead, using your dataset, Autopilot directly fine-tunes your target model to enhance a default objective metric, the cross-entropy loss. After fine-tuning a language model, you can evaluate the quality of its generated text using different metrics. For a list of the available metrics, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-llms-finetuning-metrics.html">Metrics for fine-tuning LLMs in Autopilot</a>.</p></li>
    /// </ul>
    /// </note>
    pub fn set_auto_ml_job_objective(mut self, input: ::std::option::Option<crate::types::AutoMlJobObjective>) -> Self {
        self.inner = self.inner.set_auto_ml_job_objective(input);
        self
    }
    /// <p>Specifies a metric to minimize or maximize as the objective of a job. If not specified, the default objective metric depends on the problem type. For the list of default values per problem type, see <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_AutoMLJobObjective.html">AutoMLJobObjective</a>.</p><note>
    /// <ul>
    /// <li>
    /// <p>For tabular problem types: You must either provide both the <code>AutoMLJobObjective</code> and indicate the type of supervised learning problem in <code>AutoMLProblemTypeConfig</code> (<code>TabularJobConfig.ProblemType</code>), or none at all.</p></li>
    /// <li>
    /// <p>For text generation problem types (LLMs fine-tuning): Fine-tuning language models in Autopilot does not require setting the <code>AutoMLJobObjective</code> field. Autopilot fine-tunes LLMs without requiring multiple candidates to be trained and evaluated. Instead, using your dataset, Autopilot directly fine-tunes your target model to enhance a default objective metric, the cross-entropy loss. After fine-tuning a language model, you can evaluate the quality of its generated text using different metrics. For a list of the available metrics, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-llms-finetuning-metrics.html">Metrics for fine-tuning LLMs in Autopilot</a>.</p></li>
    /// </ul>
    /// </note>
    pub fn get_auto_ml_job_objective(&self) -> &::std::option::Option<crate::types::AutoMlJobObjective> {
        self.inner.get_auto_ml_job_objective()
    }
    /// <p>Specifies how to generate the endpoint name for an automatic one-click Autopilot model deployment.</p>
    pub fn model_deploy_config(mut self, input: crate::types::ModelDeployConfig) -> Self {
        self.inner = self.inner.model_deploy_config(input);
        self
    }
    /// <p>Specifies how to generate the endpoint name for an automatic one-click Autopilot model deployment.</p>
    pub fn set_model_deploy_config(mut self, input: ::std::option::Option<crate::types::ModelDeployConfig>) -> Self {
        self.inner = self.inner.set_model_deploy_config(input);
        self
    }
    /// <p>Specifies how to generate the endpoint name for an automatic one-click Autopilot model deployment.</p>
    pub fn get_model_deploy_config(&self) -> &::std::option::Option<crate::types::ModelDeployConfig> {
        self.inner.get_model_deploy_config()
    }
    /// <p>This structure specifies how to split the data into train and validation datasets.</p>
    /// <p>The validation and training datasets must contain the same headers. For jobs created by calling <code>CreateAutoMLJob</code>, the validation dataset must be less than 2 GB in size.</p><note>
    /// <p>This attribute must not be set for the time-series forecasting problem type, as Autopilot automatically splits the input dataset into training and validation sets.</p>
    /// </note>
    pub fn data_split_config(mut self, input: crate::types::AutoMlDataSplitConfig) -> Self {
        self.inner = self.inner.data_split_config(input);
        self
    }
    /// <p>This structure specifies how to split the data into train and validation datasets.</p>
    /// <p>The validation and training datasets must contain the same headers. For jobs created by calling <code>CreateAutoMLJob</code>, the validation dataset must be less than 2 GB in size.</p><note>
    /// <p>This attribute must not be set for the time-series forecasting problem type, as Autopilot automatically splits the input dataset into training and validation sets.</p>
    /// </note>
    pub fn set_data_split_config(mut self, input: ::std::option::Option<crate::types::AutoMlDataSplitConfig>) -> Self {
        self.inner = self.inner.set_data_split_config(input);
        self
    }
    /// <p>This structure specifies how to split the data into train and validation datasets.</p>
    /// <p>The validation and training datasets must contain the same headers. For jobs created by calling <code>CreateAutoMLJob</code>, the validation dataset must be less than 2 GB in size.</p><note>
    /// <p>This attribute must not be set for the time-series forecasting problem type, as Autopilot automatically splits the input dataset into training and validation sets.</p>
    /// </note>
    pub fn get_data_split_config(&self) -> &::std::option::Option<crate::types::AutoMlDataSplitConfig> {
        self.inner.get_data_split_config()
    }
}
