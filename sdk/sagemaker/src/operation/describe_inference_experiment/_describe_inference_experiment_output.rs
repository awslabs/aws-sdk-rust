// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeInferenceExperimentOutput  {
    /// <p>The ARN of the inference experiment being described.</p>
    #[doc(hidden)]
    pub arn: std::option::Option<std::string::String>,
    /// <p>The name of the inference experiment.</p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
    /// <p>The type of the inference experiment.</p>
    #[doc(hidden)]
    pub r#type: std::option::Option<crate::types::InferenceExperimentType>,
    /// <p>The duration for which the inference experiment ran or will run.</p>
    #[doc(hidden)]
    pub schedule: std::option::Option<crate::types::InferenceExperimentSchedule>,
    /// <p> The status of the inference experiment. The following are the possible statuses for an inference experiment: </p> 
    /// <ul> 
    /// <li> <p> <code>Creating</code> - Amazon SageMaker is creating your experiment. </p> </li> 
    /// <li> <p> <code>Created</code> - Amazon SageMaker has finished the creation of your experiment and will begin the experiment at the scheduled time. </p> </li> 
    /// <li> <p> <code>Updating</code> - When you make changes to your experiment, your experiment shows as updating. </p> </li> 
    /// <li> <p> <code>Starting</code> - Amazon SageMaker is beginning your experiment. </p> </li> 
    /// <li> <p> <code>Running</code> - Your experiment is in progress. </p> </li> 
    /// <li> <p> <code>Stopping</code> - Amazon SageMaker is stopping your experiment. </p> </li> 
    /// <li> <p> <code>Completed</code> - Your experiment has completed. </p> </li> 
    /// <li> <p> <code>Cancelled</code> - When you conclude your experiment early using the <code>StopInferenceExperiment</code> API, or if any operation fails with an unexpected error, it shows as cancelled. </p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub status: std::option::Option<crate::types::InferenceExperimentStatus>,
    /// <p> The error message or client-specified <code>Reason</code> from the <code>StopInferenceExperiment</code> API, that explains the status of the inference experiment. </p>
    #[doc(hidden)]
    pub status_reason: std::option::Option<std::string::String>,
    /// <p>The description of the inference experiment.</p>
    #[doc(hidden)]
    pub description: std::option::Option<std::string::String>,
    /// <p>The timestamp at which you created the inference experiment.</p>
    #[doc(hidden)]
    pub creation_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> The timestamp at which the inference experiment was completed. </p>
    #[doc(hidden)]
    pub completion_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The timestamp at which you last modified the inference experiment.</p>
    #[doc(hidden)]
    pub last_modified_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p> The ARN of the IAM role that Amazon SageMaker can assume to access model artifacts and container images, and manage Amazon SageMaker Inference endpoints for model deployment. </p>
    #[doc(hidden)]
    pub role_arn: std::option::Option<std::string::String>,
    /// <p>The metadata of the endpoint on which the inference experiment ran.</p>
    #[doc(hidden)]
    pub endpoint_metadata: std::option::Option<crate::types::EndpointMetadata>,
    /// <p> An array of <code>ModelVariantConfigSummary</code> objects. There is one for each variant in the inference experiment. Each <code>ModelVariantConfigSummary</code> object in the array describes the infrastructure configuration for deploying the corresponding variant. </p>
    #[doc(hidden)]
    pub model_variants: std::option::Option<std::vec::Vec<crate::types::ModelVariantConfigSummary>>,
    /// <p>The Amazon S3 location and configuration for storing inference request and response data.</p>
    #[doc(hidden)]
    pub data_storage_config: std::option::Option<crate::types::InferenceExperimentDataStorageConfig>,
    /// <p> The configuration of <code>ShadowMode</code> inference experiment type, which shows the production variant that takes all the inference requests, and the shadow variant to which Amazon SageMaker replicates a percentage of the inference requests. For the shadow variant it also shows the percentage of requests that Amazon SageMaker replicates. </p>
    #[doc(hidden)]
    pub shadow_mode_config: std::option::Option<crate::types::ShadowModeConfig>,
    /// <p> The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that Amazon SageMaker uses to encrypt data on the storage volume attached to the ML compute instance that hosts the endpoint. For more information, see <code>CreateInferenceExperimentRequest$KmsKey</code>. </p>
    #[doc(hidden)]
    pub kms_key: std::option::Option<std::string::String>,
    _request_id: Option<String>,
}
impl DescribeInferenceExperimentOutput {
    /// <p>The ARN of the inference experiment being described.</p>
    pub fn arn(&self) -> std::option::Option<& str> {
        self.arn.as_deref()
    }
    /// <p>The name of the inference experiment.</p>
    pub fn name(&self) -> std::option::Option<& str> {
        self.name.as_deref()
    }
    /// <p>The type of the inference experiment.</p>
    pub fn r#type(&self) -> std::option::Option<& crate::types::InferenceExperimentType> {
        self.r#type.as_ref()
    }
    /// <p>The duration for which the inference experiment ran or will run.</p>
    pub fn schedule(&self) -> std::option::Option<& crate::types::InferenceExperimentSchedule> {
        self.schedule.as_ref()
    }
    /// <p> The status of the inference experiment. The following are the possible statuses for an inference experiment: </p> 
    /// <ul> 
    /// <li> <p> <code>Creating</code> - Amazon SageMaker is creating your experiment. </p> </li> 
    /// <li> <p> <code>Created</code> - Amazon SageMaker has finished the creation of your experiment and will begin the experiment at the scheduled time. </p> </li> 
    /// <li> <p> <code>Updating</code> - When you make changes to your experiment, your experiment shows as updating. </p> </li> 
    /// <li> <p> <code>Starting</code> - Amazon SageMaker is beginning your experiment. </p> </li> 
    /// <li> <p> <code>Running</code> - Your experiment is in progress. </p> </li> 
    /// <li> <p> <code>Stopping</code> - Amazon SageMaker is stopping your experiment. </p> </li> 
    /// <li> <p> <code>Completed</code> - Your experiment has completed. </p> </li> 
    /// <li> <p> <code>Cancelled</code> - When you conclude your experiment early using the <code>StopInferenceExperiment</code> API, or if any operation fails with an unexpected error, it shows as cancelled. </p> </li> 
    /// </ul>
    pub fn status(&self) -> std::option::Option<& crate::types::InferenceExperimentStatus> {
        self.status.as_ref()
    }
    /// <p> The error message or client-specified <code>Reason</code> from the <code>StopInferenceExperiment</code> API, that explains the status of the inference experiment. </p>
    pub fn status_reason(&self) -> std::option::Option<& str> {
        self.status_reason.as_deref()
    }
    /// <p>The description of the inference experiment.</p>
    pub fn description(&self) -> std::option::Option<& str> {
        self.description.as_deref()
    }
    /// <p>The timestamp at which you created the inference experiment.</p>
    pub fn creation_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.creation_time.as_ref()
    }
    /// <p> The timestamp at which the inference experiment was completed. </p>
    pub fn completion_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.completion_time.as_ref()
    }
    /// <p>The timestamp at which you last modified the inference experiment.</p>
    pub fn last_modified_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.last_modified_time.as_ref()
    }
    /// <p> The ARN of the IAM role that Amazon SageMaker can assume to access model artifacts and container images, and manage Amazon SageMaker Inference endpoints for model deployment. </p>
    pub fn role_arn(&self) -> std::option::Option<& str> {
        self.role_arn.as_deref()
    }
    /// <p>The metadata of the endpoint on which the inference experiment ran.</p>
    pub fn endpoint_metadata(&self) -> std::option::Option<& crate::types::EndpointMetadata> {
        self.endpoint_metadata.as_ref()
    }
    /// <p> An array of <code>ModelVariantConfigSummary</code> objects. There is one for each variant in the inference experiment. Each <code>ModelVariantConfigSummary</code> object in the array describes the infrastructure configuration for deploying the corresponding variant. </p>
    pub fn model_variants(&self) -> std::option::Option<& [crate::types::ModelVariantConfigSummary]> {
        self.model_variants.as_deref()
    }
    /// <p>The Amazon S3 location and configuration for storing inference request and response data.</p>
    pub fn data_storage_config(&self) -> std::option::Option<& crate::types::InferenceExperimentDataStorageConfig> {
        self.data_storage_config.as_ref()
    }
    /// <p> The configuration of <code>ShadowMode</code> inference experiment type, which shows the production variant that takes all the inference requests, and the shadow variant to which Amazon SageMaker replicates a percentage of the inference requests. For the shadow variant it also shows the percentage of requests that Amazon SageMaker replicates. </p>
    pub fn shadow_mode_config(&self) -> std::option::Option<& crate::types::ShadowModeConfig> {
        self.shadow_mode_config.as_ref()
    }
    /// <p> The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that Amazon SageMaker uses to encrypt data on the storage volume attached to the ML compute instance that hosts the endpoint. For more information, see <code>CreateInferenceExperimentRequest$KmsKey</code>. </p>
    pub fn kms_key(&self) -> std::option::Option<& str> {
        self.kms_key.as_deref()
    }
}
impl aws_http::request_id::RequestId for DescribeInferenceExperimentOutput {
                                fn request_id(&self) -> Option<&str> {
                                    self._request_id.as_deref()
                                }
                            }
impl DescribeInferenceExperimentOutput {
    /// Creates a new builder-style object to manufacture [`DescribeInferenceExperimentOutput`](crate::operation::describe_inference_experiment::DescribeInferenceExperimentOutput).
    pub fn builder() -> crate::operation::describe_inference_experiment::builders::DescribeInferenceExperimentOutputBuilder {
        crate::operation::describe_inference_experiment::builders::DescribeInferenceExperimentOutputBuilder::default()
    }
}

/// A builder for [`DescribeInferenceExperimentOutput`](crate::operation::describe_inference_experiment::DescribeInferenceExperimentOutput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct DescribeInferenceExperimentOutputBuilder {
    pub(crate) arn: std::option::Option<std::string::String>,
    pub(crate) name: std::option::Option<std::string::String>,
    pub(crate) r#type: std::option::Option<crate::types::InferenceExperimentType>,
    pub(crate) schedule: std::option::Option<crate::types::InferenceExperimentSchedule>,
    pub(crate) status: std::option::Option<crate::types::InferenceExperimentStatus>,
    pub(crate) status_reason: std::option::Option<std::string::String>,
    pub(crate) description: std::option::Option<std::string::String>,
    pub(crate) creation_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) completion_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) last_modified_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) role_arn: std::option::Option<std::string::String>,
    pub(crate) endpoint_metadata: std::option::Option<crate::types::EndpointMetadata>,
    pub(crate) model_variants: std::option::Option<std::vec::Vec<crate::types::ModelVariantConfigSummary>>,
    pub(crate) data_storage_config: std::option::Option<crate::types::InferenceExperimentDataStorageConfig>,
    pub(crate) shadow_mode_config: std::option::Option<crate::types::ShadowModeConfig>,
    pub(crate) kms_key: std::option::Option<std::string::String>,
    _request_id: Option<String>,
}
impl DescribeInferenceExperimentOutputBuilder {
    /// <p>The ARN of the inference experiment being described.</p>
    pub fn arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.arn = Some(input.into());
        self
    }
    /// <p>The ARN of the inference experiment being described.</p>
    pub fn set_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.arn = input; self
    }
    /// <p>The name of the inference experiment.</p>
    pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
        self.name = Some(input.into());
        self
    }
    /// <p>The name of the inference experiment.</p>
    pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.name = input; self
    }
    /// <p>The type of the inference experiment.</p>
    pub fn r#type(mut self, input: crate::types::InferenceExperimentType) -> Self {
        self.r#type = Some(input);
        self
    }
    /// <p>The type of the inference experiment.</p>
    pub fn set_type(mut self, input: std::option::Option<crate::types::InferenceExperimentType>) -> Self {
        self.r#type = input; self
    }
    /// <p>The duration for which the inference experiment ran or will run.</p>
    pub fn schedule(mut self, input: crate::types::InferenceExperimentSchedule) -> Self {
        self.schedule = Some(input);
        self
    }
    /// <p>The duration for which the inference experiment ran or will run.</p>
    pub fn set_schedule(mut self, input: std::option::Option<crate::types::InferenceExperimentSchedule>) -> Self {
        self.schedule = input; self
    }
    /// <p> The status of the inference experiment. The following are the possible statuses for an inference experiment: </p> 
    /// <ul> 
    /// <li> <p> <code>Creating</code> - Amazon SageMaker is creating your experiment. </p> </li> 
    /// <li> <p> <code>Created</code> - Amazon SageMaker has finished the creation of your experiment and will begin the experiment at the scheduled time. </p> </li> 
    /// <li> <p> <code>Updating</code> - When you make changes to your experiment, your experiment shows as updating. </p> </li> 
    /// <li> <p> <code>Starting</code> - Amazon SageMaker is beginning your experiment. </p> </li> 
    /// <li> <p> <code>Running</code> - Your experiment is in progress. </p> </li> 
    /// <li> <p> <code>Stopping</code> - Amazon SageMaker is stopping your experiment. </p> </li> 
    /// <li> <p> <code>Completed</code> - Your experiment has completed. </p> </li> 
    /// <li> <p> <code>Cancelled</code> - When you conclude your experiment early using the <code>StopInferenceExperiment</code> API, or if any operation fails with an unexpected error, it shows as cancelled. </p> </li> 
    /// </ul>
    pub fn status(mut self, input: crate::types::InferenceExperimentStatus) -> Self {
        self.status = Some(input);
        self
    }
    /// <p> The status of the inference experiment. The following are the possible statuses for an inference experiment: </p> 
    /// <ul> 
    /// <li> <p> <code>Creating</code> - Amazon SageMaker is creating your experiment. </p> </li> 
    /// <li> <p> <code>Created</code> - Amazon SageMaker has finished the creation of your experiment and will begin the experiment at the scheduled time. </p> </li> 
    /// <li> <p> <code>Updating</code> - When you make changes to your experiment, your experiment shows as updating. </p> </li> 
    /// <li> <p> <code>Starting</code> - Amazon SageMaker is beginning your experiment. </p> </li> 
    /// <li> <p> <code>Running</code> - Your experiment is in progress. </p> </li> 
    /// <li> <p> <code>Stopping</code> - Amazon SageMaker is stopping your experiment. </p> </li> 
    /// <li> <p> <code>Completed</code> - Your experiment has completed. </p> </li> 
    /// <li> <p> <code>Cancelled</code> - When you conclude your experiment early using the <code>StopInferenceExperiment</code> API, or if any operation fails with an unexpected error, it shows as cancelled. </p> </li> 
    /// </ul>
    pub fn set_status(mut self, input: std::option::Option<crate::types::InferenceExperimentStatus>) -> Self {
        self.status = input; self
    }
    /// <p> The error message or client-specified <code>Reason</code> from the <code>StopInferenceExperiment</code> API, that explains the status of the inference experiment. </p>
    pub fn status_reason(mut self, input: impl Into<std::string::String>) -> Self {
        self.status_reason = Some(input.into());
        self
    }
    /// <p> The error message or client-specified <code>Reason</code> from the <code>StopInferenceExperiment</code> API, that explains the status of the inference experiment. </p>
    pub fn set_status_reason(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.status_reason = input; self
    }
    /// <p>The description of the inference experiment.</p>
    pub fn description(mut self, input: impl Into<std::string::String>) -> Self {
        self.description = Some(input.into());
        self
    }
    /// <p>The description of the inference experiment.</p>
    pub fn set_description(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.description = input; self
    }
    /// <p>The timestamp at which you created the inference experiment.</p>
    pub fn creation_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.creation_time = Some(input);
        self
    }
    /// <p>The timestamp at which you created the inference experiment.</p>
    pub fn set_creation_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.creation_time = input; self
    }
    /// <p> The timestamp at which the inference experiment was completed. </p>
    pub fn completion_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.completion_time = Some(input);
        self
    }
    /// <p> The timestamp at which the inference experiment was completed. </p>
    pub fn set_completion_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.completion_time = input; self
    }
    /// <p>The timestamp at which you last modified the inference experiment.</p>
    pub fn last_modified_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.last_modified_time = Some(input);
        self
    }
    /// <p>The timestamp at which you last modified the inference experiment.</p>
    pub fn set_last_modified_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.last_modified_time = input; self
    }
    /// <p> The ARN of the IAM role that Amazon SageMaker can assume to access model artifacts and container images, and manage Amazon SageMaker Inference endpoints for model deployment. </p>
    pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.role_arn = Some(input.into());
        self
    }
    /// <p> The ARN of the IAM role that Amazon SageMaker can assume to access model artifacts and container images, and manage Amazon SageMaker Inference endpoints for model deployment. </p>
    pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.role_arn = input; self
    }
    /// <p>The metadata of the endpoint on which the inference experiment ran.</p>
    pub fn endpoint_metadata(mut self, input: crate::types::EndpointMetadata) -> Self {
        self.endpoint_metadata = Some(input);
        self
    }
    /// <p>The metadata of the endpoint on which the inference experiment ran.</p>
    pub fn set_endpoint_metadata(mut self, input: std::option::Option<crate::types::EndpointMetadata>) -> Self {
        self.endpoint_metadata = input; self
    }
    /// Appends an item to `model_variants`.
    ///
    /// To override the contents of this collection use [`set_model_variants`](Self::set_model_variants).
    ///
    /// <p> An array of <code>ModelVariantConfigSummary</code> objects. There is one for each variant in the inference experiment. Each <code>ModelVariantConfigSummary</code> object in the array describes the infrastructure configuration for deploying the corresponding variant. </p>
    pub fn model_variants(mut self, input: crate::types::ModelVariantConfigSummary) -> Self {
        let mut v = self.model_variants.unwrap_or_default();
                        v.push(input);
                        self.model_variants = Some(v);
                        self
    }
    /// <p> An array of <code>ModelVariantConfigSummary</code> objects. There is one for each variant in the inference experiment. Each <code>ModelVariantConfigSummary</code> object in the array describes the infrastructure configuration for deploying the corresponding variant. </p>
    pub fn set_model_variants(mut self, input: std::option::Option<std::vec::Vec<crate::types::ModelVariantConfigSummary>>) -> Self {
        self.model_variants = input; self
    }
    /// <p>The Amazon S3 location and configuration for storing inference request and response data.</p>
    pub fn data_storage_config(mut self, input: crate::types::InferenceExperimentDataStorageConfig) -> Self {
        self.data_storage_config = Some(input);
        self
    }
    /// <p>The Amazon S3 location and configuration for storing inference request and response data.</p>
    pub fn set_data_storage_config(mut self, input: std::option::Option<crate::types::InferenceExperimentDataStorageConfig>) -> Self {
        self.data_storage_config = input; self
    }
    /// <p> The configuration of <code>ShadowMode</code> inference experiment type, which shows the production variant that takes all the inference requests, and the shadow variant to which Amazon SageMaker replicates a percentage of the inference requests. For the shadow variant it also shows the percentage of requests that Amazon SageMaker replicates. </p>
    pub fn shadow_mode_config(mut self, input: crate::types::ShadowModeConfig) -> Self {
        self.shadow_mode_config = Some(input);
        self
    }
    /// <p> The configuration of <code>ShadowMode</code> inference experiment type, which shows the production variant that takes all the inference requests, and the shadow variant to which Amazon SageMaker replicates a percentage of the inference requests. For the shadow variant it also shows the percentage of requests that Amazon SageMaker replicates. </p>
    pub fn set_shadow_mode_config(mut self, input: std::option::Option<crate::types::ShadowModeConfig>) -> Self {
        self.shadow_mode_config = input; self
    }
    /// <p> The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that Amazon SageMaker uses to encrypt data on the storage volume attached to the ML compute instance that hosts the endpoint. For more information, see <code>CreateInferenceExperimentRequest$KmsKey</code>. </p>
    pub fn kms_key(mut self, input: impl Into<std::string::String>) -> Self {
        self.kms_key = Some(input.into());
        self
    }
    /// <p> The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that Amazon SageMaker uses to encrypt data on the storage volume attached to the ML compute instance that hosts the endpoint. For more information, see <code>CreateInferenceExperimentRequest$KmsKey</code>. </p>
    pub fn set_kms_key(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.kms_key = input; self
    }
    pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
                                    self._request_id = Some(request_id.into());
                                    self
                                }
    
                                pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
                                    self._request_id = request_id;
                                    self
                                }
    /// Consumes the builder and constructs a [`DescribeInferenceExperimentOutput`](crate::operation::describe_inference_experiment::DescribeInferenceExperimentOutput).
    pub fn build(self) -> crate::operation::describe_inference_experiment::DescribeInferenceExperimentOutput {
        crate::operation::describe_inference_experiment::DescribeInferenceExperimentOutput {
            arn: self.arn
            ,
            name: self.name
            ,
            r#type: self.r#type
            ,
            schedule: self.schedule
            ,
            status: self.status
            ,
            status_reason: self.status_reason
            ,
            description: self.description
            ,
            creation_time: self.creation_time
            ,
            completion_time: self.completion_time
            ,
            last_modified_time: self.last_modified_time
            ,
            role_arn: self.role_arn
            ,
            endpoint_metadata: self.endpoint_metadata
            ,
            model_variants: self.model_variants
            ,
            data_storage_config: self.data_storage_config
            ,
            shadow_mode_config: self.shadow_mode_config
            ,
            kms_key: self.kms_key
            ,
            _request_id: self._request_id,
        }
    }
}

