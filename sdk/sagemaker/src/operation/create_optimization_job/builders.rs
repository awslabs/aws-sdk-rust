// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
pub use crate::operation::create_optimization_job::_create_optimization_job_output::CreateOptimizationJobOutputBuilder;

pub use crate::operation::create_optimization_job::_create_optimization_job_input::CreateOptimizationJobInputBuilder;

impl crate::operation::create_optimization_job::builders::CreateOptimizationJobInputBuilder {
    /// Sends a request with this input using the given client.
    pub async fn send_with(
        self,
        client: &crate::Client,
    ) -> ::std::result::Result<
        crate::operation::create_optimization_job::CreateOptimizationJobOutput,
        ::aws_smithy_runtime_api::client::result::SdkError<
            crate::operation::create_optimization_job::CreateOptimizationJobError,
            ::aws_smithy_runtime_api::client::orchestrator::HttpResponse,
        >,
    > {
        let mut fluent_builder = client.create_optimization_job();
        fluent_builder.inner = self;
        fluent_builder.send().await
    }
}
/// Fluent builder constructing a request to `CreateOptimizationJob`.
///
/// <p>Creates a job that optimizes a model for inference performance. To create the job, you provide the location of a source model, and you provide the settings for the optimization techniques that you want the job to apply. When the job completes successfully, SageMaker uploads the new optimized model to the output destination that you specify.</p>
/// <p>For more information about how to use this action, and about the supported optimization techniques, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-optimize.html">Optimize model inference with Amazon SageMaker</a>.</p>
#[derive(::std::clone::Clone, ::std::fmt::Debug)]
pub struct CreateOptimizationJobFluentBuilder {
    handle: ::std::sync::Arc<crate::client::Handle>,
    inner: crate::operation::create_optimization_job::builders::CreateOptimizationJobInputBuilder,
    config_override: ::std::option::Option<crate::config::Builder>,
}
impl
    crate::client::customize::internal::CustomizableSend<
        crate::operation::create_optimization_job::CreateOptimizationJobOutput,
        crate::operation::create_optimization_job::CreateOptimizationJobError,
    > for CreateOptimizationJobFluentBuilder
{
    fn send(
        self,
        config_override: crate::config::Builder,
    ) -> crate::client::customize::internal::BoxFuture<
        crate::client::customize::internal::SendResult<
            crate::operation::create_optimization_job::CreateOptimizationJobOutput,
            crate::operation::create_optimization_job::CreateOptimizationJobError,
        >,
    > {
        ::std::boxed::Box::pin(async move { self.config_override(config_override).send().await })
    }
}
impl CreateOptimizationJobFluentBuilder {
    /// Creates a new `CreateOptimizationJobFluentBuilder`.
    pub(crate) fn new(handle: ::std::sync::Arc<crate::client::Handle>) -> Self {
        Self {
            handle,
            inner: ::std::default::Default::default(),
            config_override: ::std::option::Option::None,
        }
    }
    /// Access the CreateOptimizationJob as a reference.
    pub fn as_input(&self) -> &crate::operation::create_optimization_job::builders::CreateOptimizationJobInputBuilder {
        &self.inner
    }
    /// Sends the request and returns the response.
    ///
    /// If an error occurs, an `SdkError` will be returned with additional details that
    /// can be matched against.
    ///
    /// By default, any retryable failures will be retried twice. Retry behavior
    /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
    /// set when configuring the client.
    pub async fn send(
        self,
    ) -> ::std::result::Result<
        crate::operation::create_optimization_job::CreateOptimizationJobOutput,
        ::aws_smithy_runtime_api::client::result::SdkError<
            crate::operation::create_optimization_job::CreateOptimizationJobError,
            ::aws_smithy_runtime_api::client::orchestrator::HttpResponse,
        >,
    > {
        let input = self
            .inner
            .build()
            .map_err(::aws_smithy_runtime_api::client::result::SdkError::construction_failure)?;
        let runtime_plugins = crate::operation::create_optimization_job::CreateOptimizationJob::operation_runtime_plugins(
            self.handle.runtime_plugins.clone(),
            &self.handle.conf,
            self.config_override,
        );
        crate::operation::create_optimization_job::CreateOptimizationJob::orchestrate(&runtime_plugins, input).await
    }

    /// Consumes this builder, creating a customizable operation that can be modified before being sent.
    pub fn customize(
        self,
    ) -> crate::client::customize::CustomizableOperation<
        crate::operation::create_optimization_job::CreateOptimizationJobOutput,
        crate::operation::create_optimization_job::CreateOptimizationJobError,
        Self,
    > {
        crate::client::customize::CustomizableOperation::new(self)
    }
    pub(crate) fn config_override(mut self, config_override: impl ::std::convert::Into<crate::config::Builder>) -> Self {
        self.set_config_override(::std::option::Option::Some(config_override.into()));
        self
    }

    pub(crate) fn set_config_override(&mut self, config_override: ::std::option::Option<crate::config::Builder>) -> &mut Self {
        self.config_override = config_override;
        self
    }
    /// <p>A custom name for the new optimization job.</p>
    pub fn optimization_job_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.inner = self.inner.optimization_job_name(input.into());
        self
    }
    /// <p>A custom name for the new optimization job.</p>
    pub fn set_optimization_job_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.inner = self.inner.set_optimization_job_name(input);
        self
    }
    /// <p>A custom name for the new optimization job.</p>
    pub fn get_optimization_job_name(&self) -> &::std::option::Option<::std::string::String> {
        self.inner.get_optimization_job_name()
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role that enables Amazon SageMaker AI to perform tasks on your behalf.</p>
    /// <p>During model optimization, Amazon SageMaker AI needs your permission to:</p>
    /// <ul>
    /// <li>
    /// <p>Read input data from an S3 bucket</p></li>
    /// <li>
    /// <p>Write model artifacts to an S3 bucket</p></li>
    /// <li>
    /// <p>Write logs to Amazon CloudWatch Logs</p></li>
    /// <li>
    /// <p>Publish metrics to Amazon CloudWatch</p></li>
    /// </ul>
    /// <p>You grant permissions for all of these tasks to an IAM role. To pass this role to Amazon SageMaker AI, the caller of this API must have the <code>iam:PassRole</code> permission. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html">Amazon SageMaker AI Roles.</a></p>
    pub fn role_arn(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.inner = self.inner.role_arn(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role that enables Amazon SageMaker AI to perform tasks on your behalf.</p>
    /// <p>During model optimization, Amazon SageMaker AI needs your permission to:</p>
    /// <ul>
    /// <li>
    /// <p>Read input data from an S3 bucket</p></li>
    /// <li>
    /// <p>Write model artifacts to an S3 bucket</p></li>
    /// <li>
    /// <p>Write logs to Amazon CloudWatch Logs</p></li>
    /// <li>
    /// <p>Publish metrics to Amazon CloudWatch</p></li>
    /// </ul>
    /// <p>You grant permissions for all of these tasks to an IAM role. To pass this role to Amazon SageMaker AI, the caller of this API must have the <code>iam:PassRole</code> permission. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html">Amazon SageMaker AI Roles.</a></p>
    pub fn set_role_arn(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.inner = self.inner.set_role_arn(input);
        self
    }
    /// <p>The Amazon Resource Name (ARN) of an IAM role that enables Amazon SageMaker AI to perform tasks on your behalf.</p>
    /// <p>During model optimization, Amazon SageMaker AI needs your permission to:</p>
    /// <ul>
    /// <li>
    /// <p>Read input data from an S3 bucket</p></li>
    /// <li>
    /// <p>Write model artifacts to an S3 bucket</p></li>
    /// <li>
    /// <p>Write logs to Amazon CloudWatch Logs</p></li>
    /// <li>
    /// <p>Publish metrics to Amazon CloudWatch</p></li>
    /// </ul>
    /// <p>You grant permissions for all of these tasks to an IAM role. To pass this role to Amazon SageMaker AI, the caller of this API must have the <code>iam:PassRole</code> permission. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html">Amazon SageMaker AI Roles.</a></p>
    pub fn get_role_arn(&self) -> &::std::option::Option<::std::string::String> {
        self.inner.get_role_arn()
    }
    /// <p>The location of the source model to optimize with an optimization job.</p>
    pub fn model_source(mut self, input: crate::types::OptimizationJobModelSource) -> Self {
        self.inner = self.inner.model_source(input);
        self
    }
    /// <p>The location of the source model to optimize with an optimization job.</p>
    pub fn set_model_source(mut self, input: ::std::option::Option<crate::types::OptimizationJobModelSource>) -> Self {
        self.inner = self.inner.set_model_source(input);
        self
    }
    /// <p>The location of the source model to optimize with an optimization job.</p>
    pub fn get_model_source(&self) -> &::std::option::Option<crate::types::OptimizationJobModelSource> {
        self.inner.get_model_source()
    }
    /// <p>The type of instance that hosts the optimized model that you create with the optimization job.</p>
    pub fn deployment_instance_type(mut self, input: crate::types::OptimizationJobDeploymentInstanceType) -> Self {
        self.inner = self.inner.deployment_instance_type(input);
        self
    }
    /// <p>The type of instance that hosts the optimized model that you create with the optimization job.</p>
    pub fn set_deployment_instance_type(mut self, input: ::std::option::Option<crate::types::OptimizationJobDeploymentInstanceType>) -> Self {
        self.inner = self.inner.set_deployment_instance_type(input);
        self
    }
    /// <p>The type of instance that hosts the optimized model that you create with the optimization job.</p>
    pub fn get_deployment_instance_type(&self) -> &::std::option::Option<crate::types::OptimizationJobDeploymentInstanceType> {
        self.inner.get_deployment_instance_type()
    }
    /// <p>The maximum number of instances to use for the optimization job.</p>
    pub fn max_instance_count(mut self, input: i32) -> Self {
        self.inner = self.inner.max_instance_count(input);
        self
    }
    /// <p>The maximum number of instances to use for the optimization job.</p>
    pub fn set_max_instance_count(mut self, input: ::std::option::Option<i32>) -> Self {
        self.inner = self.inner.set_max_instance_count(input);
        self
    }
    /// <p>The maximum number of instances to use for the optimization job.</p>
    pub fn get_max_instance_count(&self) -> &::std::option::Option<i32> {
        self.inner.get_max_instance_count()
    }
    ///
    /// Adds a key-value pair to `OptimizationEnvironment`.
    ///
    /// To override the contents of this collection use [`set_optimization_environment`](Self::set_optimization_environment).
    ///
    /// <p>The environment variables to set in the model container.</p>
    pub fn optimization_environment(
        mut self,
        k: impl ::std::convert::Into<::std::string::String>,
        v: impl ::std::convert::Into<::std::string::String>,
    ) -> Self {
        self.inner = self.inner.optimization_environment(k.into(), v.into());
        self
    }
    /// <p>The environment variables to set in the model container.</p>
    pub fn set_optimization_environment(
        mut self,
        input: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    ) -> Self {
        self.inner = self.inner.set_optimization_environment(input);
        self
    }
    /// <p>The environment variables to set in the model container.</p>
    pub fn get_optimization_environment(&self) -> &::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>> {
        self.inner.get_optimization_environment()
    }
    ///
    /// Appends an item to `OptimizationConfigs`.
    ///
    /// To override the contents of this collection use [`set_optimization_configs`](Self::set_optimization_configs).
    ///
    /// <p>Settings for each of the optimization techniques that the job applies.</p>
    pub fn optimization_configs(mut self, input: crate::types::OptimizationConfig) -> Self {
        self.inner = self.inner.optimization_configs(input);
        self
    }
    /// <p>Settings for each of the optimization techniques that the job applies.</p>
    pub fn set_optimization_configs(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::OptimizationConfig>>) -> Self {
        self.inner = self.inner.set_optimization_configs(input);
        self
    }
    /// <p>Settings for each of the optimization techniques that the job applies.</p>
    pub fn get_optimization_configs(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::OptimizationConfig>> {
        self.inner.get_optimization_configs()
    }
    /// <p>Details for where to store the optimized model that you create with the optimization job.</p>
    pub fn output_config(mut self, input: crate::types::OptimizationJobOutputConfig) -> Self {
        self.inner = self.inner.output_config(input);
        self
    }
    /// <p>Details for where to store the optimized model that you create with the optimization job.</p>
    pub fn set_output_config(mut self, input: ::std::option::Option<crate::types::OptimizationJobOutputConfig>) -> Self {
        self.inner = self.inner.set_output_config(input);
        self
    }
    /// <p>Details for where to store the optimized model that you create with the optimization job.</p>
    pub fn get_output_config(&self) -> &::std::option::Option<crate::types::OptimizationJobOutputConfig> {
        self.inner.get_output_config()
    }
    /// <p>Specifies a limit to how long a job can run. When the job reaches the time limit, SageMaker ends the job. Use this API to cap costs.</p>
    /// <p>To stop a training job, SageMaker sends the algorithm the <code>SIGTERM</code> signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts, so the results of training are not lost.</p>
    /// <p>The training algorithms provided by SageMaker automatically save the intermediate results of a model training job when possible. This attempt to save artifacts is only a best effort case as model might not be in a state from which it can be saved. For example, if training has just started, the model might not be ready to save. When saved, this intermediate data is a valid model artifact. You can use it to create a model with <code>CreateModel</code>.</p><note>
    /// <p>The Neural Topic Model (NTM) currently does not support saving intermediate model artifacts. When training NTMs, make sure that the maximum runtime is sufficient for the training job to complete.</p>
    /// </note>
    pub fn stopping_condition(mut self, input: crate::types::StoppingCondition) -> Self {
        self.inner = self.inner.stopping_condition(input);
        self
    }
    /// <p>Specifies a limit to how long a job can run. When the job reaches the time limit, SageMaker ends the job. Use this API to cap costs.</p>
    /// <p>To stop a training job, SageMaker sends the algorithm the <code>SIGTERM</code> signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts, so the results of training are not lost.</p>
    /// <p>The training algorithms provided by SageMaker automatically save the intermediate results of a model training job when possible. This attempt to save artifacts is only a best effort case as model might not be in a state from which it can be saved. For example, if training has just started, the model might not be ready to save. When saved, this intermediate data is a valid model artifact. You can use it to create a model with <code>CreateModel</code>.</p><note>
    /// <p>The Neural Topic Model (NTM) currently does not support saving intermediate model artifacts. When training NTMs, make sure that the maximum runtime is sufficient for the training job to complete.</p>
    /// </note>
    pub fn set_stopping_condition(mut self, input: ::std::option::Option<crate::types::StoppingCondition>) -> Self {
        self.inner = self.inner.set_stopping_condition(input);
        self
    }
    /// <p>Specifies a limit to how long a job can run. When the job reaches the time limit, SageMaker ends the job. Use this API to cap costs.</p>
    /// <p>To stop a training job, SageMaker sends the algorithm the <code>SIGTERM</code> signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts, so the results of training are not lost.</p>
    /// <p>The training algorithms provided by SageMaker automatically save the intermediate results of a model training job when possible. This attempt to save artifacts is only a best effort case as model might not be in a state from which it can be saved. For example, if training has just started, the model might not be ready to save. When saved, this intermediate data is a valid model artifact. You can use it to create a model with <code>CreateModel</code>.</p><note>
    /// <p>The Neural Topic Model (NTM) currently does not support saving intermediate model artifacts. When training NTMs, make sure that the maximum runtime is sufficient for the training job to complete.</p>
    /// </note>
    pub fn get_stopping_condition(&self) -> &::std::option::Option<crate::types::StoppingCondition> {
        self.inner.get_stopping_condition()
    }
    ///
    /// Appends an item to `Tags`.
    ///
    /// To override the contents of this collection use [`set_tags`](Self::set_tags).
    ///
    /// <p>A list of key-value pairs associated with the optimization job. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html">Tagging Amazon Web Services resources</a> in the <i>Amazon Web Services General Reference Guide</i>.</p>
    pub fn tags(mut self, input: crate::types::Tag) -> Self {
        self.inner = self.inner.tags(input);
        self
    }
    /// <p>A list of key-value pairs associated with the optimization job. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html">Tagging Amazon Web Services resources</a> in the <i>Amazon Web Services General Reference Guide</i>.</p>
    pub fn set_tags(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::Tag>>) -> Self {
        self.inner = self.inner.set_tags(input);
        self
    }
    /// <p>A list of key-value pairs associated with the optimization job. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html">Tagging Amazon Web Services resources</a> in the <i>Amazon Web Services General Reference Guide</i>.</p>
    pub fn get_tags(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::Tag>> {
        self.inner.get_tags()
    }
    /// <p>A VPC in Amazon VPC that your optimized model has access to.</p>
    pub fn vpc_config(mut self, input: crate::types::OptimizationVpcConfig) -> Self {
        self.inner = self.inner.vpc_config(input);
        self
    }
    /// <p>A VPC in Amazon VPC that your optimized model has access to.</p>
    pub fn set_vpc_config(mut self, input: ::std::option::Option<crate::types::OptimizationVpcConfig>) -> Self {
        self.inner = self.inner.set_vpc_config(input);
        self
    }
    /// <p>A VPC in Amazon VPC that your optimized model has access to.</p>
    pub fn get_vpc_config(&self) -> &::std::option::Option<crate::types::OptimizationVpcConfig> {
        self.inner.get_vpc_config()
    }
}
