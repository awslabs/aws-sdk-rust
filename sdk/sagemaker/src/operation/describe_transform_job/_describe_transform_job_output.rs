// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeTransformJobOutput  {
    /// <p>The name of the transform job.</p>
    #[doc(hidden)]
    pub transform_job_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the transform job.</p>
    #[doc(hidden)]
    pub transform_job_arn: std::option::Option<std::string::String>,
    /// <p>The status of the transform job. If the transform job failed, the reason is returned in the <code>FailureReason</code> field.</p>
    #[doc(hidden)]
    pub transform_job_status: std::option::Option<crate::types::TransformJobStatus>,
    /// <p>If the transform job failed, <code>FailureReason</code> describes why it failed. A transform job creates a log file, which includes error messages, and stores it as an Amazon S3 object. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/logging-cloudwatch.html">Log Amazon SageMaker Events with Amazon CloudWatch</a>.</p>
    #[doc(hidden)]
    pub failure_reason: std::option::Option<std::string::String>,
    /// <p>The name of the model used in the transform job.</p>
    #[doc(hidden)]
    pub model_name: std::option::Option<std::string::String>,
    /// <p>The maximum number of parallel requests on each instance node that can be launched in a transform job. The default value is 1.</p>
    #[doc(hidden)]
    pub max_concurrent_transforms: std::option::Option<i32>,
    /// <p>The timeout and maximum number of retries for processing a transform job invocation.</p>
    #[doc(hidden)]
    pub model_client_config: std::option::Option<crate::types::ModelClientConfig>,
    /// <p>The maximum payload size, in MB, used in the transform job.</p>
    #[doc(hidden)]
    pub max_payload_in_mb: std::option::Option<i32>,
    /// <p>Specifies the number of records to include in a mini-batch for an HTTP inference request. A <i>record</i> <i></i> is a single unit of input data that inference can be made on. For example, a single line in a CSV file is a record. </p> 
    /// <p>To enable the batch strategy, you must set <code>SplitType</code> to <code>Line</code>, <code>RecordIO</code>, or <code>TFRecord</code>.</p>
    #[doc(hidden)]
    pub batch_strategy: std::option::Option<crate::types::BatchStrategy>,
    /// <p>The environment variables to set in the Docker container. We support up to 16 key and values entries in the map.</p>
    #[doc(hidden)]
    pub environment: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    /// <p>Describes the dataset to be transformed and the Amazon S3 location where it is stored.</p>
    #[doc(hidden)]
    pub transform_input: std::option::Option<crate::types::TransformInput>,
    /// <p>Identifies the Amazon S3 location where you want Amazon SageMaker to save the results from the transform job.</p>
    #[doc(hidden)]
    pub transform_output: std::option::Option<crate::types::TransformOutput>,
    /// <p>Configuration to control how SageMaker captures inference data.</p>
    #[doc(hidden)]
    pub data_capture_config: std::option::Option<crate::types::BatchDataCaptureConfig>,
    /// <p>Describes the resources, including ML instance types and ML instance count, to use for the transform job.</p>
    #[doc(hidden)]
    pub transform_resources: std::option::Option<crate::types::TransformResources>,
    /// <p>A timestamp that shows when the transform Job was created.</p>
    #[doc(hidden)]
    pub creation_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates when the transform job starts on ML instances. You are billed for the time interval between this time and the value of <code>TransformEndTime</code>.</p>
    #[doc(hidden)]
    pub transform_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates when the transform job has been completed, or has stopped or failed. You are billed for the time interval between this time and the value of <code>TransformStartTime</code>.</p>
    #[doc(hidden)]
    pub transform_end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The Amazon Resource Name (ARN) of the Amazon SageMaker Ground Truth labeling job that created the transform or training job.</p>
    #[doc(hidden)]
    pub labeling_job_arn: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the AutoML transform job.</p>
    #[doc(hidden)]
    pub auto_ml_job_arn: std::option::Option<std::string::String>,
    /// <p>The data structure used to specify the data to be used for inference in a batch transform job and to associate the data that is relevant to the prediction results in the output. The input filter provided allows you to exclude input data that is not needed for inference in a batch transform job. The output filter provided allows you to include input data relevant to interpreting the predictions in the output from the job. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html">Associate Prediction Results with their Corresponding Input Records</a>.</p>
    #[doc(hidden)]
    pub data_processing: std::option::Option<crate::types::DataProcessing>,
    /// <p>Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs:</p> 
    /// <ul> 
    /// <li> <p> <code>CreateProcessingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTrainingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTransformJob</code> </p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub experiment_config: std::option::Option<crate::types::ExperimentConfig>,
    _request_id: Option<String>,
}
impl DescribeTransformJobOutput {
    /// <p>The name of the transform job.</p>
    pub fn transform_job_name(&self) -> std::option::Option<& str> {
        self.transform_job_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the transform job.</p>
    pub fn transform_job_arn(&self) -> std::option::Option<& str> {
        self.transform_job_arn.as_deref()
    }
    /// <p>The status of the transform job. If the transform job failed, the reason is returned in the <code>FailureReason</code> field.</p>
    pub fn transform_job_status(&self) -> std::option::Option<& crate::types::TransformJobStatus> {
        self.transform_job_status.as_ref()
    }
    /// <p>If the transform job failed, <code>FailureReason</code> describes why it failed. A transform job creates a log file, which includes error messages, and stores it as an Amazon S3 object. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/logging-cloudwatch.html">Log Amazon SageMaker Events with Amazon CloudWatch</a>.</p>
    pub fn failure_reason(&self) -> std::option::Option<& str> {
        self.failure_reason.as_deref()
    }
    /// <p>The name of the model used in the transform job.</p>
    pub fn model_name(&self) -> std::option::Option<& str> {
        self.model_name.as_deref()
    }
    /// <p>The maximum number of parallel requests on each instance node that can be launched in a transform job. The default value is 1.</p>
    pub fn max_concurrent_transforms(&self) -> std::option::Option<i32> {
        self.max_concurrent_transforms
    }
    /// <p>The timeout and maximum number of retries for processing a transform job invocation.</p>
    pub fn model_client_config(&self) -> std::option::Option<& crate::types::ModelClientConfig> {
        self.model_client_config.as_ref()
    }
    /// <p>The maximum payload size, in MB, used in the transform job.</p>
    pub fn max_payload_in_mb(&self) -> std::option::Option<i32> {
        self.max_payload_in_mb
    }
    /// <p>Specifies the number of records to include in a mini-batch for an HTTP inference request. A <i>record</i> <i></i> is a single unit of input data that inference can be made on. For example, a single line in a CSV file is a record. </p> 
    /// <p>To enable the batch strategy, you must set <code>SplitType</code> to <code>Line</code>, <code>RecordIO</code>, or <code>TFRecord</code>.</p>
    pub fn batch_strategy(&self) -> std::option::Option<& crate::types::BatchStrategy> {
        self.batch_strategy.as_ref()
    }
    /// <p>The environment variables to set in the Docker container. We support up to 16 key and values entries in the map.</p>
    pub fn environment(&self) -> std::option::Option<& std::collections::HashMap<std::string::String, std::string::String>> {
        self.environment.as_ref()
    }
    /// <p>Describes the dataset to be transformed and the Amazon S3 location where it is stored.</p>
    pub fn transform_input(&self) -> std::option::Option<& crate::types::TransformInput> {
        self.transform_input.as_ref()
    }
    /// <p>Identifies the Amazon S3 location where you want Amazon SageMaker to save the results from the transform job.</p>
    pub fn transform_output(&self) -> std::option::Option<& crate::types::TransformOutput> {
        self.transform_output.as_ref()
    }
    /// <p>Configuration to control how SageMaker captures inference data.</p>
    pub fn data_capture_config(&self) -> std::option::Option<& crate::types::BatchDataCaptureConfig> {
        self.data_capture_config.as_ref()
    }
    /// <p>Describes the resources, including ML instance types and ML instance count, to use for the transform job.</p>
    pub fn transform_resources(&self) -> std::option::Option<& crate::types::TransformResources> {
        self.transform_resources.as_ref()
    }
    /// <p>A timestamp that shows when the transform Job was created.</p>
    pub fn creation_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.creation_time.as_ref()
    }
    /// <p>Indicates when the transform job starts on ML instances. You are billed for the time interval between this time and the value of <code>TransformEndTime</code>.</p>
    pub fn transform_start_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.transform_start_time.as_ref()
    }
    /// <p>Indicates when the transform job has been completed, or has stopped or failed. You are billed for the time interval between this time and the value of <code>TransformStartTime</code>.</p>
    pub fn transform_end_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.transform_end_time.as_ref()
    }
    /// <p>The Amazon Resource Name (ARN) of the Amazon SageMaker Ground Truth labeling job that created the transform or training job.</p>
    pub fn labeling_job_arn(&self) -> std::option::Option<& str> {
        self.labeling_job_arn.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the AutoML transform job.</p>
    pub fn auto_ml_job_arn(&self) -> std::option::Option<& str> {
        self.auto_ml_job_arn.as_deref()
    }
    /// <p>The data structure used to specify the data to be used for inference in a batch transform job and to associate the data that is relevant to the prediction results in the output. The input filter provided allows you to exclude input data that is not needed for inference in a batch transform job. The output filter provided allows you to include input data relevant to interpreting the predictions in the output from the job. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html">Associate Prediction Results with their Corresponding Input Records</a>.</p>
    pub fn data_processing(&self) -> std::option::Option<& crate::types::DataProcessing> {
        self.data_processing.as_ref()
    }
    /// <p>Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs:</p> 
    /// <ul> 
    /// <li> <p> <code>CreateProcessingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTrainingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTransformJob</code> </p> </li> 
    /// </ul>
    pub fn experiment_config(&self) -> std::option::Option<& crate::types::ExperimentConfig> {
        self.experiment_config.as_ref()
    }
}
impl aws_http::request_id::RequestId for DescribeTransformJobOutput {
                                fn request_id(&self) -> Option<&str> {
                                    self._request_id.as_deref()
                                }
                            }
impl DescribeTransformJobOutput {
    /// Creates a new builder-style object to manufacture [`DescribeTransformJobOutput`](crate::operation::describe_transform_job::DescribeTransformJobOutput).
    pub fn builder() -> crate::operation::describe_transform_job::builders::DescribeTransformJobOutputBuilder {
        crate::operation::describe_transform_job::builders::DescribeTransformJobOutputBuilder::default()
    }
}

/// A builder for [`DescribeTransformJobOutput`](crate::operation::describe_transform_job::DescribeTransformJobOutput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct DescribeTransformJobOutputBuilder {
    pub(crate) transform_job_name: std::option::Option<std::string::String>,
    pub(crate) transform_job_arn: std::option::Option<std::string::String>,
    pub(crate) transform_job_status: std::option::Option<crate::types::TransformJobStatus>,
    pub(crate) failure_reason: std::option::Option<std::string::String>,
    pub(crate) model_name: std::option::Option<std::string::String>,
    pub(crate) max_concurrent_transforms: std::option::Option<i32>,
    pub(crate) model_client_config: std::option::Option<crate::types::ModelClientConfig>,
    pub(crate) max_payload_in_mb: std::option::Option<i32>,
    pub(crate) batch_strategy: std::option::Option<crate::types::BatchStrategy>,
    pub(crate) environment: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    pub(crate) transform_input: std::option::Option<crate::types::TransformInput>,
    pub(crate) transform_output: std::option::Option<crate::types::TransformOutput>,
    pub(crate) data_capture_config: std::option::Option<crate::types::BatchDataCaptureConfig>,
    pub(crate) transform_resources: std::option::Option<crate::types::TransformResources>,
    pub(crate) creation_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) transform_start_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) transform_end_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) labeling_job_arn: std::option::Option<std::string::String>,
    pub(crate) auto_ml_job_arn: std::option::Option<std::string::String>,
    pub(crate) data_processing: std::option::Option<crate::types::DataProcessing>,
    pub(crate) experiment_config: std::option::Option<crate::types::ExperimentConfig>,
    _request_id: Option<String>,
}
impl DescribeTransformJobOutputBuilder {
    /// <p>The name of the transform job.</p>
    pub fn transform_job_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.transform_job_name = Some(input.into());
        self
    }
    /// <p>The name of the transform job.</p>
    pub fn set_transform_job_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.transform_job_name = input; self
    }
    /// <p>The Amazon Resource Name (ARN) of the transform job.</p>
    pub fn transform_job_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.transform_job_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the transform job.</p>
    pub fn set_transform_job_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.transform_job_arn = input; self
    }
    /// <p>The status of the transform job. If the transform job failed, the reason is returned in the <code>FailureReason</code> field.</p>
    pub fn transform_job_status(mut self, input: crate::types::TransformJobStatus) -> Self {
        self.transform_job_status = Some(input);
        self
    }
    /// <p>The status of the transform job. If the transform job failed, the reason is returned in the <code>FailureReason</code> field.</p>
    pub fn set_transform_job_status(mut self, input: std::option::Option<crate::types::TransformJobStatus>) -> Self {
        self.transform_job_status = input; self
    }
    /// <p>If the transform job failed, <code>FailureReason</code> describes why it failed. A transform job creates a log file, which includes error messages, and stores it as an Amazon S3 object. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/logging-cloudwatch.html">Log Amazon SageMaker Events with Amazon CloudWatch</a>.</p>
    pub fn failure_reason(mut self, input: impl Into<std::string::String>) -> Self {
        self.failure_reason = Some(input.into());
        self
    }
    /// <p>If the transform job failed, <code>FailureReason</code> describes why it failed. A transform job creates a log file, which includes error messages, and stores it as an Amazon S3 object. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/logging-cloudwatch.html">Log Amazon SageMaker Events with Amazon CloudWatch</a>.</p>
    pub fn set_failure_reason(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.failure_reason = input; self
    }
    /// <p>The name of the model used in the transform job.</p>
    pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.model_name = Some(input.into());
        self
    }
    /// <p>The name of the model used in the transform job.</p>
    pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.model_name = input; self
    }
    /// <p>The maximum number of parallel requests on each instance node that can be launched in a transform job. The default value is 1.</p>
    pub fn max_concurrent_transforms(mut self, input: i32) -> Self {
        self.max_concurrent_transforms = Some(input);
        self
    }
    /// <p>The maximum number of parallel requests on each instance node that can be launched in a transform job. The default value is 1.</p>
    pub fn set_max_concurrent_transforms(mut self, input: std::option::Option<i32>) -> Self {
        self.max_concurrent_transforms = input; self
    }
    /// <p>The timeout and maximum number of retries for processing a transform job invocation.</p>
    pub fn model_client_config(mut self, input: crate::types::ModelClientConfig) -> Self {
        self.model_client_config = Some(input);
        self
    }
    /// <p>The timeout and maximum number of retries for processing a transform job invocation.</p>
    pub fn set_model_client_config(mut self, input: std::option::Option<crate::types::ModelClientConfig>) -> Self {
        self.model_client_config = input; self
    }
    /// <p>The maximum payload size, in MB, used in the transform job.</p>
    pub fn max_payload_in_mb(mut self, input: i32) -> Self {
        self.max_payload_in_mb = Some(input);
        self
    }
    /// <p>The maximum payload size, in MB, used in the transform job.</p>
    pub fn set_max_payload_in_mb(mut self, input: std::option::Option<i32>) -> Self {
        self.max_payload_in_mb = input; self
    }
    /// <p>Specifies the number of records to include in a mini-batch for an HTTP inference request. A <i>record</i> <i></i> is a single unit of input data that inference can be made on. For example, a single line in a CSV file is a record. </p> 
    /// <p>To enable the batch strategy, you must set <code>SplitType</code> to <code>Line</code>, <code>RecordIO</code>, or <code>TFRecord</code>.</p>
    pub fn batch_strategy(mut self, input: crate::types::BatchStrategy) -> Self {
        self.batch_strategy = Some(input);
        self
    }
    /// <p>Specifies the number of records to include in a mini-batch for an HTTP inference request. A <i>record</i> <i></i> is a single unit of input data that inference can be made on. For example, a single line in a CSV file is a record. </p> 
    /// <p>To enable the batch strategy, you must set <code>SplitType</code> to <code>Line</code>, <code>RecordIO</code>, or <code>TFRecord</code>.</p>
    pub fn set_batch_strategy(mut self, input: std::option::Option<crate::types::BatchStrategy>) -> Self {
        self.batch_strategy = input; self
    }
    /// Adds a key-value pair to `environment`.
    ///
    /// To override the contents of this collection use [`set_environment`](Self::set_environment).
    ///
    /// <p>The environment variables to set in the Docker container. We support up to 16 key and values entries in the map.</p>
    pub fn environment(mut self, k: impl Into<std::string::String>, v: impl Into<std::string::String>) -> Self {
        let mut hash_map = self.environment.unwrap_or_default();
                        hash_map.insert(k.into(), v.into());
                        self.environment = Some(hash_map);
                        self
    }
    /// <p>The environment variables to set in the Docker container. We support up to 16 key and values entries in the map.</p>
    pub fn set_environment(mut self, input: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>) -> Self {
        self.environment = input; self
    }
    /// <p>Describes the dataset to be transformed and the Amazon S3 location where it is stored.</p>
    pub fn transform_input(mut self, input: crate::types::TransformInput) -> Self {
        self.transform_input = Some(input);
        self
    }
    /// <p>Describes the dataset to be transformed and the Amazon S3 location where it is stored.</p>
    pub fn set_transform_input(mut self, input: std::option::Option<crate::types::TransformInput>) -> Self {
        self.transform_input = input; self
    }
    /// <p>Identifies the Amazon S3 location where you want Amazon SageMaker to save the results from the transform job.</p>
    pub fn transform_output(mut self, input: crate::types::TransformOutput) -> Self {
        self.transform_output = Some(input);
        self
    }
    /// <p>Identifies the Amazon S3 location where you want Amazon SageMaker to save the results from the transform job.</p>
    pub fn set_transform_output(mut self, input: std::option::Option<crate::types::TransformOutput>) -> Self {
        self.transform_output = input; self
    }
    /// <p>Configuration to control how SageMaker captures inference data.</p>
    pub fn data_capture_config(mut self, input: crate::types::BatchDataCaptureConfig) -> Self {
        self.data_capture_config = Some(input);
        self
    }
    /// <p>Configuration to control how SageMaker captures inference data.</p>
    pub fn set_data_capture_config(mut self, input: std::option::Option<crate::types::BatchDataCaptureConfig>) -> Self {
        self.data_capture_config = input; self
    }
    /// <p>Describes the resources, including ML instance types and ML instance count, to use for the transform job.</p>
    pub fn transform_resources(mut self, input: crate::types::TransformResources) -> Self {
        self.transform_resources = Some(input);
        self
    }
    /// <p>Describes the resources, including ML instance types and ML instance count, to use for the transform job.</p>
    pub fn set_transform_resources(mut self, input: std::option::Option<crate::types::TransformResources>) -> Self {
        self.transform_resources = input; self
    }
    /// <p>A timestamp that shows when the transform Job was created.</p>
    pub fn creation_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.creation_time = Some(input);
        self
    }
    /// <p>A timestamp that shows when the transform Job was created.</p>
    pub fn set_creation_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.creation_time = input; self
    }
    /// <p>Indicates when the transform job starts on ML instances. You are billed for the time interval between this time and the value of <code>TransformEndTime</code>.</p>
    pub fn transform_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.transform_start_time = Some(input);
        self
    }
    /// <p>Indicates when the transform job starts on ML instances. You are billed for the time interval between this time and the value of <code>TransformEndTime</code>.</p>
    pub fn set_transform_start_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.transform_start_time = input; self
    }
    /// <p>Indicates when the transform job has been completed, or has stopped or failed. You are billed for the time interval between this time and the value of <code>TransformStartTime</code>.</p>
    pub fn transform_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.transform_end_time = Some(input);
        self
    }
    /// <p>Indicates when the transform job has been completed, or has stopped or failed. You are billed for the time interval between this time and the value of <code>TransformStartTime</code>.</p>
    pub fn set_transform_end_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.transform_end_time = input; self
    }
    /// <p>The Amazon Resource Name (ARN) of the Amazon SageMaker Ground Truth labeling job that created the transform or training job.</p>
    pub fn labeling_job_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.labeling_job_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the Amazon SageMaker Ground Truth labeling job that created the transform or training job.</p>
    pub fn set_labeling_job_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.labeling_job_arn = input; self
    }
    /// <p>The Amazon Resource Name (ARN) of the AutoML transform job.</p>
    pub fn auto_ml_job_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.auto_ml_job_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the AutoML transform job.</p>
    pub fn set_auto_ml_job_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.auto_ml_job_arn = input; self
    }
    /// <p>The data structure used to specify the data to be used for inference in a batch transform job and to associate the data that is relevant to the prediction results in the output. The input filter provided allows you to exclude input data that is not needed for inference in a batch transform job. The output filter provided allows you to include input data relevant to interpreting the predictions in the output from the job. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html">Associate Prediction Results with their Corresponding Input Records</a>.</p>
    pub fn data_processing(mut self, input: crate::types::DataProcessing) -> Self {
        self.data_processing = Some(input);
        self
    }
    /// <p>The data structure used to specify the data to be used for inference in a batch transform job and to associate the data that is relevant to the prediction results in the output. The input filter provided allows you to exclude input data that is not needed for inference in a batch transform job. The output filter provided allows you to include input data relevant to interpreting the predictions in the output from the job. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html">Associate Prediction Results with their Corresponding Input Records</a>.</p>
    pub fn set_data_processing(mut self, input: std::option::Option<crate::types::DataProcessing>) -> Self {
        self.data_processing = input; self
    }
    /// <p>Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs:</p> 
    /// <ul> 
    /// <li> <p> <code>CreateProcessingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTrainingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTransformJob</code> </p> </li> 
    /// </ul>
    pub fn experiment_config(mut self, input: crate::types::ExperimentConfig) -> Self {
        self.experiment_config = Some(input);
        self
    }
    /// <p>Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs:</p> 
    /// <ul> 
    /// <li> <p> <code>CreateProcessingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTrainingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTransformJob</code> </p> </li> 
    /// </ul>
    pub fn set_experiment_config(mut self, input: std::option::Option<crate::types::ExperimentConfig>) -> Self {
        self.experiment_config = input; self
    }
    pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
                                    self._request_id = Some(request_id.into());
                                    self
                                }
    
                                pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
                                    self._request_id = request_id;
                                    self
                                }
    /// Consumes the builder and constructs a [`DescribeTransformJobOutput`](crate::operation::describe_transform_job::DescribeTransformJobOutput).
    pub fn build(self) -> crate::operation::describe_transform_job::DescribeTransformJobOutput {
        crate::operation::describe_transform_job::DescribeTransformJobOutput {
            transform_job_name: self.transform_job_name
            ,
            transform_job_arn: self.transform_job_arn
            ,
            transform_job_status: self.transform_job_status
            ,
            failure_reason: self.failure_reason
            ,
            model_name: self.model_name
            ,
            max_concurrent_transforms: self.max_concurrent_transforms
            ,
            model_client_config: self.model_client_config
            ,
            max_payload_in_mb: self.max_payload_in_mb
            ,
            batch_strategy: self.batch_strategy
            ,
            environment: self.environment
            ,
            transform_input: self.transform_input
            ,
            transform_output: self.transform_output
            ,
            data_capture_config: self.data_capture_config
            ,
            transform_resources: self.transform_resources
            ,
            creation_time: self.creation_time
            ,
            transform_start_time: self.transform_start_time
            ,
            transform_end_time: self.transform_end_time
            ,
            labeling_job_arn: self.labeling_job_arn
            ,
            auto_ml_job_arn: self.auto_ml_job_arn
            ,
            data_processing: self.data_processing
            ,
            experiment_config: self.experiment_config
            ,
            _request_id: self._request_id,
        }
    }
}

