// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DescribeTrainingJobOutput  {
    /// <p> Name of the model training job. </p>
    #[doc(hidden)]
    pub training_job_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the training job.</p>
    #[doc(hidden)]
    pub training_job_arn: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the training job was launched by a hyperparameter tuning job.</p>
    #[doc(hidden)]
    pub tuning_job_arn: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the SageMaker Ground Truth labeling job that created the transform or training job.</p>
    #[doc(hidden)]
    pub labeling_job_arn: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of an AutoML job.</p>
    #[doc(hidden)]
    pub auto_ml_job_arn: std::option::Option<std::string::String>,
    /// <p>Information about the Amazon S3 location that is configured for storing model artifacts. </p>
    #[doc(hidden)]
    pub model_artifacts: std::option::Option<crate::types::ModelArtifacts>,
    /// <p>The status of the training job.</p> 
    /// <p>SageMaker provides the following training job statuses:</p> 
    /// <ul> 
    /// <li> <p> <code>InProgress</code> - The training is in progress.</p> </li> 
    /// <li> <p> <code>Completed</code> - The training job has completed.</p> </li> 
    /// <li> <p> <code>Failed</code> - The training job has failed. To see the reason for the failure, see the <code>FailureReason</code> field in the response to a <code>DescribeTrainingJobResponse</code> call.</p> </li> 
    /// <li> <p> <code>Stopping</code> - The training job is stopping.</p> </li> 
    /// <li> <p> <code>Stopped</code> - The training job has stopped.</p> </li> 
    /// </ul> 
    /// <p>For more detailed information, see <code>SecondaryStatus</code>. </p>
    #[doc(hidden)]
    pub training_job_status: std::option::Option<crate::types::TrainingJobStatus>,
    /// <p> Provides detailed information about the state of the training job. For detailed information on the secondary status of the training job, see <code>StatusMessage</code> under <code>SecondaryStatusTransition</code>.</p> 
    /// <p>SageMaker provides primary statuses and secondary statuses that apply to each of them:</p> 
    /// <dl> 
    /// <dt>
    /// InProgress
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Starting</code> - Starting the training job.</p> </li> 
    /// <li> <p> <code>Downloading</code> - An optional stage for algorithms that support <code>File</code> training input mode. It indicates that data is being downloaded to the ML storage volumes.</p> </li> 
    /// <li> <p> <code>Training</code> - Training is in progress.</p> </li> 
    /// <li> <p> <code>Interrupted</code> - The job stopped because the managed spot training instances were interrupted. </p> </li> 
    /// <li> <p> <code>Uploading</code> - Training is complete and the model artifacts are being uploaded to the S3 location.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Completed
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Completed</code> - The training job has completed.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Failed
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Failed</code> - The training job has failed. The reason for the failure is returned in the <code>FailureReason</code> field of <code>DescribeTrainingJobResponse</code>.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Stopped
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>MaxRuntimeExceeded</code> - The job stopped because it exceeded the maximum allowed runtime.</p> </li> 
    /// <li> <p> <code>MaxWaitTimeExceeded</code> - The job stopped because it exceeded the maximum allowed wait time.</p> </li> 
    /// <li> <p> <code>Stopped</code> - The training job has stopped.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Stopping
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Stopping</code> - Stopping the training job.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// </dl> <important> 
    /// <p>Valid values for <code>SecondaryStatus</code> are subject to change. </p> 
    /// </important> 
    /// <p>We no longer support the following secondary statuses:</p> 
    /// <ul> 
    /// <li> <p> <code>LaunchingMLInstances</code> </p> </li> 
    /// <li> <p> <code>PreparingTraining</code> </p> </li> 
    /// <li> <p> <code>DownloadingTrainingImage</code> </p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub secondary_status: std::option::Option<crate::types::SecondaryStatus>,
    /// <p>If the training job failed, the reason it failed. </p>
    #[doc(hidden)]
    pub failure_reason: std::option::Option<std::string::String>,
    /// <p>Algorithm-specific parameters. </p>
    #[doc(hidden)]
    pub hyper_parameters: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    /// <p>Information about the algorithm used for training, and algorithm metadata. </p>
    #[doc(hidden)]
    pub algorithm_specification: std::option::Option<crate::types::AlgorithmSpecification>,
    /// <p>The Amazon Web Services Identity and Access Management (IAM) role configured for the training job. </p>
    #[doc(hidden)]
    pub role_arn: std::option::Option<std::string::String>,
    /// <p>An array of <code>Channel</code> objects that describes each data input channel. </p>
    #[doc(hidden)]
    pub input_data_config: std::option::Option<std::vec::Vec<crate::types::Channel>>,
    /// <p>The S3 path where model artifacts that you configured when creating the job are stored. SageMaker creates subfolders for model artifacts. </p>
    #[doc(hidden)]
    pub output_data_config: std::option::Option<crate::types::OutputDataConfig>,
    /// <p>Resources, including ML compute instances and ML storage volumes, that are configured for model training. </p>
    #[doc(hidden)]
    pub resource_config: std::option::Option<crate::types::ResourceConfig>,
    /// <p>A <code>VpcConfig</code> object that specifies the VPC that this training job has access to. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html">Protect Training Jobs by Using an Amazon Virtual Private Cloud</a>.</p>
    #[doc(hidden)]
    pub vpc_config: std::option::Option<crate::types::VpcConfig>,
    /// <p>Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, SageMaker ends the training job. Use this API to cap model training costs.</p> 
    /// <p>To stop a job, SageMaker sends the algorithm the <code>SIGTERM</code> signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts, so the results of training are not lost. </p>
    #[doc(hidden)]
    pub stopping_condition: std::option::Option<crate::types::StoppingCondition>,
    /// <p>A timestamp that indicates when the training job was created.</p>
    #[doc(hidden)]
    pub creation_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates the time when the training job starts on training instances. You are billed for the time interval between this time and the value of <code>TrainingEndTime</code>. The start time in CloudWatch Logs might be later than this time. The difference is due to the time it takes to download the training data and to the size of the training container.</p>
    #[doc(hidden)]
    pub training_start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Indicates the time when the training job ends on training instances. You are billed for the time interval between the value of <code>TrainingStartTime</code> and this time. For successful jobs and stopped jobs, this is the time after model artifacts are uploaded. For failed jobs, this is the time when SageMaker detects a job failure.</p>
    #[doc(hidden)]
    pub training_end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>A timestamp that indicates when the status of the training job was last modified.</p>
    #[doc(hidden)]
    pub last_modified_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>A history of all of the secondary statuses that the training job has transitioned through.</p>
    #[doc(hidden)]
    pub secondary_status_transitions: std::option::Option<std::vec::Vec<crate::types::SecondaryStatusTransition>>,
    /// <p>A collection of <code>MetricData</code> objects that specify the names, values, and dates and times that the training algorithm emitted to Amazon CloudWatch.</p>
    #[doc(hidden)]
    pub final_metric_data_list: std::option::Option<std::vec::Vec<crate::types::MetricData>>,
    /// <p>If you want to allow inbound or outbound network calls, except for calls between peers within a training cluster for distributed training, choose <code>True</code>. If you enable network isolation for training jobs that are configured to use a VPC, SageMaker downloads and uploads customer data and model artifacts through the specified VPC, but the training container does not have network access.</p>
    #[doc(hidden)]
    pub enable_network_isolation: bool,
    /// <p>To encrypt all communications between ML compute instances in distributed training, choose <code>True</code>. Encryption provides greater security for distributed training, but training might take longer. How long it takes depends on the amount of communication between compute instances, especially if you use a deep learning algorithms in distributed training.</p>
    #[doc(hidden)]
    pub enable_inter_container_traffic_encryption: bool,
    /// <p>A Boolean indicating whether managed spot training is enabled (<code>True</code>) or not (<code>False</code>).</p>
    #[doc(hidden)]
    pub enable_managed_spot_training: bool,
    /// <p>Contains information about the output location for managed spot training checkpoint data. </p>
    #[doc(hidden)]
    pub checkpoint_config: std::option::Option<crate::types::CheckpointConfig>,
    /// <p>The training time in seconds.</p>
    #[doc(hidden)]
    pub training_time_in_seconds: std::option::Option<i32>,
    /// <p>The billable time in seconds. Billable time refers to the absolute wall-clock time.</p> 
    /// <p>Multiply <code>BillableTimeInSeconds</code> by the number of instances (<code>InstanceCount</code>) in your training cluster to get the total compute time SageMaker bills you if you run distributed training. The formula is as follows: <code>BillableTimeInSeconds * InstanceCount</code> .</p> 
    /// <p>You can calculate the savings from using managed spot training using the formula <code>(1 - BillableTimeInSeconds / TrainingTimeInSeconds) * 100</code>. For example, if <code>BillableTimeInSeconds</code> is 100 and <code>TrainingTimeInSeconds</code> is 500, the savings is 80%.</p>
    #[doc(hidden)]
    pub billable_time_in_seconds: std::option::Option<i32>,
    /// <p>Configuration information for the Amazon SageMaker Debugger hook parameters, metric and tensor collections, and storage paths. To learn more about how to configure the <code>DebugHookConfig</code> parameter, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-createtrainingjob-api.html">Use the SageMaker and Debugger Configuration API Operations to Create, Update, and Debug Your Training Job</a>.</p>
    #[doc(hidden)]
    pub debug_hook_config: std::option::Option<crate::types::DebugHookConfig>,
    /// <p>Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs:</p> 
    /// <ul> 
    /// <li> <p> <code>CreateProcessingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTrainingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTransformJob</code> </p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub experiment_config: std::option::Option<crate::types::ExperimentConfig>,
    /// <p>Configuration information for Amazon SageMaker Debugger rules for debugging output tensors.</p>
    #[doc(hidden)]
    pub debug_rule_configurations: std::option::Option<std::vec::Vec<crate::types::DebugRuleConfiguration>>,
    /// <p>Configuration of storage locations for the Amazon SageMaker Debugger TensorBoard output data.</p>
    #[doc(hidden)]
    pub tensor_board_output_config: std::option::Option<crate::types::TensorBoardOutputConfig>,
    /// <p>Evaluation status of Amazon SageMaker Debugger rules for debugging on a training job.</p>
    #[doc(hidden)]
    pub debug_rule_evaluation_statuses: std::option::Option<std::vec::Vec<crate::types::DebugRuleEvaluationStatus>>,
    /// <p>Configuration information for Amazon SageMaker Debugger system monitoring, framework profiling, and storage paths.</p>
    #[doc(hidden)]
    pub profiler_config: std::option::Option<crate::types::ProfilerConfig>,
    /// <p>Configuration information for Amazon SageMaker Debugger rules for profiling system and framework metrics.</p>
    #[doc(hidden)]
    pub profiler_rule_configurations: std::option::Option<std::vec::Vec<crate::types::ProfilerRuleConfiguration>>,
    /// <p>Evaluation status of Amazon SageMaker Debugger rules for profiling on a training job.</p>
    #[doc(hidden)]
    pub profiler_rule_evaluation_statuses: std::option::Option<std::vec::Vec<crate::types::ProfilerRuleEvaluationStatus>>,
    /// <p>Profiling status of a training job.</p>
    #[doc(hidden)]
    pub profiling_status: std::option::Option<crate::types::ProfilingStatus>,
    /// <p>The number of times to retry the job when the job fails due to an <code>InternalServerError</code>.</p>
    #[doc(hidden)]
    pub retry_strategy: std::option::Option<crate::types::RetryStrategy>,
    /// <p>The environment variables to set in the Docker container.</p>
    #[doc(hidden)]
    pub environment: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    /// <p>The status of the warm pool associated with the training job.</p>
    #[doc(hidden)]
    pub warm_pool_status: std::option::Option<crate::types::WarmPoolStatus>,
    _request_id: Option<String>,
}
impl DescribeTrainingJobOutput {
    /// <p> Name of the model training job. </p>
    pub fn training_job_name(&self) -> std::option::Option<& str> {
        self.training_job_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the training job.</p>
    pub fn training_job_arn(&self) -> std::option::Option<& str> {
        self.training_job_arn.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the training job was launched by a hyperparameter tuning job.</p>
    pub fn tuning_job_arn(&self) -> std::option::Option<& str> {
        self.tuning_job_arn.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the SageMaker Ground Truth labeling job that created the transform or training job.</p>
    pub fn labeling_job_arn(&self) -> std::option::Option<& str> {
        self.labeling_job_arn.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of an AutoML job.</p>
    pub fn auto_ml_job_arn(&self) -> std::option::Option<& str> {
        self.auto_ml_job_arn.as_deref()
    }
    /// <p>Information about the Amazon S3 location that is configured for storing model artifacts. </p>
    pub fn model_artifacts(&self) -> std::option::Option<& crate::types::ModelArtifacts> {
        self.model_artifacts.as_ref()
    }
    /// <p>The status of the training job.</p> 
    /// <p>SageMaker provides the following training job statuses:</p> 
    /// <ul> 
    /// <li> <p> <code>InProgress</code> - The training is in progress.</p> </li> 
    /// <li> <p> <code>Completed</code> - The training job has completed.</p> </li> 
    /// <li> <p> <code>Failed</code> - The training job has failed. To see the reason for the failure, see the <code>FailureReason</code> field in the response to a <code>DescribeTrainingJobResponse</code> call.</p> </li> 
    /// <li> <p> <code>Stopping</code> - The training job is stopping.</p> </li> 
    /// <li> <p> <code>Stopped</code> - The training job has stopped.</p> </li> 
    /// </ul> 
    /// <p>For more detailed information, see <code>SecondaryStatus</code>. </p>
    pub fn training_job_status(&self) -> std::option::Option<& crate::types::TrainingJobStatus> {
        self.training_job_status.as_ref()
    }
    /// <p> Provides detailed information about the state of the training job. For detailed information on the secondary status of the training job, see <code>StatusMessage</code> under <code>SecondaryStatusTransition</code>.</p> 
    /// <p>SageMaker provides primary statuses and secondary statuses that apply to each of them:</p> 
    /// <dl> 
    /// <dt>
    /// InProgress
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Starting</code> - Starting the training job.</p> </li> 
    /// <li> <p> <code>Downloading</code> - An optional stage for algorithms that support <code>File</code> training input mode. It indicates that data is being downloaded to the ML storage volumes.</p> </li> 
    /// <li> <p> <code>Training</code> - Training is in progress.</p> </li> 
    /// <li> <p> <code>Interrupted</code> - The job stopped because the managed spot training instances were interrupted. </p> </li> 
    /// <li> <p> <code>Uploading</code> - Training is complete and the model artifacts are being uploaded to the S3 location.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Completed
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Completed</code> - The training job has completed.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Failed
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Failed</code> - The training job has failed. The reason for the failure is returned in the <code>FailureReason</code> field of <code>DescribeTrainingJobResponse</code>.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Stopped
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>MaxRuntimeExceeded</code> - The job stopped because it exceeded the maximum allowed runtime.</p> </li> 
    /// <li> <p> <code>MaxWaitTimeExceeded</code> - The job stopped because it exceeded the maximum allowed wait time.</p> </li> 
    /// <li> <p> <code>Stopped</code> - The training job has stopped.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Stopping
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Stopping</code> - Stopping the training job.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// </dl> <important> 
    /// <p>Valid values for <code>SecondaryStatus</code> are subject to change. </p> 
    /// </important> 
    /// <p>We no longer support the following secondary statuses:</p> 
    /// <ul> 
    /// <li> <p> <code>LaunchingMLInstances</code> </p> </li> 
    /// <li> <p> <code>PreparingTraining</code> </p> </li> 
    /// <li> <p> <code>DownloadingTrainingImage</code> </p> </li> 
    /// </ul>
    pub fn secondary_status(&self) -> std::option::Option<& crate::types::SecondaryStatus> {
        self.secondary_status.as_ref()
    }
    /// <p>If the training job failed, the reason it failed. </p>
    pub fn failure_reason(&self) -> std::option::Option<& str> {
        self.failure_reason.as_deref()
    }
    /// <p>Algorithm-specific parameters. </p>
    pub fn hyper_parameters(&self) -> std::option::Option<& std::collections::HashMap<std::string::String, std::string::String>> {
        self.hyper_parameters.as_ref()
    }
    /// <p>Information about the algorithm used for training, and algorithm metadata. </p>
    pub fn algorithm_specification(&self) -> std::option::Option<& crate::types::AlgorithmSpecification> {
        self.algorithm_specification.as_ref()
    }
    /// <p>The Amazon Web Services Identity and Access Management (IAM) role configured for the training job. </p>
    pub fn role_arn(&self) -> std::option::Option<& str> {
        self.role_arn.as_deref()
    }
    /// <p>An array of <code>Channel</code> objects that describes each data input channel. </p>
    pub fn input_data_config(&self) -> std::option::Option<& [crate::types::Channel]> {
        self.input_data_config.as_deref()
    }
    /// <p>The S3 path where model artifacts that you configured when creating the job are stored. SageMaker creates subfolders for model artifacts. </p>
    pub fn output_data_config(&self) -> std::option::Option<& crate::types::OutputDataConfig> {
        self.output_data_config.as_ref()
    }
    /// <p>Resources, including ML compute instances and ML storage volumes, that are configured for model training. </p>
    pub fn resource_config(&self) -> std::option::Option<& crate::types::ResourceConfig> {
        self.resource_config.as_ref()
    }
    /// <p>A <code>VpcConfig</code> object that specifies the VPC that this training job has access to. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html">Protect Training Jobs by Using an Amazon Virtual Private Cloud</a>.</p>
    pub fn vpc_config(&self) -> std::option::Option<& crate::types::VpcConfig> {
        self.vpc_config.as_ref()
    }
    /// <p>Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, SageMaker ends the training job. Use this API to cap model training costs.</p> 
    /// <p>To stop a job, SageMaker sends the algorithm the <code>SIGTERM</code> signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts, so the results of training are not lost. </p>
    pub fn stopping_condition(&self) -> std::option::Option<& crate::types::StoppingCondition> {
        self.stopping_condition.as_ref()
    }
    /// <p>A timestamp that indicates when the training job was created.</p>
    pub fn creation_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.creation_time.as_ref()
    }
    /// <p>Indicates the time when the training job starts on training instances. You are billed for the time interval between this time and the value of <code>TrainingEndTime</code>. The start time in CloudWatch Logs might be later than this time. The difference is due to the time it takes to download the training data and to the size of the training container.</p>
    pub fn training_start_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.training_start_time.as_ref()
    }
    /// <p>Indicates the time when the training job ends on training instances. You are billed for the time interval between the value of <code>TrainingStartTime</code> and this time. For successful jobs and stopped jobs, this is the time after model artifacts are uploaded. For failed jobs, this is the time when SageMaker detects a job failure.</p>
    pub fn training_end_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.training_end_time.as_ref()
    }
    /// <p>A timestamp that indicates when the status of the training job was last modified.</p>
    pub fn last_modified_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.last_modified_time.as_ref()
    }
    /// <p>A history of all of the secondary statuses that the training job has transitioned through.</p>
    pub fn secondary_status_transitions(&self) -> std::option::Option<& [crate::types::SecondaryStatusTransition]> {
        self.secondary_status_transitions.as_deref()
    }
    /// <p>A collection of <code>MetricData</code> objects that specify the names, values, and dates and times that the training algorithm emitted to Amazon CloudWatch.</p>
    pub fn final_metric_data_list(&self) -> std::option::Option<& [crate::types::MetricData]> {
        self.final_metric_data_list.as_deref()
    }
    /// <p>If you want to allow inbound or outbound network calls, except for calls between peers within a training cluster for distributed training, choose <code>True</code>. If you enable network isolation for training jobs that are configured to use a VPC, SageMaker downloads and uploads customer data and model artifacts through the specified VPC, but the training container does not have network access.</p>
    pub fn enable_network_isolation(&self) -> bool {
        self.enable_network_isolation
    }
    /// <p>To encrypt all communications between ML compute instances in distributed training, choose <code>True</code>. Encryption provides greater security for distributed training, but training might take longer. How long it takes depends on the amount of communication between compute instances, especially if you use a deep learning algorithms in distributed training.</p>
    pub fn enable_inter_container_traffic_encryption(&self) -> bool {
        self.enable_inter_container_traffic_encryption
    }
    /// <p>A Boolean indicating whether managed spot training is enabled (<code>True</code>) or not (<code>False</code>).</p>
    pub fn enable_managed_spot_training(&self) -> bool {
        self.enable_managed_spot_training
    }
    /// <p>Contains information about the output location for managed spot training checkpoint data. </p>
    pub fn checkpoint_config(&self) -> std::option::Option<& crate::types::CheckpointConfig> {
        self.checkpoint_config.as_ref()
    }
    /// <p>The training time in seconds.</p>
    pub fn training_time_in_seconds(&self) -> std::option::Option<i32> {
        self.training_time_in_seconds
    }
    /// <p>The billable time in seconds. Billable time refers to the absolute wall-clock time.</p> 
    /// <p>Multiply <code>BillableTimeInSeconds</code> by the number of instances (<code>InstanceCount</code>) in your training cluster to get the total compute time SageMaker bills you if you run distributed training. The formula is as follows: <code>BillableTimeInSeconds * InstanceCount</code> .</p> 
    /// <p>You can calculate the savings from using managed spot training using the formula <code>(1 - BillableTimeInSeconds / TrainingTimeInSeconds) * 100</code>. For example, if <code>BillableTimeInSeconds</code> is 100 and <code>TrainingTimeInSeconds</code> is 500, the savings is 80%.</p>
    pub fn billable_time_in_seconds(&self) -> std::option::Option<i32> {
        self.billable_time_in_seconds
    }
    /// <p>Configuration information for the Amazon SageMaker Debugger hook parameters, metric and tensor collections, and storage paths. To learn more about how to configure the <code>DebugHookConfig</code> parameter, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-createtrainingjob-api.html">Use the SageMaker and Debugger Configuration API Operations to Create, Update, and Debug Your Training Job</a>.</p>
    pub fn debug_hook_config(&self) -> std::option::Option<& crate::types::DebugHookConfig> {
        self.debug_hook_config.as_ref()
    }
    /// <p>Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs:</p> 
    /// <ul> 
    /// <li> <p> <code>CreateProcessingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTrainingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTransformJob</code> </p> </li> 
    /// </ul>
    pub fn experiment_config(&self) -> std::option::Option<& crate::types::ExperimentConfig> {
        self.experiment_config.as_ref()
    }
    /// <p>Configuration information for Amazon SageMaker Debugger rules for debugging output tensors.</p>
    pub fn debug_rule_configurations(&self) -> std::option::Option<& [crate::types::DebugRuleConfiguration]> {
        self.debug_rule_configurations.as_deref()
    }
    /// <p>Configuration of storage locations for the Amazon SageMaker Debugger TensorBoard output data.</p>
    pub fn tensor_board_output_config(&self) -> std::option::Option<& crate::types::TensorBoardOutputConfig> {
        self.tensor_board_output_config.as_ref()
    }
    /// <p>Evaluation status of Amazon SageMaker Debugger rules for debugging on a training job.</p>
    pub fn debug_rule_evaluation_statuses(&self) -> std::option::Option<& [crate::types::DebugRuleEvaluationStatus]> {
        self.debug_rule_evaluation_statuses.as_deref()
    }
    /// <p>Configuration information for Amazon SageMaker Debugger system monitoring, framework profiling, and storage paths.</p>
    pub fn profiler_config(&self) -> std::option::Option<& crate::types::ProfilerConfig> {
        self.profiler_config.as_ref()
    }
    /// <p>Configuration information for Amazon SageMaker Debugger rules for profiling system and framework metrics.</p>
    pub fn profiler_rule_configurations(&self) -> std::option::Option<& [crate::types::ProfilerRuleConfiguration]> {
        self.profiler_rule_configurations.as_deref()
    }
    /// <p>Evaluation status of Amazon SageMaker Debugger rules for profiling on a training job.</p>
    pub fn profiler_rule_evaluation_statuses(&self) -> std::option::Option<& [crate::types::ProfilerRuleEvaluationStatus]> {
        self.profiler_rule_evaluation_statuses.as_deref()
    }
    /// <p>Profiling status of a training job.</p>
    pub fn profiling_status(&self) -> std::option::Option<& crate::types::ProfilingStatus> {
        self.profiling_status.as_ref()
    }
    /// <p>The number of times to retry the job when the job fails due to an <code>InternalServerError</code>.</p>
    pub fn retry_strategy(&self) -> std::option::Option<& crate::types::RetryStrategy> {
        self.retry_strategy.as_ref()
    }
    /// <p>The environment variables to set in the Docker container.</p>
    pub fn environment(&self) -> std::option::Option<& std::collections::HashMap<std::string::String, std::string::String>> {
        self.environment.as_ref()
    }
    /// <p>The status of the warm pool associated with the training job.</p>
    pub fn warm_pool_status(&self) -> std::option::Option<& crate::types::WarmPoolStatus> {
        self.warm_pool_status.as_ref()
    }
}
impl aws_http::request_id::RequestId for DescribeTrainingJobOutput {
                                fn request_id(&self) -> Option<&str> {
                                    self._request_id.as_deref()
                                }
                            }
impl DescribeTrainingJobOutput {
    /// Creates a new builder-style object to manufacture [`DescribeTrainingJobOutput`](crate::operation::describe_training_job::DescribeTrainingJobOutput).
    pub fn builder() -> crate::operation::describe_training_job::builders::DescribeTrainingJobOutputBuilder {
        crate::operation::describe_training_job::builders::DescribeTrainingJobOutputBuilder::default()
    }
}

/// A builder for [`DescribeTrainingJobOutput`](crate::operation::describe_training_job::DescribeTrainingJobOutput).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct DescribeTrainingJobOutputBuilder {
    pub(crate) training_job_name: std::option::Option<std::string::String>,
    pub(crate) training_job_arn: std::option::Option<std::string::String>,
    pub(crate) tuning_job_arn: std::option::Option<std::string::String>,
    pub(crate) labeling_job_arn: std::option::Option<std::string::String>,
    pub(crate) auto_ml_job_arn: std::option::Option<std::string::String>,
    pub(crate) model_artifacts: std::option::Option<crate::types::ModelArtifacts>,
    pub(crate) training_job_status: std::option::Option<crate::types::TrainingJobStatus>,
    pub(crate) secondary_status: std::option::Option<crate::types::SecondaryStatus>,
    pub(crate) failure_reason: std::option::Option<std::string::String>,
    pub(crate) hyper_parameters: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    pub(crate) algorithm_specification: std::option::Option<crate::types::AlgorithmSpecification>,
    pub(crate) role_arn: std::option::Option<std::string::String>,
    pub(crate) input_data_config: std::option::Option<std::vec::Vec<crate::types::Channel>>,
    pub(crate) output_data_config: std::option::Option<crate::types::OutputDataConfig>,
    pub(crate) resource_config: std::option::Option<crate::types::ResourceConfig>,
    pub(crate) vpc_config: std::option::Option<crate::types::VpcConfig>,
    pub(crate) stopping_condition: std::option::Option<crate::types::StoppingCondition>,
    pub(crate) creation_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) training_start_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) training_end_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) last_modified_time: std::option::Option<aws_smithy_types::DateTime>,
    pub(crate) secondary_status_transitions: std::option::Option<std::vec::Vec<crate::types::SecondaryStatusTransition>>,
    pub(crate) final_metric_data_list: std::option::Option<std::vec::Vec<crate::types::MetricData>>,
    pub(crate) enable_network_isolation: std::option::Option<bool>,
    pub(crate) enable_inter_container_traffic_encryption: std::option::Option<bool>,
    pub(crate) enable_managed_spot_training: std::option::Option<bool>,
    pub(crate) checkpoint_config: std::option::Option<crate::types::CheckpointConfig>,
    pub(crate) training_time_in_seconds: std::option::Option<i32>,
    pub(crate) billable_time_in_seconds: std::option::Option<i32>,
    pub(crate) debug_hook_config: std::option::Option<crate::types::DebugHookConfig>,
    pub(crate) experiment_config: std::option::Option<crate::types::ExperimentConfig>,
    pub(crate) debug_rule_configurations: std::option::Option<std::vec::Vec<crate::types::DebugRuleConfiguration>>,
    pub(crate) tensor_board_output_config: std::option::Option<crate::types::TensorBoardOutputConfig>,
    pub(crate) debug_rule_evaluation_statuses: std::option::Option<std::vec::Vec<crate::types::DebugRuleEvaluationStatus>>,
    pub(crate) profiler_config: std::option::Option<crate::types::ProfilerConfig>,
    pub(crate) profiler_rule_configurations: std::option::Option<std::vec::Vec<crate::types::ProfilerRuleConfiguration>>,
    pub(crate) profiler_rule_evaluation_statuses: std::option::Option<std::vec::Vec<crate::types::ProfilerRuleEvaluationStatus>>,
    pub(crate) profiling_status: std::option::Option<crate::types::ProfilingStatus>,
    pub(crate) retry_strategy: std::option::Option<crate::types::RetryStrategy>,
    pub(crate) environment: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    pub(crate) warm_pool_status: std::option::Option<crate::types::WarmPoolStatus>,
    _request_id: Option<String>,
}
impl DescribeTrainingJobOutputBuilder {
    /// <p> Name of the model training job. </p>
    pub fn training_job_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.training_job_name = Some(input.into());
        self
    }
    /// <p> Name of the model training job. </p>
    pub fn set_training_job_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.training_job_name = input; self
    }
    /// <p>The Amazon Resource Name (ARN) of the training job.</p>
    pub fn training_job_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.training_job_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the training job.</p>
    pub fn set_training_job_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.training_job_arn = input; self
    }
    /// <p>The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the training job was launched by a hyperparameter tuning job.</p>
    pub fn tuning_job_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.tuning_job_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the training job was launched by a hyperparameter tuning job.</p>
    pub fn set_tuning_job_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.tuning_job_arn = input; self
    }
    /// <p>The Amazon Resource Name (ARN) of the SageMaker Ground Truth labeling job that created the transform or training job.</p>
    pub fn labeling_job_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.labeling_job_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the SageMaker Ground Truth labeling job that created the transform or training job.</p>
    pub fn set_labeling_job_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.labeling_job_arn = input; self
    }
    /// <p>The Amazon Resource Name (ARN) of an AutoML job.</p>
    pub fn auto_ml_job_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.auto_ml_job_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of an AutoML job.</p>
    pub fn set_auto_ml_job_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.auto_ml_job_arn = input; self
    }
    /// <p>Information about the Amazon S3 location that is configured for storing model artifacts. </p>
    pub fn model_artifacts(mut self, input: crate::types::ModelArtifacts) -> Self {
        self.model_artifacts = Some(input);
        self
    }
    /// <p>Information about the Amazon S3 location that is configured for storing model artifacts. </p>
    pub fn set_model_artifacts(mut self, input: std::option::Option<crate::types::ModelArtifacts>) -> Self {
        self.model_artifacts = input; self
    }
    /// <p>The status of the training job.</p> 
    /// <p>SageMaker provides the following training job statuses:</p> 
    /// <ul> 
    /// <li> <p> <code>InProgress</code> - The training is in progress.</p> </li> 
    /// <li> <p> <code>Completed</code> - The training job has completed.</p> </li> 
    /// <li> <p> <code>Failed</code> - The training job has failed. To see the reason for the failure, see the <code>FailureReason</code> field in the response to a <code>DescribeTrainingJobResponse</code> call.</p> </li> 
    /// <li> <p> <code>Stopping</code> - The training job is stopping.</p> </li> 
    /// <li> <p> <code>Stopped</code> - The training job has stopped.</p> </li> 
    /// </ul> 
    /// <p>For more detailed information, see <code>SecondaryStatus</code>. </p>
    pub fn training_job_status(mut self, input: crate::types::TrainingJobStatus) -> Self {
        self.training_job_status = Some(input);
        self
    }
    /// <p>The status of the training job.</p> 
    /// <p>SageMaker provides the following training job statuses:</p> 
    /// <ul> 
    /// <li> <p> <code>InProgress</code> - The training is in progress.</p> </li> 
    /// <li> <p> <code>Completed</code> - The training job has completed.</p> </li> 
    /// <li> <p> <code>Failed</code> - The training job has failed. To see the reason for the failure, see the <code>FailureReason</code> field in the response to a <code>DescribeTrainingJobResponse</code> call.</p> </li> 
    /// <li> <p> <code>Stopping</code> - The training job is stopping.</p> </li> 
    /// <li> <p> <code>Stopped</code> - The training job has stopped.</p> </li> 
    /// </ul> 
    /// <p>For more detailed information, see <code>SecondaryStatus</code>. </p>
    pub fn set_training_job_status(mut self, input: std::option::Option<crate::types::TrainingJobStatus>) -> Self {
        self.training_job_status = input; self
    }
    /// <p> Provides detailed information about the state of the training job. For detailed information on the secondary status of the training job, see <code>StatusMessage</code> under <code>SecondaryStatusTransition</code>.</p> 
    /// <p>SageMaker provides primary statuses and secondary statuses that apply to each of them:</p> 
    /// <dl> 
    /// <dt>
    /// InProgress
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Starting</code> - Starting the training job.</p> </li> 
    /// <li> <p> <code>Downloading</code> - An optional stage for algorithms that support <code>File</code> training input mode. It indicates that data is being downloaded to the ML storage volumes.</p> </li> 
    /// <li> <p> <code>Training</code> - Training is in progress.</p> </li> 
    /// <li> <p> <code>Interrupted</code> - The job stopped because the managed spot training instances were interrupted. </p> </li> 
    /// <li> <p> <code>Uploading</code> - Training is complete and the model artifacts are being uploaded to the S3 location.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Completed
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Completed</code> - The training job has completed.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Failed
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Failed</code> - The training job has failed. The reason for the failure is returned in the <code>FailureReason</code> field of <code>DescribeTrainingJobResponse</code>.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Stopped
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>MaxRuntimeExceeded</code> - The job stopped because it exceeded the maximum allowed runtime.</p> </li> 
    /// <li> <p> <code>MaxWaitTimeExceeded</code> - The job stopped because it exceeded the maximum allowed wait time.</p> </li> 
    /// <li> <p> <code>Stopped</code> - The training job has stopped.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Stopping
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Stopping</code> - Stopping the training job.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// </dl> <important> 
    /// <p>Valid values for <code>SecondaryStatus</code> are subject to change. </p> 
    /// </important> 
    /// <p>We no longer support the following secondary statuses:</p> 
    /// <ul> 
    /// <li> <p> <code>LaunchingMLInstances</code> </p> </li> 
    /// <li> <p> <code>PreparingTraining</code> </p> </li> 
    /// <li> <p> <code>DownloadingTrainingImage</code> </p> </li> 
    /// </ul>
    pub fn secondary_status(mut self, input: crate::types::SecondaryStatus) -> Self {
        self.secondary_status = Some(input);
        self
    }
    /// <p> Provides detailed information about the state of the training job. For detailed information on the secondary status of the training job, see <code>StatusMessage</code> under <code>SecondaryStatusTransition</code>.</p> 
    /// <p>SageMaker provides primary statuses and secondary statuses that apply to each of them:</p> 
    /// <dl> 
    /// <dt>
    /// InProgress
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Starting</code> - Starting the training job.</p> </li> 
    /// <li> <p> <code>Downloading</code> - An optional stage for algorithms that support <code>File</code> training input mode. It indicates that data is being downloaded to the ML storage volumes.</p> </li> 
    /// <li> <p> <code>Training</code> - Training is in progress.</p> </li> 
    /// <li> <p> <code>Interrupted</code> - The job stopped because the managed spot training instances were interrupted. </p> </li> 
    /// <li> <p> <code>Uploading</code> - Training is complete and the model artifacts are being uploaded to the S3 location.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Completed
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Completed</code> - The training job has completed.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Failed
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Failed</code> - The training job has failed. The reason for the failure is returned in the <code>FailureReason</code> field of <code>DescribeTrainingJobResponse</code>.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Stopped
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>MaxRuntimeExceeded</code> - The job stopped because it exceeded the maximum allowed runtime.</p> </li> 
    /// <li> <p> <code>MaxWaitTimeExceeded</code> - The job stopped because it exceeded the maximum allowed wait time.</p> </li> 
    /// <li> <p> <code>Stopped</code> - The training job has stopped.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// <dt>
    /// Stopping
    /// </dt> 
    /// <dd> 
    /// <ul> 
    /// <li> <p> <code>Stopping</code> - Stopping the training job.</p> </li> 
    /// </ul> 
    /// </dd> 
    /// </dl> <important> 
    /// <p>Valid values for <code>SecondaryStatus</code> are subject to change. </p> 
    /// </important> 
    /// <p>We no longer support the following secondary statuses:</p> 
    /// <ul> 
    /// <li> <p> <code>LaunchingMLInstances</code> </p> </li> 
    /// <li> <p> <code>PreparingTraining</code> </p> </li> 
    /// <li> <p> <code>DownloadingTrainingImage</code> </p> </li> 
    /// </ul>
    pub fn set_secondary_status(mut self, input: std::option::Option<crate::types::SecondaryStatus>) -> Self {
        self.secondary_status = input; self
    }
    /// <p>If the training job failed, the reason it failed. </p>
    pub fn failure_reason(mut self, input: impl Into<std::string::String>) -> Self {
        self.failure_reason = Some(input.into());
        self
    }
    /// <p>If the training job failed, the reason it failed. </p>
    pub fn set_failure_reason(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.failure_reason = input; self
    }
    /// Adds a key-value pair to `hyper_parameters`.
    ///
    /// To override the contents of this collection use [`set_hyper_parameters`](Self::set_hyper_parameters).
    ///
    /// <p>Algorithm-specific parameters. </p>
    pub fn hyper_parameters(mut self, k: impl Into<std::string::String>, v: impl Into<std::string::String>) -> Self {
        let mut hash_map = self.hyper_parameters.unwrap_or_default();
                        hash_map.insert(k.into(), v.into());
                        self.hyper_parameters = Some(hash_map);
                        self
    }
    /// <p>Algorithm-specific parameters. </p>
    pub fn set_hyper_parameters(mut self, input: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>) -> Self {
        self.hyper_parameters = input; self
    }
    /// <p>Information about the algorithm used for training, and algorithm metadata. </p>
    pub fn algorithm_specification(mut self, input: crate::types::AlgorithmSpecification) -> Self {
        self.algorithm_specification = Some(input);
        self
    }
    /// <p>Information about the algorithm used for training, and algorithm metadata. </p>
    pub fn set_algorithm_specification(mut self, input: std::option::Option<crate::types::AlgorithmSpecification>) -> Self {
        self.algorithm_specification = input; self
    }
    /// <p>The Amazon Web Services Identity and Access Management (IAM) role configured for the training job. </p>
    pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.role_arn = Some(input.into());
        self
    }
    /// <p>The Amazon Web Services Identity and Access Management (IAM) role configured for the training job. </p>
    pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.role_arn = input; self
    }
    /// Appends an item to `input_data_config`.
    ///
    /// To override the contents of this collection use [`set_input_data_config`](Self::set_input_data_config).
    ///
    /// <p>An array of <code>Channel</code> objects that describes each data input channel. </p>
    pub fn input_data_config(mut self, input: crate::types::Channel) -> Self {
        let mut v = self.input_data_config.unwrap_or_default();
                        v.push(input);
                        self.input_data_config = Some(v);
                        self
    }
    /// <p>An array of <code>Channel</code> objects that describes each data input channel. </p>
    pub fn set_input_data_config(mut self, input: std::option::Option<std::vec::Vec<crate::types::Channel>>) -> Self {
        self.input_data_config = input; self
    }
    /// <p>The S3 path where model artifacts that you configured when creating the job are stored. SageMaker creates subfolders for model artifacts. </p>
    pub fn output_data_config(mut self, input: crate::types::OutputDataConfig) -> Self {
        self.output_data_config = Some(input);
        self
    }
    /// <p>The S3 path where model artifacts that you configured when creating the job are stored. SageMaker creates subfolders for model artifacts. </p>
    pub fn set_output_data_config(mut self, input: std::option::Option<crate::types::OutputDataConfig>) -> Self {
        self.output_data_config = input; self
    }
    /// <p>Resources, including ML compute instances and ML storage volumes, that are configured for model training. </p>
    pub fn resource_config(mut self, input: crate::types::ResourceConfig) -> Self {
        self.resource_config = Some(input);
        self
    }
    /// <p>Resources, including ML compute instances and ML storage volumes, that are configured for model training. </p>
    pub fn set_resource_config(mut self, input: std::option::Option<crate::types::ResourceConfig>) -> Self {
        self.resource_config = input; self
    }
    /// <p>A <code>VpcConfig</code> object that specifies the VPC that this training job has access to. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html">Protect Training Jobs by Using an Amazon Virtual Private Cloud</a>.</p>
    pub fn vpc_config(mut self, input: crate::types::VpcConfig) -> Self {
        self.vpc_config = Some(input);
        self
    }
    /// <p>A <code>VpcConfig</code> object that specifies the VPC that this training job has access to. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html">Protect Training Jobs by Using an Amazon Virtual Private Cloud</a>.</p>
    pub fn set_vpc_config(mut self, input: std::option::Option<crate::types::VpcConfig>) -> Self {
        self.vpc_config = input; self
    }
    /// <p>Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, SageMaker ends the training job. Use this API to cap model training costs.</p> 
    /// <p>To stop a job, SageMaker sends the algorithm the <code>SIGTERM</code> signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts, so the results of training are not lost. </p>
    pub fn stopping_condition(mut self, input: crate::types::StoppingCondition) -> Self {
        self.stopping_condition = Some(input);
        self
    }
    /// <p>Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, SageMaker ends the training job. Use this API to cap model training costs.</p> 
    /// <p>To stop a job, SageMaker sends the algorithm the <code>SIGTERM</code> signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts, so the results of training are not lost. </p>
    pub fn set_stopping_condition(mut self, input: std::option::Option<crate::types::StoppingCondition>) -> Self {
        self.stopping_condition = input; self
    }
    /// <p>A timestamp that indicates when the training job was created.</p>
    pub fn creation_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.creation_time = Some(input);
        self
    }
    /// <p>A timestamp that indicates when the training job was created.</p>
    pub fn set_creation_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.creation_time = input; self
    }
    /// <p>Indicates the time when the training job starts on training instances. You are billed for the time interval between this time and the value of <code>TrainingEndTime</code>. The start time in CloudWatch Logs might be later than this time. The difference is due to the time it takes to download the training data and to the size of the training container.</p>
    pub fn training_start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.training_start_time = Some(input);
        self
    }
    /// <p>Indicates the time when the training job starts on training instances. You are billed for the time interval between this time and the value of <code>TrainingEndTime</code>. The start time in CloudWatch Logs might be later than this time. The difference is due to the time it takes to download the training data and to the size of the training container.</p>
    pub fn set_training_start_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.training_start_time = input; self
    }
    /// <p>Indicates the time when the training job ends on training instances. You are billed for the time interval between the value of <code>TrainingStartTime</code> and this time. For successful jobs and stopped jobs, this is the time after model artifacts are uploaded. For failed jobs, this is the time when SageMaker detects a job failure.</p>
    pub fn training_end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.training_end_time = Some(input);
        self
    }
    /// <p>Indicates the time when the training job ends on training instances. You are billed for the time interval between the value of <code>TrainingStartTime</code> and this time. For successful jobs and stopped jobs, this is the time after model artifacts are uploaded. For failed jobs, this is the time when SageMaker detects a job failure.</p>
    pub fn set_training_end_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.training_end_time = input; self
    }
    /// <p>A timestamp that indicates when the status of the training job was last modified.</p>
    pub fn last_modified_time(mut self, input: aws_smithy_types::DateTime) -> Self {
        self.last_modified_time = Some(input);
        self
    }
    /// <p>A timestamp that indicates when the status of the training job was last modified.</p>
    pub fn set_last_modified_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
        self.last_modified_time = input; self
    }
    /// Appends an item to `secondary_status_transitions`.
    ///
    /// To override the contents of this collection use [`set_secondary_status_transitions`](Self::set_secondary_status_transitions).
    ///
    /// <p>A history of all of the secondary statuses that the training job has transitioned through.</p>
    pub fn secondary_status_transitions(mut self, input: crate::types::SecondaryStatusTransition) -> Self {
        let mut v = self.secondary_status_transitions.unwrap_or_default();
                        v.push(input);
                        self.secondary_status_transitions = Some(v);
                        self
    }
    /// <p>A history of all of the secondary statuses that the training job has transitioned through.</p>
    pub fn set_secondary_status_transitions(mut self, input: std::option::Option<std::vec::Vec<crate::types::SecondaryStatusTransition>>) -> Self {
        self.secondary_status_transitions = input; self
    }
    /// Appends an item to `final_metric_data_list`.
    ///
    /// To override the contents of this collection use [`set_final_metric_data_list`](Self::set_final_metric_data_list).
    ///
    /// <p>A collection of <code>MetricData</code> objects that specify the names, values, and dates and times that the training algorithm emitted to Amazon CloudWatch.</p>
    pub fn final_metric_data_list(mut self, input: crate::types::MetricData) -> Self {
        let mut v = self.final_metric_data_list.unwrap_or_default();
                        v.push(input);
                        self.final_metric_data_list = Some(v);
                        self
    }
    /// <p>A collection of <code>MetricData</code> objects that specify the names, values, and dates and times that the training algorithm emitted to Amazon CloudWatch.</p>
    pub fn set_final_metric_data_list(mut self, input: std::option::Option<std::vec::Vec<crate::types::MetricData>>) -> Self {
        self.final_metric_data_list = input; self
    }
    /// <p>If you want to allow inbound or outbound network calls, except for calls between peers within a training cluster for distributed training, choose <code>True</code>. If you enable network isolation for training jobs that are configured to use a VPC, SageMaker downloads and uploads customer data and model artifacts through the specified VPC, but the training container does not have network access.</p>
    pub fn enable_network_isolation(mut self, input: bool) -> Self {
        self.enable_network_isolation = Some(input);
        self
    }
    /// <p>If you want to allow inbound or outbound network calls, except for calls between peers within a training cluster for distributed training, choose <code>True</code>. If you enable network isolation for training jobs that are configured to use a VPC, SageMaker downloads and uploads customer data and model artifacts through the specified VPC, but the training container does not have network access.</p>
    pub fn set_enable_network_isolation(mut self, input: std::option::Option<bool>) -> Self {
        self.enable_network_isolation = input; self
    }
    /// <p>To encrypt all communications between ML compute instances in distributed training, choose <code>True</code>. Encryption provides greater security for distributed training, but training might take longer. How long it takes depends on the amount of communication between compute instances, especially if you use a deep learning algorithms in distributed training.</p>
    pub fn enable_inter_container_traffic_encryption(mut self, input: bool) -> Self {
        self.enable_inter_container_traffic_encryption = Some(input);
        self
    }
    /// <p>To encrypt all communications between ML compute instances in distributed training, choose <code>True</code>. Encryption provides greater security for distributed training, but training might take longer. How long it takes depends on the amount of communication between compute instances, especially if you use a deep learning algorithms in distributed training.</p>
    pub fn set_enable_inter_container_traffic_encryption(mut self, input: std::option::Option<bool>) -> Self {
        self.enable_inter_container_traffic_encryption = input; self
    }
    /// <p>A Boolean indicating whether managed spot training is enabled (<code>True</code>) or not (<code>False</code>).</p>
    pub fn enable_managed_spot_training(mut self, input: bool) -> Self {
        self.enable_managed_spot_training = Some(input);
        self
    }
    /// <p>A Boolean indicating whether managed spot training is enabled (<code>True</code>) or not (<code>False</code>).</p>
    pub fn set_enable_managed_spot_training(mut self, input: std::option::Option<bool>) -> Self {
        self.enable_managed_spot_training = input; self
    }
    /// <p>Contains information about the output location for managed spot training checkpoint data. </p>
    pub fn checkpoint_config(mut self, input: crate::types::CheckpointConfig) -> Self {
        self.checkpoint_config = Some(input);
        self
    }
    /// <p>Contains information about the output location for managed spot training checkpoint data. </p>
    pub fn set_checkpoint_config(mut self, input: std::option::Option<crate::types::CheckpointConfig>) -> Self {
        self.checkpoint_config = input; self
    }
    /// <p>The training time in seconds.</p>
    pub fn training_time_in_seconds(mut self, input: i32) -> Self {
        self.training_time_in_seconds = Some(input);
        self
    }
    /// <p>The training time in seconds.</p>
    pub fn set_training_time_in_seconds(mut self, input: std::option::Option<i32>) -> Self {
        self.training_time_in_seconds = input; self
    }
    /// <p>The billable time in seconds. Billable time refers to the absolute wall-clock time.</p> 
    /// <p>Multiply <code>BillableTimeInSeconds</code> by the number of instances (<code>InstanceCount</code>) in your training cluster to get the total compute time SageMaker bills you if you run distributed training. The formula is as follows: <code>BillableTimeInSeconds * InstanceCount</code> .</p> 
    /// <p>You can calculate the savings from using managed spot training using the formula <code>(1 - BillableTimeInSeconds / TrainingTimeInSeconds) * 100</code>. For example, if <code>BillableTimeInSeconds</code> is 100 and <code>TrainingTimeInSeconds</code> is 500, the savings is 80%.</p>
    pub fn billable_time_in_seconds(mut self, input: i32) -> Self {
        self.billable_time_in_seconds = Some(input);
        self
    }
    /// <p>The billable time in seconds. Billable time refers to the absolute wall-clock time.</p> 
    /// <p>Multiply <code>BillableTimeInSeconds</code> by the number of instances (<code>InstanceCount</code>) in your training cluster to get the total compute time SageMaker bills you if you run distributed training. The formula is as follows: <code>BillableTimeInSeconds * InstanceCount</code> .</p> 
    /// <p>You can calculate the savings from using managed spot training using the formula <code>(1 - BillableTimeInSeconds / TrainingTimeInSeconds) * 100</code>. For example, if <code>BillableTimeInSeconds</code> is 100 and <code>TrainingTimeInSeconds</code> is 500, the savings is 80%.</p>
    pub fn set_billable_time_in_seconds(mut self, input: std::option::Option<i32>) -> Self {
        self.billable_time_in_seconds = input; self
    }
    /// <p>Configuration information for the Amazon SageMaker Debugger hook parameters, metric and tensor collections, and storage paths. To learn more about how to configure the <code>DebugHookConfig</code> parameter, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-createtrainingjob-api.html">Use the SageMaker and Debugger Configuration API Operations to Create, Update, and Debug Your Training Job</a>.</p>
    pub fn debug_hook_config(mut self, input: crate::types::DebugHookConfig) -> Self {
        self.debug_hook_config = Some(input);
        self
    }
    /// <p>Configuration information for the Amazon SageMaker Debugger hook parameters, metric and tensor collections, and storage paths. To learn more about how to configure the <code>DebugHookConfig</code> parameter, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-createtrainingjob-api.html">Use the SageMaker and Debugger Configuration API Operations to Create, Update, and Debug Your Training Job</a>.</p>
    pub fn set_debug_hook_config(mut self, input: std::option::Option<crate::types::DebugHookConfig>) -> Self {
        self.debug_hook_config = input; self
    }
    /// <p>Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs:</p> 
    /// <ul> 
    /// <li> <p> <code>CreateProcessingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTrainingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTransformJob</code> </p> </li> 
    /// </ul>
    pub fn experiment_config(mut self, input: crate::types::ExperimentConfig) -> Self {
        self.experiment_config = Some(input);
        self
    }
    /// <p>Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs:</p> 
    /// <ul> 
    /// <li> <p> <code>CreateProcessingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTrainingJob</code> </p> </li> 
    /// <li> <p> <code>CreateTransformJob</code> </p> </li> 
    /// </ul>
    pub fn set_experiment_config(mut self, input: std::option::Option<crate::types::ExperimentConfig>) -> Self {
        self.experiment_config = input; self
    }
    /// Appends an item to `debug_rule_configurations`.
    ///
    /// To override the contents of this collection use [`set_debug_rule_configurations`](Self::set_debug_rule_configurations).
    ///
    /// <p>Configuration information for Amazon SageMaker Debugger rules for debugging output tensors.</p>
    pub fn debug_rule_configurations(mut self, input: crate::types::DebugRuleConfiguration) -> Self {
        let mut v = self.debug_rule_configurations.unwrap_or_default();
                        v.push(input);
                        self.debug_rule_configurations = Some(v);
                        self
    }
    /// <p>Configuration information for Amazon SageMaker Debugger rules for debugging output tensors.</p>
    pub fn set_debug_rule_configurations(mut self, input: std::option::Option<std::vec::Vec<crate::types::DebugRuleConfiguration>>) -> Self {
        self.debug_rule_configurations = input; self
    }
    /// <p>Configuration of storage locations for the Amazon SageMaker Debugger TensorBoard output data.</p>
    pub fn tensor_board_output_config(mut self, input: crate::types::TensorBoardOutputConfig) -> Self {
        self.tensor_board_output_config = Some(input);
        self
    }
    /// <p>Configuration of storage locations for the Amazon SageMaker Debugger TensorBoard output data.</p>
    pub fn set_tensor_board_output_config(mut self, input: std::option::Option<crate::types::TensorBoardOutputConfig>) -> Self {
        self.tensor_board_output_config = input; self
    }
    /// Appends an item to `debug_rule_evaluation_statuses`.
    ///
    /// To override the contents of this collection use [`set_debug_rule_evaluation_statuses`](Self::set_debug_rule_evaluation_statuses).
    ///
    /// <p>Evaluation status of Amazon SageMaker Debugger rules for debugging on a training job.</p>
    pub fn debug_rule_evaluation_statuses(mut self, input: crate::types::DebugRuleEvaluationStatus) -> Self {
        let mut v = self.debug_rule_evaluation_statuses.unwrap_or_default();
                        v.push(input);
                        self.debug_rule_evaluation_statuses = Some(v);
                        self
    }
    /// <p>Evaluation status of Amazon SageMaker Debugger rules for debugging on a training job.</p>
    pub fn set_debug_rule_evaluation_statuses(mut self, input: std::option::Option<std::vec::Vec<crate::types::DebugRuleEvaluationStatus>>) -> Self {
        self.debug_rule_evaluation_statuses = input; self
    }
    /// <p>Configuration information for Amazon SageMaker Debugger system monitoring, framework profiling, and storage paths.</p>
    pub fn profiler_config(mut self, input: crate::types::ProfilerConfig) -> Self {
        self.profiler_config = Some(input);
        self
    }
    /// <p>Configuration information for Amazon SageMaker Debugger system monitoring, framework profiling, and storage paths.</p>
    pub fn set_profiler_config(mut self, input: std::option::Option<crate::types::ProfilerConfig>) -> Self {
        self.profiler_config = input; self
    }
    /// Appends an item to `profiler_rule_configurations`.
    ///
    /// To override the contents of this collection use [`set_profiler_rule_configurations`](Self::set_profiler_rule_configurations).
    ///
    /// <p>Configuration information for Amazon SageMaker Debugger rules for profiling system and framework metrics.</p>
    pub fn profiler_rule_configurations(mut self, input: crate::types::ProfilerRuleConfiguration) -> Self {
        let mut v = self.profiler_rule_configurations.unwrap_or_default();
                        v.push(input);
                        self.profiler_rule_configurations = Some(v);
                        self
    }
    /// <p>Configuration information for Amazon SageMaker Debugger rules for profiling system and framework metrics.</p>
    pub fn set_profiler_rule_configurations(mut self, input: std::option::Option<std::vec::Vec<crate::types::ProfilerRuleConfiguration>>) -> Self {
        self.profiler_rule_configurations = input; self
    }
    /// Appends an item to `profiler_rule_evaluation_statuses`.
    ///
    /// To override the contents of this collection use [`set_profiler_rule_evaluation_statuses`](Self::set_profiler_rule_evaluation_statuses).
    ///
    /// <p>Evaluation status of Amazon SageMaker Debugger rules for profiling on a training job.</p>
    pub fn profiler_rule_evaluation_statuses(mut self, input: crate::types::ProfilerRuleEvaluationStatus) -> Self {
        let mut v = self.profiler_rule_evaluation_statuses.unwrap_or_default();
                        v.push(input);
                        self.profiler_rule_evaluation_statuses = Some(v);
                        self
    }
    /// <p>Evaluation status of Amazon SageMaker Debugger rules for profiling on a training job.</p>
    pub fn set_profiler_rule_evaluation_statuses(mut self, input: std::option::Option<std::vec::Vec<crate::types::ProfilerRuleEvaluationStatus>>) -> Self {
        self.profiler_rule_evaluation_statuses = input; self
    }
    /// <p>Profiling status of a training job.</p>
    pub fn profiling_status(mut self, input: crate::types::ProfilingStatus) -> Self {
        self.profiling_status = Some(input);
        self
    }
    /// <p>Profiling status of a training job.</p>
    pub fn set_profiling_status(mut self, input: std::option::Option<crate::types::ProfilingStatus>) -> Self {
        self.profiling_status = input; self
    }
    /// <p>The number of times to retry the job when the job fails due to an <code>InternalServerError</code>.</p>
    pub fn retry_strategy(mut self, input: crate::types::RetryStrategy) -> Self {
        self.retry_strategy = Some(input);
        self
    }
    /// <p>The number of times to retry the job when the job fails due to an <code>InternalServerError</code>.</p>
    pub fn set_retry_strategy(mut self, input: std::option::Option<crate::types::RetryStrategy>) -> Self {
        self.retry_strategy = input; self
    }
    /// Adds a key-value pair to `environment`.
    ///
    /// To override the contents of this collection use [`set_environment`](Self::set_environment).
    ///
    /// <p>The environment variables to set in the Docker container.</p>
    pub fn environment(mut self, k: impl Into<std::string::String>, v: impl Into<std::string::String>) -> Self {
        let mut hash_map = self.environment.unwrap_or_default();
                        hash_map.insert(k.into(), v.into());
                        self.environment = Some(hash_map);
                        self
    }
    /// <p>The environment variables to set in the Docker container.</p>
    pub fn set_environment(mut self, input: std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>) -> Self {
        self.environment = input; self
    }
    /// <p>The status of the warm pool associated with the training job.</p>
    pub fn warm_pool_status(mut self, input: crate::types::WarmPoolStatus) -> Self {
        self.warm_pool_status = Some(input);
        self
    }
    /// <p>The status of the warm pool associated with the training job.</p>
    pub fn set_warm_pool_status(mut self, input: std::option::Option<crate::types::WarmPoolStatus>) -> Self {
        self.warm_pool_status = input; self
    }
    pub(crate) fn _request_id(mut self, request_id: impl Into<String>) -> Self {
                                    self._request_id = Some(request_id.into());
                                    self
                                }
    
                                pub(crate) fn _set_request_id(&mut self, request_id: Option<String>) -> &mut Self {
                                    self._request_id = request_id;
                                    self
                                }
    /// Consumes the builder and constructs a [`DescribeTrainingJobOutput`](crate::operation::describe_training_job::DescribeTrainingJobOutput).
    pub fn build(self) -> crate::operation::describe_training_job::DescribeTrainingJobOutput {
        crate::operation::describe_training_job::DescribeTrainingJobOutput {
            training_job_name: self.training_job_name
            ,
            training_job_arn: self.training_job_arn
            ,
            tuning_job_arn: self.tuning_job_arn
            ,
            labeling_job_arn: self.labeling_job_arn
            ,
            auto_ml_job_arn: self.auto_ml_job_arn
            ,
            model_artifacts: self.model_artifacts
            ,
            training_job_status: self.training_job_status
            ,
            secondary_status: self.secondary_status
            ,
            failure_reason: self.failure_reason
            ,
            hyper_parameters: self.hyper_parameters
            ,
            algorithm_specification: self.algorithm_specification
            ,
            role_arn: self.role_arn
            ,
            input_data_config: self.input_data_config
            ,
            output_data_config: self.output_data_config
            ,
            resource_config: self.resource_config
            ,
            vpc_config: self.vpc_config
            ,
            stopping_condition: self.stopping_condition
            ,
            creation_time: self.creation_time
            ,
            training_start_time: self.training_start_time
            ,
            training_end_time: self.training_end_time
            ,
            last_modified_time: self.last_modified_time
            ,
            secondary_status_transitions: self.secondary_status_transitions
            ,
            final_metric_data_list: self.final_metric_data_list
            ,
            enable_network_isolation: self.enable_network_isolation
                .unwrap_or_default()
            ,
            enable_inter_container_traffic_encryption: self.enable_inter_container_traffic_encryption
                .unwrap_or_default()
            ,
            enable_managed_spot_training: self.enable_managed_spot_training
                .unwrap_or_default()
            ,
            checkpoint_config: self.checkpoint_config
            ,
            training_time_in_seconds: self.training_time_in_seconds
            ,
            billable_time_in_seconds: self.billable_time_in_seconds
            ,
            debug_hook_config: self.debug_hook_config
            ,
            experiment_config: self.experiment_config
            ,
            debug_rule_configurations: self.debug_rule_configurations
            ,
            tensor_board_output_config: self.tensor_board_output_config
            ,
            debug_rule_evaluation_statuses: self.debug_rule_evaluation_statuses
            ,
            profiler_config: self.profiler_config
            ,
            profiler_rule_configurations: self.profiler_rule_configurations
            ,
            profiler_rule_evaluation_statuses: self.profiler_rule_evaluation_statuses
            ,
            profiling_status: self.profiling_status
            ,
            retry_strategy: self.retry_strategy
            ,
            environment: self.environment
            ,
            warm_pool_status: self.warm_pool_status
            ,
            _request_id: self._request_id,
        }
    }
}

