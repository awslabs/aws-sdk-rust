// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>The inference configuration parameter for the model container.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ClarifyInferenceConfig {
    /// <p>Provides the JMESPath expression to extract the features from a model container input in JSON Lines format. For example, if <code>FeaturesAttribute</code> is the JMESPath expression <code>'myfeatures'</code>, it extracts a list of features <code>[1,2,3]</code> from request data <code>'{"myfeatures":[1,2,3]}'</code>.</p>
    #[doc(hidden)]
    pub features_attribute: std::option::Option<std::string::String>,
    /// <p>A template string used to format a JSON record into an acceptable model container input. For example, a <code>ContentTemplate</code> string <code>'{"myfeatures":$features}'</code> will format a list of features <code>[1,2,3]</code> into the record string <code>'{"myfeatures":[1,2,3]}'</code>. Required only when the model container input is in JSON Lines format.</p>
    #[doc(hidden)]
    pub content_template: std::option::Option<std::string::String>,
    /// <p>The maximum number of records in a request that the model container can process when querying the model container for the predictions of a <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-create-endpoint.html#clarify-online-explainability-create-endpoint-synthetic">synthetic dataset</a>. A record is a unit of input data that inference can be made on, for example, a single line in CSV data. If <code>MaxRecordCount</code> is <code>1</code>, the model container expects one record per request. A value of 2 or greater means that the model expects batch requests, which can reduce overhead and speed up the inferencing process. If this parameter is not provided, the explainer will tune the record count per request according to the model container's capacity at runtime.</p>
    #[doc(hidden)]
    pub max_record_count: std::option::Option<i32>,
    /// <p>The maximum payload size (MB) allowed of a request from the explainer to the model container. Defaults to <code>6</code> MB.</p>
    #[doc(hidden)]
    pub max_payload_in_mb: std::option::Option<i32>,
    /// <p>A zero-based index used to extract a probability value (score) or list from model container output in CSV format. If this value is not provided, the entire model container output will be treated as a probability value (score) or list.</p>
    /// <p> <b>Example for a single class model:</b> If the model container output consists of a string-formatted prediction label followed by its probability: <code>'1,0.6'</code>, set <code>ProbabilityIndex</code> to <code>1</code> to select the probability value <code>0.6</code>.</p>
    /// <p> <b>Example for a multiclass model:</b> If the model container output consists of a string-formatted prediction label followed by its probability: <code>'"[\'cat\',\'dog\',\'fish\']","[0.1,0.6,0.3]"'</code>, set <code>ProbabilityIndex</code> to <code>1</code> to select the probability values <code>[0.1,0.6,0.3]</code>.</p>
    #[doc(hidden)]
    pub probability_index: std::option::Option<i32>,
    /// <p>A zero-based index used to extract a label header or list of label headers from model container output in CSV format.</p>
    /// <p> <b>Example for a multiclass model:</b> If the model container output consists of label headers followed by probabilities: <code>'"[\'cat\',\'dog\',\'fish\']","[0.1,0.6,0.3]"'</code>, set <code>LabelIndex</code> to <code>0</code> to select the label headers <code>['cat','dog','fish']</code>.</p>
    #[doc(hidden)]
    pub label_index: std::option::Option<i32>,
    /// <p>A JMESPath expression used to extract the probability (or score) from the model container output if the model container is in JSON Lines format.</p>
    /// <p> <b>Example</b>: If the model container output of a single request is <code>'{"predicted_label":1,"probability":0.6}'</code>, then set <code>ProbabilityAttribute</code> to <code>'probability'</code>.</p>
    #[doc(hidden)]
    pub probability_attribute: std::option::Option<std::string::String>,
    /// <p>A JMESPath expression used to locate the list of label headers in the model container output.</p>
    /// <p> <b>Example</b>: If the model container output of a batch request is <code>'{"labels":["cat","dog","fish"],"probability":[0.6,0.3,0.1]}'</code>, then set <code>LabelAttribute</code> to <code>'labels'</code> to extract the list of label headers <code>["cat","dog","fish"]</code> </p>
    #[doc(hidden)]
    pub label_attribute: std::option::Option<std::string::String>,
    /// <p>For multiclass classification problems, the label headers are the names of the classes. Otherwise, the label header is the name of the predicted label. These are used to help readability for the output of the <code>InvokeEndpoint</code> API. See the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information. If there are no label headers in the model container output, provide them manually using this parameter.</p>
    #[doc(hidden)]
    pub label_headers: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>The names of the features. If provided, these are included in the endpoint response payload to help readability of the <code>InvokeEndpoint</code> output. See the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">Response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information.</p>
    #[doc(hidden)]
    pub feature_headers: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>A list of data types of the features (optional). Applicable only to NLP explainability. If provided, <code>FeatureTypes</code> must have at least one <code>'text'</code> string (for example, <code>['text']</code>). If <code>FeatureTypes</code> is not provided, the explainer infers the feature types based on the baseline data. The feature types are included in the endpoint response payload. For additional information see the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information.</p>
    #[doc(hidden)]
    pub feature_types: std::option::Option<std::vec::Vec<crate::types::ClarifyFeatureType>>,
}
impl ClarifyInferenceConfig {
    /// <p>Provides the JMESPath expression to extract the features from a model container input in JSON Lines format. For example, if <code>FeaturesAttribute</code> is the JMESPath expression <code>'myfeatures'</code>, it extracts a list of features <code>[1,2,3]</code> from request data <code>'{"myfeatures":[1,2,3]}'</code>.</p>
    pub fn features_attribute(&self) -> std::option::Option<&str> {
        self.features_attribute.as_deref()
    }
    /// <p>A template string used to format a JSON record into an acceptable model container input. For example, a <code>ContentTemplate</code> string <code>'{"myfeatures":$features}'</code> will format a list of features <code>[1,2,3]</code> into the record string <code>'{"myfeatures":[1,2,3]}'</code>. Required only when the model container input is in JSON Lines format.</p>
    pub fn content_template(&self) -> std::option::Option<&str> {
        self.content_template.as_deref()
    }
    /// <p>The maximum number of records in a request that the model container can process when querying the model container for the predictions of a <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-create-endpoint.html#clarify-online-explainability-create-endpoint-synthetic">synthetic dataset</a>. A record is a unit of input data that inference can be made on, for example, a single line in CSV data. If <code>MaxRecordCount</code> is <code>1</code>, the model container expects one record per request. A value of 2 or greater means that the model expects batch requests, which can reduce overhead and speed up the inferencing process. If this parameter is not provided, the explainer will tune the record count per request according to the model container's capacity at runtime.</p>
    pub fn max_record_count(&self) -> std::option::Option<i32> {
        self.max_record_count
    }
    /// <p>The maximum payload size (MB) allowed of a request from the explainer to the model container. Defaults to <code>6</code> MB.</p>
    pub fn max_payload_in_mb(&self) -> std::option::Option<i32> {
        self.max_payload_in_mb
    }
    /// <p>A zero-based index used to extract a probability value (score) or list from model container output in CSV format. If this value is not provided, the entire model container output will be treated as a probability value (score) or list.</p>
    /// <p> <b>Example for a single class model:</b> If the model container output consists of a string-formatted prediction label followed by its probability: <code>'1,0.6'</code>, set <code>ProbabilityIndex</code> to <code>1</code> to select the probability value <code>0.6</code>.</p>
    /// <p> <b>Example for a multiclass model:</b> If the model container output consists of a string-formatted prediction label followed by its probability: <code>'"[\'cat\',\'dog\',\'fish\']","[0.1,0.6,0.3]"'</code>, set <code>ProbabilityIndex</code> to <code>1</code> to select the probability values <code>[0.1,0.6,0.3]</code>.</p>
    pub fn probability_index(&self) -> std::option::Option<i32> {
        self.probability_index
    }
    /// <p>A zero-based index used to extract a label header or list of label headers from model container output in CSV format.</p>
    /// <p> <b>Example for a multiclass model:</b> If the model container output consists of label headers followed by probabilities: <code>'"[\'cat\',\'dog\',\'fish\']","[0.1,0.6,0.3]"'</code>, set <code>LabelIndex</code> to <code>0</code> to select the label headers <code>['cat','dog','fish']</code>.</p>
    pub fn label_index(&self) -> std::option::Option<i32> {
        self.label_index
    }
    /// <p>A JMESPath expression used to extract the probability (or score) from the model container output if the model container is in JSON Lines format.</p>
    /// <p> <b>Example</b>: If the model container output of a single request is <code>'{"predicted_label":1,"probability":0.6}'</code>, then set <code>ProbabilityAttribute</code> to <code>'probability'</code>.</p>
    pub fn probability_attribute(&self) -> std::option::Option<&str> {
        self.probability_attribute.as_deref()
    }
    /// <p>A JMESPath expression used to locate the list of label headers in the model container output.</p>
    /// <p> <b>Example</b>: If the model container output of a batch request is <code>'{"labels":["cat","dog","fish"],"probability":[0.6,0.3,0.1]}'</code>, then set <code>LabelAttribute</code> to <code>'labels'</code> to extract the list of label headers <code>["cat","dog","fish"]</code> </p>
    pub fn label_attribute(&self) -> std::option::Option<&str> {
        self.label_attribute.as_deref()
    }
    /// <p>For multiclass classification problems, the label headers are the names of the classes. Otherwise, the label header is the name of the predicted label. These are used to help readability for the output of the <code>InvokeEndpoint</code> API. See the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information. If there are no label headers in the model container output, provide them manually using this parameter.</p>
    pub fn label_headers(&self) -> std::option::Option<&[std::string::String]> {
        self.label_headers.as_deref()
    }
    /// <p>The names of the features. If provided, these are included in the endpoint response payload to help readability of the <code>InvokeEndpoint</code> output. See the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">Response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information.</p>
    pub fn feature_headers(&self) -> std::option::Option<&[std::string::String]> {
        self.feature_headers.as_deref()
    }
    /// <p>A list of data types of the features (optional). Applicable only to NLP explainability. If provided, <code>FeatureTypes</code> must have at least one <code>'text'</code> string (for example, <code>['text']</code>). If <code>FeatureTypes</code> is not provided, the explainer infers the feature types based on the baseline data. The feature types are included in the endpoint response payload. For additional information see the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information.</p>
    pub fn feature_types(&self) -> std::option::Option<&[crate::types::ClarifyFeatureType]> {
        self.feature_types.as_deref()
    }
}
impl ClarifyInferenceConfig {
    /// Creates a new builder-style object to manufacture [`ClarifyInferenceConfig`](crate::types::ClarifyInferenceConfig).
    pub fn builder() -> crate::types::builders::ClarifyInferenceConfigBuilder {
        crate::types::builders::ClarifyInferenceConfigBuilder::default()
    }
}

/// A builder for [`ClarifyInferenceConfig`](crate::types::ClarifyInferenceConfig).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct ClarifyInferenceConfigBuilder {
    pub(crate) features_attribute: std::option::Option<std::string::String>,
    pub(crate) content_template: std::option::Option<std::string::String>,
    pub(crate) max_record_count: std::option::Option<i32>,
    pub(crate) max_payload_in_mb: std::option::Option<i32>,
    pub(crate) probability_index: std::option::Option<i32>,
    pub(crate) label_index: std::option::Option<i32>,
    pub(crate) probability_attribute: std::option::Option<std::string::String>,
    pub(crate) label_attribute: std::option::Option<std::string::String>,
    pub(crate) label_headers: std::option::Option<std::vec::Vec<std::string::String>>,
    pub(crate) feature_headers: std::option::Option<std::vec::Vec<std::string::String>>,
    pub(crate) feature_types: std::option::Option<std::vec::Vec<crate::types::ClarifyFeatureType>>,
}
impl ClarifyInferenceConfigBuilder {
    /// <p>Provides the JMESPath expression to extract the features from a model container input in JSON Lines format. For example, if <code>FeaturesAttribute</code> is the JMESPath expression <code>'myfeatures'</code>, it extracts a list of features <code>[1,2,3]</code> from request data <code>'{"myfeatures":[1,2,3]}'</code>.</p>
    pub fn features_attribute(mut self, input: impl Into<std::string::String>) -> Self {
        self.features_attribute = Some(input.into());
        self
    }
    /// <p>Provides the JMESPath expression to extract the features from a model container input in JSON Lines format. For example, if <code>FeaturesAttribute</code> is the JMESPath expression <code>'myfeatures'</code>, it extracts a list of features <code>[1,2,3]</code> from request data <code>'{"myfeatures":[1,2,3]}'</code>.</p>
    pub fn set_features_attribute(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.features_attribute = input;
        self
    }
    /// <p>A template string used to format a JSON record into an acceptable model container input. For example, a <code>ContentTemplate</code> string <code>'{"myfeatures":$features}'</code> will format a list of features <code>[1,2,3]</code> into the record string <code>'{"myfeatures":[1,2,3]}'</code>. Required only when the model container input is in JSON Lines format.</p>
    pub fn content_template(mut self, input: impl Into<std::string::String>) -> Self {
        self.content_template = Some(input.into());
        self
    }
    /// <p>A template string used to format a JSON record into an acceptable model container input. For example, a <code>ContentTemplate</code> string <code>'{"myfeatures":$features}'</code> will format a list of features <code>[1,2,3]</code> into the record string <code>'{"myfeatures":[1,2,3]}'</code>. Required only when the model container input is in JSON Lines format.</p>
    pub fn set_content_template(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.content_template = input;
        self
    }
    /// <p>The maximum number of records in a request that the model container can process when querying the model container for the predictions of a <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-create-endpoint.html#clarify-online-explainability-create-endpoint-synthetic">synthetic dataset</a>. A record is a unit of input data that inference can be made on, for example, a single line in CSV data. If <code>MaxRecordCount</code> is <code>1</code>, the model container expects one record per request. A value of 2 or greater means that the model expects batch requests, which can reduce overhead and speed up the inferencing process. If this parameter is not provided, the explainer will tune the record count per request according to the model container's capacity at runtime.</p>
    pub fn max_record_count(mut self, input: i32) -> Self {
        self.max_record_count = Some(input);
        self
    }
    /// <p>The maximum number of records in a request that the model container can process when querying the model container for the predictions of a <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-create-endpoint.html#clarify-online-explainability-create-endpoint-synthetic">synthetic dataset</a>. A record is a unit of input data that inference can be made on, for example, a single line in CSV data. If <code>MaxRecordCount</code> is <code>1</code>, the model container expects one record per request. A value of 2 or greater means that the model expects batch requests, which can reduce overhead and speed up the inferencing process. If this parameter is not provided, the explainer will tune the record count per request according to the model container's capacity at runtime.</p>
    pub fn set_max_record_count(mut self, input: std::option::Option<i32>) -> Self {
        self.max_record_count = input;
        self
    }
    /// <p>The maximum payload size (MB) allowed of a request from the explainer to the model container. Defaults to <code>6</code> MB.</p>
    pub fn max_payload_in_mb(mut self, input: i32) -> Self {
        self.max_payload_in_mb = Some(input);
        self
    }
    /// <p>The maximum payload size (MB) allowed of a request from the explainer to the model container. Defaults to <code>6</code> MB.</p>
    pub fn set_max_payload_in_mb(mut self, input: std::option::Option<i32>) -> Self {
        self.max_payload_in_mb = input;
        self
    }
    /// <p>A zero-based index used to extract a probability value (score) or list from model container output in CSV format. If this value is not provided, the entire model container output will be treated as a probability value (score) or list.</p>
    /// <p> <b>Example for a single class model:</b> If the model container output consists of a string-formatted prediction label followed by its probability: <code>'1,0.6'</code>, set <code>ProbabilityIndex</code> to <code>1</code> to select the probability value <code>0.6</code>.</p>
    /// <p> <b>Example for a multiclass model:</b> If the model container output consists of a string-formatted prediction label followed by its probability: <code>'"[\'cat\',\'dog\',\'fish\']","[0.1,0.6,0.3]"'</code>, set <code>ProbabilityIndex</code> to <code>1</code> to select the probability values <code>[0.1,0.6,0.3]</code>.</p>
    pub fn probability_index(mut self, input: i32) -> Self {
        self.probability_index = Some(input);
        self
    }
    /// <p>A zero-based index used to extract a probability value (score) or list from model container output in CSV format. If this value is not provided, the entire model container output will be treated as a probability value (score) or list.</p>
    /// <p> <b>Example for a single class model:</b> If the model container output consists of a string-formatted prediction label followed by its probability: <code>'1,0.6'</code>, set <code>ProbabilityIndex</code> to <code>1</code> to select the probability value <code>0.6</code>.</p>
    /// <p> <b>Example for a multiclass model:</b> If the model container output consists of a string-formatted prediction label followed by its probability: <code>'"[\'cat\',\'dog\',\'fish\']","[0.1,0.6,0.3]"'</code>, set <code>ProbabilityIndex</code> to <code>1</code> to select the probability values <code>[0.1,0.6,0.3]</code>.</p>
    pub fn set_probability_index(mut self, input: std::option::Option<i32>) -> Self {
        self.probability_index = input;
        self
    }
    /// <p>A zero-based index used to extract a label header or list of label headers from model container output in CSV format.</p>
    /// <p> <b>Example for a multiclass model:</b> If the model container output consists of label headers followed by probabilities: <code>'"[\'cat\',\'dog\',\'fish\']","[0.1,0.6,0.3]"'</code>, set <code>LabelIndex</code> to <code>0</code> to select the label headers <code>['cat','dog','fish']</code>.</p>
    pub fn label_index(mut self, input: i32) -> Self {
        self.label_index = Some(input);
        self
    }
    /// <p>A zero-based index used to extract a label header or list of label headers from model container output in CSV format.</p>
    /// <p> <b>Example for a multiclass model:</b> If the model container output consists of label headers followed by probabilities: <code>'"[\'cat\',\'dog\',\'fish\']","[0.1,0.6,0.3]"'</code>, set <code>LabelIndex</code> to <code>0</code> to select the label headers <code>['cat','dog','fish']</code>.</p>
    pub fn set_label_index(mut self, input: std::option::Option<i32>) -> Self {
        self.label_index = input;
        self
    }
    /// <p>A JMESPath expression used to extract the probability (or score) from the model container output if the model container is in JSON Lines format.</p>
    /// <p> <b>Example</b>: If the model container output of a single request is <code>'{"predicted_label":1,"probability":0.6}'</code>, then set <code>ProbabilityAttribute</code> to <code>'probability'</code>.</p>
    pub fn probability_attribute(mut self, input: impl Into<std::string::String>) -> Self {
        self.probability_attribute = Some(input.into());
        self
    }
    /// <p>A JMESPath expression used to extract the probability (or score) from the model container output if the model container is in JSON Lines format.</p>
    /// <p> <b>Example</b>: If the model container output of a single request is <code>'{"predicted_label":1,"probability":0.6}'</code>, then set <code>ProbabilityAttribute</code> to <code>'probability'</code>.</p>
    pub fn set_probability_attribute(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.probability_attribute = input;
        self
    }
    /// <p>A JMESPath expression used to locate the list of label headers in the model container output.</p>
    /// <p> <b>Example</b>: If the model container output of a batch request is <code>'{"labels":["cat","dog","fish"],"probability":[0.6,0.3,0.1]}'</code>, then set <code>LabelAttribute</code> to <code>'labels'</code> to extract the list of label headers <code>["cat","dog","fish"]</code> </p>
    pub fn label_attribute(mut self, input: impl Into<std::string::String>) -> Self {
        self.label_attribute = Some(input.into());
        self
    }
    /// <p>A JMESPath expression used to locate the list of label headers in the model container output.</p>
    /// <p> <b>Example</b>: If the model container output of a batch request is <code>'{"labels":["cat","dog","fish"],"probability":[0.6,0.3,0.1]}'</code>, then set <code>LabelAttribute</code> to <code>'labels'</code> to extract the list of label headers <code>["cat","dog","fish"]</code> </p>
    pub fn set_label_attribute(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.label_attribute = input;
        self
    }
    /// Appends an item to `label_headers`.
    ///
    /// To override the contents of this collection use [`set_label_headers`](Self::set_label_headers).
    ///
    /// <p>For multiclass classification problems, the label headers are the names of the classes. Otherwise, the label header is the name of the predicted label. These are used to help readability for the output of the <code>InvokeEndpoint</code> API. See the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information. If there are no label headers in the model container output, provide them manually using this parameter.</p>
    pub fn label_headers(mut self, input: impl Into<std::string::String>) -> Self {
        let mut v = self.label_headers.unwrap_or_default();
        v.push(input.into());
        self.label_headers = Some(v);
        self
    }
    /// <p>For multiclass classification problems, the label headers are the names of the classes. Otherwise, the label header is the name of the predicted label. These are used to help readability for the output of the <code>InvokeEndpoint</code> API. See the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information. If there are no label headers in the model container output, provide them manually using this parameter.</p>
    pub fn set_label_headers(
        mut self,
        input: std::option::Option<std::vec::Vec<std::string::String>>,
    ) -> Self {
        self.label_headers = input;
        self
    }
    /// Appends an item to `feature_headers`.
    ///
    /// To override the contents of this collection use [`set_feature_headers`](Self::set_feature_headers).
    ///
    /// <p>The names of the features. If provided, these are included in the endpoint response payload to help readability of the <code>InvokeEndpoint</code> output. See the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">Response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information.</p>
    pub fn feature_headers(mut self, input: impl Into<std::string::String>) -> Self {
        let mut v = self.feature_headers.unwrap_or_default();
        v.push(input.into());
        self.feature_headers = Some(v);
        self
    }
    /// <p>The names of the features. If provided, these are included in the endpoint response payload to help readability of the <code>InvokeEndpoint</code> output. See the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">Response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information.</p>
    pub fn set_feature_headers(
        mut self,
        input: std::option::Option<std::vec::Vec<std::string::String>>,
    ) -> Self {
        self.feature_headers = input;
        self
    }
    /// Appends an item to `feature_types`.
    ///
    /// To override the contents of this collection use [`set_feature_types`](Self::set_feature_types).
    ///
    /// <p>A list of data types of the features (optional). Applicable only to NLP explainability. If provided, <code>FeatureTypes</code> must have at least one <code>'text'</code> string (for example, <code>['text']</code>). If <code>FeatureTypes</code> is not provided, the explainer infers the feature types based on the baseline data. The feature types are included in the endpoint response payload. For additional information see the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information.</p>
    pub fn feature_types(mut self, input: crate::types::ClarifyFeatureType) -> Self {
        let mut v = self.feature_types.unwrap_or_default();
        v.push(input);
        self.feature_types = Some(v);
        self
    }
    /// <p>A list of data types of the features (optional). Applicable only to NLP explainability. If provided, <code>FeatureTypes</code> must have at least one <code>'text'</code> string (for example, <code>['text']</code>). If <code>FeatureTypes</code> is not provided, the explainer infers the feature types based on the baseline data. The feature types are included in the endpoint response payload. For additional information see the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-online-explainability-invoke-endpoint.html#clarify-online-explainability-response">response</a> section under <b>Invoke the endpoint</b> in the Developer Guide for more information.</p>
    pub fn set_feature_types(
        mut self,
        input: std::option::Option<std::vec::Vec<crate::types::ClarifyFeatureType>>,
    ) -> Self {
        self.feature_types = input;
        self
    }
    /// Consumes the builder and constructs a [`ClarifyInferenceConfig`](crate::types::ClarifyInferenceConfig).
    pub fn build(self) -> crate::types::ClarifyInferenceConfig {
        crate::types::ClarifyInferenceConfig {
            features_attribute: self.features_attribute,
            content_template: self.content_template,
            max_record_count: self.max_record_count,
            max_payload_in_mb: self.max_payload_in_mb,
            probability_index: self.probability_index,
            label_index: self.label_index,
            probability_attribute: self.probability_attribute,
            label_attribute: self.label_attribute,
            label_headers: self.label_headers,
            feature_headers: self.feature_headers,
            feature_types: self.feature_types,
        }
    }
}
