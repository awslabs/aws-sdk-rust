// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Describes the Docker container for the model package.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ModelPackageContainerDefinition {
    /// <p>The DNS host name for the Docker container.</p>
    #[doc(hidden)]
    pub container_hostname: std::option::Option<std::string::String>,
    /// <p>The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.</p>
    /// <p>If you are using your own custom algorithm instead of an algorithm provided by SageMaker, the inference code must meet SageMaker requirements. SageMaker supports both <code>registry/repository[:tag]</code> and <code>registry/repository[@digest]</code> image path formats. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html">Using Your Own Algorithms with Amazon SageMaker</a>.</p>
    #[doc(hidden)]
    pub image: std::option::Option<std::string::String>,
    /// <p>An MD5 hash of the training algorithm that identifies the Docker image used for training.</p>
    #[doc(hidden)]
    pub image_digest: std::option::Option<std::string::String>,
    /// <p>The Amazon S3 path where the model artifacts, which result from model training, are stored. This path must point to a single <code>gzip</code> compressed tar archive (<code>.tar.gz</code> suffix).</p> <note>
    /// <p>The model artifacts must be in an S3 bucket that is in the same region as the model package.</p>
    /// </note>
    #[doc(hidden)]
    pub model_data_url: std::option::Option<std::string::String>,
    /// <p>The Amazon Web Services Marketplace product ID of the model package.</p>
    #[doc(hidden)]
    pub product_id: std::option::Option<std::string::String>,
    /// <p>The environment variables to set in the Docker container. Each key and value in the <code>Environment</code> string to string map can have length of up to 1024. We support up to 16 entries in the map.</p>
    #[doc(hidden)]
    pub environment:
        std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    /// <p>A structure with Model Input details.</p>
    #[doc(hidden)]
    pub model_input: std::option::Option<crate::types::ModelInput>,
    /// <p>The machine learning framework of the model package container image.</p>
    #[doc(hidden)]
    pub framework: std::option::Option<std::string::String>,
    /// <p>The framework version of the Model Package Container Image.</p>
    #[doc(hidden)]
    pub framework_version: std::option::Option<std::string::String>,
    /// <p>The name of a pre-trained machine learning benchmarked by Amazon SageMaker Inference Recommender model that matches your model. You can find a list of benchmarked models by calling <code>ListModelMetadata</code>.</p>
    #[doc(hidden)]
    pub nearest_model_name: std::option::Option<std::string::String>,
}
impl ModelPackageContainerDefinition {
    /// <p>The DNS host name for the Docker container.</p>
    pub fn container_hostname(&self) -> std::option::Option<&str> {
        self.container_hostname.as_deref()
    }
    /// <p>The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.</p>
    /// <p>If you are using your own custom algorithm instead of an algorithm provided by SageMaker, the inference code must meet SageMaker requirements. SageMaker supports both <code>registry/repository[:tag]</code> and <code>registry/repository[@digest]</code> image path formats. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html">Using Your Own Algorithms with Amazon SageMaker</a>.</p>
    pub fn image(&self) -> std::option::Option<&str> {
        self.image.as_deref()
    }
    /// <p>An MD5 hash of the training algorithm that identifies the Docker image used for training.</p>
    pub fn image_digest(&self) -> std::option::Option<&str> {
        self.image_digest.as_deref()
    }
    /// <p>The Amazon S3 path where the model artifacts, which result from model training, are stored. This path must point to a single <code>gzip</code> compressed tar archive (<code>.tar.gz</code> suffix).</p> <note>
    /// <p>The model artifacts must be in an S3 bucket that is in the same region as the model package.</p>
    /// </note>
    pub fn model_data_url(&self) -> std::option::Option<&str> {
        self.model_data_url.as_deref()
    }
    /// <p>The Amazon Web Services Marketplace product ID of the model package.</p>
    pub fn product_id(&self) -> std::option::Option<&str> {
        self.product_id.as_deref()
    }
    /// <p>The environment variables to set in the Docker container. Each key and value in the <code>Environment</code> string to string map can have length of up to 1024. We support up to 16 entries in the map.</p>
    pub fn environment(
        &self,
    ) -> std::option::Option<&std::collections::HashMap<std::string::String, std::string::String>>
    {
        self.environment.as_ref()
    }
    /// <p>A structure with Model Input details.</p>
    pub fn model_input(&self) -> std::option::Option<&crate::types::ModelInput> {
        self.model_input.as_ref()
    }
    /// <p>The machine learning framework of the model package container image.</p>
    pub fn framework(&self) -> std::option::Option<&str> {
        self.framework.as_deref()
    }
    /// <p>The framework version of the Model Package Container Image.</p>
    pub fn framework_version(&self) -> std::option::Option<&str> {
        self.framework_version.as_deref()
    }
    /// <p>The name of a pre-trained machine learning benchmarked by Amazon SageMaker Inference Recommender model that matches your model. You can find a list of benchmarked models by calling <code>ListModelMetadata</code>.</p>
    pub fn nearest_model_name(&self) -> std::option::Option<&str> {
        self.nearest_model_name.as_deref()
    }
}
impl ModelPackageContainerDefinition {
    /// Creates a new builder-style object to manufacture [`ModelPackageContainerDefinition`](crate::types::ModelPackageContainerDefinition).
    pub fn builder() -> crate::types::builders::ModelPackageContainerDefinitionBuilder {
        crate::types::builders::ModelPackageContainerDefinitionBuilder::default()
    }
}

/// A builder for [`ModelPackageContainerDefinition`](crate::types::ModelPackageContainerDefinition).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct ModelPackageContainerDefinitionBuilder {
    pub(crate) container_hostname: std::option::Option<std::string::String>,
    pub(crate) image: std::option::Option<std::string::String>,
    pub(crate) image_digest: std::option::Option<std::string::String>,
    pub(crate) model_data_url: std::option::Option<std::string::String>,
    pub(crate) product_id: std::option::Option<std::string::String>,
    pub(crate) environment:
        std::option::Option<std::collections::HashMap<std::string::String, std::string::String>>,
    pub(crate) model_input: std::option::Option<crate::types::ModelInput>,
    pub(crate) framework: std::option::Option<std::string::String>,
    pub(crate) framework_version: std::option::Option<std::string::String>,
    pub(crate) nearest_model_name: std::option::Option<std::string::String>,
}
impl ModelPackageContainerDefinitionBuilder {
    /// <p>The DNS host name for the Docker container.</p>
    pub fn container_hostname(mut self, input: impl Into<std::string::String>) -> Self {
        self.container_hostname = Some(input.into());
        self
    }
    /// <p>The DNS host name for the Docker container.</p>
    pub fn set_container_hostname(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.container_hostname = input;
        self
    }
    /// <p>The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.</p>
    /// <p>If you are using your own custom algorithm instead of an algorithm provided by SageMaker, the inference code must meet SageMaker requirements. SageMaker supports both <code>registry/repository[:tag]</code> and <code>registry/repository[@digest]</code> image path formats. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html">Using Your Own Algorithms with Amazon SageMaker</a>.</p>
    pub fn image(mut self, input: impl Into<std::string::String>) -> Self {
        self.image = Some(input.into());
        self
    }
    /// <p>The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.</p>
    /// <p>If you are using your own custom algorithm instead of an algorithm provided by SageMaker, the inference code must meet SageMaker requirements. SageMaker supports both <code>registry/repository[:tag]</code> and <code>registry/repository[@digest]</code> image path formats. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html">Using Your Own Algorithms with Amazon SageMaker</a>.</p>
    pub fn set_image(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.image = input;
        self
    }
    /// <p>An MD5 hash of the training algorithm that identifies the Docker image used for training.</p>
    pub fn image_digest(mut self, input: impl Into<std::string::String>) -> Self {
        self.image_digest = Some(input.into());
        self
    }
    /// <p>An MD5 hash of the training algorithm that identifies the Docker image used for training.</p>
    pub fn set_image_digest(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.image_digest = input;
        self
    }
    /// <p>The Amazon S3 path where the model artifacts, which result from model training, are stored. This path must point to a single <code>gzip</code> compressed tar archive (<code>.tar.gz</code> suffix).</p> <note>
    /// <p>The model artifacts must be in an S3 bucket that is in the same region as the model package.</p>
    /// </note>
    pub fn model_data_url(mut self, input: impl Into<std::string::String>) -> Self {
        self.model_data_url = Some(input.into());
        self
    }
    /// <p>The Amazon S3 path where the model artifacts, which result from model training, are stored. This path must point to a single <code>gzip</code> compressed tar archive (<code>.tar.gz</code> suffix).</p> <note>
    /// <p>The model artifacts must be in an S3 bucket that is in the same region as the model package.</p>
    /// </note>
    pub fn set_model_data_url(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.model_data_url = input;
        self
    }
    /// <p>The Amazon Web Services Marketplace product ID of the model package.</p>
    pub fn product_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.product_id = Some(input.into());
        self
    }
    /// <p>The Amazon Web Services Marketplace product ID of the model package.</p>
    pub fn set_product_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.product_id = input;
        self
    }
    /// Adds a key-value pair to `environment`.
    ///
    /// To override the contents of this collection use [`set_environment`](Self::set_environment).
    ///
    /// <p>The environment variables to set in the Docker container. Each key and value in the <code>Environment</code> string to string map can have length of up to 1024. We support up to 16 entries in the map.</p>
    pub fn environment(
        mut self,
        k: impl Into<std::string::String>,
        v: impl Into<std::string::String>,
    ) -> Self {
        let mut hash_map = self.environment.unwrap_or_default();
        hash_map.insert(k.into(), v.into());
        self.environment = Some(hash_map);
        self
    }
    /// <p>The environment variables to set in the Docker container. Each key and value in the <code>Environment</code> string to string map can have length of up to 1024. We support up to 16 entries in the map.</p>
    pub fn set_environment(
        mut self,
        input: std::option::Option<
            std::collections::HashMap<std::string::String, std::string::String>,
        >,
    ) -> Self {
        self.environment = input;
        self
    }
    /// <p>A structure with Model Input details.</p>
    pub fn model_input(mut self, input: crate::types::ModelInput) -> Self {
        self.model_input = Some(input);
        self
    }
    /// <p>A structure with Model Input details.</p>
    pub fn set_model_input(mut self, input: std::option::Option<crate::types::ModelInput>) -> Self {
        self.model_input = input;
        self
    }
    /// <p>The machine learning framework of the model package container image.</p>
    pub fn framework(mut self, input: impl Into<std::string::String>) -> Self {
        self.framework = Some(input.into());
        self
    }
    /// <p>The machine learning framework of the model package container image.</p>
    pub fn set_framework(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.framework = input;
        self
    }
    /// <p>The framework version of the Model Package Container Image.</p>
    pub fn framework_version(mut self, input: impl Into<std::string::String>) -> Self {
        self.framework_version = Some(input.into());
        self
    }
    /// <p>The framework version of the Model Package Container Image.</p>
    pub fn set_framework_version(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.framework_version = input;
        self
    }
    /// <p>The name of a pre-trained machine learning benchmarked by Amazon SageMaker Inference Recommender model that matches your model. You can find a list of benchmarked models by calling <code>ListModelMetadata</code>.</p>
    pub fn nearest_model_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.nearest_model_name = Some(input.into());
        self
    }
    /// <p>The name of a pre-trained machine learning benchmarked by Amazon SageMaker Inference Recommender model that matches your model. You can find a list of benchmarked models by calling <code>ListModelMetadata</code>.</p>
    pub fn set_nearest_model_name(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.nearest_model_name = input;
        self
    }
    /// Consumes the builder and constructs a [`ModelPackageContainerDefinition`](crate::types::ModelPackageContainerDefinition).
    pub fn build(self) -> crate::types::ModelPackageContainerDefinition {
        crate::types::ModelPackageContainerDefinition {
            container_hostname: self.container_hostname,
            image: self.image,
            image_digest: self.image_digest,
            model_data_url: self.model_data_url,
            product_id: self.product_id,
            environment: self.environment,
            model_input: self.model_input,
            framework: self.framework,
            framework_version: self.framework_version,
            nearest_model_name: self.nearest_model_name,
        }
    }
}
