// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Describes the Docker container for the model package.</p>
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct ModelPackageContainerDefinition {
    /// <p>The DNS host name for the Docker container.</p>
    pub container_hostname: ::std::option::Option<::std::string::String>,
    /// <p>The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.</p>
    /// <p>If you are using your own custom algorithm instead of an algorithm provided by SageMaker, the inference code must meet SageMaker requirements. SageMaker supports both <code>registry/repository[:tag]</code> and <code>registry/repository[@digest]</code> image path formats. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html">Using Your Own Algorithms with Amazon SageMaker</a>.</p>
    pub image: ::std::option::Option<::std::string::String>,
    /// <p>An MD5 hash of the training algorithm that identifies the Docker image used for training.</p>
    pub image_digest: ::std::option::Option<::std::string::String>,
    /// <p>The Amazon S3 path where the model artifacts, which result from model training, are stored. This path must point to a single <code>gzip</code> compressed tar archive (<code>.tar.gz</code> suffix).</p><note>
    /// <p>The model artifacts must be in an S3 bucket that is in the same region as the model package.</p>
    /// </note>
    pub model_data_url: ::std::option::Option<::std::string::String>,
    /// <p>The Amazon Web Services Marketplace product ID of the model package.</p>
    pub product_id: ::std::option::Option<::std::string::String>,
    /// <p>The environment variables to set in the Docker container. Each key and value in the <code>Environment</code> string to string map can have length of up to 1024. We support up to 16 entries in the map.</p>
    pub environment: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    /// <p>A structure with Model Input details.</p>
    pub model_input: ::std::option::Option<crate::types::ModelInput>,
    /// <p>The machine learning framework of the model package container image.</p>
    pub framework: ::std::option::Option<::std::string::String>,
    /// <p>The framework version of the Model Package Container Image.</p>
    pub framework_version: ::std::option::Option<::std::string::String>,
    /// <p>The name of a pre-trained machine learning benchmarked by Amazon SageMaker Inference Recommender model that matches your model. You can find a list of benchmarked models by calling <code>ListModelMetadata</code>.</p>
    pub nearest_model_name: ::std::option::Option<::std::string::String>,
    /// <p>The additional data source that is used during inference in the Docker container for your model package.</p>
    pub additional_s3_data_source: ::std::option::Option<crate::types::AdditionalS3DataSource>,
}
impl ModelPackageContainerDefinition {
    /// <p>The DNS host name for the Docker container.</p>
    pub fn container_hostname(&self) -> ::std::option::Option<&str> {
        self.container_hostname.as_deref()
    }
    /// <p>The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.</p>
    /// <p>If you are using your own custom algorithm instead of an algorithm provided by SageMaker, the inference code must meet SageMaker requirements. SageMaker supports both <code>registry/repository[:tag]</code> and <code>registry/repository[@digest]</code> image path formats. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html">Using Your Own Algorithms with Amazon SageMaker</a>.</p>
    pub fn image(&self) -> ::std::option::Option<&str> {
        self.image.as_deref()
    }
    /// <p>An MD5 hash of the training algorithm that identifies the Docker image used for training.</p>
    pub fn image_digest(&self) -> ::std::option::Option<&str> {
        self.image_digest.as_deref()
    }
    /// <p>The Amazon S3 path where the model artifacts, which result from model training, are stored. This path must point to a single <code>gzip</code> compressed tar archive (<code>.tar.gz</code> suffix).</p><note>
    /// <p>The model artifacts must be in an S3 bucket that is in the same region as the model package.</p>
    /// </note>
    pub fn model_data_url(&self) -> ::std::option::Option<&str> {
        self.model_data_url.as_deref()
    }
    /// <p>The Amazon Web Services Marketplace product ID of the model package.</p>
    pub fn product_id(&self) -> ::std::option::Option<&str> {
        self.product_id.as_deref()
    }
    /// <p>The environment variables to set in the Docker container. Each key and value in the <code>Environment</code> string to string map can have length of up to 1024. We support up to 16 entries in the map.</p>
    pub fn environment(&self) -> ::std::option::Option<&::std::collections::HashMap<::std::string::String, ::std::string::String>> {
        self.environment.as_ref()
    }
    /// <p>A structure with Model Input details.</p>
    pub fn model_input(&self) -> ::std::option::Option<&crate::types::ModelInput> {
        self.model_input.as_ref()
    }
    /// <p>The machine learning framework of the model package container image.</p>
    pub fn framework(&self) -> ::std::option::Option<&str> {
        self.framework.as_deref()
    }
    /// <p>The framework version of the Model Package Container Image.</p>
    pub fn framework_version(&self) -> ::std::option::Option<&str> {
        self.framework_version.as_deref()
    }
    /// <p>The name of a pre-trained machine learning benchmarked by Amazon SageMaker Inference Recommender model that matches your model. You can find a list of benchmarked models by calling <code>ListModelMetadata</code>.</p>
    pub fn nearest_model_name(&self) -> ::std::option::Option<&str> {
        self.nearest_model_name.as_deref()
    }
    /// <p>The additional data source that is used during inference in the Docker container for your model package.</p>
    pub fn additional_s3_data_source(&self) -> ::std::option::Option<&crate::types::AdditionalS3DataSource> {
        self.additional_s3_data_source.as_ref()
    }
}
impl ModelPackageContainerDefinition {
    /// Creates a new builder-style object to manufacture [`ModelPackageContainerDefinition`](crate::types::ModelPackageContainerDefinition).
    pub fn builder() -> crate::types::builders::ModelPackageContainerDefinitionBuilder {
        crate::types::builders::ModelPackageContainerDefinitionBuilder::default()
    }
}

/// A builder for [`ModelPackageContainerDefinition`](crate::types::ModelPackageContainerDefinition).
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
pub struct ModelPackageContainerDefinitionBuilder {
    pub(crate) container_hostname: ::std::option::Option<::std::string::String>,
    pub(crate) image: ::std::option::Option<::std::string::String>,
    pub(crate) image_digest: ::std::option::Option<::std::string::String>,
    pub(crate) model_data_url: ::std::option::Option<::std::string::String>,
    pub(crate) product_id: ::std::option::Option<::std::string::String>,
    pub(crate) environment: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    pub(crate) model_input: ::std::option::Option<crate::types::ModelInput>,
    pub(crate) framework: ::std::option::Option<::std::string::String>,
    pub(crate) framework_version: ::std::option::Option<::std::string::String>,
    pub(crate) nearest_model_name: ::std::option::Option<::std::string::String>,
    pub(crate) additional_s3_data_source: ::std::option::Option<crate::types::AdditionalS3DataSource>,
}
impl ModelPackageContainerDefinitionBuilder {
    /// <p>The DNS host name for the Docker container.</p>
    pub fn container_hostname(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.container_hostname = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The DNS host name for the Docker container.</p>
    pub fn set_container_hostname(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.container_hostname = input;
        self
    }
    /// <p>The DNS host name for the Docker container.</p>
    pub fn get_container_hostname(&self) -> &::std::option::Option<::std::string::String> {
        &self.container_hostname
    }
    /// <p>The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.</p>
    /// <p>If you are using your own custom algorithm instead of an algorithm provided by SageMaker, the inference code must meet SageMaker requirements. SageMaker supports both <code>registry/repository[:tag]</code> and <code>registry/repository[@digest]</code> image path formats. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html">Using Your Own Algorithms with Amazon SageMaker</a>.</p>
    /// This field is required.
    pub fn image(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.image = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.</p>
    /// <p>If you are using your own custom algorithm instead of an algorithm provided by SageMaker, the inference code must meet SageMaker requirements. SageMaker supports both <code>registry/repository[:tag]</code> and <code>registry/repository[@digest]</code> image path formats. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html">Using Your Own Algorithms with Amazon SageMaker</a>.</p>
    pub fn set_image(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.image = input;
        self
    }
    /// <p>The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.</p>
    /// <p>If you are using your own custom algorithm instead of an algorithm provided by SageMaker, the inference code must meet SageMaker requirements. SageMaker supports both <code>registry/repository[:tag]</code> and <code>registry/repository[@digest]</code> image path formats. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html">Using Your Own Algorithms with Amazon SageMaker</a>.</p>
    pub fn get_image(&self) -> &::std::option::Option<::std::string::String> {
        &self.image
    }
    /// <p>An MD5 hash of the training algorithm that identifies the Docker image used for training.</p>
    pub fn image_digest(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.image_digest = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>An MD5 hash of the training algorithm that identifies the Docker image used for training.</p>
    pub fn set_image_digest(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.image_digest = input;
        self
    }
    /// <p>An MD5 hash of the training algorithm that identifies the Docker image used for training.</p>
    pub fn get_image_digest(&self) -> &::std::option::Option<::std::string::String> {
        &self.image_digest
    }
    /// <p>The Amazon S3 path where the model artifacts, which result from model training, are stored. This path must point to a single <code>gzip</code> compressed tar archive (<code>.tar.gz</code> suffix).</p><note>
    /// <p>The model artifacts must be in an S3 bucket that is in the same region as the model package.</p>
    /// </note>
    pub fn model_data_url(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.model_data_url = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The Amazon S3 path where the model artifacts, which result from model training, are stored. This path must point to a single <code>gzip</code> compressed tar archive (<code>.tar.gz</code> suffix).</p><note>
    /// <p>The model artifacts must be in an S3 bucket that is in the same region as the model package.</p>
    /// </note>
    pub fn set_model_data_url(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.model_data_url = input;
        self
    }
    /// <p>The Amazon S3 path where the model artifacts, which result from model training, are stored. This path must point to a single <code>gzip</code> compressed tar archive (<code>.tar.gz</code> suffix).</p><note>
    /// <p>The model artifacts must be in an S3 bucket that is in the same region as the model package.</p>
    /// </note>
    pub fn get_model_data_url(&self) -> &::std::option::Option<::std::string::String> {
        &self.model_data_url
    }
    /// <p>The Amazon Web Services Marketplace product ID of the model package.</p>
    pub fn product_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.product_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The Amazon Web Services Marketplace product ID of the model package.</p>
    pub fn set_product_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.product_id = input;
        self
    }
    /// <p>The Amazon Web Services Marketplace product ID of the model package.</p>
    pub fn get_product_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.product_id
    }
    /// Adds a key-value pair to `environment`.
    ///
    /// To override the contents of this collection use [`set_environment`](Self::set_environment).
    ///
    /// <p>The environment variables to set in the Docker container. Each key and value in the <code>Environment</code> string to string map can have length of up to 1024. We support up to 16 entries in the map.</p>
    pub fn environment(mut self, k: impl ::std::convert::Into<::std::string::String>, v: impl ::std::convert::Into<::std::string::String>) -> Self {
        let mut hash_map = self.environment.unwrap_or_default();
        hash_map.insert(k.into(), v.into());
        self.environment = ::std::option::Option::Some(hash_map);
        self
    }
    /// <p>The environment variables to set in the Docker container. Each key and value in the <code>Environment</code> string to string map can have length of up to 1024. We support up to 16 entries in the map.</p>
    pub fn set_environment(
        mut self,
        input: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    ) -> Self {
        self.environment = input;
        self
    }
    /// <p>The environment variables to set in the Docker container. Each key and value in the <code>Environment</code> string to string map can have length of up to 1024. We support up to 16 entries in the map.</p>
    pub fn get_environment(&self) -> &::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>> {
        &self.environment
    }
    /// <p>A structure with Model Input details.</p>
    pub fn model_input(mut self, input: crate::types::ModelInput) -> Self {
        self.model_input = ::std::option::Option::Some(input);
        self
    }
    /// <p>A structure with Model Input details.</p>
    pub fn set_model_input(mut self, input: ::std::option::Option<crate::types::ModelInput>) -> Self {
        self.model_input = input;
        self
    }
    /// <p>A structure with Model Input details.</p>
    pub fn get_model_input(&self) -> &::std::option::Option<crate::types::ModelInput> {
        &self.model_input
    }
    /// <p>The machine learning framework of the model package container image.</p>
    pub fn framework(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.framework = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The machine learning framework of the model package container image.</p>
    pub fn set_framework(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.framework = input;
        self
    }
    /// <p>The machine learning framework of the model package container image.</p>
    pub fn get_framework(&self) -> &::std::option::Option<::std::string::String> {
        &self.framework
    }
    /// <p>The framework version of the Model Package Container Image.</p>
    pub fn framework_version(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.framework_version = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The framework version of the Model Package Container Image.</p>
    pub fn set_framework_version(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.framework_version = input;
        self
    }
    /// <p>The framework version of the Model Package Container Image.</p>
    pub fn get_framework_version(&self) -> &::std::option::Option<::std::string::String> {
        &self.framework_version
    }
    /// <p>The name of a pre-trained machine learning benchmarked by Amazon SageMaker Inference Recommender model that matches your model. You can find a list of benchmarked models by calling <code>ListModelMetadata</code>.</p>
    pub fn nearest_model_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.nearest_model_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The name of a pre-trained machine learning benchmarked by Amazon SageMaker Inference Recommender model that matches your model. You can find a list of benchmarked models by calling <code>ListModelMetadata</code>.</p>
    pub fn set_nearest_model_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.nearest_model_name = input;
        self
    }
    /// <p>The name of a pre-trained machine learning benchmarked by Amazon SageMaker Inference Recommender model that matches your model. You can find a list of benchmarked models by calling <code>ListModelMetadata</code>.</p>
    pub fn get_nearest_model_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.nearest_model_name
    }
    /// <p>The additional data source that is used during inference in the Docker container for your model package.</p>
    pub fn additional_s3_data_source(mut self, input: crate::types::AdditionalS3DataSource) -> Self {
        self.additional_s3_data_source = ::std::option::Option::Some(input);
        self
    }
    /// <p>The additional data source that is used during inference in the Docker container for your model package.</p>
    pub fn set_additional_s3_data_source(mut self, input: ::std::option::Option<crate::types::AdditionalS3DataSource>) -> Self {
        self.additional_s3_data_source = input;
        self
    }
    /// <p>The additional data source that is used during inference in the Docker container for your model package.</p>
    pub fn get_additional_s3_data_source(&self) -> &::std::option::Option<crate::types::AdditionalS3DataSource> {
        &self.additional_s3_data_source
    }
    /// Consumes the builder and constructs a [`ModelPackageContainerDefinition`](crate::types::ModelPackageContainerDefinition).
    pub fn build(self) -> crate::types::ModelPackageContainerDefinition {
        crate::types::ModelPackageContainerDefinition {
            container_hostname: self.container_hostname,
            image: self.image,
            image_digest: self.image_digest,
            model_data_url: self.model_data_url,
            product_id: self.product_id,
            environment: self.environment,
            model_input: self.model_input,
            framework: self.framework,
            framework_version: self.framework_version,
            nearest_model_name: self.nearest_model_name,
            additional_s3_data_source: self.additional_s3_data_source,
        }
    }
}
