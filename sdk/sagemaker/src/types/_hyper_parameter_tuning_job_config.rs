// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Configures a hyperparameter tuning job.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct HyperParameterTuningJobConfig {
    /// <p>Specifies how hyperparameter tuning chooses the combinations of hyperparameter values to use for the training job it launches. For information about search strategies, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html">How Hyperparameter Tuning Works</a>.</p>
    #[doc(hidden)]
    pub strategy: std::option::Option<crate::types::HyperParameterTuningJobStrategyType>,
    /// <p>The configuration for the <code>Hyperband</code> optimization strategy. This parameter should be provided only if <code>Hyperband</code> is selected as the strategy for <code>HyperParameterTuningJobConfig</code>.</p>
    #[doc(hidden)]
    pub strategy_config: std::option::Option<crate::types::HyperParameterTuningJobStrategyConfig>,
    /// <p>The <code>HyperParameterTuningJobObjective</code> specifies the objective metric used to evaluate the performance of training jobs launched by this tuning job.</p>
    #[doc(hidden)]
    pub hyper_parameter_tuning_job_objective:
        std::option::Option<crate::types::HyperParameterTuningJobObjective>,
    /// <p>The <code>ResourceLimits</code> object that specifies the maximum number of training and parallel training jobs that can be used for this hyperparameter tuning job.</p>
    #[doc(hidden)]
    pub resource_limits: std::option::Option<crate::types::ResourceLimits>,
    /// <p>The <code>ParameterRanges</code> object that specifies the ranges of hyperparameters that this tuning job searches over to find the optimal configuration for the highest model performance against your chosen objective metric. </p>
    #[doc(hidden)]
    pub parameter_ranges: std::option::Option<crate::types::ParameterRanges>,
    /// <p>Specifies whether to use early stopping for training jobs launched by the hyperparameter tuning job. Because the <code>Hyperband</code> strategy has its own advanced internal early stopping mechanism, <code>TrainingJobEarlyStoppingType</code> must be <code>OFF</code> to use <code>Hyperband</code>. This parameter can take on one of the following values (the default value is <code>OFF</code>):</p>
    /// <dl>
    /// <dt>
    /// OFF
    /// </dt>
    /// <dd>
    /// <p>Training jobs launched by the hyperparameter tuning job do not use early stopping.</p>
    /// </dd>
    /// <dt>
    /// AUTO
    /// </dt>
    /// <dd>
    /// <p>SageMaker stops training jobs launched by the hyperparameter tuning job when they are unlikely to perform better than previously completed training jobs. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html">Stop Training Jobs Early</a>.</p>
    /// </dd>
    /// </dl>
    #[doc(hidden)]
    pub training_job_early_stopping_type:
        std::option::Option<crate::types::TrainingJobEarlyStoppingType>,
    /// <p>The tuning job's completion criteria.</p>
    #[doc(hidden)]
    pub tuning_job_completion_criteria:
        std::option::Option<crate::types::TuningJobCompletionCriteria>,
    /// <p>A value used to initialize a pseudo-random number generator. Setting a random seed and using the same seed later for the same tuning job will allow hyperparameter optimization to find more a consistent hyperparameter configuration between the two runs.</p>
    #[doc(hidden)]
    pub random_seed: std::option::Option<i32>,
}
impl HyperParameterTuningJobConfig {
    /// <p>Specifies how hyperparameter tuning chooses the combinations of hyperparameter values to use for the training job it launches. For information about search strategies, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html">How Hyperparameter Tuning Works</a>.</p>
    pub fn strategy(
        &self,
    ) -> std::option::Option<&crate::types::HyperParameterTuningJobStrategyType> {
        self.strategy.as_ref()
    }
    /// <p>The configuration for the <code>Hyperband</code> optimization strategy. This parameter should be provided only if <code>Hyperband</code> is selected as the strategy for <code>HyperParameterTuningJobConfig</code>.</p>
    pub fn strategy_config(
        &self,
    ) -> std::option::Option<&crate::types::HyperParameterTuningJobStrategyConfig> {
        self.strategy_config.as_ref()
    }
    /// <p>The <code>HyperParameterTuningJobObjective</code> specifies the objective metric used to evaluate the performance of training jobs launched by this tuning job.</p>
    pub fn hyper_parameter_tuning_job_objective(
        &self,
    ) -> std::option::Option<&crate::types::HyperParameterTuningJobObjective> {
        self.hyper_parameter_tuning_job_objective.as_ref()
    }
    /// <p>The <code>ResourceLimits</code> object that specifies the maximum number of training and parallel training jobs that can be used for this hyperparameter tuning job.</p>
    pub fn resource_limits(&self) -> std::option::Option<&crate::types::ResourceLimits> {
        self.resource_limits.as_ref()
    }
    /// <p>The <code>ParameterRanges</code> object that specifies the ranges of hyperparameters that this tuning job searches over to find the optimal configuration for the highest model performance against your chosen objective metric. </p>
    pub fn parameter_ranges(&self) -> std::option::Option<&crate::types::ParameterRanges> {
        self.parameter_ranges.as_ref()
    }
    /// <p>Specifies whether to use early stopping for training jobs launched by the hyperparameter tuning job. Because the <code>Hyperband</code> strategy has its own advanced internal early stopping mechanism, <code>TrainingJobEarlyStoppingType</code> must be <code>OFF</code> to use <code>Hyperband</code>. This parameter can take on one of the following values (the default value is <code>OFF</code>):</p>
    /// <dl>
    /// <dt>
    /// OFF
    /// </dt>
    /// <dd>
    /// <p>Training jobs launched by the hyperparameter tuning job do not use early stopping.</p>
    /// </dd>
    /// <dt>
    /// AUTO
    /// </dt>
    /// <dd>
    /// <p>SageMaker stops training jobs launched by the hyperparameter tuning job when they are unlikely to perform better than previously completed training jobs. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html">Stop Training Jobs Early</a>.</p>
    /// </dd>
    /// </dl>
    pub fn training_job_early_stopping_type(
        &self,
    ) -> std::option::Option<&crate::types::TrainingJobEarlyStoppingType> {
        self.training_job_early_stopping_type.as_ref()
    }
    /// <p>The tuning job's completion criteria.</p>
    pub fn tuning_job_completion_criteria(
        &self,
    ) -> std::option::Option<&crate::types::TuningJobCompletionCriteria> {
        self.tuning_job_completion_criteria.as_ref()
    }
    /// <p>A value used to initialize a pseudo-random number generator. Setting a random seed and using the same seed later for the same tuning job will allow hyperparameter optimization to find more a consistent hyperparameter configuration between the two runs.</p>
    pub fn random_seed(&self) -> std::option::Option<i32> {
        self.random_seed
    }
}
impl HyperParameterTuningJobConfig {
    /// Creates a new builder-style object to manufacture [`HyperParameterTuningJobConfig`](crate::types::HyperParameterTuningJobConfig).
    pub fn builder() -> crate::types::builders::HyperParameterTuningJobConfigBuilder {
        crate::types::builders::HyperParameterTuningJobConfigBuilder::default()
    }
}

/// A builder for [`HyperParameterTuningJobConfig`](crate::types::HyperParameterTuningJobConfig).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct HyperParameterTuningJobConfigBuilder {
    pub(crate) strategy: std::option::Option<crate::types::HyperParameterTuningJobStrategyType>,
    pub(crate) strategy_config:
        std::option::Option<crate::types::HyperParameterTuningJobStrategyConfig>,
    pub(crate) hyper_parameter_tuning_job_objective:
        std::option::Option<crate::types::HyperParameterTuningJobObjective>,
    pub(crate) resource_limits: std::option::Option<crate::types::ResourceLimits>,
    pub(crate) parameter_ranges: std::option::Option<crate::types::ParameterRanges>,
    pub(crate) training_job_early_stopping_type:
        std::option::Option<crate::types::TrainingJobEarlyStoppingType>,
    pub(crate) tuning_job_completion_criteria:
        std::option::Option<crate::types::TuningJobCompletionCriteria>,
    pub(crate) random_seed: std::option::Option<i32>,
}
impl HyperParameterTuningJobConfigBuilder {
    /// <p>Specifies how hyperparameter tuning chooses the combinations of hyperparameter values to use for the training job it launches. For information about search strategies, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html">How Hyperparameter Tuning Works</a>.</p>
    pub fn strategy(mut self, input: crate::types::HyperParameterTuningJobStrategyType) -> Self {
        self.strategy = Some(input);
        self
    }
    /// <p>Specifies how hyperparameter tuning chooses the combinations of hyperparameter values to use for the training job it launches. For information about search strategies, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html">How Hyperparameter Tuning Works</a>.</p>
    pub fn set_strategy(
        mut self,
        input: std::option::Option<crate::types::HyperParameterTuningJobStrategyType>,
    ) -> Self {
        self.strategy = input;
        self
    }
    /// <p>The configuration for the <code>Hyperband</code> optimization strategy. This parameter should be provided only if <code>Hyperband</code> is selected as the strategy for <code>HyperParameterTuningJobConfig</code>.</p>
    pub fn strategy_config(
        mut self,
        input: crate::types::HyperParameterTuningJobStrategyConfig,
    ) -> Self {
        self.strategy_config = Some(input);
        self
    }
    /// <p>The configuration for the <code>Hyperband</code> optimization strategy. This parameter should be provided only if <code>Hyperband</code> is selected as the strategy for <code>HyperParameterTuningJobConfig</code>.</p>
    pub fn set_strategy_config(
        mut self,
        input: std::option::Option<crate::types::HyperParameterTuningJobStrategyConfig>,
    ) -> Self {
        self.strategy_config = input;
        self
    }
    /// <p>The <code>HyperParameterTuningJobObjective</code> specifies the objective metric used to evaluate the performance of training jobs launched by this tuning job.</p>
    pub fn hyper_parameter_tuning_job_objective(
        mut self,
        input: crate::types::HyperParameterTuningJobObjective,
    ) -> Self {
        self.hyper_parameter_tuning_job_objective = Some(input);
        self
    }
    /// <p>The <code>HyperParameterTuningJobObjective</code> specifies the objective metric used to evaluate the performance of training jobs launched by this tuning job.</p>
    pub fn set_hyper_parameter_tuning_job_objective(
        mut self,
        input: std::option::Option<crate::types::HyperParameterTuningJobObjective>,
    ) -> Self {
        self.hyper_parameter_tuning_job_objective = input;
        self
    }
    /// <p>The <code>ResourceLimits</code> object that specifies the maximum number of training and parallel training jobs that can be used for this hyperparameter tuning job.</p>
    pub fn resource_limits(mut self, input: crate::types::ResourceLimits) -> Self {
        self.resource_limits = Some(input);
        self
    }
    /// <p>The <code>ResourceLimits</code> object that specifies the maximum number of training and parallel training jobs that can be used for this hyperparameter tuning job.</p>
    pub fn set_resource_limits(
        mut self,
        input: std::option::Option<crate::types::ResourceLimits>,
    ) -> Self {
        self.resource_limits = input;
        self
    }
    /// <p>The <code>ParameterRanges</code> object that specifies the ranges of hyperparameters that this tuning job searches over to find the optimal configuration for the highest model performance against your chosen objective metric. </p>
    pub fn parameter_ranges(mut self, input: crate::types::ParameterRanges) -> Self {
        self.parameter_ranges = Some(input);
        self
    }
    /// <p>The <code>ParameterRanges</code> object that specifies the ranges of hyperparameters that this tuning job searches over to find the optimal configuration for the highest model performance against your chosen objective metric. </p>
    pub fn set_parameter_ranges(
        mut self,
        input: std::option::Option<crate::types::ParameterRanges>,
    ) -> Self {
        self.parameter_ranges = input;
        self
    }
    /// <p>Specifies whether to use early stopping for training jobs launched by the hyperparameter tuning job. Because the <code>Hyperband</code> strategy has its own advanced internal early stopping mechanism, <code>TrainingJobEarlyStoppingType</code> must be <code>OFF</code> to use <code>Hyperband</code>. This parameter can take on one of the following values (the default value is <code>OFF</code>):</p>
    /// <dl>
    /// <dt>
    /// OFF
    /// </dt>
    /// <dd>
    /// <p>Training jobs launched by the hyperparameter tuning job do not use early stopping.</p>
    /// </dd>
    /// <dt>
    /// AUTO
    /// </dt>
    /// <dd>
    /// <p>SageMaker stops training jobs launched by the hyperparameter tuning job when they are unlikely to perform better than previously completed training jobs. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html">Stop Training Jobs Early</a>.</p>
    /// </dd>
    /// </dl>
    pub fn training_job_early_stopping_type(
        mut self,
        input: crate::types::TrainingJobEarlyStoppingType,
    ) -> Self {
        self.training_job_early_stopping_type = Some(input);
        self
    }
    /// <p>Specifies whether to use early stopping for training jobs launched by the hyperparameter tuning job. Because the <code>Hyperband</code> strategy has its own advanced internal early stopping mechanism, <code>TrainingJobEarlyStoppingType</code> must be <code>OFF</code> to use <code>Hyperband</code>. This parameter can take on one of the following values (the default value is <code>OFF</code>):</p>
    /// <dl>
    /// <dt>
    /// OFF
    /// </dt>
    /// <dd>
    /// <p>Training jobs launched by the hyperparameter tuning job do not use early stopping.</p>
    /// </dd>
    /// <dt>
    /// AUTO
    /// </dt>
    /// <dd>
    /// <p>SageMaker stops training jobs launched by the hyperparameter tuning job when they are unlikely to perform better than previously completed training jobs. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html">Stop Training Jobs Early</a>.</p>
    /// </dd>
    /// </dl>
    pub fn set_training_job_early_stopping_type(
        mut self,
        input: std::option::Option<crate::types::TrainingJobEarlyStoppingType>,
    ) -> Self {
        self.training_job_early_stopping_type = input;
        self
    }
    /// <p>The tuning job's completion criteria.</p>
    pub fn tuning_job_completion_criteria(
        mut self,
        input: crate::types::TuningJobCompletionCriteria,
    ) -> Self {
        self.tuning_job_completion_criteria = Some(input);
        self
    }
    /// <p>The tuning job's completion criteria.</p>
    pub fn set_tuning_job_completion_criteria(
        mut self,
        input: std::option::Option<crate::types::TuningJobCompletionCriteria>,
    ) -> Self {
        self.tuning_job_completion_criteria = input;
        self
    }
    /// <p>A value used to initialize a pseudo-random number generator. Setting a random seed and using the same seed later for the same tuning job will allow hyperparameter optimization to find more a consistent hyperparameter configuration between the two runs.</p>
    pub fn random_seed(mut self, input: i32) -> Self {
        self.random_seed = Some(input);
        self
    }
    /// <p>A value used to initialize a pseudo-random number generator. Setting a random seed and using the same seed later for the same tuning job will allow hyperparameter optimization to find more a consistent hyperparameter configuration between the two runs.</p>
    pub fn set_random_seed(mut self, input: std::option::Option<i32>) -> Self {
        self.random_seed = input;
        self
    }
    /// Consumes the builder and constructs a [`HyperParameterTuningJobConfig`](crate::types::HyperParameterTuningJobConfig).
    pub fn build(self) -> crate::types::HyperParameterTuningJobConfig {
        crate::types::HyperParameterTuningJobConfig {
            strategy: self.strategy,
            strategy_config: self.strategy_config,
            hyper_parameter_tuning_job_objective: self.hyper_parameter_tuning_job_objective,
            resource_limits: self.resource_limits,
            parameter_ranges: self.parameter_ranges,
            training_job_early_stopping_type: self.training_job_early_stopping_type,
            tuning_job_completion_criteria: self.tuning_job_completion_criteria,
            random_seed: self.random_seed,
        }
    }
}
