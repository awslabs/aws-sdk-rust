// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Describes the resources, including machine learning (ML) compute instances and ML storage volumes, to use for model training. </p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ResourceConfig {
    /// <p>The ML compute instance type. </p> <note>
    /// <p>SageMaker Training on Amazon Elastic Compute Cloud (EC2) P4de instances is in preview release starting December 9th, 2022. </p>
    /// <p> <a href="http://aws.amazon.com/ec2/instance-types/p4/">Amazon EC2 P4de instances</a> (currently in preview) are powered by 8 NVIDIA A100 GPUs with 80GB high-performance HBM2e GPU memory, which accelerate the speed of training ML models that need to be trained on large datasets of high-resolution data. In this preview release, Amazon SageMaker supports ML training jobs on P4de instances (<code>ml.p4de.24xlarge</code>) to reduce model training time. The <code>ml.p4de.24xlarge</code> instances are available in the following Amazon Web Services Regions. </p>
    /// <ul>
    /// <li> <p>US East (N. Virginia) (us-east-1)</p> </li>
    /// <li> <p>US West (Oregon) (us-west-2)</p> </li>
    /// </ul>
    /// <p>To request quota limit increase and start using P4de instances, contact the SageMaker Training service team through your account team.</p>
    /// </note>
    #[doc(hidden)]
    pub instance_type: std::option::Option<crate::types::TrainingInstanceType>,
    /// <p>The number of ML compute instances to use. For distributed training, provide a value greater than 1. </p>
    #[doc(hidden)]
    pub instance_count: i32,
    /// <p>The size of the ML storage volume that you want to provision. </p>
    /// <p>ML storage volumes store model artifacts and incremental states. Training algorithms might also use the ML storage volume for scratch space. If you want to store the training data in the ML storage volume, choose <code>File</code> as the <code>TrainingInputMode</code> in the algorithm specification. </p>
    /// <p>When using an ML instance with <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html#nvme-ssd-volumes">NVMe SSD volumes</a>, SageMaker doesn't provision Amazon EBS General Purpose SSD (gp2) storage. Available storage is fixed to the NVMe-type instance's storage capacity. SageMaker configures storage paths for training datasets, checkpoints, model artifacts, and outputs to use the entire capacity of the instance storage. For example, ML instance families with the NVMe-type instance storage include <code>ml.p4d</code>, <code>ml.g4dn</code>, and <code>ml.g5</code>. </p>
    /// <p>When using an ML instance with the EBS-only storage option and without instance storage, you must define the size of EBS volume through <code>VolumeSizeInGB</code> in the <code>ResourceConfig</code> API. For example, ML instance families that use EBS volumes include <code>ml.c5</code> and <code>ml.p2</code>. </p>
    /// <p>To look up instance types and their instance storage types and volumes, see <a href="http://aws.amazon.com/ec2/instance-types/">Amazon EC2 Instance Types</a>.</p>
    /// <p>To find the default local paths defined by the SageMaker training platform, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-train-storage.html">Amazon SageMaker Training Storage Folders for Training Datasets, Checkpoints, Model Artifacts, and Outputs</a>.</p>
    #[doc(hidden)]
    pub volume_size_in_gb: i32,
    /// <p>The Amazon Web Services KMS key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the training job.</p> <note>
    /// <p>Certain Nitro-based instances include local storage, dependent on the instance type. Local storage volumes are encrypted using a hardware module on the instance. You can't request a <code>VolumeKmsKeyId</code> when using an instance type with local storage.</p>
    /// <p>For a list of instance types that support local instance storage, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes">Instance Store Volumes</a>.</p>
    /// <p>For more information about local instance storage encryption, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html">SSD Instance Store Volumes</a>.</p>
    /// </note>
    /// <p>The <code>VolumeKmsKeyId</code> can be in any of the following formats:</p>
    /// <ul>
    /// <li> <p>// KMS Key ID</p> <p> <code>"1234abcd-12ab-34cd-56ef-1234567890ab"</code> </p> </li>
    /// <li> <p>// Amazon Resource Name (ARN) of a KMS Key</p> <p> <code>"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"</code> </p> </li>
    /// </ul>
    #[doc(hidden)]
    pub volume_kms_key_id: std::option::Option<std::string::String>,
    /// <p>The configuration of a heterogeneous cluster in JSON format.</p>
    #[doc(hidden)]
    pub instance_groups: std::option::Option<std::vec::Vec<crate::types::InstanceGroup>>,
    /// <p>The duration of time in seconds to retain configured resources in a warm pool for subsequent training jobs.</p>
    #[doc(hidden)]
    pub keep_alive_period_in_seconds: std::option::Option<i32>,
}
impl ResourceConfig {
    /// <p>The ML compute instance type. </p> <note>
    /// <p>SageMaker Training on Amazon Elastic Compute Cloud (EC2) P4de instances is in preview release starting December 9th, 2022. </p>
    /// <p> <a href="http://aws.amazon.com/ec2/instance-types/p4/">Amazon EC2 P4de instances</a> (currently in preview) are powered by 8 NVIDIA A100 GPUs with 80GB high-performance HBM2e GPU memory, which accelerate the speed of training ML models that need to be trained on large datasets of high-resolution data. In this preview release, Amazon SageMaker supports ML training jobs on P4de instances (<code>ml.p4de.24xlarge</code>) to reduce model training time. The <code>ml.p4de.24xlarge</code> instances are available in the following Amazon Web Services Regions. </p>
    /// <ul>
    /// <li> <p>US East (N. Virginia) (us-east-1)</p> </li>
    /// <li> <p>US West (Oregon) (us-west-2)</p> </li>
    /// </ul>
    /// <p>To request quota limit increase and start using P4de instances, contact the SageMaker Training service team through your account team.</p>
    /// </note>
    pub fn instance_type(&self) -> std::option::Option<&crate::types::TrainingInstanceType> {
        self.instance_type.as_ref()
    }
    /// <p>The number of ML compute instances to use. For distributed training, provide a value greater than 1. </p>
    pub fn instance_count(&self) -> i32 {
        self.instance_count
    }
    /// <p>The size of the ML storage volume that you want to provision. </p>
    /// <p>ML storage volumes store model artifacts and incremental states. Training algorithms might also use the ML storage volume for scratch space. If you want to store the training data in the ML storage volume, choose <code>File</code> as the <code>TrainingInputMode</code> in the algorithm specification. </p>
    /// <p>When using an ML instance with <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html#nvme-ssd-volumes">NVMe SSD volumes</a>, SageMaker doesn't provision Amazon EBS General Purpose SSD (gp2) storage. Available storage is fixed to the NVMe-type instance's storage capacity. SageMaker configures storage paths for training datasets, checkpoints, model artifacts, and outputs to use the entire capacity of the instance storage. For example, ML instance families with the NVMe-type instance storage include <code>ml.p4d</code>, <code>ml.g4dn</code>, and <code>ml.g5</code>. </p>
    /// <p>When using an ML instance with the EBS-only storage option and without instance storage, you must define the size of EBS volume through <code>VolumeSizeInGB</code> in the <code>ResourceConfig</code> API. For example, ML instance families that use EBS volumes include <code>ml.c5</code> and <code>ml.p2</code>. </p>
    /// <p>To look up instance types and their instance storage types and volumes, see <a href="http://aws.amazon.com/ec2/instance-types/">Amazon EC2 Instance Types</a>.</p>
    /// <p>To find the default local paths defined by the SageMaker training platform, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-train-storage.html">Amazon SageMaker Training Storage Folders for Training Datasets, Checkpoints, Model Artifacts, and Outputs</a>.</p>
    pub fn volume_size_in_gb(&self) -> i32 {
        self.volume_size_in_gb
    }
    /// <p>The Amazon Web Services KMS key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the training job.</p> <note>
    /// <p>Certain Nitro-based instances include local storage, dependent on the instance type. Local storage volumes are encrypted using a hardware module on the instance. You can't request a <code>VolumeKmsKeyId</code> when using an instance type with local storage.</p>
    /// <p>For a list of instance types that support local instance storage, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes">Instance Store Volumes</a>.</p>
    /// <p>For more information about local instance storage encryption, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html">SSD Instance Store Volumes</a>.</p>
    /// </note>
    /// <p>The <code>VolumeKmsKeyId</code> can be in any of the following formats:</p>
    /// <ul>
    /// <li> <p>// KMS Key ID</p> <p> <code>"1234abcd-12ab-34cd-56ef-1234567890ab"</code> </p> </li>
    /// <li> <p>// Amazon Resource Name (ARN) of a KMS Key</p> <p> <code>"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"</code> </p> </li>
    /// </ul>
    pub fn volume_kms_key_id(&self) -> std::option::Option<&str> {
        self.volume_kms_key_id.as_deref()
    }
    /// <p>The configuration of a heterogeneous cluster in JSON format.</p>
    pub fn instance_groups(&self) -> std::option::Option<&[crate::types::InstanceGroup]> {
        self.instance_groups.as_deref()
    }
    /// <p>The duration of time in seconds to retain configured resources in a warm pool for subsequent training jobs.</p>
    pub fn keep_alive_period_in_seconds(&self) -> std::option::Option<i32> {
        self.keep_alive_period_in_seconds
    }
}
impl ResourceConfig {
    /// Creates a new builder-style object to manufacture [`ResourceConfig`](crate::types::ResourceConfig).
    pub fn builder() -> crate::types::builders::ResourceConfigBuilder {
        crate::types::builders::ResourceConfigBuilder::default()
    }
}

/// A builder for [`ResourceConfig`](crate::types::ResourceConfig).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct ResourceConfigBuilder {
    pub(crate) instance_type: std::option::Option<crate::types::TrainingInstanceType>,
    pub(crate) instance_count: std::option::Option<i32>,
    pub(crate) volume_size_in_gb: std::option::Option<i32>,
    pub(crate) volume_kms_key_id: std::option::Option<std::string::String>,
    pub(crate) instance_groups: std::option::Option<std::vec::Vec<crate::types::InstanceGroup>>,
    pub(crate) keep_alive_period_in_seconds: std::option::Option<i32>,
}
impl ResourceConfigBuilder {
    /// <p>The ML compute instance type. </p> <note>
    /// <p>SageMaker Training on Amazon Elastic Compute Cloud (EC2) P4de instances is in preview release starting December 9th, 2022. </p>
    /// <p> <a href="http://aws.amazon.com/ec2/instance-types/p4/">Amazon EC2 P4de instances</a> (currently in preview) are powered by 8 NVIDIA A100 GPUs with 80GB high-performance HBM2e GPU memory, which accelerate the speed of training ML models that need to be trained on large datasets of high-resolution data. In this preview release, Amazon SageMaker supports ML training jobs on P4de instances (<code>ml.p4de.24xlarge</code>) to reduce model training time. The <code>ml.p4de.24xlarge</code> instances are available in the following Amazon Web Services Regions. </p>
    /// <ul>
    /// <li> <p>US East (N. Virginia) (us-east-1)</p> </li>
    /// <li> <p>US West (Oregon) (us-west-2)</p> </li>
    /// </ul>
    /// <p>To request quota limit increase and start using P4de instances, contact the SageMaker Training service team through your account team.</p>
    /// </note>
    pub fn instance_type(mut self, input: crate::types::TrainingInstanceType) -> Self {
        self.instance_type = Some(input);
        self
    }
    /// <p>The ML compute instance type. </p> <note>
    /// <p>SageMaker Training on Amazon Elastic Compute Cloud (EC2) P4de instances is in preview release starting December 9th, 2022. </p>
    /// <p> <a href="http://aws.amazon.com/ec2/instance-types/p4/">Amazon EC2 P4de instances</a> (currently in preview) are powered by 8 NVIDIA A100 GPUs with 80GB high-performance HBM2e GPU memory, which accelerate the speed of training ML models that need to be trained on large datasets of high-resolution data. In this preview release, Amazon SageMaker supports ML training jobs on P4de instances (<code>ml.p4de.24xlarge</code>) to reduce model training time. The <code>ml.p4de.24xlarge</code> instances are available in the following Amazon Web Services Regions. </p>
    /// <ul>
    /// <li> <p>US East (N. Virginia) (us-east-1)</p> </li>
    /// <li> <p>US West (Oregon) (us-west-2)</p> </li>
    /// </ul>
    /// <p>To request quota limit increase and start using P4de instances, contact the SageMaker Training service team through your account team.</p>
    /// </note>
    pub fn set_instance_type(
        mut self,
        input: std::option::Option<crate::types::TrainingInstanceType>,
    ) -> Self {
        self.instance_type = input;
        self
    }
    /// <p>The number of ML compute instances to use. For distributed training, provide a value greater than 1. </p>
    pub fn instance_count(mut self, input: i32) -> Self {
        self.instance_count = Some(input);
        self
    }
    /// <p>The number of ML compute instances to use. For distributed training, provide a value greater than 1. </p>
    pub fn set_instance_count(mut self, input: std::option::Option<i32>) -> Self {
        self.instance_count = input;
        self
    }
    /// <p>The size of the ML storage volume that you want to provision. </p>
    /// <p>ML storage volumes store model artifacts and incremental states. Training algorithms might also use the ML storage volume for scratch space. If you want to store the training data in the ML storage volume, choose <code>File</code> as the <code>TrainingInputMode</code> in the algorithm specification. </p>
    /// <p>When using an ML instance with <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html#nvme-ssd-volumes">NVMe SSD volumes</a>, SageMaker doesn't provision Amazon EBS General Purpose SSD (gp2) storage. Available storage is fixed to the NVMe-type instance's storage capacity. SageMaker configures storage paths for training datasets, checkpoints, model artifacts, and outputs to use the entire capacity of the instance storage. For example, ML instance families with the NVMe-type instance storage include <code>ml.p4d</code>, <code>ml.g4dn</code>, and <code>ml.g5</code>. </p>
    /// <p>When using an ML instance with the EBS-only storage option and without instance storage, you must define the size of EBS volume through <code>VolumeSizeInGB</code> in the <code>ResourceConfig</code> API. For example, ML instance families that use EBS volumes include <code>ml.c5</code> and <code>ml.p2</code>. </p>
    /// <p>To look up instance types and their instance storage types and volumes, see <a href="http://aws.amazon.com/ec2/instance-types/">Amazon EC2 Instance Types</a>.</p>
    /// <p>To find the default local paths defined by the SageMaker training platform, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-train-storage.html">Amazon SageMaker Training Storage Folders for Training Datasets, Checkpoints, Model Artifacts, and Outputs</a>.</p>
    pub fn volume_size_in_gb(mut self, input: i32) -> Self {
        self.volume_size_in_gb = Some(input);
        self
    }
    /// <p>The size of the ML storage volume that you want to provision. </p>
    /// <p>ML storage volumes store model artifacts and incremental states. Training algorithms might also use the ML storage volume for scratch space. If you want to store the training data in the ML storage volume, choose <code>File</code> as the <code>TrainingInputMode</code> in the algorithm specification. </p>
    /// <p>When using an ML instance with <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html#nvme-ssd-volumes">NVMe SSD volumes</a>, SageMaker doesn't provision Amazon EBS General Purpose SSD (gp2) storage. Available storage is fixed to the NVMe-type instance's storage capacity. SageMaker configures storage paths for training datasets, checkpoints, model artifacts, and outputs to use the entire capacity of the instance storage. For example, ML instance families with the NVMe-type instance storage include <code>ml.p4d</code>, <code>ml.g4dn</code>, and <code>ml.g5</code>. </p>
    /// <p>When using an ML instance with the EBS-only storage option and without instance storage, you must define the size of EBS volume through <code>VolumeSizeInGB</code> in the <code>ResourceConfig</code> API. For example, ML instance families that use EBS volumes include <code>ml.c5</code> and <code>ml.p2</code>. </p>
    /// <p>To look up instance types and their instance storage types and volumes, see <a href="http://aws.amazon.com/ec2/instance-types/">Amazon EC2 Instance Types</a>.</p>
    /// <p>To find the default local paths defined by the SageMaker training platform, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-train-storage.html">Amazon SageMaker Training Storage Folders for Training Datasets, Checkpoints, Model Artifacts, and Outputs</a>.</p>
    pub fn set_volume_size_in_gb(mut self, input: std::option::Option<i32>) -> Self {
        self.volume_size_in_gb = input;
        self
    }
    /// <p>The Amazon Web Services KMS key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the training job.</p> <note>
    /// <p>Certain Nitro-based instances include local storage, dependent on the instance type. Local storage volumes are encrypted using a hardware module on the instance. You can't request a <code>VolumeKmsKeyId</code> when using an instance type with local storage.</p>
    /// <p>For a list of instance types that support local instance storage, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes">Instance Store Volumes</a>.</p>
    /// <p>For more information about local instance storage encryption, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html">SSD Instance Store Volumes</a>.</p>
    /// </note>
    /// <p>The <code>VolumeKmsKeyId</code> can be in any of the following formats:</p>
    /// <ul>
    /// <li> <p>// KMS Key ID</p> <p> <code>"1234abcd-12ab-34cd-56ef-1234567890ab"</code> </p> </li>
    /// <li> <p>// Amazon Resource Name (ARN) of a KMS Key</p> <p> <code>"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"</code> </p> </li>
    /// </ul>
    pub fn volume_kms_key_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.volume_kms_key_id = Some(input.into());
        self
    }
    /// <p>The Amazon Web Services KMS key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the training job.</p> <note>
    /// <p>Certain Nitro-based instances include local storage, dependent on the instance type. Local storage volumes are encrypted using a hardware module on the instance. You can't request a <code>VolumeKmsKeyId</code> when using an instance type with local storage.</p>
    /// <p>For a list of instance types that support local instance storage, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes">Instance Store Volumes</a>.</p>
    /// <p>For more information about local instance storage encryption, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html">SSD Instance Store Volumes</a>.</p>
    /// </note>
    /// <p>The <code>VolumeKmsKeyId</code> can be in any of the following formats:</p>
    /// <ul>
    /// <li> <p>// KMS Key ID</p> <p> <code>"1234abcd-12ab-34cd-56ef-1234567890ab"</code> </p> </li>
    /// <li> <p>// Amazon Resource Name (ARN) of a KMS Key</p> <p> <code>"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"</code> </p> </li>
    /// </ul>
    pub fn set_volume_kms_key_id(
        mut self,
        input: std::option::Option<std::string::String>,
    ) -> Self {
        self.volume_kms_key_id = input;
        self
    }
    /// Appends an item to `instance_groups`.
    ///
    /// To override the contents of this collection use [`set_instance_groups`](Self::set_instance_groups).
    ///
    /// <p>The configuration of a heterogeneous cluster in JSON format.</p>
    pub fn instance_groups(mut self, input: crate::types::InstanceGroup) -> Self {
        let mut v = self.instance_groups.unwrap_or_default();
        v.push(input);
        self.instance_groups = Some(v);
        self
    }
    /// <p>The configuration of a heterogeneous cluster in JSON format.</p>
    pub fn set_instance_groups(
        mut self,
        input: std::option::Option<std::vec::Vec<crate::types::InstanceGroup>>,
    ) -> Self {
        self.instance_groups = input;
        self
    }
    /// <p>The duration of time in seconds to retain configured resources in a warm pool for subsequent training jobs.</p>
    pub fn keep_alive_period_in_seconds(mut self, input: i32) -> Self {
        self.keep_alive_period_in_seconds = Some(input);
        self
    }
    /// <p>The duration of time in seconds to retain configured resources in a warm pool for subsequent training jobs.</p>
    pub fn set_keep_alive_period_in_seconds(mut self, input: std::option::Option<i32>) -> Self {
        self.keep_alive_period_in_seconds = input;
        self
    }
    /// Consumes the builder and constructs a [`ResourceConfig`](crate::types::ResourceConfig).
    pub fn build(self) -> crate::types::ResourceConfig {
        crate::types::ResourceConfig {
            instance_type: self.instance_type,
            instance_count: self.instance_count.unwrap_or_default(),
            volume_size_in_gb: self.volume_size_in_gb.unwrap_or_default(),
            volume_kms_key_id: self.volume_kms_key_id,
            instance_groups: self.instance_groups,
            keep_alive_period_in_seconds: self.keep_alive_period_in_seconds,
        }
    }
}
