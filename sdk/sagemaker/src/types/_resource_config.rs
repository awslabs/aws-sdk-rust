// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Describes the resources, including machine learning (ML) compute instances and ML storage volumes, to use for model training.</p>
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct ResourceConfig {
    /// <p>The ML compute instance type.</p>
    pub instance_type: ::std::option::Option<crate::types::TrainingInstanceType>,
    /// <p>The number of ML compute instances to use. For distributed training, provide a value greater than 1.</p>
    pub instance_count: ::std::option::Option<i32>,
    /// <p>The size of the ML storage volume that you want to provision.</p>
    /// <p>ML storage volumes store model artifacts and incremental states. Training algorithms might also use the ML storage volume for scratch space. If you want to store the training data in the ML storage volume, choose <code>File</code> as the <code>TrainingInputMode</code> in the algorithm specification.</p>
    /// <p>When using an ML instance with <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html#nvme-ssd-volumes">NVMe SSD volumes</a>, SageMaker doesn't provision Amazon EBS General Purpose SSD (gp2) storage. Available storage is fixed to the NVMe-type instance's storage capacity. SageMaker configures storage paths for training datasets, checkpoints, model artifacts, and outputs to use the entire capacity of the instance storage. For example, ML instance families with the NVMe-type instance storage include <code>ml.p4d</code>, <code>ml.g4dn</code>, and <code>ml.g5</code>.</p>
    /// <p>When using an ML instance with the EBS-only storage option and without instance storage, you must define the size of EBS volume through <code>VolumeSizeInGB</code> in the <code>ResourceConfig</code> API. For example, ML instance families that use EBS volumes include <code>ml.c5</code> and <code>ml.p2</code>.</p>
    /// <p>To look up instance types and their instance storage types and volumes, see <a href="http://aws.amazon.com/ec2/instance-types/">Amazon EC2 Instance Types</a>.</p>
    /// <p>To find the default local paths defined by the SageMaker training platform, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-train-storage.html">Amazon SageMaker Training Storage Folders for Training Datasets, Checkpoints, Model Artifacts, and Outputs</a>.</p>
    pub volume_size_in_gb: ::std::option::Option<i32>,
    /// <p>The Amazon Web Services KMS key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the training job.</p><note>
    /// <p>Certain Nitro-based instances include local storage, dependent on the instance type. Local storage volumes are encrypted using a hardware module on the instance. You can't request a <code>VolumeKmsKeyId</code> when using an instance type with local storage.</p>
    /// <p>For a list of instance types that support local instance storage, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes">Instance Store Volumes</a>.</p>
    /// <p>For more information about local instance storage encryption, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html">SSD Instance Store Volumes</a>.</p>
    /// </note>
    /// <p>The <code>VolumeKmsKeyId</code> can be in any of the following formats:</p>
    /// <ul>
    /// <li>
    /// <p>// KMS Key ID</p>
    /// <p><code>"1234abcd-12ab-34cd-56ef-1234567890ab"</code></p></li>
    /// <li>
    /// <p>// Amazon Resource Name (ARN) of a KMS Key</p>
    /// <p><code>"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"</code></p></li>
    /// </ul>
    pub volume_kms_key_id: ::std::option::Option<::std::string::String>,
    /// <p>The duration of time in seconds to retain configured resources in a warm pool for subsequent training jobs.</p>
    pub keep_alive_period_in_seconds: ::std::option::Option<i32>,
    /// <p>The configuration of a heterogeneous cluster in JSON format.</p>
    pub instance_groups: ::std::option::Option<::std::vec::Vec<crate::types::InstanceGroup>>,
    /// <p>The Amazon Resource Name (ARN); of the training plan to use for this resource configuration.</p>
    pub training_plan_arn: ::std::option::Option<::std::string::String>,
    /// <p>Configuration for how training job instances are placed and allocated within UltraServers. Only applicable for UltraServer capacity.</p>
    pub instance_placement_config: ::std::option::Option<crate::types::InstancePlacementConfig>,
}
impl ResourceConfig {
    /// <p>The ML compute instance type.</p>
    pub fn instance_type(&self) -> ::std::option::Option<&crate::types::TrainingInstanceType> {
        self.instance_type.as_ref()
    }
    /// <p>The number of ML compute instances to use. For distributed training, provide a value greater than 1.</p>
    pub fn instance_count(&self) -> ::std::option::Option<i32> {
        self.instance_count
    }
    /// <p>The size of the ML storage volume that you want to provision.</p>
    /// <p>ML storage volumes store model artifacts and incremental states. Training algorithms might also use the ML storage volume for scratch space. If you want to store the training data in the ML storage volume, choose <code>File</code> as the <code>TrainingInputMode</code> in the algorithm specification.</p>
    /// <p>When using an ML instance with <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html#nvme-ssd-volumes">NVMe SSD volumes</a>, SageMaker doesn't provision Amazon EBS General Purpose SSD (gp2) storage. Available storage is fixed to the NVMe-type instance's storage capacity. SageMaker configures storage paths for training datasets, checkpoints, model artifacts, and outputs to use the entire capacity of the instance storage. For example, ML instance families with the NVMe-type instance storage include <code>ml.p4d</code>, <code>ml.g4dn</code>, and <code>ml.g5</code>.</p>
    /// <p>When using an ML instance with the EBS-only storage option and without instance storage, you must define the size of EBS volume through <code>VolumeSizeInGB</code> in the <code>ResourceConfig</code> API. For example, ML instance families that use EBS volumes include <code>ml.c5</code> and <code>ml.p2</code>.</p>
    /// <p>To look up instance types and their instance storage types and volumes, see <a href="http://aws.amazon.com/ec2/instance-types/">Amazon EC2 Instance Types</a>.</p>
    /// <p>To find the default local paths defined by the SageMaker training platform, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-train-storage.html">Amazon SageMaker Training Storage Folders for Training Datasets, Checkpoints, Model Artifacts, and Outputs</a>.</p>
    pub fn volume_size_in_gb(&self) -> ::std::option::Option<i32> {
        self.volume_size_in_gb
    }
    /// <p>The Amazon Web Services KMS key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the training job.</p><note>
    /// <p>Certain Nitro-based instances include local storage, dependent on the instance type. Local storage volumes are encrypted using a hardware module on the instance. You can't request a <code>VolumeKmsKeyId</code> when using an instance type with local storage.</p>
    /// <p>For a list of instance types that support local instance storage, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes">Instance Store Volumes</a>.</p>
    /// <p>For more information about local instance storage encryption, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html">SSD Instance Store Volumes</a>.</p>
    /// </note>
    /// <p>The <code>VolumeKmsKeyId</code> can be in any of the following formats:</p>
    /// <ul>
    /// <li>
    /// <p>// KMS Key ID</p>
    /// <p><code>"1234abcd-12ab-34cd-56ef-1234567890ab"</code></p></li>
    /// <li>
    /// <p>// Amazon Resource Name (ARN) of a KMS Key</p>
    /// <p><code>"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"</code></p></li>
    /// </ul>
    pub fn volume_kms_key_id(&self) -> ::std::option::Option<&str> {
        self.volume_kms_key_id.as_deref()
    }
    /// <p>The duration of time in seconds to retain configured resources in a warm pool for subsequent training jobs.</p>
    pub fn keep_alive_period_in_seconds(&self) -> ::std::option::Option<i32> {
        self.keep_alive_period_in_seconds
    }
    /// <p>The configuration of a heterogeneous cluster in JSON format.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.instance_groups.is_none()`.
    pub fn instance_groups(&self) -> &[crate::types::InstanceGroup] {
        self.instance_groups.as_deref().unwrap_or_default()
    }
    /// <p>The Amazon Resource Name (ARN); of the training plan to use for this resource configuration.</p>
    pub fn training_plan_arn(&self) -> ::std::option::Option<&str> {
        self.training_plan_arn.as_deref()
    }
    /// <p>Configuration for how training job instances are placed and allocated within UltraServers. Only applicable for UltraServer capacity.</p>
    pub fn instance_placement_config(&self) -> ::std::option::Option<&crate::types::InstancePlacementConfig> {
        self.instance_placement_config.as_ref()
    }
}
impl ResourceConfig {
    /// Creates a new builder-style object to manufacture [`ResourceConfig`](crate::types::ResourceConfig).
    pub fn builder() -> crate::types::builders::ResourceConfigBuilder {
        crate::types::builders::ResourceConfigBuilder::default()
    }
}

/// A builder for [`ResourceConfig`](crate::types::ResourceConfig).
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
#[non_exhaustive]
pub struct ResourceConfigBuilder {
    pub(crate) instance_type: ::std::option::Option<crate::types::TrainingInstanceType>,
    pub(crate) instance_count: ::std::option::Option<i32>,
    pub(crate) volume_size_in_gb: ::std::option::Option<i32>,
    pub(crate) volume_kms_key_id: ::std::option::Option<::std::string::String>,
    pub(crate) keep_alive_period_in_seconds: ::std::option::Option<i32>,
    pub(crate) instance_groups: ::std::option::Option<::std::vec::Vec<crate::types::InstanceGroup>>,
    pub(crate) training_plan_arn: ::std::option::Option<::std::string::String>,
    pub(crate) instance_placement_config: ::std::option::Option<crate::types::InstancePlacementConfig>,
}
impl ResourceConfigBuilder {
    /// <p>The ML compute instance type.</p>
    pub fn instance_type(mut self, input: crate::types::TrainingInstanceType) -> Self {
        self.instance_type = ::std::option::Option::Some(input);
        self
    }
    /// <p>The ML compute instance type.</p>
    pub fn set_instance_type(mut self, input: ::std::option::Option<crate::types::TrainingInstanceType>) -> Self {
        self.instance_type = input;
        self
    }
    /// <p>The ML compute instance type.</p>
    pub fn get_instance_type(&self) -> &::std::option::Option<crate::types::TrainingInstanceType> {
        &self.instance_type
    }
    /// <p>The number of ML compute instances to use. For distributed training, provide a value greater than 1.</p>
    pub fn instance_count(mut self, input: i32) -> Self {
        self.instance_count = ::std::option::Option::Some(input);
        self
    }
    /// <p>The number of ML compute instances to use. For distributed training, provide a value greater than 1.</p>
    pub fn set_instance_count(mut self, input: ::std::option::Option<i32>) -> Self {
        self.instance_count = input;
        self
    }
    /// <p>The number of ML compute instances to use. For distributed training, provide a value greater than 1.</p>
    pub fn get_instance_count(&self) -> &::std::option::Option<i32> {
        &self.instance_count
    }
    /// <p>The size of the ML storage volume that you want to provision.</p>
    /// <p>ML storage volumes store model artifacts and incremental states. Training algorithms might also use the ML storage volume for scratch space. If you want to store the training data in the ML storage volume, choose <code>File</code> as the <code>TrainingInputMode</code> in the algorithm specification.</p>
    /// <p>When using an ML instance with <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html#nvme-ssd-volumes">NVMe SSD volumes</a>, SageMaker doesn't provision Amazon EBS General Purpose SSD (gp2) storage. Available storage is fixed to the NVMe-type instance's storage capacity. SageMaker configures storage paths for training datasets, checkpoints, model artifacts, and outputs to use the entire capacity of the instance storage. For example, ML instance families with the NVMe-type instance storage include <code>ml.p4d</code>, <code>ml.g4dn</code>, and <code>ml.g5</code>.</p>
    /// <p>When using an ML instance with the EBS-only storage option and without instance storage, you must define the size of EBS volume through <code>VolumeSizeInGB</code> in the <code>ResourceConfig</code> API. For example, ML instance families that use EBS volumes include <code>ml.c5</code> and <code>ml.p2</code>.</p>
    /// <p>To look up instance types and their instance storage types and volumes, see <a href="http://aws.amazon.com/ec2/instance-types/">Amazon EC2 Instance Types</a>.</p>
    /// <p>To find the default local paths defined by the SageMaker training platform, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-train-storage.html">Amazon SageMaker Training Storage Folders for Training Datasets, Checkpoints, Model Artifacts, and Outputs</a>.</p>
    pub fn volume_size_in_gb(mut self, input: i32) -> Self {
        self.volume_size_in_gb = ::std::option::Option::Some(input);
        self
    }
    /// <p>The size of the ML storage volume that you want to provision.</p>
    /// <p>ML storage volumes store model artifacts and incremental states. Training algorithms might also use the ML storage volume for scratch space. If you want to store the training data in the ML storage volume, choose <code>File</code> as the <code>TrainingInputMode</code> in the algorithm specification.</p>
    /// <p>When using an ML instance with <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html#nvme-ssd-volumes">NVMe SSD volumes</a>, SageMaker doesn't provision Amazon EBS General Purpose SSD (gp2) storage. Available storage is fixed to the NVMe-type instance's storage capacity. SageMaker configures storage paths for training datasets, checkpoints, model artifacts, and outputs to use the entire capacity of the instance storage. For example, ML instance families with the NVMe-type instance storage include <code>ml.p4d</code>, <code>ml.g4dn</code>, and <code>ml.g5</code>.</p>
    /// <p>When using an ML instance with the EBS-only storage option and without instance storage, you must define the size of EBS volume through <code>VolumeSizeInGB</code> in the <code>ResourceConfig</code> API. For example, ML instance families that use EBS volumes include <code>ml.c5</code> and <code>ml.p2</code>.</p>
    /// <p>To look up instance types and their instance storage types and volumes, see <a href="http://aws.amazon.com/ec2/instance-types/">Amazon EC2 Instance Types</a>.</p>
    /// <p>To find the default local paths defined by the SageMaker training platform, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-train-storage.html">Amazon SageMaker Training Storage Folders for Training Datasets, Checkpoints, Model Artifacts, and Outputs</a>.</p>
    pub fn set_volume_size_in_gb(mut self, input: ::std::option::Option<i32>) -> Self {
        self.volume_size_in_gb = input;
        self
    }
    /// <p>The size of the ML storage volume that you want to provision.</p>
    /// <p>ML storage volumes store model artifacts and incremental states. Training algorithms might also use the ML storage volume for scratch space. If you want to store the training data in the ML storage volume, choose <code>File</code> as the <code>TrainingInputMode</code> in the algorithm specification.</p>
    /// <p>When using an ML instance with <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html#nvme-ssd-volumes">NVMe SSD volumes</a>, SageMaker doesn't provision Amazon EBS General Purpose SSD (gp2) storage. Available storage is fixed to the NVMe-type instance's storage capacity. SageMaker configures storage paths for training datasets, checkpoints, model artifacts, and outputs to use the entire capacity of the instance storage. For example, ML instance families with the NVMe-type instance storage include <code>ml.p4d</code>, <code>ml.g4dn</code>, and <code>ml.g5</code>.</p>
    /// <p>When using an ML instance with the EBS-only storage option and without instance storage, you must define the size of EBS volume through <code>VolumeSizeInGB</code> in the <code>ResourceConfig</code> API. For example, ML instance families that use EBS volumes include <code>ml.c5</code> and <code>ml.p2</code>.</p>
    /// <p>To look up instance types and their instance storage types and volumes, see <a href="http://aws.amazon.com/ec2/instance-types/">Amazon EC2 Instance Types</a>.</p>
    /// <p>To find the default local paths defined by the SageMaker training platform, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-train-storage.html">Amazon SageMaker Training Storage Folders for Training Datasets, Checkpoints, Model Artifacts, and Outputs</a>.</p>
    pub fn get_volume_size_in_gb(&self) -> &::std::option::Option<i32> {
        &self.volume_size_in_gb
    }
    /// <p>The Amazon Web Services KMS key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the training job.</p><note>
    /// <p>Certain Nitro-based instances include local storage, dependent on the instance type. Local storage volumes are encrypted using a hardware module on the instance. You can't request a <code>VolumeKmsKeyId</code> when using an instance type with local storage.</p>
    /// <p>For a list of instance types that support local instance storage, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes">Instance Store Volumes</a>.</p>
    /// <p>For more information about local instance storage encryption, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html">SSD Instance Store Volumes</a>.</p>
    /// </note>
    /// <p>The <code>VolumeKmsKeyId</code> can be in any of the following formats:</p>
    /// <ul>
    /// <li>
    /// <p>// KMS Key ID</p>
    /// <p><code>"1234abcd-12ab-34cd-56ef-1234567890ab"</code></p></li>
    /// <li>
    /// <p>// Amazon Resource Name (ARN) of a KMS Key</p>
    /// <p><code>"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"</code></p></li>
    /// </ul>
    pub fn volume_kms_key_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.volume_kms_key_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The Amazon Web Services KMS key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the training job.</p><note>
    /// <p>Certain Nitro-based instances include local storage, dependent on the instance type. Local storage volumes are encrypted using a hardware module on the instance. You can't request a <code>VolumeKmsKeyId</code> when using an instance type with local storage.</p>
    /// <p>For a list of instance types that support local instance storage, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes">Instance Store Volumes</a>.</p>
    /// <p>For more information about local instance storage encryption, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html">SSD Instance Store Volumes</a>.</p>
    /// </note>
    /// <p>The <code>VolumeKmsKeyId</code> can be in any of the following formats:</p>
    /// <ul>
    /// <li>
    /// <p>// KMS Key ID</p>
    /// <p><code>"1234abcd-12ab-34cd-56ef-1234567890ab"</code></p></li>
    /// <li>
    /// <p>// Amazon Resource Name (ARN) of a KMS Key</p>
    /// <p><code>"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"</code></p></li>
    /// </ul>
    pub fn set_volume_kms_key_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.volume_kms_key_id = input;
        self
    }
    /// <p>The Amazon Web Services KMS key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the training job.</p><note>
    /// <p>Certain Nitro-based instances include local storage, dependent on the instance type. Local storage volumes are encrypted using a hardware module on the instance. You can't request a <code>VolumeKmsKeyId</code> when using an instance type with local storage.</p>
    /// <p>For a list of instance types that support local instance storage, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes">Instance Store Volumes</a>.</p>
    /// <p>For more information about local instance storage encryption, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html">SSD Instance Store Volumes</a>.</p>
    /// </note>
    /// <p>The <code>VolumeKmsKeyId</code> can be in any of the following formats:</p>
    /// <ul>
    /// <li>
    /// <p>// KMS Key ID</p>
    /// <p><code>"1234abcd-12ab-34cd-56ef-1234567890ab"</code></p></li>
    /// <li>
    /// <p>// Amazon Resource Name (ARN) of a KMS Key</p>
    /// <p><code>"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"</code></p></li>
    /// </ul>
    pub fn get_volume_kms_key_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.volume_kms_key_id
    }
    /// <p>The duration of time in seconds to retain configured resources in a warm pool for subsequent training jobs.</p>
    pub fn keep_alive_period_in_seconds(mut self, input: i32) -> Self {
        self.keep_alive_period_in_seconds = ::std::option::Option::Some(input);
        self
    }
    /// <p>The duration of time in seconds to retain configured resources in a warm pool for subsequent training jobs.</p>
    pub fn set_keep_alive_period_in_seconds(mut self, input: ::std::option::Option<i32>) -> Self {
        self.keep_alive_period_in_seconds = input;
        self
    }
    /// <p>The duration of time in seconds to retain configured resources in a warm pool for subsequent training jobs.</p>
    pub fn get_keep_alive_period_in_seconds(&self) -> &::std::option::Option<i32> {
        &self.keep_alive_period_in_seconds
    }
    /// Appends an item to `instance_groups`.
    ///
    /// To override the contents of this collection use [`set_instance_groups`](Self::set_instance_groups).
    ///
    /// <p>The configuration of a heterogeneous cluster in JSON format.</p>
    pub fn instance_groups(mut self, input: crate::types::InstanceGroup) -> Self {
        let mut v = self.instance_groups.unwrap_or_default();
        v.push(input);
        self.instance_groups = ::std::option::Option::Some(v);
        self
    }
    /// <p>The configuration of a heterogeneous cluster in JSON format.</p>
    pub fn set_instance_groups(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::InstanceGroup>>) -> Self {
        self.instance_groups = input;
        self
    }
    /// <p>The configuration of a heterogeneous cluster in JSON format.</p>
    pub fn get_instance_groups(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::InstanceGroup>> {
        &self.instance_groups
    }
    /// <p>The Amazon Resource Name (ARN); of the training plan to use for this resource configuration.</p>
    pub fn training_plan_arn(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.training_plan_arn = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN); of the training plan to use for this resource configuration.</p>
    pub fn set_training_plan_arn(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.training_plan_arn = input;
        self
    }
    /// <p>The Amazon Resource Name (ARN); of the training plan to use for this resource configuration.</p>
    pub fn get_training_plan_arn(&self) -> &::std::option::Option<::std::string::String> {
        &self.training_plan_arn
    }
    /// <p>Configuration for how training job instances are placed and allocated within UltraServers. Only applicable for UltraServer capacity.</p>
    pub fn instance_placement_config(mut self, input: crate::types::InstancePlacementConfig) -> Self {
        self.instance_placement_config = ::std::option::Option::Some(input);
        self
    }
    /// <p>Configuration for how training job instances are placed and allocated within UltraServers. Only applicable for UltraServer capacity.</p>
    pub fn set_instance_placement_config(mut self, input: ::std::option::Option<crate::types::InstancePlacementConfig>) -> Self {
        self.instance_placement_config = input;
        self
    }
    /// <p>Configuration for how training job instances are placed and allocated within UltraServers. Only applicable for UltraServer capacity.</p>
    pub fn get_instance_placement_config(&self) -> &::std::option::Option<crate::types::InstancePlacementConfig> {
        &self.instance_placement_config
    }
    /// Consumes the builder and constructs a [`ResourceConfig`](crate::types::ResourceConfig).
    pub fn build(self) -> crate::types::ResourceConfig {
        crate::types::ResourceConfig {
            instance_type: self.instance_type,
            instance_count: self.instance_count,
            volume_size_in_gb: self.volume_size_in_gb,
            volume_kms_key_id: self.volume_kms_key_id,
            keep_alive_period_in_seconds: self.keep_alive_period_in_seconds,
            instance_groups: self.instance_groups,
            training_plan_arn: self.training_plan_arn,
            instance_placement_config: self.instance_placement_config,
        }
    }
}
