// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Identifies a model that you want to host and the resources chosen to deploy for hosting it. If you are deploying multiple models, tell SageMaker how to distribute traffic among the models by specifying variant weights. </p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ProductionVariant {
    /// <p>The name of the production variant.</p>
    #[doc(hidden)]
    pub variant_name: std::option::Option<std::string::String>,
    /// <p>The name of the model that you want to host. This is the name that you specified when creating the model.</p>
    #[doc(hidden)]
    pub model_name: std::option::Option<std::string::String>,
    /// <p>Number of instances to launch initially.</p>
    #[doc(hidden)]
    pub initial_instance_count: std::option::Option<i32>,
    /// <p>The ML compute instance type.</p>
    #[doc(hidden)]
    pub instance_type: std::option::Option<crate::types::ProductionVariantInstanceType>,
    /// <p>Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. The traffic to a production variant is determined by the ratio of the <code>VariantWeight</code> to the sum of all <code>VariantWeight</code> values across all ProductionVariants. If unspecified, it defaults to 1.0. </p>
    #[doc(hidden)]
    pub initial_variant_weight: std::option::Option<f32>,
    /// <p>The size of the Elastic Inference (EI) instance to use for the production variant. EI instances provide on-demand GPU computing for inference. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html">Using Elastic Inference in Amazon SageMaker</a>.</p>
    #[doc(hidden)]
    pub accelerator_type: std::option::Option<crate::types::ProductionVariantAcceleratorType>,
    /// <p>Specifies configuration for a core dump from the model container when the process crashes.</p>
    #[doc(hidden)]
    pub core_dump_config: std::option::Option<crate::types::ProductionVariantCoreDumpConfig>,
    /// <p>The serverless configuration for an endpoint. Specifies a serverless endpoint configuration instead of an instance-based endpoint configuration.</p>
    #[doc(hidden)]
    pub serverless_config: std::option::Option<crate::types::ProductionVariantServerlessConfig>,
    /// <p>The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Currently only Amazon EBS gp2 storage volumes are supported.</p>
    #[doc(hidden)]
    pub volume_size_in_gb: std::option::Option<i32>,
    /// <p>The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant.</p>
    #[doc(hidden)]
    pub model_data_download_timeout_in_seconds: std::option::Option<i32>,
    /// <p>The timeout value, in seconds, for your inference container to pass health check by SageMaker Hosting. For more information about health check, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests">How Your Container Should Respond to Health Check (Ping) Requests</a>.</p>
    #[doc(hidden)]
    pub container_startup_health_check_timeout_in_seconds: std::option::Option<i32>,
}
impl ProductionVariant {
    /// <p>The name of the production variant.</p>
    pub fn variant_name(&self) -> std::option::Option<&str> {
        self.variant_name.as_deref()
    }
    /// <p>The name of the model that you want to host. This is the name that you specified when creating the model.</p>
    pub fn model_name(&self) -> std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>Number of instances to launch initially.</p>
    pub fn initial_instance_count(&self) -> std::option::Option<i32> {
        self.initial_instance_count
    }
    /// <p>The ML compute instance type.</p>
    pub fn instance_type(
        &self,
    ) -> std::option::Option<&crate::types::ProductionVariantInstanceType> {
        self.instance_type.as_ref()
    }
    /// <p>Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. The traffic to a production variant is determined by the ratio of the <code>VariantWeight</code> to the sum of all <code>VariantWeight</code> values across all ProductionVariants. If unspecified, it defaults to 1.0. </p>
    pub fn initial_variant_weight(&self) -> std::option::Option<f32> {
        self.initial_variant_weight
    }
    /// <p>The size of the Elastic Inference (EI) instance to use for the production variant. EI instances provide on-demand GPU computing for inference. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html">Using Elastic Inference in Amazon SageMaker</a>.</p>
    pub fn accelerator_type(
        &self,
    ) -> std::option::Option<&crate::types::ProductionVariantAcceleratorType> {
        self.accelerator_type.as_ref()
    }
    /// <p>Specifies configuration for a core dump from the model container when the process crashes.</p>
    pub fn core_dump_config(
        &self,
    ) -> std::option::Option<&crate::types::ProductionVariantCoreDumpConfig> {
        self.core_dump_config.as_ref()
    }
    /// <p>The serverless configuration for an endpoint. Specifies a serverless endpoint configuration instead of an instance-based endpoint configuration.</p>
    pub fn serverless_config(
        &self,
    ) -> std::option::Option<&crate::types::ProductionVariantServerlessConfig> {
        self.serverless_config.as_ref()
    }
    /// <p>The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Currently only Amazon EBS gp2 storage volumes are supported.</p>
    pub fn volume_size_in_gb(&self) -> std::option::Option<i32> {
        self.volume_size_in_gb
    }
    /// <p>The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant.</p>
    pub fn model_data_download_timeout_in_seconds(&self) -> std::option::Option<i32> {
        self.model_data_download_timeout_in_seconds
    }
    /// <p>The timeout value, in seconds, for your inference container to pass health check by SageMaker Hosting. For more information about health check, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests">How Your Container Should Respond to Health Check (Ping) Requests</a>.</p>
    pub fn container_startup_health_check_timeout_in_seconds(&self) -> std::option::Option<i32> {
        self.container_startup_health_check_timeout_in_seconds
    }
}
impl ProductionVariant {
    /// Creates a new builder-style object to manufacture [`ProductionVariant`](crate::types::ProductionVariant).
    pub fn builder() -> crate::types::builders::ProductionVariantBuilder {
        crate::types::builders::ProductionVariantBuilder::default()
    }
}

/// A builder for [`ProductionVariant`](crate::types::ProductionVariant).
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
pub struct ProductionVariantBuilder {
    pub(crate) variant_name: std::option::Option<std::string::String>,
    pub(crate) model_name: std::option::Option<std::string::String>,
    pub(crate) initial_instance_count: std::option::Option<i32>,
    pub(crate) instance_type: std::option::Option<crate::types::ProductionVariantInstanceType>,
    pub(crate) initial_variant_weight: std::option::Option<f32>,
    pub(crate) accelerator_type:
        std::option::Option<crate::types::ProductionVariantAcceleratorType>,
    pub(crate) core_dump_config: std::option::Option<crate::types::ProductionVariantCoreDumpConfig>,
    pub(crate) serverless_config:
        std::option::Option<crate::types::ProductionVariantServerlessConfig>,
    pub(crate) volume_size_in_gb: std::option::Option<i32>,
    pub(crate) model_data_download_timeout_in_seconds: std::option::Option<i32>,
    pub(crate) container_startup_health_check_timeout_in_seconds: std::option::Option<i32>,
}
impl ProductionVariantBuilder {
    /// <p>The name of the production variant.</p>
    pub fn variant_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.variant_name = Some(input.into());
        self
    }
    /// <p>The name of the production variant.</p>
    pub fn set_variant_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.variant_name = input;
        self
    }
    /// <p>The name of the model that you want to host. This is the name that you specified when creating the model.</p>
    pub fn model_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.model_name = Some(input.into());
        self
    }
    /// <p>The name of the model that you want to host. This is the name that you specified when creating the model.</p>
    pub fn set_model_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.model_name = input;
        self
    }
    /// <p>Number of instances to launch initially.</p>
    pub fn initial_instance_count(mut self, input: i32) -> Self {
        self.initial_instance_count = Some(input);
        self
    }
    /// <p>Number of instances to launch initially.</p>
    pub fn set_initial_instance_count(mut self, input: std::option::Option<i32>) -> Self {
        self.initial_instance_count = input;
        self
    }
    /// <p>The ML compute instance type.</p>
    pub fn instance_type(mut self, input: crate::types::ProductionVariantInstanceType) -> Self {
        self.instance_type = Some(input);
        self
    }
    /// <p>The ML compute instance type.</p>
    pub fn set_instance_type(
        mut self,
        input: std::option::Option<crate::types::ProductionVariantInstanceType>,
    ) -> Self {
        self.instance_type = input;
        self
    }
    /// <p>Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. The traffic to a production variant is determined by the ratio of the <code>VariantWeight</code> to the sum of all <code>VariantWeight</code> values across all ProductionVariants. If unspecified, it defaults to 1.0. </p>
    pub fn initial_variant_weight(mut self, input: f32) -> Self {
        self.initial_variant_weight = Some(input);
        self
    }
    /// <p>Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. The traffic to a production variant is determined by the ratio of the <code>VariantWeight</code> to the sum of all <code>VariantWeight</code> values across all ProductionVariants. If unspecified, it defaults to 1.0. </p>
    pub fn set_initial_variant_weight(mut self, input: std::option::Option<f32>) -> Self {
        self.initial_variant_weight = input;
        self
    }
    /// <p>The size of the Elastic Inference (EI) instance to use for the production variant. EI instances provide on-demand GPU computing for inference. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html">Using Elastic Inference in Amazon SageMaker</a>.</p>
    pub fn accelerator_type(
        mut self,
        input: crate::types::ProductionVariantAcceleratorType,
    ) -> Self {
        self.accelerator_type = Some(input);
        self
    }
    /// <p>The size of the Elastic Inference (EI) instance to use for the production variant. EI instances provide on-demand GPU computing for inference. For more information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html">Using Elastic Inference in Amazon SageMaker</a>.</p>
    pub fn set_accelerator_type(
        mut self,
        input: std::option::Option<crate::types::ProductionVariantAcceleratorType>,
    ) -> Self {
        self.accelerator_type = input;
        self
    }
    /// <p>Specifies configuration for a core dump from the model container when the process crashes.</p>
    pub fn core_dump_config(
        mut self,
        input: crate::types::ProductionVariantCoreDumpConfig,
    ) -> Self {
        self.core_dump_config = Some(input);
        self
    }
    /// <p>Specifies configuration for a core dump from the model container when the process crashes.</p>
    pub fn set_core_dump_config(
        mut self,
        input: std::option::Option<crate::types::ProductionVariantCoreDumpConfig>,
    ) -> Self {
        self.core_dump_config = input;
        self
    }
    /// <p>The serverless configuration for an endpoint. Specifies a serverless endpoint configuration instead of an instance-based endpoint configuration.</p>
    pub fn serverless_config(
        mut self,
        input: crate::types::ProductionVariantServerlessConfig,
    ) -> Self {
        self.serverless_config = Some(input);
        self
    }
    /// <p>The serverless configuration for an endpoint. Specifies a serverless endpoint configuration instead of an instance-based endpoint configuration.</p>
    pub fn set_serverless_config(
        mut self,
        input: std::option::Option<crate::types::ProductionVariantServerlessConfig>,
    ) -> Self {
        self.serverless_config = input;
        self
    }
    /// <p>The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Currently only Amazon EBS gp2 storage volumes are supported.</p>
    pub fn volume_size_in_gb(mut self, input: i32) -> Self {
        self.volume_size_in_gb = Some(input);
        self
    }
    /// <p>The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Currently only Amazon EBS gp2 storage volumes are supported.</p>
    pub fn set_volume_size_in_gb(mut self, input: std::option::Option<i32>) -> Self {
        self.volume_size_in_gb = input;
        self
    }
    /// <p>The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant.</p>
    pub fn model_data_download_timeout_in_seconds(mut self, input: i32) -> Self {
        self.model_data_download_timeout_in_seconds = Some(input);
        self
    }
    /// <p>The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant.</p>
    pub fn set_model_data_download_timeout_in_seconds(
        mut self,
        input: std::option::Option<i32>,
    ) -> Self {
        self.model_data_download_timeout_in_seconds = input;
        self
    }
    /// <p>The timeout value, in seconds, for your inference container to pass health check by SageMaker Hosting. For more information about health check, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests">How Your Container Should Respond to Health Check (Ping) Requests</a>.</p>
    pub fn container_startup_health_check_timeout_in_seconds(mut self, input: i32) -> Self {
        self.container_startup_health_check_timeout_in_seconds = Some(input);
        self
    }
    /// <p>The timeout value, in seconds, for your inference container to pass health check by SageMaker Hosting. For more information about health check, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests">How Your Container Should Respond to Health Check (Ping) Requests</a>.</p>
    pub fn set_container_startup_health_check_timeout_in_seconds(
        mut self,
        input: std::option::Option<i32>,
    ) -> Self {
        self.container_startup_health_check_timeout_in_seconds = input;
        self
    }
    /// Consumes the builder and constructs a [`ProductionVariant`](crate::types::ProductionVariant).
    pub fn build(self) -> crate::types::ProductionVariant {
        crate::types::ProductionVariant {
            variant_name: self.variant_name,
            model_name: self.model_name,
            initial_instance_count: self.initial_instance_count,
            instance_type: self.instance_type,
            initial_variant_weight: self.initial_variant_weight,
            accelerator_type: self.accelerator_type,
            core_dump_config: self.core_dump_config,
            serverless_config: self.serverless_config,
            volume_size_in_gb: self.volume_size_in_gb,
            model_data_download_timeout_in_seconds: self.model_data_download_timeout_in_seconds,
            container_startup_health_check_timeout_in_seconds: self
                .container_startup_health_check_timeout_in_seconds,
        }
    }
}
