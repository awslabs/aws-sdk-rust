// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Defines the input needed to run a training job using the algorithm.</p>
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct TrainingJobDefinition {
    /// <p>The training input mode that the algorithm supports. For more information about input modes, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html">Algorithms</a>.</p>
    /// <p> <b>Pipe mode</b> </p>
    /// <p>If an algorithm supports <code>Pipe</code> mode, Amazon SageMaker streams data directly from Amazon S3 to the container.</p>
    /// <p> <b>File mode</b> </p>
    /// <p>If an algorithm supports <code>File</code> mode, SageMaker downloads the training data from S3 to the provisioned ML storage volume, and mounts the directory to the Docker volume for the training container.</p>
    /// <p>You must provision the ML storage volume with sufficient capacity to accommodate the data downloaded from S3. In addition to the training data, the ML storage volume also stores the output model. The algorithm container uses the ML storage volume to also store intermediate information, if any.</p>
    /// <p>For distributed algorithms, training data is distributed uniformly. Your training duration is predictable if the input data objects sizes are approximately the same. SageMaker does not split the files any further for model training. If the object sizes are skewed, training won't be optimal as the data distribution is also skewed when one host in a training cluster is overloaded, thus becoming a bottleneck in training.</p>
    /// <p> <b>FastFile mode</b> </p>
    /// <p>If an algorithm supports <code>FastFile</code> mode, SageMaker streams data directly from S3 to the container with no code changes, and provides file system access to the data. Users can author their training script to interact with these files as if they were stored on disk.</p>
    /// <p> <code>FastFile</code> mode works best when the data is read sequentially. Augmented manifest files aren't supported. The startup time is lower when there are fewer files in the S3 bucket provided.</p>
    pub training_input_mode: ::std::option::Option<crate::types::TrainingInputMode>,
    /// <p>The hyperparameters used for the training job.</p>
    pub hyper_parameters: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    /// <p>An array of <code>Channel</code> objects, each of which specifies an input source.</p>
    pub input_data_config: ::std::option::Option<::std::vec::Vec<crate::types::Channel>>,
    /// <p>the path to the S3 bucket where you want to store model artifacts. SageMaker creates subfolders for the artifacts.</p>
    pub output_data_config: ::std::option::Option<crate::types::OutputDataConfig>,
    /// <p>The resources, including the ML compute instances and ML storage volumes, to use for model training.</p>
    pub resource_config: ::std::option::Option<crate::types::ResourceConfig>,
    /// <p>Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, SageMaker ends the training job. Use this API to cap model training costs.</p>
    /// <p>To stop a job, SageMaker sends the algorithm the SIGTERM signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts.</p>
    pub stopping_condition: ::std::option::Option<crate::types::StoppingCondition>,
}
impl TrainingJobDefinition {
    /// <p>The training input mode that the algorithm supports. For more information about input modes, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html">Algorithms</a>.</p>
    /// <p> <b>Pipe mode</b> </p>
    /// <p>If an algorithm supports <code>Pipe</code> mode, Amazon SageMaker streams data directly from Amazon S3 to the container.</p>
    /// <p> <b>File mode</b> </p>
    /// <p>If an algorithm supports <code>File</code> mode, SageMaker downloads the training data from S3 to the provisioned ML storage volume, and mounts the directory to the Docker volume for the training container.</p>
    /// <p>You must provision the ML storage volume with sufficient capacity to accommodate the data downloaded from S3. In addition to the training data, the ML storage volume also stores the output model. The algorithm container uses the ML storage volume to also store intermediate information, if any.</p>
    /// <p>For distributed algorithms, training data is distributed uniformly. Your training duration is predictable if the input data objects sizes are approximately the same. SageMaker does not split the files any further for model training. If the object sizes are skewed, training won't be optimal as the data distribution is also skewed when one host in a training cluster is overloaded, thus becoming a bottleneck in training.</p>
    /// <p> <b>FastFile mode</b> </p>
    /// <p>If an algorithm supports <code>FastFile</code> mode, SageMaker streams data directly from S3 to the container with no code changes, and provides file system access to the data. Users can author their training script to interact with these files as if they were stored on disk.</p>
    /// <p> <code>FastFile</code> mode works best when the data is read sequentially. Augmented manifest files aren't supported. The startup time is lower when there are fewer files in the S3 bucket provided.</p>
    pub fn training_input_mode(&self) -> ::std::option::Option<&crate::types::TrainingInputMode> {
        self.training_input_mode.as_ref()
    }
    /// <p>The hyperparameters used for the training job.</p>
    pub fn hyper_parameters(&self) -> ::std::option::Option<&::std::collections::HashMap<::std::string::String, ::std::string::String>> {
        self.hyper_parameters.as_ref()
    }
    /// <p>An array of <code>Channel</code> objects, each of which specifies an input source.</p>
    ///
    /// If no value was sent for this field, a default will be set. If you want to determine if no value was sent, use `.input_data_config.is_none()`.
    pub fn input_data_config(&self) -> &[crate::types::Channel] {
        self.input_data_config.as_deref().unwrap_or_default()
    }
    /// <p>the path to the S3 bucket where you want to store model artifacts. SageMaker creates subfolders for the artifacts.</p>
    pub fn output_data_config(&self) -> ::std::option::Option<&crate::types::OutputDataConfig> {
        self.output_data_config.as_ref()
    }
    /// <p>The resources, including the ML compute instances and ML storage volumes, to use for model training.</p>
    pub fn resource_config(&self) -> ::std::option::Option<&crate::types::ResourceConfig> {
        self.resource_config.as_ref()
    }
    /// <p>Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, SageMaker ends the training job. Use this API to cap model training costs.</p>
    /// <p>To stop a job, SageMaker sends the algorithm the SIGTERM signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts.</p>
    pub fn stopping_condition(&self) -> ::std::option::Option<&crate::types::StoppingCondition> {
        self.stopping_condition.as_ref()
    }
}
impl TrainingJobDefinition {
    /// Creates a new builder-style object to manufacture [`TrainingJobDefinition`](crate::types::TrainingJobDefinition).
    pub fn builder() -> crate::types::builders::TrainingJobDefinitionBuilder {
        crate::types::builders::TrainingJobDefinitionBuilder::default()
    }
}

/// A builder for [`TrainingJobDefinition`](crate::types::TrainingJobDefinition).
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
pub struct TrainingJobDefinitionBuilder {
    pub(crate) training_input_mode: ::std::option::Option<crate::types::TrainingInputMode>,
    pub(crate) hyper_parameters: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    pub(crate) input_data_config: ::std::option::Option<::std::vec::Vec<crate::types::Channel>>,
    pub(crate) output_data_config: ::std::option::Option<crate::types::OutputDataConfig>,
    pub(crate) resource_config: ::std::option::Option<crate::types::ResourceConfig>,
    pub(crate) stopping_condition: ::std::option::Option<crate::types::StoppingCondition>,
}
impl TrainingJobDefinitionBuilder {
    /// <p>The training input mode that the algorithm supports. For more information about input modes, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html">Algorithms</a>.</p>
    /// <p> <b>Pipe mode</b> </p>
    /// <p>If an algorithm supports <code>Pipe</code> mode, Amazon SageMaker streams data directly from Amazon S3 to the container.</p>
    /// <p> <b>File mode</b> </p>
    /// <p>If an algorithm supports <code>File</code> mode, SageMaker downloads the training data from S3 to the provisioned ML storage volume, and mounts the directory to the Docker volume for the training container.</p>
    /// <p>You must provision the ML storage volume with sufficient capacity to accommodate the data downloaded from S3. In addition to the training data, the ML storage volume also stores the output model. The algorithm container uses the ML storage volume to also store intermediate information, if any.</p>
    /// <p>For distributed algorithms, training data is distributed uniformly. Your training duration is predictable if the input data objects sizes are approximately the same. SageMaker does not split the files any further for model training. If the object sizes are skewed, training won't be optimal as the data distribution is also skewed when one host in a training cluster is overloaded, thus becoming a bottleneck in training.</p>
    /// <p> <b>FastFile mode</b> </p>
    /// <p>If an algorithm supports <code>FastFile</code> mode, SageMaker streams data directly from S3 to the container with no code changes, and provides file system access to the data. Users can author their training script to interact with these files as if they were stored on disk.</p>
    /// <p> <code>FastFile</code> mode works best when the data is read sequentially. Augmented manifest files aren't supported. The startup time is lower when there are fewer files in the S3 bucket provided.</p>
    /// This field is required.
    pub fn training_input_mode(mut self, input: crate::types::TrainingInputMode) -> Self {
        self.training_input_mode = ::std::option::Option::Some(input);
        self
    }
    /// <p>The training input mode that the algorithm supports. For more information about input modes, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html">Algorithms</a>.</p>
    /// <p> <b>Pipe mode</b> </p>
    /// <p>If an algorithm supports <code>Pipe</code> mode, Amazon SageMaker streams data directly from Amazon S3 to the container.</p>
    /// <p> <b>File mode</b> </p>
    /// <p>If an algorithm supports <code>File</code> mode, SageMaker downloads the training data from S3 to the provisioned ML storage volume, and mounts the directory to the Docker volume for the training container.</p>
    /// <p>You must provision the ML storage volume with sufficient capacity to accommodate the data downloaded from S3. In addition to the training data, the ML storage volume also stores the output model. The algorithm container uses the ML storage volume to also store intermediate information, if any.</p>
    /// <p>For distributed algorithms, training data is distributed uniformly. Your training duration is predictable if the input data objects sizes are approximately the same. SageMaker does not split the files any further for model training. If the object sizes are skewed, training won't be optimal as the data distribution is also skewed when one host in a training cluster is overloaded, thus becoming a bottleneck in training.</p>
    /// <p> <b>FastFile mode</b> </p>
    /// <p>If an algorithm supports <code>FastFile</code> mode, SageMaker streams data directly from S3 to the container with no code changes, and provides file system access to the data. Users can author their training script to interact with these files as if they were stored on disk.</p>
    /// <p> <code>FastFile</code> mode works best when the data is read sequentially. Augmented manifest files aren't supported. The startup time is lower when there are fewer files in the S3 bucket provided.</p>
    pub fn set_training_input_mode(mut self, input: ::std::option::Option<crate::types::TrainingInputMode>) -> Self {
        self.training_input_mode = input;
        self
    }
    /// <p>The training input mode that the algorithm supports. For more information about input modes, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html">Algorithms</a>.</p>
    /// <p> <b>Pipe mode</b> </p>
    /// <p>If an algorithm supports <code>Pipe</code> mode, Amazon SageMaker streams data directly from Amazon S3 to the container.</p>
    /// <p> <b>File mode</b> </p>
    /// <p>If an algorithm supports <code>File</code> mode, SageMaker downloads the training data from S3 to the provisioned ML storage volume, and mounts the directory to the Docker volume for the training container.</p>
    /// <p>You must provision the ML storage volume with sufficient capacity to accommodate the data downloaded from S3. In addition to the training data, the ML storage volume also stores the output model. The algorithm container uses the ML storage volume to also store intermediate information, if any.</p>
    /// <p>For distributed algorithms, training data is distributed uniformly. Your training duration is predictable if the input data objects sizes are approximately the same. SageMaker does not split the files any further for model training. If the object sizes are skewed, training won't be optimal as the data distribution is also skewed when one host in a training cluster is overloaded, thus becoming a bottleneck in training.</p>
    /// <p> <b>FastFile mode</b> </p>
    /// <p>If an algorithm supports <code>FastFile</code> mode, SageMaker streams data directly from S3 to the container with no code changes, and provides file system access to the data. Users can author their training script to interact with these files as if they were stored on disk.</p>
    /// <p> <code>FastFile</code> mode works best when the data is read sequentially. Augmented manifest files aren't supported. The startup time is lower when there are fewer files in the S3 bucket provided.</p>
    pub fn get_training_input_mode(&self) -> &::std::option::Option<crate::types::TrainingInputMode> {
        &self.training_input_mode
    }
    /// Adds a key-value pair to `hyper_parameters`.
    ///
    /// To override the contents of this collection use [`set_hyper_parameters`](Self::set_hyper_parameters).
    ///
    /// <p>The hyperparameters used for the training job.</p>
    pub fn hyper_parameters(
        mut self,
        k: impl ::std::convert::Into<::std::string::String>,
        v: impl ::std::convert::Into<::std::string::String>,
    ) -> Self {
        let mut hash_map = self.hyper_parameters.unwrap_or_default();
        hash_map.insert(k.into(), v.into());
        self.hyper_parameters = ::std::option::Option::Some(hash_map);
        self
    }
    /// <p>The hyperparameters used for the training job.</p>
    pub fn set_hyper_parameters(
        mut self,
        input: ::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>>,
    ) -> Self {
        self.hyper_parameters = input;
        self
    }
    /// <p>The hyperparameters used for the training job.</p>
    pub fn get_hyper_parameters(&self) -> &::std::option::Option<::std::collections::HashMap<::std::string::String, ::std::string::String>> {
        &self.hyper_parameters
    }
    /// Appends an item to `input_data_config`.
    ///
    /// To override the contents of this collection use [`set_input_data_config`](Self::set_input_data_config).
    ///
    /// <p>An array of <code>Channel</code> objects, each of which specifies an input source.</p>
    pub fn input_data_config(mut self, input: crate::types::Channel) -> Self {
        let mut v = self.input_data_config.unwrap_or_default();
        v.push(input);
        self.input_data_config = ::std::option::Option::Some(v);
        self
    }
    /// <p>An array of <code>Channel</code> objects, each of which specifies an input source.</p>
    pub fn set_input_data_config(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::Channel>>) -> Self {
        self.input_data_config = input;
        self
    }
    /// <p>An array of <code>Channel</code> objects, each of which specifies an input source.</p>
    pub fn get_input_data_config(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::Channel>> {
        &self.input_data_config
    }
    /// <p>the path to the S3 bucket where you want to store model artifacts. SageMaker creates subfolders for the artifacts.</p>
    /// This field is required.
    pub fn output_data_config(mut self, input: crate::types::OutputDataConfig) -> Self {
        self.output_data_config = ::std::option::Option::Some(input);
        self
    }
    /// <p>the path to the S3 bucket where you want to store model artifacts. SageMaker creates subfolders for the artifacts.</p>
    pub fn set_output_data_config(mut self, input: ::std::option::Option<crate::types::OutputDataConfig>) -> Self {
        self.output_data_config = input;
        self
    }
    /// <p>the path to the S3 bucket where you want to store model artifacts. SageMaker creates subfolders for the artifacts.</p>
    pub fn get_output_data_config(&self) -> &::std::option::Option<crate::types::OutputDataConfig> {
        &self.output_data_config
    }
    /// <p>The resources, including the ML compute instances and ML storage volumes, to use for model training.</p>
    /// This field is required.
    pub fn resource_config(mut self, input: crate::types::ResourceConfig) -> Self {
        self.resource_config = ::std::option::Option::Some(input);
        self
    }
    /// <p>The resources, including the ML compute instances and ML storage volumes, to use for model training.</p>
    pub fn set_resource_config(mut self, input: ::std::option::Option<crate::types::ResourceConfig>) -> Self {
        self.resource_config = input;
        self
    }
    /// <p>The resources, including the ML compute instances and ML storage volumes, to use for model training.</p>
    pub fn get_resource_config(&self) -> &::std::option::Option<crate::types::ResourceConfig> {
        &self.resource_config
    }
    /// <p>Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, SageMaker ends the training job. Use this API to cap model training costs.</p>
    /// <p>To stop a job, SageMaker sends the algorithm the SIGTERM signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts.</p>
    /// This field is required.
    pub fn stopping_condition(mut self, input: crate::types::StoppingCondition) -> Self {
        self.stopping_condition = ::std::option::Option::Some(input);
        self
    }
    /// <p>Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, SageMaker ends the training job. Use this API to cap model training costs.</p>
    /// <p>To stop a job, SageMaker sends the algorithm the SIGTERM signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts.</p>
    pub fn set_stopping_condition(mut self, input: ::std::option::Option<crate::types::StoppingCondition>) -> Self {
        self.stopping_condition = input;
        self
    }
    /// <p>Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, SageMaker ends the training job. Use this API to cap model training costs.</p>
    /// <p>To stop a job, SageMaker sends the algorithm the SIGTERM signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts.</p>
    pub fn get_stopping_condition(&self) -> &::std::option::Option<crate::types::StoppingCondition> {
        &self.stopping_condition
    }
    /// Consumes the builder and constructs a [`TrainingJobDefinition`](crate::types::TrainingJobDefinition).
    pub fn build(self) -> crate::types::TrainingJobDefinition {
        crate::types::TrainingJobDefinition {
            training_input_mode: self.training_input_mode,
            hyper_parameters: self.hyper_parameters,
            input_data_config: self.input_data_config,
            output_data_config: self.output_data_config,
            resource_config: self.resource_config,
            stopping_condition: self.stopping_condition,
        }
    }
}
