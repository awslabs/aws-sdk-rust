// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`CreateAutoMLJobV2`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_ml_job_name(impl Into<String>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::auto_ml_job_name) / [`set_auto_ml_job_name(Option<String>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::set_auto_ml_job_name):<br>required: **true**<br><p>Identifies an Autopilot job. The name must be unique to your account and is case insensitive.</p><br>
    ///   - [`auto_ml_job_input_data_config(AutoMlJobChannel)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::auto_ml_job_input_data_config) / [`set_auto_ml_job_input_data_config(Option<Vec::<AutoMlJobChannel>>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::set_auto_ml_job_input_data_config):<br>required: **true**<br><p>An array of channel objects describing the input data and their location. Each channel is a named input source. Similar to the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateAutoMLJob.html#sagemaker-CreateAutoMLJob-request-InputDataConfig">InputDataConfig</a> attribute in the <code>CreateAutoMLJob</code> input parameters. The supported formats depend on the problem type:</p> <ul>  <li>   <p>For tabular problem types: <code>S3Prefix</code>, <code>ManifestFile</code>.</p></li>  <li>   <p>For image classification: <code>S3Prefix</code>, <code>ManifestFile</code>, <code>AugmentedManifestFile</code>.</p></li>  <li>   <p>For text classification: <code>S3Prefix</code>.</p></li>  <li>   <p>For time-series forecasting: <code>S3Prefix</code>.</p></li>  <li>   <p>For text generation (LLMs fine-tuning): <code>S3Prefix</code>.</p></li> </ul><br>
    ///   - [`output_data_config(AutoMlOutputDataConfig)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::output_data_config) / [`set_output_data_config(Option<AutoMlOutputDataConfig>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::set_output_data_config):<br>required: **true**<br><p>Provides information about encryption and the Amazon S3 output path needed to store artifacts from an AutoML job.</p><br>
    ///   - [`auto_ml_problem_type_config(AutoMlProblemTypeConfig)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::auto_ml_problem_type_config) / [`set_auto_ml_problem_type_config(Option<AutoMlProblemTypeConfig>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::set_auto_ml_problem_type_config):<br>required: **true**<br><p>Defines the configuration settings of one of the supported problem types.</p><br>
    ///   - [`role_arn(impl Into<String>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::role_arn) / [`set_role_arn(Option<String>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::set_role_arn):<br>required: **true**<br><p>The ARN of the role that is used to access the data.</p><br>
    ///   - [`tags(Tag)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::tags) / [`set_tags(Option<Vec::<Tag>>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::set_tags):<br>required: **false**<br><p>An array of key-value pairs. You can use tags to categorize your Amazon Web Services resources in different ways, such as by purpose, owner, or environment. For more information, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html">Tagging Amazon Web ServicesResources</a>. Tag keys must be unique per resource.</p><br>
    ///   - [`security_config(AutoMlSecurityConfig)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::security_config) / [`set_security_config(Option<AutoMlSecurityConfig>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::set_security_config):<br>required: **false**<br><p>The security configuration for traffic encryption or Amazon VPC settings.</p><br>
    ///   - [`auto_ml_job_objective(AutoMlJobObjective)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::auto_ml_job_objective) / [`set_auto_ml_job_objective(Option<AutoMlJobObjective>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::set_auto_ml_job_objective):<br>required: **false**<br><p>Specifies a metric to minimize or maximize as the objective of a job. If not specified, the default objective metric depends on the problem type. For the list of default values per problem type, see <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_AutoMLJobObjective.html">AutoMLJobObjective</a>.</p><note>  <ul>   <li>    <p>For tabular problem types: You must either provide both the <code>AutoMLJobObjective</code> and indicate the type of supervised learning problem in <code>AutoMLProblemTypeConfig</code> (<code>TabularJobConfig.ProblemType</code>), or none at all.</p></li>   <li>    <p>For text generation problem types (LLMs fine-tuning): Fine-tuning language models in Autopilot does not require setting the <code>AutoMLJobObjective</code> field. Autopilot fine-tunes LLMs without requiring multiple candidates to be trained and evaluated. Instead, using your dataset, Autopilot directly fine-tunes your target model to enhance a default objective metric, the cross-entropy loss. After fine-tuning a language model, you can evaluate the quality of its generated text using different metrics. For a list of the available metrics, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-llms-finetuning-metrics.html">Metrics for fine-tuning LLMs in Autopilot</a>.</p></li>  </ul> </note><br>
    ///   - [`model_deploy_config(ModelDeployConfig)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::model_deploy_config) / [`set_model_deploy_config(Option<ModelDeployConfig>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::set_model_deploy_config):<br>required: **false**<br><p>Specifies how to generate the endpoint name for an automatic one-click Autopilot model deployment.</p><br>
    ///   - [`data_split_config(AutoMlDataSplitConfig)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::data_split_config) / [`set_data_split_config(Option<AutoMlDataSplitConfig>)`](crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::set_data_split_config):<br>required: **false**<br><p>This structure specifies how to split the data into train and validation datasets.</p> <p>The validation and training datasets must contain the same headers. For jobs created by calling <code>CreateAutoMLJob</code>, the validation dataset must be less than 2 GB in size.</p><note>  <p>This attribute must not be set for the time-series forecasting problem type, as Autopilot automatically splits the input dataset into training and validation sets.</p> </note><br>
    /// - On success, responds with [`CreateAutoMlJobV2Output`](crate::operation::create_auto_ml_job_v2::CreateAutoMlJobV2Output) with field(s):
    ///   - [`auto_ml_job_arn(Option<String>)`](crate::operation::create_auto_ml_job_v2::CreateAutoMlJobV2Output::auto_ml_job_arn): <p>The unique ARN assigned to the AutoMLJob when it is created.</p>
    /// - On failure, responds with [`SdkError<CreateAutoMLJobV2Error>`](crate::operation::create_auto_ml_job_v2::CreateAutoMLJobV2Error)
    pub fn create_auto_ml_job_v2(&self) -> crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder {
        crate::operation::create_auto_ml_job_v2::builders::CreateAutoMLJobV2FluentBuilder::new(self.handle.clone())
    }
}
