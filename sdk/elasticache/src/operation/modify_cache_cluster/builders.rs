// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
pub use crate::operation::modify_cache_cluster::_modify_cache_cluster_output::ModifyCacheClusterOutputBuilder;

pub use crate::operation::modify_cache_cluster::_modify_cache_cluster_input::ModifyCacheClusterInputBuilder;

/// Fluent builder constructing a request to `ModifyCacheCluster`.
/// 
/// <p>Modifies the settings for a cluster. You can use this operation to change one or more cluster configuration parameters by specifying the parameters and the new values.</p>
#[derive(std::clone::Clone, std::fmt::Debug)]
pub struct ModifyCacheClusterFluentBuilder {
                handle: std::sync::Arc<crate::client::Handle>,
                inner: crate::operation::modify_cache_cluster::builders::ModifyCacheClusterInputBuilder
            }
impl ModifyCacheClusterFluentBuilder  {
    /// Creates a new `ModifyCacheCluster`.
                    pub(crate) fn new(handle: std::sync::Arc<crate::client::Handle>) -> Self {
                        Self { handle, inner: Default::default() }
                    }
    
                    /// Consume this builder, creating a customizable operation that can be modified before being
                    /// sent. The operation's inner [http::Request] can be modified as well.
                    pub async fn customize(self) -> std::result::Result<
                        crate::client::customize::CustomizableOperation<crate::operation::modify_cache_cluster::ModifyCacheCluster, aws_http::retry::AwsResponseRetryClassifier,>,
                        aws_smithy_http::result::SdkError<crate::operation::modify_cache_cluster::ModifyCacheClusterError>
                    >  {
                        let handle = self.handle.clone();
                        let operation = self.inner.build().map_err(aws_smithy_http::result::SdkError::construction_failure)?
                            .make_operation(&handle.conf)
                            .await
                            .map_err(aws_smithy_http::result::SdkError::construction_failure)?;
                        Ok(crate::client::customize::CustomizableOperation { handle, operation })
                    }
    
                    /// Sends the request and returns the response.
                    ///
                    /// If an error occurs, an `SdkError` will be returned with additional details that
                    /// can be matched against.
                    ///
                    /// By default, any retryable failures will be retried twice. Retry behavior
                    /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
                    /// set when configuring the client.
                    pub async fn send(self) -> std::result::Result<crate::operation::modify_cache_cluster::ModifyCacheClusterOutput, aws_smithy_http::result::SdkError<crate::operation::modify_cache_cluster::ModifyCacheClusterError>>
                     {
                        let op = self.inner.build().map_err(aws_smithy_http::result::SdkError::construction_failure)?
                            .make_operation(&self.handle.conf)
                            .await
                            .map_err(aws_smithy_http::result::SdkError::construction_failure)?;
                        self.handle.client.call(op).await
                    }
    /// <p>The cluster identifier. This value is stored as a lowercase string.</p>
    pub fn cache_cluster_id(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.cache_cluster_id(input.into());
        self
    }
    /// <p>The cluster identifier. This value is stored as a lowercase string.</p>
    pub fn set_cache_cluster_id(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_cache_cluster_id(input);
        self
    }
    /// <p>The number of cache nodes that the cluster should have. If the value for <code>NumCacheNodes</code> is greater than the sum of the number of current cache nodes and the number of cache nodes pending creation (which may be zero), more nodes are added. If the value is less than the number of existing cache nodes, nodes are removed. If the value is equal to the number of current cache nodes, any pending add or remove requests are canceled.</p> 
    /// <p>If you are removing cache nodes, you must use the <code>CacheNodeIdsToRemove</code> parameter to provide the IDs of the specific cache nodes to remove.</p> 
    /// <p>For clusters running Redis, this value must be 1. For clusters running Memcached, this value must be between 1 and 40.</p> <note> 
    /// <p>Adding or removing Memcached cache nodes can be applied immediately or as a pending operation (see <code>ApplyImmediately</code>).</p> 
    /// <p>A pending operation to modify the number of cache nodes in a cluster during its maintenance window, whether by adding or removing nodes in accordance with the scale out architecture, is not queued. The customer's latest request to add or remove nodes to the cluster overrides any previous pending operations to modify the number of cache nodes in the cluster. For example, a request to remove 2 nodes would override a previous pending operation to remove 3 nodes. Similarly, a request to add 2 nodes would override a previous pending operation to remove 3 nodes and vice versa. As Memcached cache nodes may now be provisioned in different Availability Zones with flexible cache node placement, a request to add nodes does not automatically override a previous pending operation to add nodes. The customer can modify the previous pending operation to add more nodes or explicitly cancel the pending request and retry the new request. To cancel pending operations to modify the number of cache nodes in a cluster, use the <code>ModifyCacheCluster</code> request and set <code>NumCacheNodes</code> equal to the number of cache nodes currently in the cluster.</p> 
    /// </note>
    pub fn num_cache_nodes(mut self, input: i32) -> Self {
        self.inner = self.inner.num_cache_nodes(input);
        self
    }
    /// <p>The number of cache nodes that the cluster should have. If the value for <code>NumCacheNodes</code> is greater than the sum of the number of current cache nodes and the number of cache nodes pending creation (which may be zero), more nodes are added. If the value is less than the number of existing cache nodes, nodes are removed. If the value is equal to the number of current cache nodes, any pending add or remove requests are canceled.</p> 
    /// <p>If you are removing cache nodes, you must use the <code>CacheNodeIdsToRemove</code> parameter to provide the IDs of the specific cache nodes to remove.</p> 
    /// <p>For clusters running Redis, this value must be 1. For clusters running Memcached, this value must be between 1 and 40.</p> <note> 
    /// <p>Adding or removing Memcached cache nodes can be applied immediately or as a pending operation (see <code>ApplyImmediately</code>).</p> 
    /// <p>A pending operation to modify the number of cache nodes in a cluster during its maintenance window, whether by adding or removing nodes in accordance with the scale out architecture, is not queued. The customer's latest request to add or remove nodes to the cluster overrides any previous pending operations to modify the number of cache nodes in the cluster. For example, a request to remove 2 nodes would override a previous pending operation to remove 3 nodes. Similarly, a request to add 2 nodes would override a previous pending operation to remove 3 nodes and vice versa. As Memcached cache nodes may now be provisioned in different Availability Zones with flexible cache node placement, a request to add nodes does not automatically override a previous pending operation to add nodes. The customer can modify the previous pending operation to add more nodes or explicitly cancel the pending request and retry the new request. To cancel pending operations to modify the number of cache nodes in a cluster, use the <code>ModifyCacheCluster</code> request and set <code>NumCacheNodes</code> equal to the number of cache nodes currently in the cluster.</p> 
    /// </note>
    pub fn set_num_cache_nodes(mut self, input: std::option::Option<i32>) -> Self {
        self.inner = self.inner.set_num_cache_nodes(input);
        self
    }
    /// Appends an item to `CacheNodeIdsToRemove`.
    ///
    /// To override the contents of this collection use [`set_cache_node_ids_to_remove`](Self::set_cache_node_ids_to_remove).
    ///
    /// <p>A list of cache node IDs to be removed. A node ID is a numeric identifier (0001, 0002, etc.). This parameter is only valid when <code>NumCacheNodes</code> is less than the existing number of cache nodes. The number of cache node IDs supplied in this parameter must match the difference between the existing number of cache nodes in the cluster or pending cache nodes, whichever is greater, and the value of <code>NumCacheNodes</code> in the request.</p> 
    /// <p>For example: If you have 3 active cache nodes, 7 pending cache nodes, and the number of cache nodes in this <code>ModifyCacheCluster</code> call is 5, you must list 2 (7 - 5) cache node IDs to remove.</p>
    pub fn cache_node_ids_to_remove(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.cache_node_ids_to_remove(input.into());
        self
    }
    /// <p>A list of cache node IDs to be removed. A node ID is a numeric identifier (0001, 0002, etc.). This parameter is only valid when <code>NumCacheNodes</code> is less than the existing number of cache nodes. The number of cache node IDs supplied in this parameter must match the difference between the existing number of cache nodes in the cluster or pending cache nodes, whichever is greater, and the value of <code>NumCacheNodes</code> in the request.</p> 
    /// <p>For example: If you have 3 active cache nodes, 7 pending cache nodes, and the number of cache nodes in this <code>ModifyCacheCluster</code> call is 5, you must list 2 (7 - 5) cache node IDs to remove.</p>
    pub fn set_cache_node_ids_to_remove(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
        self.inner = self.inner.set_cache_node_ids_to_remove(input);
        self
    }
    /// <p>Specifies whether the new nodes in this Memcached cluster are all created in a single Availability Zone or created across multiple Availability Zones.</p> 
    /// <p>Valid values: <code>single-az</code> | <code>cross-az</code>.</p> 
    /// <p>This option is only supported for Memcached clusters.</p> <note> 
    /// <p>You cannot specify <code>single-az</code> if the Memcached cluster already has cache nodes in different Availability Zones. If <code>cross-az</code> is specified, existing Memcached nodes remain in their current Availability Zone.</p> 
    /// <p>Only newly created nodes are located in different Availability Zones. </p> 
    /// </note>
    pub fn az_mode(mut self, input: crate::types::AzMode) -> Self {
        self.inner = self.inner.az_mode(input);
        self
    }
    /// <p>Specifies whether the new nodes in this Memcached cluster are all created in a single Availability Zone or created across multiple Availability Zones.</p> 
    /// <p>Valid values: <code>single-az</code> | <code>cross-az</code>.</p> 
    /// <p>This option is only supported for Memcached clusters.</p> <note> 
    /// <p>You cannot specify <code>single-az</code> if the Memcached cluster already has cache nodes in different Availability Zones. If <code>cross-az</code> is specified, existing Memcached nodes remain in their current Availability Zone.</p> 
    /// <p>Only newly created nodes are located in different Availability Zones. </p> 
    /// </note>
    pub fn set_az_mode(mut self, input: std::option::Option<crate::types::AzMode>) -> Self {
        self.inner = self.inner.set_az_mode(input);
        self
    }
    /// Appends an item to `NewAvailabilityZones`.
    ///
    /// To override the contents of this collection use [`set_new_availability_zones`](Self::set_new_availability_zones).
    ///
    /// <note> 
    /// <p>This option is only supported on Memcached clusters.</p> 
    /// </note> 
    /// <p>The list of Availability Zones where the new Memcached cache nodes are created.</p> 
    /// <p>This parameter is only valid when <code>NumCacheNodes</code> in the request is greater than the sum of the number of active cache nodes and the number of cache nodes pending creation (which may be zero). The number of Availability Zones supplied in this list must match the cache nodes being added in this request.</p> 
    /// <p>Scenarios:</p> 
    /// <ul> 
    /// <li> <p> <b>Scenario 1:</b> You have 3 active nodes and wish to add 2 nodes. Specify <code>NumCacheNodes=5</code> (3 + 2) and optionally specify two Availability Zones for the two new nodes.</p> </li> 
    /// <li> <p> <b>Scenario 2:</b> You have 3 active nodes and 2 nodes pending creation (from the scenario 1 call) and want to add 1 more node. Specify <code>NumCacheNodes=6</code> ((3 + 2) + 1) and optionally specify an Availability Zone for the new node.</p> </li> 
    /// <li> <p> <b>Scenario 3:</b> You want to cancel all pending operations. Specify <code>NumCacheNodes=3</code> to cancel all pending operations.</p> </li> 
    /// </ul> 
    /// <p>The Availability Zone placement of nodes pending creation cannot be modified. If you wish to cancel any nodes pending creation, add 0 nodes by setting <code>NumCacheNodes</code> to the number of current nodes.</p> 
    /// <p>If <code>cross-az</code> is specified, existing Memcached nodes remain in their current Availability Zone. Only newly created nodes can be located in different Availability Zones. For guidance on how to move existing Memcached nodes to different Availability Zones, see the <b>Availability Zone Considerations</b> section of <a href="https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/CacheNodes.SupportedTypes.html">Cache Node Considerations for Memcached</a>.</p> 
    /// <p> <b>Impact of new add/remove requests upon pending requests</b> </p> 
    /// <ul> 
    /// <li> <p>Scenario-1</p> 
    /// <ul> 
    /// <li> <p>Pending Action: Delete</p> </li> 
    /// <li> <p>New Request: Delete</p> </li> 
    /// <li> <p>Result: The new delete, pending or immediate, replaces the pending delete.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>Scenario-2</p> 
    /// <ul> 
    /// <li> <p>Pending Action: Delete</p> </li> 
    /// <li> <p>New Request: Create</p> </li> 
    /// <li> <p>Result: The new create, pending or immediate, replaces the pending delete.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>Scenario-3</p> 
    /// <ul> 
    /// <li> <p>Pending Action: Create</p> </li> 
    /// <li> <p>New Request: Delete</p> </li> 
    /// <li> <p>Result: The new delete, pending or immediate, replaces the pending create.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>Scenario-4</p> 
    /// <ul> 
    /// <li> <p>Pending Action: Create</p> </li> 
    /// <li> <p>New Request: Create</p> </li> 
    /// <li> <p>Result: The new create is added to the pending create.</p> <important> 
    /// <p> <b>Important:</b> If the new create request is <b>Apply Immediately - Yes</b>, all creates are performed immediately. If the new create request is <b>Apply Immediately - No</b>, all creates are pending.</p> 
    /// </important> </li> 
    /// </ul> </li> 
    /// </ul>
    pub fn new_availability_zones(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.new_availability_zones(input.into());
        self
    }
    /// <note> 
    /// <p>This option is only supported on Memcached clusters.</p> 
    /// </note> 
    /// <p>The list of Availability Zones where the new Memcached cache nodes are created.</p> 
    /// <p>This parameter is only valid when <code>NumCacheNodes</code> in the request is greater than the sum of the number of active cache nodes and the number of cache nodes pending creation (which may be zero). The number of Availability Zones supplied in this list must match the cache nodes being added in this request.</p> 
    /// <p>Scenarios:</p> 
    /// <ul> 
    /// <li> <p> <b>Scenario 1:</b> You have 3 active nodes and wish to add 2 nodes. Specify <code>NumCacheNodes=5</code> (3 + 2) and optionally specify two Availability Zones for the two new nodes.</p> </li> 
    /// <li> <p> <b>Scenario 2:</b> You have 3 active nodes and 2 nodes pending creation (from the scenario 1 call) and want to add 1 more node. Specify <code>NumCacheNodes=6</code> ((3 + 2) + 1) and optionally specify an Availability Zone for the new node.</p> </li> 
    /// <li> <p> <b>Scenario 3:</b> You want to cancel all pending operations. Specify <code>NumCacheNodes=3</code> to cancel all pending operations.</p> </li> 
    /// </ul> 
    /// <p>The Availability Zone placement of nodes pending creation cannot be modified. If you wish to cancel any nodes pending creation, add 0 nodes by setting <code>NumCacheNodes</code> to the number of current nodes.</p> 
    /// <p>If <code>cross-az</code> is specified, existing Memcached nodes remain in their current Availability Zone. Only newly created nodes can be located in different Availability Zones. For guidance on how to move existing Memcached nodes to different Availability Zones, see the <b>Availability Zone Considerations</b> section of <a href="https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/CacheNodes.SupportedTypes.html">Cache Node Considerations for Memcached</a>.</p> 
    /// <p> <b>Impact of new add/remove requests upon pending requests</b> </p> 
    /// <ul> 
    /// <li> <p>Scenario-1</p> 
    /// <ul> 
    /// <li> <p>Pending Action: Delete</p> </li> 
    /// <li> <p>New Request: Delete</p> </li> 
    /// <li> <p>Result: The new delete, pending or immediate, replaces the pending delete.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>Scenario-2</p> 
    /// <ul> 
    /// <li> <p>Pending Action: Delete</p> </li> 
    /// <li> <p>New Request: Create</p> </li> 
    /// <li> <p>Result: The new create, pending or immediate, replaces the pending delete.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>Scenario-3</p> 
    /// <ul> 
    /// <li> <p>Pending Action: Create</p> </li> 
    /// <li> <p>New Request: Delete</p> </li> 
    /// <li> <p>Result: The new delete, pending or immediate, replaces the pending create.</p> </li> 
    /// </ul> </li> 
    /// <li> <p>Scenario-4</p> 
    /// <ul> 
    /// <li> <p>Pending Action: Create</p> </li> 
    /// <li> <p>New Request: Create</p> </li> 
    /// <li> <p>Result: The new create is added to the pending create.</p> <important> 
    /// <p> <b>Important:</b> If the new create request is <b>Apply Immediately - Yes</b>, all creates are performed immediately. If the new create request is <b>Apply Immediately - No</b>, all creates are pending.</p> 
    /// </important> </li> 
    /// </ul> </li> 
    /// </ul>
    pub fn set_new_availability_zones(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
        self.inner = self.inner.set_new_availability_zones(input);
        self
    }
    /// Appends an item to `CacheSecurityGroupNames`.
    ///
    /// To override the contents of this collection use [`set_cache_security_group_names`](Self::set_cache_security_group_names).
    ///
    /// <p>A list of cache security group names to authorize on this cluster. This change is asynchronously applied as soon as possible.</p> 
    /// <p>You can use this parameter only with clusters that are created outside of an Amazon Virtual Private Cloud (Amazon VPC).</p> 
    /// <p>Constraints: Must contain no more than 255 alphanumeric characters. Must not be "Default".</p>
    pub fn cache_security_group_names(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.cache_security_group_names(input.into());
        self
    }
    /// <p>A list of cache security group names to authorize on this cluster. This change is asynchronously applied as soon as possible.</p> 
    /// <p>You can use this parameter only with clusters that are created outside of an Amazon Virtual Private Cloud (Amazon VPC).</p> 
    /// <p>Constraints: Must contain no more than 255 alphanumeric characters. Must not be "Default".</p>
    pub fn set_cache_security_group_names(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
        self.inner = self.inner.set_cache_security_group_names(input);
        self
    }
    /// Appends an item to `SecurityGroupIds`.
    ///
    /// To override the contents of this collection use [`set_security_group_ids`](Self::set_security_group_ids).
    ///
    /// <p>Specifies the VPC Security Groups associated with the cluster.</p> 
    /// <p>This parameter can be used only with clusters that are created in an Amazon Virtual Private Cloud (Amazon VPC).</p>
    pub fn security_group_ids(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.security_group_ids(input.into());
        self
    }
    /// <p>Specifies the VPC Security Groups associated with the cluster.</p> 
    /// <p>This parameter can be used only with clusters that are created in an Amazon Virtual Private Cloud (Amazon VPC).</p>
    pub fn set_security_group_ids(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
        self.inner = self.inner.set_security_group_ids(input);
        self
    }
    /// <p>Specifies the weekly time range during which maintenance on the cluster is performed. It is specified as a range in the format ddd:hh24:mi-ddd:hh24:mi (24H Clock UTC). The minimum maintenance window is a 60 minute period.</p> 
    /// <p>Valid values for <code>ddd</code> are:</p> 
    /// <ul> 
    /// <li> <p> <code>sun</code> </p> </li> 
    /// <li> <p> <code>mon</code> </p> </li> 
    /// <li> <p> <code>tue</code> </p> </li> 
    /// <li> <p> <code>wed</code> </p> </li> 
    /// <li> <p> <code>thu</code> </p> </li> 
    /// <li> <p> <code>fri</code> </p> </li> 
    /// <li> <p> <code>sat</code> </p> </li> 
    /// </ul> 
    /// <p>Example: <code>sun:23:00-mon:01:30</code> </p>
    pub fn preferred_maintenance_window(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.preferred_maintenance_window(input.into());
        self
    }
    /// <p>Specifies the weekly time range during which maintenance on the cluster is performed. It is specified as a range in the format ddd:hh24:mi-ddd:hh24:mi (24H Clock UTC). The minimum maintenance window is a 60 minute period.</p> 
    /// <p>Valid values for <code>ddd</code> are:</p> 
    /// <ul> 
    /// <li> <p> <code>sun</code> </p> </li> 
    /// <li> <p> <code>mon</code> </p> </li> 
    /// <li> <p> <code>tue</code> </p> </li> 
    /// <li> <p> <code>wed</code> </p> </li> 
    /// <li> <p> <code>thu</code> </p> </li> 
    /// <li> <p> <code>fri</code> </p> </li> 
    /// <li> <p> <code>sat</code> </p> </li> 
    /// </ul> 
    /// <p>Example: <code>sun:23:00-mon:01:30</code> </p>
    pub fn set_preferred_maintenance_window(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_preferred_maintenance_window(input);
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the Amazon SNS topic to which notifications are sent.</p> <note> 
    /// <p>The Amazon SNS topic owner must be same as the cluster owner.</p> 
    /// </note>
    pub fn notification_topic_arn(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.notification_topic_arn(input.into());
        self
    }
    /// <p>The Amazon Resource Name (ARN) of the Amazon SNS topic to which notifications are sent.</p> <note> 
    /// <p>The Amazon SNS topic owner must be same as the cluster owner.</p> 
    /// </note>
    pub fn set_notification_topic_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_notification_topic_arn(input);
        self
    }
    /// <p>The name of the cache parameter group to apply to this cluster. This change is asynchronously applied as soon as possible for parameters when the <code>ApplyImmediately</code> parameter is specified as <code>true</code> for this request.</p>
    pub fn cache_parameter_group_name(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.cache_parameter_group_name(input.into());
        self
    }
    /// <p>The name of the cache parameter group to apply to this cluster. This change is asynchronously applied as soon as possible for parameters when the <code>ApplyImmediately</code> parameter is specified as <code>true</code> for this request.</p>
    pub fn set_cache_parameter_group_name(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_cache_parameter_group_name(input);
        self
    }
    /// <p>The status of the Amazon SNS notification topic. Notifications are sent only if the status is <code>active</code>.</p> 
    /// <p>Valid values: <code>active</code> | <code>inactive</code> </p>
    pub fn notification_topic_status(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.notification_topic_status(input.into());
        self
    }
    /// <p>The status of the Amazon SNS notification topic. Notifications are sent only if the status is <code>active</code>.</p> 
    /// <p>Valid values: <code>active</code> | <code>inactive</code> </p>
    pub fn set_notification_topic_status(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_notification_topic_status(input);
        self
    }
    /// <p>If <code>true</code>, this parameter causes the modifications in this request and any pending modifications to be applied, asynchronously and as soon as possible, regardless of the <code>PreferredMaintenanceWindow</code> setting for the cluster.</p> 
    /// <p>If <code>false</code>, changes to the cluster are applied on the next maintenance reboot, or the next failure reboot, whichever occurs first.</p> <important> 
    /// <p>If you perform a <code>ModifyCacheCluster</code> before a pending modification is applied, the pending modification is replaced by the newer modification.</p> 
    /// </important> 
    /// <p>Valid values: <code>true</code> | <code>false</code> </p> 
    /// <p>Default: <code>false</code> </p>
    pub fn apply_immediately(mut self, input: bool) -> Self {
        self.inner = self.inner.apply_immediately(input);
        self
    }
    /// <p>If <code>true</code>, this parameter causes the modifications in this request and any pending modifications to be applied, asynchronously and as soon as possible, regardless of the <code>PreferredMaintenanceWindow</code> setting for the cluster.</p> 
    /// <p>If <code>false</code>, changes to the cluster are applied on the next maintenance reboot, or the next failure reboot, whichever occurs first.</p> <important> 
    /// <p>If you perform a <code>ModifyCacheCluster</code> before a pending modification is applied, the pending modification is replaced by the newer modification.</p> 
    /// </important> 
    /// <p>Valid values: <code>true</code> | <code>false</code> </p> 
    /// <p>Default: <code>false</code> </p>
    pub fn set_apply_immediately(mut self, input: std::option::Option<bool>) -> Self {
        self.inner = self.inner.set_apply_immediately(input);
        self
    }
    /// <p>The upgraded version of the cache engine to be run on the cache nodes.</p> 
    /// <p> <b>Important:</b> You can upgrade to a newer engine version (see <a href="https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/SelectEngine.html#VersionManagement">Selecting a Cache Engine and Version</a>), but you cannot downgrade to an earlier engine version. If you want to use an earlier engine version, you must delete the existing cluster and create it anew with the earlier engine version. </p>
    pub fn engine_version(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.engine_version(input.into());
        self
    }
    /// <p>The upgraded version of the cache engine to be run on the cache nodes.</p> 
    /// <p> <b>Important:</b> You can upgrade to a newer engine version (see <a href="https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/SelectEngine.html#VersionManagement">Selecting a Cache Engine and Version</a>), but you cannot downgrade to an earlier engine version. If you want to use an earlier engine version, you must delete the existing cluster and create it anew with the earlier engine version. </p>
    pub fn set_engine_version(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_engine_version(input);
        self
    }
    /// <p>&nbsp;If you are running Redis engine version 6.0 or later, set this parameter to yes if you want to opt-in to the next auto minor version upgrade campaign. This parameter is disabled for previous versions.&nbsp; </p>
    pub fn auto_minor_version_upgrade(mut self, input: bool) -> Self {
        self.inner = self.inner.auto_minor_version_upgrade(input);
        self
    }
    /// <p>&nbsp;If you are running Redis engine version 6.0 or later, set this parameter to yes if you want to opt-in to the next auto minor version upgrade campaign. This parameter is disabled for previous versions.&nbsp; </p>
    pub fn set_auto_minor_version_upgrade(mut self, input: std::option::Option<bool>) -> Self {
        self.inner = self.inner.set_auto_minor_version_upgrade(input);
        self
    }
    /// <p>The number of days for which ElastiCache retains automatic cluster snapshots before deleting them. For example, if you set <code>SnapshotRetentionLimit</code> to 5, a snapshot that was taken today is retained for 5 days before being deleted.</p> <note> 
    /// <p>If the value of <code>SnapshotRetentionLimit</code> is set to zero (0), backups are turned off.</p> 
    /// </note>
    pub fn snapshot_retention_limit(mut self, input: i32) -> Self {
        self.inner = self.inner.snapshot_retention_limit(input);
        self
    }
    /// <p>The number of days for which ElastiCache retains automatic cluster snapshots before deleting them. For example, if you set <code>SnapshotRetentionLimit</code> to 5, a snapshot that was taken today is retained for 5 days before being deleted.</p> <note> 
    /// <p>If the value of <code>SnapshotRetentionLimit</code> is set to zero (0), backups are turned off.</p> 
    /// </note>
    pub fn set_snapshot_retention_limit(mut self, input: std::option::Option<i32>) -> Self {
        self.inner = self.inner.set_snapshot_retention_limit(input);
        self
    }
    /// <p>The daily time range (in UTC) during which ElastiCache begins taking a daily snapshot of your cluster. </p>
    pub fn snapshot_window(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.snapshot_window(input.into());
        self
    }
    /// <p>The daily time range (in UTC) during which ElastiCache begins taking a daily snapshot of your cluster. </p>
    pub fn set_snapshot_window(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_snapshot_window(input);
        self
    }
    /// <p>A valid cache node type that you want to scale this cluster up to.</p>
    pub fn cache_node_type(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.cache_node_type(input.into());
        self
    }
    /// <p>A valid cache node type that you want to scale this cluster up to.</p>
    pub fn set_cache_node_type(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_cache_node_type(input);
        self
    }
    /// <p>Reserved parameter. The password used to access a password protected server. This parameter must be specified with the <code>auth-token-update</code> parameter. Password constraints:</p> 
    /// <ul> 
    /// <li> <p>Must be only printable ASCII characters</p> </li> 
    /// <li> <p>Must be at least 16 characters and no more than 128 characters in length</p> </li> 
    /// <li> <p>Cannot contain any of the following characters: '/', '"', or '@', '%'</p> </li> 
    /// </ul> 
    /// <p> For more information, see AUTH password at <a href="http://redis.io/commands/AUTH">AUTH</a>.</p>
    pub fn auth_token(mut self, input: impl Into<std::string::String>) -> Self {
        self.inner = self.inner.auth_token(input.into());
        self
    }
    /// <p>Reserved parameter. The password used to access a password protected server. This parameter must be specified with the <code>auth-token-update</code> parameter. Password constraints:</p> 
    /// <ul> 
    /// <li> <p>Must be only printable ASCII characters</p> </li> 
    /// <li> <p>Must be at least 16 characters and no more than 128 characters in length</p> </li> 
    /// <li> <p>Cannot contain any of the following characters: '/', '"', or '@', '%'</p> </li> 
    /// </ul> 
    /// <p> For more information, see AUTH password at <a href="http://redis.io/commands/AUTH">AUTH</a>.</p>
    pub fn set_auth_token(mut self, input: std::option::Option<std::string::String>) -> Self {
        self.inner = self.inner.set_auth_token(input);
        self
    }
    /// <p>Specifies the strategy to use to update the AUTH token. This parameter must be specified with the <code>auth-token</code> parameter. Possible values:</p> 
    /// <ul> 
    /// <li> <p>Rotate</p> </li> 
    /// <li> <p>Set</p> </li> 
    /// </ul> 
    /// <p> For more information, see <a href="http://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html">Authenticating Users with Redis AUTH</a> </p>
    pub fn auth_token_update_strategy(mut self, input: crate::types::AuthTokenUpdateStrategyType) -> Self {
        self.inner = self.inner.auth_token_update_strategy(input);
        self
    }
    /// <p>Specifies the strategy to use to update the AUTH token. This parameter must be specified with the <code>auth-token</code> parameter. Possible values:</p> 
    /// <ul> 
    /// <li> <p>Rotate</p> </li> 
    /// <li> <p>Set</p> </li> 
    /// </ul> 
    /// <p> For more information, see <a href="http://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html">Authenticating Users with Redis AUTH</a> </p>
    pub fn set_auth_token_update_strategy(mut self, input: std::option::Option<crate::types::AuthTokenUpdateStrategyType>) -> Self {
        self.inner = self.inner.set_auth_token_update_strategy(input);
        self
    }
    /// Appends an item to `LogDeliveryConfigurations`.
    ///
    /// To override the contents of this collection use [`set_log_delivery_configurations`](Self::set_log_delivery_configurations).
    ///
    /// <p>Specifies the destination, format and type of the logs.</p>
    pub fn log_delivery_configurations(mut self, input: crate::types::LogDeliveryConfigurationRequest) -> Self {
        self.inner = self.inner.log_delivery_configurations(input);
        self
    }
    /// <p>Specifies the destination, format and type of the logs.</p>
    pub fn set_log_delivery_configurations(mut self, input: std::option::Option<std::vec::Vec<crate::types::LogDeliveryConfigurationRequest>>) -> Self {
        self.inner = self.inner.set_log_delivery_configurations(input);
        self
    }
    /// <p>The network type you choose when modifying a cluster, either <code>ipv4</code> | <code>ipv6</code>. IPv6 is supported for workloads using Redis engine version 6.2 onward or Memcached engine version 1.6.6 on all instances built on the <a href="https://aws.amazon.com/ec2/nitro/">Nitro system</a>.</p>
    pub fn ip_discovery(mut self, input: crate::types::IpDiscovery) -> Self {
        self.inner = self.inner.ip_discovery(input);
        self
    }
    /// <p>The network type you choose when modifying a cluster, either <code>ipv4</code> | <code>ipv6</code>. IPv6 is supported for workloads using Redis engine version 6.2 onward or Memcached engine version 1.6.6 on all instances built on the <a href="https://aws.amazon.com/ec2/nitro/">Nitro system</a>.</p>
    pub fn set_ip_discovery(mut self, input: std::option::Option<crate::types::IpDiscovery>) -> Self {
        self.inner = self.inner.set_ip_discovery(input);
        self
    }
}

