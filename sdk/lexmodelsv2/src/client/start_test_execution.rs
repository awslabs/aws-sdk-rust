// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`StartTestExecution`](crate::operation::start_test_execution::builders::StartTestExecutionFluentBuilder) operation.
                            ///
                            /// - The fluent builder is configurable:
    ///   - [`test_set_id(impl Into<String>)`](crate::operation::start_test_execution::builders::StartTestExecutionFluentBuilder::test_set_id) / [`set_test_set_id(Option<String>)`](crate::operation::start_test_execution::builders::StartTestExecutionFluentBuilder::set_test_set_id):<br>required: **true**<br><p>The test set Id for the test set execution.</p><br>
    ///   - [`target(TestExecutionTarget)`](crate::operation::start_test_execution::builders::StartTestExecutionFluentBuilder::target) / [`set_target(Option<TestExecutionTarget>)`](crate::operation::start_test_execution::builders::StartTestExecutionFluentBuilder::set_target):<br>required: **true**<br><p>The target bot for the test set execution.</p><br>
    ///   - [`api_mode(TestExecutionApiMode)`](crate::operation::start_test_execution::builders::StartTestExecutionFluentBuilder::api_mode) / [`set_api_mode(Option<TestExecutionApiMode>)`](crate::operation::start_test_execution::builders::StartTestExecutionFluentBuilder::set_api_mode):<br>required: **true**<br><p>Indicates whether we use streaming or non-streaming APIs for the test set execution. For streaming, StartConversation Runtime API is used. Whereas, for non-streaming, RecognizeUtterance and RecognizeText Amazon Lex Runtime API are used.</p><br>
    ///   - [`test_execution_modality(TestExecutionModality)`](crate::operation::start_test_execution::builders::StartTestExecutionFluentBuilder::test_execution_modality) / [`set_test_execution_modality(Option<TestExecutionModality>)`](crate::operation::start_test_execution::builders::StartTestExecutionFluentBuilder::set_test_execution_modality):<br>required: **false**<br><p>Indicates whether audio or text is used.</p><br>
                            /// - On success, responds with [`StartTestExecutionOutput`](crate::operation::start_test_execution::StartTestExecutionOutput) with field(s):
    ///   - [`test_execution_id(Option<String>)`](crate::operation::start_test_execution::StartTestExecutionOutput::test_execution_id): <p>The unique identifier of the test set execution.</p>
    ///   - [`creation_date_time(Option<DateTime>)`](crate::operation::start_test_execution::StartTestExecutionOutput::creation_date_time): <p>The creation date and time for the test set execution.</p>
    ///   - [`test_set_id(Option<String>)`](crate::operation::start_test_execution::StartTestExecutionOutput::test_set_id): <p>The test set Id for the test set execution.</p>
    ///   - [`target(Option<TestExecutionTarget>)`](crate::operation::start_test_execution::StartTestExecutionOutput::target): <p>The target bot for the test set execution.</p>
    ///   - [`api_mode(Option<TestExecutionApiMode>)`](crate::operation::start_test_execution::StartTestExecutionOutput::api_mode): <p>Indicates whether we use streaming or non-streaming APIs for the test set execution. For streaming, StartConversation Amazon Lex Runtime API is used. Whereas for non-streaming, RecognizeUtterance and RecognizeText Amazon Lex Runtime API are used.</p>
    ///   - [`test_execution_modality(Option<TestExecutionModality>)`](crate::operation::start_test_execution::StartTestExecutionOutput::test_execution_modality): <p>Indicates whether audio or text is used.</p>
                            /// - On failure, responds with [`SdkError<StartTestExecutionError>`](crate::operation::start_test_execution::StartTestExecutionError)
    pub fn start_test_execution(&self) -> crate::operation::start_test_execution::builders::StartTestExecutionFluentBuilder {
                                crate::operation::start_test_execution::builders::StartTestExecutionFluentBuilder::new(self.handle.clone())
                            }
}

