// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Use this structure to launch multiple instance types and On-Demand Instances and Spot Instances within a single Auto Scaling group.</p> 
/// <p>A mixed instances policy contains information that Amazon EC2 Auto Scaling can use to launch instances and help optimize your costs. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html">Auto Scaling groups with multiple instance types and purchase options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct MixedInstancesPolicy  {
    /// <p>One or more launch templates and the instance types (overrides) that are used to launch EC2 instances to fulfill On-Demand and Spot capacities.</p>
    #[doc(hidden)]
    pub launch_template: std::option::Option<crate::model::LaunchTemplate>,
    /// <p>The instances distribution.</p>
    #[doc(hidden)]
    pub instances_distribution: std::option::Option<crate::model::InstancesDistribution>,
}
impl MixedInstancesPolicy {
    /// <p>One or more launch templates and the instance types (overrides) that are used to launch EC2 instances to fulfill On-Demand and Spot capacities.</p>
    pub fn launch_template(&self) -> std::option::Option<& crate::model::LaunchTemplate> {
        self.launch_template.as_ref()
    }
    /// <p>The instances distribution.</p>
    pub fn instances_distribution(&self) -> std::option::Option<& crate::model::InstancesDistribution> {
        self.instances_distribution.as_ref()
    }
}
/// See [`MixedInstancesPolicy`](crate::model::MixedInstancesPolicy).
pub mod mixed_instances_policy {
    
    /// A builder for [`MixedInstancesPolicy`](crate::model::MixedInstancesPolicy).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) launch_template: std::option::Option<crate::model::LaunchTemplate>,
        pub(crate) instances_distribution: std::option::Option<crate::model::InstancesDistribution>,
    }
    impl Builder {
        /// <p>One or more launch templates and the instance types (overrides) that are used to launch EC2 instances to fulfill On-Demand and Spot capacities.</p>
        pub fn launch_template(mut self, input: crate::model::LaunchTemplate) -> Self {
            self.launch_template = Some(input);
            self
        }
        /// <p>One or more launch templates and the instance types (overrides) that are used to launch EC2 instances to fulfill On-Demand and Spot capacities.</p>
        pub fn set_launch_template(mut self, input: std::option::Option<crate::model::LaunchTemplate>) -> Self {
            self.launch_template = input; self
        }
        /// <p>The instances distribution.</p>
        pub fn instances_distribution(mut self, input: crate::model::InstancesDistribution) -> Self {
            self.instances_distribution = Some(input);
            self
        }
        /// <p>The instances distribution.</p>
        pub fn set_instances_distribution(mut self, input: std::option::Option<crate::model::InstancesDistribution>) -> Self {
            self.instances_distribution = input; self
        }
        /// Consumes the builder and constructs a [`MixedInstancesPolicy`](crate::model::MixedInstancesPolicy).
        pub fn build(self) -> crate::model::MixedInstancesPolicy {
            crate::model::MixedInstancesPolicy {
                launch_template: self.launch_template
                ,
                instances_distribution: self.instances_distribution
                ,
            }
        }
    }
    
    
}
impl MixedInstancesPolicy {
    /// Creates a new builder-style object to manufacture [`MixedInstancesPolicy`](crate::model::MixedInstancesPolicy).
    pub fn builder() -> crate::model::mixed_instances_policy::Builder {
        crate::model::mixed_instances_policy::Builder::default()
    }
}

/// <p>Use this structure to specify the distribution of On-Demand Instances and Spot Instances and the allocation strategies used to fulfill On-Demand and Spot capacities for a mixed instances policy.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct InstancesDistribution  {
    /// <p>The allocation strategy to apply to your On-Demand Instances when they are launched. Possible instance types are determined by the launch template overrides that you specify.</p> 
    /// <p>The following lists the valid values:</p> 
    /// <dl> 
    /// <dt>
    /// lowest-price
    /// </dt> 
    /// <dd> 
    /// <p>Uses price to determine which instance types are the highest priority, launching the lowest priced instance types within an Availability Zone first. This is the default value for Auto Scaling groups that specify <code>InstanceRequirements</code>. </p> 
    /// </dd> 
    /// <dt>
    /// prioritized
    /// </dt> 
    /// <dd> 
    /// <p>You set the order of instance types for the launch template overrides from highest to lowest priority (from first to last in the list). Amazon EC2 Auto Scaling launches your highest priority instance types first. If all your On-Demand capacity cannot be fulfilled using your highest priority instance type, then Amazon EC2 Auto Scaling launches the remaining capacity using the second priority instance type, and so on. This is the default value for Auto Scaling groups that don't specify <code>InstanceRequirements</code> and cannot be used for groups that do.</p> 
    /// </dd> 
    /// </dl>
    #[doc(hidden)]
    pub on_demand_allocation_strategy: std::option::Option<std::string::String>,
    /// <p>The minimum amount of the Auto Scaling group's capacity that must be fulfilled by On-Demand Instances. This base portion is launched first as your group scales.</p> 
    /// <p>This number has the same unit of measurement as the group's desired capacity. If you change the default unit of measurement (number of instances) by specifying weighted capacity values in your launch template overrides list, or by changing the default desired capacity type setting of the group, you must specify this number using the same unit of measurement.</p> 
    /// <p>Default: 0</p>
    #[doc(hidden)]
    pub on_demand_base_capacity: std::option::Option<i32>,
    /// <p>Controls the percentages of On-Demand Instances and Spot Instances for your additional capacity beyond <code>OnDemandBaseCapacity</code>. Expressed as a number (for example, 20 specifies 20% On-Demand Instances, 80% Spot Instances). If set to 100, only On-Demand Instances are used.</p> 
    /// <p>Default: 100</p>
    #[doc(hidden)]
    pub on_demand_percentage_above_base_capacity: std::option::Option<i32>,
    /// <p>The allocation strategy to apply to your Spot Instances when they are launched. Possible instance types are determined by the launch template overrides that you specify.</p> 
    /// <p>The following lists the valid values:</p> 
    /// <dl> 
    /// <dt>
    /// capacity-optimized
    /// </dt> 
    /// <dd> 
    /// <p>Requests Spot Instances using pools that are optimally chosen based on the available Spot capacity. This strategy has the lowest risk of interruption. To give certain instance types a higher chance of launching first, use <code>capacity-optimized-prioritized</code>.</p> 
    /// </dd> 
    /// <dt>
    /// capacity-optimized-prioritized
    /// </dt> 
    /// <dd> 
    /// <p>You set the order of instance types for the launch template overrides from highest to lowest priority (from first to last in the list). Amazon EC2 Auto Scaling honors the instance type priorities on a best effort basis but optimizes for capacity first. Note that if the On-Demand allocation strategy is set to <code>prioritized</code>, the same priority is applied when fulfilling On-Demand capacity. This is not a valid value for Auto Scaling groups that specify <code>InstanceRequirements</code>.</p> 
    /// </dd> 
    /// <dt>
    /// lowest-price
    /// </dt> 
    /// <dd> 
    /// <p>Requests Spot Instances using the lowest priced pools within an Availability Zone, across the number of Spot pools that you specify for the <code>SpotInstancePools</code> property. To ensure that your desired capacity is met, you might receive Spot Instances from several pools. This is the default value, but it might lead to high interruption rates because this strategy only considers instance price and not available capacity.</p> 
    /// </dd> 
    /// <dt>
    /// price-capacity-optimized (recommended)
    /// </dt> 
    /// <dd> 
    /// <p>The price and capacity optimized allocation strategy looks at both price and capacity to select the Spot Instance pools that are the least likely to be interrupted and have the lowest possible price.</p> 
    /// </dd> 
    /// </dl>
    #[doc(hidden)]
    pub spot_allocation_strategy: std::option::Option<std::string::String>,
    /// <p>The number of Spot Instance pools across which to allocate your Spot Instances. The Spot pools are determined from the different instance types in the overrides. Valid only when the <code>SpotAllocationStrategy</code> is <code>lowest-price</code>. Value must be in the range of 1–20.</p> 
    /// <p>Default: 2</p>
    #[doc(hidden)]
    pub spot_instance_pools: std::option::Option<i32>,
    /// <p>The maximum price per unit hour that you are willing to pay for a Spot Instance. If your maximum price is lower than the Spot price for the instance types that you selected, your Spot Instances are not launched. We do not recommend specifying a maximum price because it can lead to increased interruptions. When Spot Instances launch, you pay the current Spot price. To remove a maximum price that you previously set, include the property but specify an empty string ("") for the value.</p> <important> 
    /// <p>If you specify a maximum price, your instances will be interrupted more frequently than if you do not specify one.</p> 
    /// </important> 
    /// <p>Valid Range: Minimum value of 0.001</p>
    #[doc(hidden)]
    pub spot_max_price: std::option::Option<std::string::String>,
}
impl InstancesDistribution {
    /// <p>The allocation strategy to apply to your On-Demand Instances when they are launched. Possible instance types are determined by the launch template overrides that you specify.</p> 
    /// <p>The following lists the valid values:</p> 
    /// <dl> 
    /// <dt>
    /// lowest-price
    /// </dt> 
    /// <dd> 
    /// <p>Uses price to determine which instance types are the highest priority, launching the lowest priced instance types within an Availability Zone first. This is the default value for Auto Scaling groups that specify <code>InstanceRequirements</code>. </p> 
    /// </dd> 
    /// <dt>
    /// prioritized
    /// </dt> 
    /// <dd> 
    /// <p>You set the order of instance types for the launch template overrides from highest to lowest priority (from first to last in the list). Amazon EC2 Auto Scaling launches your highest priority instance types first. If all your On-Demand capacity cannot be fulfilled using your highest priority instance type, then Amazon EC2 Auto Scaling launches the remaining capacity using the second priority instance type, and so on. This is the default value for Auto Scaling groups that don't specify <code>InstanceRequirements</code> and cannot be used for groups that do.</p> 
    /// </dd> 
    /// </dl>
    pub fn on_demand_allocation_strategy(&self) -> std::option::Option<& str> {
        self.on_demand_allocation_strategy.as_deref()
    }
    /// <p>The minimum amount of the Auto Scaling group's capacity that must be fulfilled by On-Demand Instances. This base portion is launched first as your group scales.</p> 
    /// <p>This number has the same unit of measurement as the group's desired capacity. If you change the default unit of measurement (number of instances) by specifying weighted capacity values in your launch template overrides list, or by changing the default desired capacity type setting of the group, you must specify this number using the same unit of measurement.</p> 
    /// <p>Default: 0</p>
    pub fn on_demand_base_capacity(&self) -> std::option::Option<i32> {
        self.on_demand_base_capacity
    }
    /// <p>Controls the percentages of On-Demand Instances and Spot Instances for your additional capacity beyond <code>OnDemandBaseCapacity</code>. Expressed as a number (for example, 20 specifies 20% On-Demand Instances, 80% Spot Instances). If set to 100, only On-Demand Instances are used.</p> 
    /// <p>Default: 100</p>
    pub fn on_demand_percentage_above_base_capacity(&self) -> std::option::Option<i32> {
        self.on_demand_percentage_above_base_capacity
    }
    /// <p>The allocation strategy to apply to your Spot Instances when they are launched. Possible instance types are determined by the launch template overrides that you specify.</p> 
    /// <p>The following lists the valid values:</p> 
    /// <dl> 
    /// <dt>
    /// capacity-optimized
    /// </dt> 
    /// <dd> 
    /// <p>Requests Spot Instances using pools that are optimally chosen based on the available Spot capacity. This strategy has the lowest risk of interruption. To give certain instance types a higher chance of launching first, use <code>capacity-optimized-prioritized</code>.</p> 
    /// </dd> 
    /// <dt>
    /// capacity-optimized-prioritized
    /// </dt> 
    /// <dd> 
    /// <p>You set the order of instance types for the launch template overrides from highest to lowest priority (from first to last in the list). Amazon EC2 Auto Scaling honors the instance type priorities on a best effort basis but optimizes for capacity first. Note that if the On-Demand allocation strategy is set to <code>prioritized</code>, the same priority is applied when fulfilling On-Demand capacity. This is not a valid value for Auto Scaling groups that specify <code>InstanceRequirements</code>.</p> 
    /// </dd> 
    /// <dt>
    /// lowest-price
    /// </dt> 
    /// <dd> 
    /// <p>Requests Spot Instances using the lowest priced pools within an Availability Zone, across the number of Spot pools that you specify for the <code>SpotInstancePools</code> property. To ensure that your desired capacity is met, you might receive Spot Instances from several pools. This is the default value, but it might lead to high interruption rates because this strategy only considers instance price and not available capacity.</p> 
    /// </dd> 
    /// <dt>
    /// price-capacity-optimized (recommended)
    /// </dt> 
    /// <dd> 
    /// <p>The price and capacity optimized allocation strategy looks at both price and capacity to select the Spot Instance pools that are the least likely to be interrupted and have the lowest possible price.</p> 
    /// </dd> 
    /// </dl>
    pub fn spot_allocation_strategy(&self) -> std::option::Option<& str> {
        self.spot_allocation_strategy.as_deref()
    }
    /// <p>The number of Spot Instance pools across which to allocate your Spot Instances. The Spot pools are determined from the different instance types in the overrides. Valid only when the <code>SpotAllocationStrategy</code> is <code>lowest-price</code>. Value must be in the range of 1–20.</p> 
    /// <p>Default: 2</p>
    pub fn spot_instance_pools(&self) -> std::option::Option<i32> {
        self.spot_instance_pools
    }
    /// <p>The maximum price per unit hour that you are willing to pay for a Spot Instance. If your maximum price is lower than the Spot price for the instance types that you selected, your Spot Instances are not launched. We do not recommend specifying a maximum price because it can lead to increased interruptions. When Spot Instances launch, you pay the current Spot price. To remove a maximum price that you previously set, include the property but specify an empty string ("") for the value.</p> <important> 
    /// <p>If you specify a maximum price, your instances will be interrupted more frequently than if you do not specify one.</p> 
    /// </important> 
    /// <p>Valid Range: Minimum value of 0.001</p>
    pub fn spot_max_price(&self) -> std::option::Option<& str> {
        self.spot_max_price.as_deref()
    }
}
/// See [`InstancesDistribution`](crate::model::InstancesDistribution).
pub mod instances_distribution {
    
    /// A builder for [`InstancesDistribution`](crate::model::InstancesDistribution).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) on_demand_allocation_strategy: std::option::Option<std::string::String>,
        pub(crate) on_demand_base_capacity: std::option::Option<i32>,
        pub(crate) on_demand_percentage_above_base_capacity: std::option::Option<i32>,
        pub(crate) spot_allocation_strategy: std::option::Option<std::string::String>,
        pub(crate) spot_instance_pools: std::option::Option<i32>,
        pub(crate) spot_max_price: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The allocation strategy to apply to your On-Demand Instances when they are launched. Possible instance types are determined by the launch template overrides that you specify.</p> 
        /// <p>The following lists the valid values:</p> 
        /// <dl> 
        /// <dt>
        /// lowest-price
        /// </dt> 
        /// <dd> 
        /// <p>Uses price to determine which instance types are the highest priority, launching the lowest priced instance types within an Availability Zone first. This is the default value for Auto Scaling groups that specify <code>InstanceRequirements</code>. </p> 
        /// </dd> 
        /// <dt>
        /// prioritized
        /// </dt> 
        /// <dd> 
        /// <p>You set the order of instance types for the launch template overrides from highest to lowest priority (from first to last in the list). Amazon EC2 Auto Scaling launches your highest priority instance types first. If all your On-Demand capacity cannot be fulfilled using your highest priority instance type, then Amazon EC2 Auto Scaling launches the remaining capacity using the second priority instance type, and so on. This is the default value for Auto Scaling groups that don't specify <code>InstanceRequirements</code> and cannot be used for groups that do.</p> 
        /// </dd> 
        /// </dl>
        pub fn on_demand_allocation_strategy(mut self, input: impl Into<std::string::String>) -> Self {
            self.on_demand_allocation_strategy = Some(input.into());
            self
        }
        /// <p>The allocation strategy to apply to your On-Demand Instances when they are launched. Possible instance types are determined by the launch template overrides that you specify.</p> 
        /// <p>The following lists the valid values:</p> 
        /// <dl> 
        /// <dt>
        /// lowest-price
        /// </dt> 
        /// <dd> 
        /// <p>Uses price to determine which instance types are the highest priority, launching the lowest priced instance types within an Availability Zone first. This is the default value for Auto Scaling groups that specify <code>InstanceRequirements</code>. </p> 
        /// </dd> 
        /// <dt>
        /// prioritized
        /// </dt> 
        /// <dd> 
        /// <p>You set the order of instance types for the launch template overrides from highest to lowest priority (from first to last in the list). Amazon EC2 Auto Scaling launches your highest priority instance types first. If all your On-Demand capacity cannot be fulfilled using your highest priority instance type, then Amazon EC2 Auto Scaling launches the remaining capacity using the second priority instance type, and so on. This is the default value for Auto Scaling groups that don't specify <code>InstanceRequirements</code> and cannot be used for groups that do.</p> 
        /// </dd> 
        /// </dl>
        pub fn set_on_demand_allocation_strategy(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.on_demand_allocation_strategy = input; self
        }
        /// <p>The minimum amount of the Auto Scaling group's capacity that must be fulfilled by On-Demand Instances. This base portion is launched first as your group scales.</p> 
        /// <p>This number has the same unit of measurement as the group's desired capacity. If you change the default unit of measurement (number of instances) by specifying weighted capacity values in your launch template overrides list, or by changing the default desired capacity type setting of the group, you must specify this number using the same unit of measurement.</p> 
        /// <p>Default: 0</p>
        pub fn on_demand_base_capacity(mut self, input: i32) -> Self {
            self.on_demand_base_capacity = Some(input);
            self
        }
        /// <p>The minimum amount of the Auto Scaling group's capacity that must be fulfilled by On-Demand Instances. This base portion is launched first as your group scales.</p> 
        /// <p>This number has the same unit of measurement as the group's desired capacity. If you change the default unit of measurement (number of instances) by specifying weighted capacity values in your launch template overrides list, or by changing the default desired capacity type setting of the group, you must specify this number using the same unit of measurement.</p> 
        /// <p>Default: 0</p>
        pub fn set_on_demand_base_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.on_demand_base_capacity = input; self
        }
        /// <p>Controls the percentages of On-Demand Instances and Spot Instances for your additional capacity beyond <code>OnDemandBaseCapacity</code>. Expressed as a number (for example, 20 specifies 20% On-Demand Instances, 80% Spot Instances). If set to 100, only On-Demand Instances are used.</p> 
        /// <p>Default: 100</p>
        pub fn on_demand_percentage_above_base_capacity(mut self, input: i32) -> Self {
            self.on_demand_percentage_above_base_capacity = Some(input);
            self
        }
        /// <p>Controls the percentages of On-Demand Instances and Spot Instances for your additional capacity beyond <code>OnDemandBaseCapacity</code>. Expressed as a number (for example, 20 specifies 20% On-Demand Instances, 80% Spot Instances). If set to 100, only On-Demand Instances are used.</p> 
        /// <p>Default: 100</p>
        pub fn set_on_demand_percentage_above_base_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.on_demand_percentage_above_base_capacity = input; self
        }
        /// <p>The allocation strategy to apply to your Spot Instances when they are launched. Possible instance types are determined by the launch template overrides that you specify.</p> 
        /// <p>The following lists the valid values:</p> 
        /// <dl> 
        /// <dt>
        /// capacity-optimized
        /// </dt> 
        /// <dd> 
        /// <p>Requests Spot Instances using pools that are optimally chosen based on the available Spot capacity. This strategy has the lowest risk of interruption. To give certain instance types a higher chance of launching first, use <code>capacity-optimized-prioritized</code>.</p> 
        /// </dd> 
        /// <dt>
        /// capacity-optimized-prioritized
        /// </dt> 
        /// <dd> 
        /// <p>You set the order of instance types for the launch template overrides from highest to lowest priority (from first to last in the list). Amazon EC2 Auto Scaling honors the instance type priorities on a best effort basis but optimizes for capacity first. Note that if the On-Demand allocation strategy is set to <code>prioritized</code>, the same priority is applied when fulfilling On-Demand capacity. This is not a valid value for Auto Scaling groups that specify <code>InstanceRequirements</code>.</p> 
        /// </dd> 
        /// <dt>
        /// lowest-price
        /// </dt> 
        /// <dd> 
        /// <p>Requests Spot Instances using the lowest priced pools within an Availability Zone, across the number of Spot pools that you specify for the <code>SpotInstancePools</code> property. To ensure that your desired capacity is met, you might receive Spot Instances from several pools. This is the default value, but it might lead to high interruption rates because this strategy only considers instance price and not available capacity.</p> 
        /// </dd> 
        /// <dt>
        /// price-capacity-optimized (recommended)
        /// </dt> 
        /// <dd> 
        /// <p>The price and capacity optimized allocation strategy looks at both price and capacity to select the Spot Instance pools that are the least likely to be interrupted and have the lowest possible price.</p> 
        /// </dd> 
        /// </dl>
        pub fn spot_allocation_strategy(mut self, input: impl Into<std::string::String>) -> Self {
            self.spot_allocation_strategy = Some(input.into());
            self
        }
        /// <p>The allocation strategy to apply to your Spot Instances when they are launched. Possible instance types are determined by the launch template overrides that you specify.</p> 
        /// <p>The following lists the valid values:</p> 
        /// <dl> 
        /// <dt>
        /// capacity-optimized
        /// </dt> 
        /// <dd> 
        /// <p>Requests Spot Instances using pools that are optimally chosen based on the available Spot capacity. This strategy has the lowest risk of interruption. To give certain instance types a higher chance of launching first, use <code>capacity-optimized-prioritized</code>.</p> 
        /// </dd> 
        /// <dt>
        /// capacity-optimized-prioritized
        /// </dt> 
        /// <dd> 
        /// <p>You set the order of instance types for the launch template overrides from highest to lowest priority (from first to last in the list). Amazon EC2 Auto Scaling honors the instance type priorities on a best effort basis but optimizes for capacity first. Note that if the On-Demand allocation strategy is set to <code>prioritized</code>, the same priority is applied when fulfilling On-Demand capacity. This is not a valid value for Auto Scaling groups that specify <code>InstanceRequirements</code>.</p> 
        /// </dd> 
        /// <dt>
        /// lowest-price
        /// </dt> 
        /// <dd> 
        /// <p>Requests Spot Instances using the lowest priced pools within an Availability Zone, across the number of Spot pools that you specify for the <code>SpotInstancePools</code> property. To ensure that your desired capacity is met, you might receive Spot Instances from several pools. This is the default value, but it might lead to high interruption rates because this strategy only considers instance price and not available capacity.</p> 
        /// </dd> 
        /// <dt>
        /// price-capacity-optimized (recommended)
        /// </dt> 
        /// <dd> 
        /// <p>The price and capacity optimized allocation strategy looks at both price and capacity to select the Spot Instance pools that are the least likely to be interrupted and have the lowest possible price.</p> 
        /// </dd> 
        /// </dl>
        pub fn set_spot_allocation_strategy(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.spot_allocation_strategy = input; self
        }
        /// <p>The number of Spot Instance pools across which to allocate your Spot Instances. The Spot pools are determined from the different instance types in the overrides. Valid only when the <code>SpotAllocationStrategy</code> is <code>lowest-price</code>. Value must be in the range of 1–20.</p> 
        /// <p>Default: 2</p>
        pub fn spot_instance_pools(mut self, input: i32) -> Self {
            self.spot_instance_pools = Some(input);
            self
        }
        /// <p>The number of Spot Instance pools across which to allocate your Spot Instances. The Spot pools are determined from the different instance types in the overrides. Valid only when the <code>SpotAllocationStrategy</code> is <code>lowest-price</code>. Value must be in the range of 1–20.</p> 
        /// <p>Default: 2</p>
        pub fn set_spot_instance_pools(mut self, input: std::option::Option<i32>) -> Self {
            self.spot_instance_pools = input; self
        }
        /// <p>The maximum price per unit hour that you are willing to pay for a Spot Instance. If your maximum price is lower than the Spot price for the instance types that you selected, your Spot Instances are not launched. We do not recommend specifying a maximum price because it can lead to increased interruptions. When Spot Instances launch, you pay the current Spot price. To remove a maximum price that you previously set, include the property but specify an empty string ("") for the value.</p> <important> 
        /// <p>If you specify a maximum price, your instances will be interrupted more frequently than if you do not specify one.</p> 
        /// </important> 
        /// <p>Valid Range: Minimum value of 0.001</p>
        pub fn spot_max_price(mut self, input: impl Into<std::string::String>) -> Self {
            self.spot_max_price = Some(input.into());
            self
        }
        /// <p>The maximum price per unit hour that you are willing to pay for a Spot Instance. If your maximum price is lower than the Spot price for the instance types that you selected, your Spot Instances are not launched. We do not recommend specifying a maximum price because it can lead to increased interruptions. When Spot Instances launch, you pay the current Spot price. To remove a maximum price that you previously set, include the property but specify an empty string ("") for the value.</p> <important> 
        /// <p>If you specify a maximum price, your instances will be interrupted more frequently than if you do not specify one.</p> 
        /// </important> 
        /// <p>Valid Range: Minimum value of 0.001</p>
        pub fn set_spot_max_price(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.spot_max_price = input; self
        }
        /// Consumes the builder and constructs a [`InstancesDistribution`](crate::model::InstancesDistribution).
        pub fn build(self) -> crate::model::InstancesDistribution {
            crate::model::InstancesDistribution {
                on_demand_allocation_strategy: self.on_demand_allocation_strategy
                ,
                on_demand_base_capacity: self.on_demand_base_capacity
                ,
                on_demand_percentage_above_base_capacity: self.on_demand_percentage_above_base_capacity
                ,
                spot_allocation_strategy: self.spot_allocation_strategy
                ,
                spot_instance_pools: self.spot_instance_pools
                ,
                spot_max_price: self.spot_max_price
                ,
            }
        }
    }
    
    
}
impl InstancesDistribution {
    /// Creates a new builder-style object to manufacture [`InstancesDistribution`](crate::model::InstancesDistribution).
    pub fn builder() -> crate::model::instances_distribution::Builder {
        crate::model::instances_distribution::Builder::default()
    }
}

/// <p>Use this structure to specify the launch templates and instance types (overrides) for a mixed instances policy.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct LaunchTemplate  {
    /// <p>The launch template.</p>
    #[doc(hidden)]
    pub launch_template_specification: std::option::Option<crate::model::LaunchTemplateSpecification>,
    /// <p>Any properties that you specify override the same properties in the launch template.</p>
    #[doc(hidden)]
    pub overrides: std::option::Option<std::vec::Vec<crate::model::LaunchTemplateOverrides>>,
}
impl LaunchTemplate {
    /// <p>The launch template.</p>
    pub fn launch_template_specification(&self) -> std::option::Option<& crate::model::LaunchTemplateSpecification> {
        self.launch_template_specification.as_ref()
    }
    /// <p>Any properties that you specify override the same properties in the launch template.</p>
    pub fn overrides(&self) -> std::option::Option<& [crate::model::LaunchTemplateOverrides]> {
        self.overrides.as_deref()
    }
}
/// See [`LaunchTemplate`](crate::model::LaunchTemplate).
pub mod launch_template {
    
    /// A builder for [`LaunchTemplate`](crate::model::LaunchTemplate).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) launch_template_specification: std::option::Option<crate::model::LaunchTemplateSpecification>,
        pub(crate) overrides: std::option::Option<std::vec::Vec<crate::model::LaunchTemplateOverrides>>,
    }
    impl Builder {
        /// <p>The launch template.</p>
        pub fn launch_template_specification(mut self, input: crate::model::LaunchTemplateSpecification) -> Self {
            self.launch_template_specification = Some(input);
            self
        }
        /// <p>The launch template.</p>
        pub fn set_launch_template_specification(mut self, input: std::option::Option<crate::model::LaunchTemplateSpecification>) -> Self {
            self.launch_template_specification = input; self
        }
        /// Appends an item to `overrides`.
        ///
        /// To override the contents of this collection use [`set_overrides`](Self::set_overrides).
        ///
        /// <p>Any properties that you specify override the same properties in the launch template.</p>
        pub fn overrides(mut self, input: crate::model::LaunchTemplateOverrides) -> Self {
            let mut v = self.overrides.unwrap_or_default();
                            v.push(input);
                            self.overrides = Some(v);
                            self
        }
        /// <p>Any properties that you specify override the same properties in the launch template.</p>
        pub fn set_overrides(mut self, input: std::option::Option<std::vec::Vec<crate::model::LaunchTemplateOverrides>>) -> Self {
            self.overrides = input; self
        }
        /// Consumes the builder and constructs a [`LaunchTemplate`](crate::model::LaunchTemplate).
        pub fn build(self) -> crate::model::LaunchTemplate {
            crate::model::LaunchTemplate {
                launch_template_specification: self.launch_template_specification
                ,
                overrides: self.overrides
                ,
            }
        }
    }
    
    
}
impl LaunchTemplate {
    /// Creates a new builder-style object to manufacture [`LaunchTemplate`](crate::model::LaunchTemplate).
    pub fn builder() -> crate::model::launch_template::Builder {
        crate::model::launch_template::Builder::default()
    }
}

/// <p>Use this structure to let Amazon EC2 Auto Scaling do the following when the Auto Scaling group has a mixed instances policy:</p> 
/// <ul> 
/// <li> <p>Override the instance type that is specified in the launch template.</p> </li> 
/// <li> <p>Use multiple instance types.</p> </li> 
/// </ul> 
/// <p>Specify the instance types that you want, or define your instance requirements instead and let Amazon EC2 Auto Scaling provision the available instance types that meet your requirements. This can provide Amazon EC2 Auto Scaling with a larger selection of instance types to choose from when fulfilling Spot and On-Demand capacities. You can view which instance types are matched before you apply the instance requirements to your Auto Scaling group.</p> 
/// <p>After you define your instance requirements, you don't have to keep updating these settings to get new EC2 instance types automatically. Amazon EC2 Auto Scaling uses the instance requirements of the Auto Scaling group to determine whether a new EC2 instance type can be used.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct LaunchTemplateOverrides  {
    /// <p>The instance type, such as <code>m3.xlarge</code>. You must specify an instance type that is supported in your requested Region and Availability Zones. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">Instance types</a> in the <i>Amazon Elastic Compute Cloud User Guide</i>.</p> 
    /// <p>You can specify up to 40 instance types per Auto Scaling group.</p>
    #[doc(hidden)]
    pub instance_type: std::option::Option<std::string::String>,
    /// <p>If you provide a list of instance types to use, you can specify the number of capacity units provided by each instance type in terms of virtual CPUs, memory, storage, throughput, or other relative performance characteristic. When a Spot or On-Demand Instance is launched, the capacity units count toward the desired capacity. Amazon EC2 Auto Scaling launches instances until the desired capacity is totally fulfilled, even if this results in an overage. For example, if there are two units remaining to fulfill capacity, and Amazon EC2 Auto Scaling can only launch an instance with a <code>WeightedCapacity</code> of five units, the instance is launched, and the desired capacity is exceeded by three units. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups-instance-weighting.html">Configuring instance weighting for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. Value must be in the range of 1–999.</p> 
    /// <p>If you specify a value for <code>WeightedCapacity</code> for one instance type, you must specify a value for <code>WeightedCapacity</code> for all of them.</p> <important> 
    /// <p>Every Auto Scaling group has three size parameters (<code>DesiredCapacity</code>, <code>MaxSize</code>, and <code>MinSize</code>). Usually, you set these sizes based on a specific number of instances. However, if you configure a mixed instances policy that defines weights for the instance types, you must specify these sizes with the same units that you use for weighting instances. </p> 
    /// </important>
    #[doc(hidden)]
    pub weighted_capacity: std::option::Option<std::string::String>,
    /// <p>Provides a launch template for the specified instance type or set of instance requirements. For example, some instance types might require a launch template with a different AMI. If not provided, Amazon EC2 Auto Scaling uses the launch template that's specified in the <code>LaunchTemplate</code> definition. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups-launch-template-overrides.html">Specifying a different launch template for an instance type</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p> 
    /// <p>You can specify up to 20 launch templates per Auto Scaling group. The launch templates specified in the overrides and in the <code>LaunchTemplate</code> definition count towards this limit.</p>
    #[doc(hidden)]
    pub launch_template_specification: std::option::Option<crate::model::LaunchTemplateSpecification>,
    /// <p>The instance requirements. Amazon EC2 Auto Scaling uses your specified requirements to identify instance types. Then, it uses your On-Demand and Spot allocation strategies to launch instances from these instance types.</p> 
    /// <p>You can specify up to four separate sets of instance requirements per Auto Scaling group. This is useful for provisioning instances from different Amazon Machine Images (AMIs) in the same Auto Scaling group. To do this, create the AMIs and create a new launch template for each AMI. Then, create a compatible set of instance requirements for each launch template. </p> <note> 
    /// <p>If you specify <code>InstanceRequirements</code>, you can't specify <code>InstanceType</code>.</p> 
    /// </note>
    #[doc(hidden)]
    pub instance_requirements: std::option::Option<crate::model::InstanceRequirements>,
}
impl LaunchTemplateOverrides {
    /// <p>The instance type, such as <code>m3.xlarge</code>. You must specify an instance type that is supported in your requested Region and Availability Zones. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">Instance types</a> in the <i>Amazon Elastic Compute Cloud User Guide</i>.</p> 
    /// <p>You can specify up to 40 instance types per Auto Scaling group.</p>
    pub fn instance_type(&self) -> std::option::Option<& str> {
        self.instance_type.as_deref()
    }
    /// <p>If you provide a list of instance types to use, you can specify the number of capacity units provided by each instance type in terms of virtual CPUs, memory, storage, throughput, or other relative performance characteristic. When a Spot or On-Demand Instance is launched, the capacity units count toward the desired capacity. Amazon EC2 Auto Scaling launches instances until the desired capacity is totally fulfilled, even if this results in an overage. For example, if there are two units remaining to fulfill capacity, and Amazon EC2 Auto Scaling can only launch an instance with a <code>WeightedCapacity</code> of five units, the instance is launched, and the desired capacity is exceeded by three units. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups-instance-weighting.html">Configuring instance weighting for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. Value must be in the range of 1–999.</p> 
    /// <p>If you specify a value for <code>WeightedCapacity</code> for one instance type, you must specify a value for <code>WeightedCapacity</code> for all of them.</p> <important> 
    /// <p>Every Auto Scaling group has three size parameters (<code>DesiredCapacity</code>, <code>MaxSize</code>, and <code>MinSize</code>). Usually, you set these sizes based on a specific number of instances. However, if you configure a mixed instances policy that defines weights for the instance types, you must specify these sizes with the same units that you use for weighting instances. </p> 
    /// </important>
    pub fn weighted_capacity(&self) -> std::option::Option<& str> {
        self.weighted_capacity.as_deref()
    }
    /// <p>Provides a launch template for the specified instance type or set of instance requirements. For example, some instance types might require a launch template with a different AMI. If not provided, Amazon EC2 Auto Scaling uses the launch template that's specified in the <code>LaunchTemplate</code> definition. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups-launch-template-overrides.html">Specifying a different launch template for an instance type</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p> 
    /// <p>You can specify up to 20 launch templates per Auto Scaling group. The launch templates specified in the overrides and in the <code>LaunchTemplate</code> definition count towards this limit.</p>
    pub fn launch_template_specification(&self) -> std::option::Option<& crate::model::LaunchTemplateSpecification> {
        self.launch_template_specification.as_ref()
    }
    /// <p>The instance requirements. Amazon EC2 Auto Scaling uses your specified requirements to identify instance types. Then, it uses your On-Demand and Spot allocation strategies to launch instances from these instance types.</p> 
    /// <p>You can specify up to four separate sets of instance requirements per Auto Scaling group. This is useful for provisioning instances from different Amazon Machine Images (AMIs) in the same Auto Scaling group. To do this, create the AMIs and create a new launch template for each AMI. Then, create a compatible set of instance requirements for each launch template. </p> <note> 
    /// <p>If you specify <code>InstanceRequirements</code>, you can't specify <code>InstanceType</code>.</p> 
    /// </note>
    pub fn instance_requirements(&self) -> std::option::Option<& crate::model::InstanceRequirements> {
        self.instance_requirements.as_ref()
    }
}
/// See [`LaunchTemplateOverrides`](crate::model::LaunchTemplateOverrides).
pub mod launch_template_overrides {
    
    /// A builder for [`LaunchTemplateOverrides`](crate::model::LaunchTemplateOverrides).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) instance_type: std::option::Option<std::string::String>,
        pub(crate) weighted_capacity: std::option::Option<std::string::String>,
        pub(crate) launch_template_specification: std::option::Option<crate::model::LaunchTemplateSpecification>,
        pub(crate) instance_requirements: std::option::Option<crate::model::InstanceRequirements>,
    }
    impl Builder {
        /// <p>The instance type, such as <code>m3.xlarge</code>. You must specify an instance type that is supported in your requested Region and Availability Zones. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">Instance types</a> in the <i>Amazon Elastic Compute Cloud User Guide</i>.</p> 
        /// <p>You can specify up to 40 instance types per Auto Scaling group.</p>
        pub fn instance_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.instance_type = Some(input.into());
            self
        }
        /// <p>The instance type, such as <code>m3.xlarge</code>. You must specify an instance type that is supported in your requested Region and Availability Zones. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">Instance types</a> in the <i>Amazon Elastic Compute Cloud User Guide</i>.</p> 
        /// <p>You can specify up to 40 instance types per Auto Scaling group.</p>
        pub fn set_instance_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.instance_type = input; self
        }
        /// <p>If you provide a list of instance types to use, you can specify the number of capacity units provided by each instance type in terms of virtual CPUs, memory, storage, throughput, or other relative performance characteristic. When a Spot or On-Demand Instance is launched, the capacity units count toward the desired capacity. Amazon EC2 Auto Scaling launches instances until the desired capacity is totally fulfilled, even if this results in an overage. For example, if there are two units remaining to fulfill capacity, and Amazon EC2 Auto Scaling can only launch an instance with a <code>WeightedCapacity</code> of five units, the instance is launched, and the desired capacity is exceeded by three units. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups-instance-weighting.html">Configuring instance weighting for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. Value must be in the range of 1–999.</p> 
        /// <p>If you specify a value for <code>WeightedCapacity</code> for one instance type, you must specify a value for <code>WeightedCapacity</code> for all of them.</p> <important> 
        /// <p>Every Auto Scaling group has three size parameters (<code>DesiredCapacity</code>, <code>MaxSize</code>, and <code>MinSize</code>). Usually, you set these sizes based on a specific number of instances. However, if you configure a mixed instances policy that defines weights for the instance types, you must specify these sizes with the same units that you use for weighting instances. </p> 
        /// </important>
        pub fn weighted_capacity(mut self, input: impl Into<std::string::String>) -> Self {
            self.weighted_capacity = Some(input.into());
            self
        }
        /// <p>If you provide a list of instance types to use, you can specify the number of capacity units provided by each instance type in terms of virtual CPUs, memory, storage, throughput, or other relative performance characteristic. When a Spot or On-Demand Instance is launched, the capacity units count toward the desired capacity. Amazon EC2 Auto Scaling launches instances until the desired capacity is totally fulfilled, even if this results in an overage. For example, if there are two units remaining to fulfill capacity, and Amazon EC2 Auto Scaling can only launch an instance with a <code>WeightedCapacity</code> of five units, the instance is launched, and the desired capacity is exceeded by three units. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups-instance-weighting.html">Configuring instance weighting for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. Value must be in the range of 1–999.</p> 
        /// <p>If you specify a value for <code>WeightedCapacity</code> for one instance type, you must specify a value for <code>WeightedCapacity</code> for all of them.</p> <important> 
        /// <p>Every Auto Scaling group has three size parameters (<code>DesiredCapacity</code>, <code>MaxSize</code>, and <code>MinSize</code>). Usually, you set these sizes based on a specific number of instances. However, if you configure a mixed instances policy that defines weights for the instance types, you must specify these sizes with the same units that you use for weighting instances. </p> 
        /// </important>
        pub fn set_weighted_capacity(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.weighted_capacity = input; self
        }
        /// <p>Provides a launch template for the specified instance type or set of instance requirements. For example, some instance types might require a launch template with a different AMI. If not provided, Amazon EC2 Auto Scaling uses the launch template that's specified in the <code>LaunchTemplate</code> definition. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups-launch-template-overrides.html">Specifying a different launch template for an instance type</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p> 
        /// <p>You can specify up to 20 launch templates per Auto Scaling group. The launch templates specified in the overrides and in the <code>LaunchTemplate</code> definition count towards this limit.</p>
        pub fn launch_template_specification(mut self, input: crate::model::LaunchTemplateSpecification) -> Self {
            self.launch_template_specification = Some(input);
            self
        }
        /// <p>Provides a launch template for the specified instance type or set of instance requirements. For example, some instance types might require a launch template with a different AMI. If not provided, Amazon EC2 Auto Scaling uses the launch template that's specified in the <code>LaunchTemplate</code> definition. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups-launch-template-overrides.html">Specifying a different launch template for an instance type</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p> 
        /// <p>You can specify up to 20 launch templates per Auto Scaling group. The launch templates specified in the overrides and in the <code>LaunchTemplate</code> definition count towards this limit.</p>
        pub fn set_launch_template_specification(mut self, input: std::option::Option<crate::model::LaunchTemplateSpecification>) -> Self {
            self.launch_template_specification = input; self
        }
        /// <p>The instance requirements. Amazon EC2 Auto Scaling uses your specified requirements to identify instance types. Then, it uses your On-Demand and Spot allocation strategies to launch instances from these instance types.</p> 
        /// <p>You can specify up to four separate sets of instance requirements per Auto Scaling group. This is useful for provisioning instances from different Amazon Machine Images (AMIs) in the same Auto Scaling group. To do this, create the AMIs and create a new launch template for each AMI. Then, create a compatible set of instance requirements for each launch template. </p> <note> 
        /// <p>If you specify <code>InstanceRequirements</code>, you can't specify <code>InstanceType</code>.</p> 
        /// </note>
        pub fn instance_requirements(mut self, input: crate::model::InstanceRequirements) -> Self {
            self.instance_requirements = Some(input);
            self
        }
        /// <p>The instance requirements. Amazon EC2 Auto Scaling uses your specified requirements to identify instance types. Then, it uses your On-Demand and Spot allocation strategies to launch instances from these instance types.</p> 
        /// <p>You can specify up to four separate sets of instance requirements per Auto Scaling group. This is useful for provisioning instances from different Amazon Machine Images (AMIs) in the same Auto Scaling group. To do this, create the AMIs and create a new launch template for each AMI. Then, create a compatible set of instance requirements for each launch template. </p> <note> 
        /// <p>If you specify <code>InstanceRequirements</code>, you can't specify <code>InstanceType</code>.</p> 
        /// </note>
        pub fn set_instance_requirements(mut self, input: std::option::Option<crate::model::InstanceRequirements>) -> Self {
            self.instance_requirements = input; self
        }
        /// Consumes the builder and constructs a [`LaunchTemplateOverrides`](crate::model::LaunchTemplateOverrides).
        pub fn build(self) -> crate::model::LaunchTemplateOverrides {
            crate::model::LaunchTemplateOverrides {
                instance_type: self.instance_type
                ,
                weighted_capacity: self.weighted_capacity
                ,
                launch_template_specification: self.launch_template_specification
                ,
                instance_requirements: self.instance_requirements
                ,
            }
        }
    }
    
    
}
impl LaunchTemplateOverrides {
    /// Creates a new builder-style object to manufacture [`LaunchTemplateOverrides`](crate::model::LaunchTemplateOverrides).
    pub fn builder() -> crate::model::launch_template_overrides::Builder {
        crate::model::launch_template_overrides::Builder::default()
    }
}

/// <p>The attributes for the instance types for a mixed instances policy. Amazon EC2 Auto Scaling uses your specified requirements to identify instance types. Then, it uses your On-Demand and Spot allocation strategies to launch instances from these instance types.</p> 
/// <p>When you specify multiple attributes, you get instance types that satisfy all of the specified attributes. If you specify multiple values for an attribute, you get instance types that satisfy any of the specified values.</p> 
/// <p>To limit the list of instance types from which Amazon EC2 Auto Scaling can identify matching instance types, you can use one of the following parameters, but not both in the same request:</p> 
/// <ul> 
/// <li> <p> <code>AllowedInstanceTypes</code> - The instance types to include in the list. All other instance types are ignored, even if they match your specified attributes.</p> </li> 
/// <li> <p> <code>ExcludedInstanceTypes</code> - The instance types to exclude from the list, even if they match your specified attributes.</p> </li> 
/// </ul> <note> 
/// <p>You must specify <code>VCpuCount</code> and <code>MemoryMiB</code>. All other attributes are optional. Any unspecified optional attribute is set to its default.</p> 
/// </note> 
/// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-instance-type-requirements.html">Creating an Auto Scaling group using attribute-based instance type selection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. For help determining which instance types match your attributes before you apply them to your Auto Scaling group, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-fleet-attribute-based-instance-type-selection.html#ec2fleet-get-instance-types-from-instance-requirements">Preview instance types with specified attributes</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct InstanceRequirements  {
    /// <p>The minimum and maximum number of vCPUs for an instance type.</p>
    #[doc(hidden)]
    pub v_cpu_count: std::option::Option<crate::model::VCpuCountRequest>,
    /// <p>The minimum and maximum instance memory size for an instance type, in MiB.</p>
    #[doc(hidden)]
    pub memory_mi_b: std::option::Option<crate::model::MemoryMiBRequest>,
    /// <p>Lists which specific CPU manufacturers to include.</p> 
    /// <ul> 
    /// <li> <p>For instance types with Intel CPUs, specify <code>intel</code>.</p> </li> 
    /// <li> <p>For instance types with AMD CPUs, specify <code>amd</code>.</p> </li> 
    /// <li> <p>For instance types with Amazon Web Services CPUs, specify <code>amazon-web-services</code>.</p> </li> 
    /// </ul> <note> 
    /// <p>Don't confuse the CPU hardware manufacturer with the CPU hardware architecture. Instances will be launched with a compatible CPU architecture based on the Amazon Machine Image (AMI) that you specify in your launch template. </p> 
    /// </note> 
    /// <p>Default: Any manufacturer</p>
    #[doc(hidden)]
    pub cpu_manufacturers: std::option::Option<std::vec::Vec<crate::model::CpuManufacturer>>,
    /// <p>The minimum and maximum amount of memory per vCPU for an instance type, in GiB.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    #[doc(hidden)]
    pub memory_gi_b_per_v_cpu: std::option::Option<crate::model::MemoryGiBPerVCpuRequest>,
    /// <p>The instance types to exclude. You can use strings with one or more wild cards, represented by an asterisk (<code>*</code>), to exclude an instance family, type, size, or generation. The following are examples: <code>m5.8xlarge</code>, <code>c5*.*</code>, <code>m5a.*</code>, <code>r*</code>, <code>*3*</code>. </p> 
    /// <p>For example, if you specify <code>c5*</code>, you are excluding the entire C5 instance family, which includes all C5a and C5n instance types. If you specify <code>m5a.*</code>, Amazon EC2 Auto Scaling will exclude all the M5a instance types, but not the M5n instance types.</p> <note> 
    /// <p>If you specify <code>ExcludedInstanceTypes</code>, you can't specify <code>AllowedInstanceTypes</code>.</p> 
    /// </note> 
    /// <p>Default: No excluded instance types</p>
    #[doc(hidden)]
    pub excluded_instance_types: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>Indicates whether current or previous generation instance types are included.</p> 
    /// <ul> 
    /// <li> <p>For current generation instance types, specify <code>current</code>. The current generation includes EC2 instance types currently recommended for use. This typically includes the latest two to three generations in each instance family. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">Instance types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> </li> 
    /// <li> <p>For previous generation instance types, specify <code>previous</code>.</p> </li> 
    /// </ul> 
    /// <p>Default: Any current or previous generation</p>
    #[doc(hidden)]
    pub instance_generations: std::option::Option<std::vec::Vec<crate::model::InstanceGeneration>>,
    /// <p>The price protection threshold for Spot Instances. This is the maximum you’ll pay for a Spot Instance, expressed as a percentage higher than the least expensive current generation M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as <code>999999</code>. </p> 
    /// <p>If you set <code>DesiredCapacityType</code> to <code>vcpu</code> or <code>memory-mib</code>, the price protection threshold is applied based on the per vCPU or per memory price instead of the per instance price. </p> 
    /// <p>Default: <code>100</code> </p>
    #[doc(hidden)]
    pub spot_max_price_percentage_over_lowest_price: std::option::Option<i32>,
    /// <p>The price protection threshold for On-Demand Instances. This is the maximum you’ll pay for an On-Demand Instance, expressed as a percentage higher than the least expensive current generation M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as <code>999999</code>. </p> 
    /// <p>If you set <code>DesiredCapacityType</code> to <code>vcpu</code> or <code>memory-mib</code>, the price protection threshold is applied based on the per vCPU or per memory price instead of the per instance price. </p> 
    /// <p>Default: <code>20</code> </p>
    #[doc(hidden)]
    pub on_demand_max_price_percentage_over_lowest_price: std::option::Option<i32>,
    /// <p>Indicates whether bare metal instance types are included, excluded, or required.</p> 
    /// <p>Default: <code>excluded</code> </p>
    #[doc(hidden)]
    pub bare_metal: std::option::Option<crate::model::BareMetal>,
    /// <p>Indicates whether burstable performance instance types are included, excluded, or required. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/burstable-performance-instances.html">Burstable performance instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
    /// <p>Default: <code>excluded</code> </p>
    #[doc(hidden)]
    pub burstable_performance: std::option::Option<crate::model::BurstablePerformance>,
    /// <p>Indicates whether instance types must provide On-Demand Instance hibernation support.</p> 
    /// <p>Default: <code>false</code> </p>
    #[doc(hidden)]
    pub require_hibernate_support: std::option::Option<bool>,
    /// <p>The minimum and maximum number of network interfaces for an instance type.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    #[doc(hidden)]
    pub network_interface_count: std::option::Option<crate::model::NetworkInterfaceCountRequest>,
    /// <p>Indicates whether instance types with instance store volumes are included, excluded, or required. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html">Amazon EC2 instance store</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
    /// <p>Default: <code>included</code> </p>
    #[doc(hidden)]
    pub local_storage: std::option::Option<crate::model::LocalStorage>,
    /// <p>Indicates the type of local storage that is required.</p> 
    /// <ul> 
    /// <li> <p>For instance types with hard disk drive (HDD) storage, specify <code>hdd</code>.</p> </li> 
    /// <li> <p>For instance types with solid state drive (SSD) storage, specify <code>ssd</code>.</p> </li> 
    /// </ul> 
    /// <p>Default: Any local storage type</p>
    #[doc(hidden)]
    pub local_storage_types: std::option::Option<std::vec::Vec<crate::model::LocalStorageType>>,
    /// <p>The minimum and maximum total local storage size for an instance type, in GB.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    #[doc(hidden)]
    pub total_local_storage_gb: std::option::Option<crate::model::TotalLocalStorageGbRequest>,
    /// <p>The minimum and maximum baseline bandwidth performance for an instance type, in Mbps. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html">Amazon EBS–optimized instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    #[doc(hidden)]
    pub baseline_ebs_bandwidth_mbps: std::option::Option<crate::model::BaselineEbsBandwidthMbpsRequest>,
    /// <p>Lists the accelerator types that must be on an instance type.</p> 
    /// <ul> 
    /// <li> <p>For instance types with GPU accelerators, specify <code>gpu</code>.</p> </li> 
    /// <li> <p>For instance types with FPGA accelerators, specify <code>fpga</code>.</p> </li> 
    /// <li> <p>For instance types with inference accelerators, specify <code>inference</code>.</p> </li> 
    /// </ul> 
    /// <p>Default: Any accelerator type</p>
    #[doc(hidden)]
    pub accelerator_types: std::option::Option<std::vec::Vec<crate::model::AcceleratorType>>,
    /// <p>The minimum and maximum number of accelerators (GPUs, FPGAs, or Amazon Web Services Inferentia chips) for an instance type.</p> 
    /// <p>To exclude accelerator-enabled instance types, set <code>Max</code> to <code>0</code>.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    #[doc(hidden)]
    pub accelerator_count: std::option::Option<crate::model::AcceleratorCountRequest>,
    /// <p>Indicates whether instance types must have accelerators by specific manufacturers.</p> 
    /// <ul> 
    /// <li> <p>For instance types with NVIDIA devices, specify <code>nvidia</code>.</p> </li> 
    /// <li> <p>For instance types with AMD devices, specify <code>amd</code>.</p> </li> 
    /// <li> <p>For instance types with Amazon Web Services devices, specify <code>amazon-web-services</code>.</p> </li> 
    /// <li> <p>For instance types with Xilinx devices, specify <code>xilinx</code>.</p> </li> 
    /// </ul> 
    /// <p>Default: Any manufacturer</p>
    #[doc(hidden)]
    pub accelerator_manufacturers: std::option::Option<std::vec::Vec<crate::model::AcceleratorManufacturer>>,
    /// <p>Lists the accelerators that must be on an instance type.</p> 
    /// <ul> 
    /// <li> <p>For instance types with NVIDIA A100 GPUs, specify <code>a100</code>.</p> </li> 
    /// <li> <p>For instance types with NVIDIA V100 GPUs, specify <code>v100</code>.</p> </li> 
    /// <li> <p>For instance types with NVIDIA K80 GPUs, specify <code>k80</code>.</p> </li> 
    /// <li> <p>For instance types with NVIDIA T4 GPUs, specify <code>t4</code>.</p> </li> 
    /// <li> <p>For instance types with NVIDIA M60 GPUs, specify <code>m60</code>.</p> </li> 
    /// <li> <p>For instance types with AMD Radeon Pro V520 GPUs, specify <code>radeon-pro-v520</code>.</p> </li> 
    /// <li> <p>For instance types with Xilinx VU9P FPGAs, specify <code>vu9p</code>.</p> </li> 
    /// </ul> 
    /// <p>Default: Any accelerator</p>
    #[doc(hidden)]
    pub accelerator_names: std::option::Option<std::vec::Vec<crate::model::AcceleratorName>>,
    /// <p>The minimum and maximum total memory size for the accelerators on an instance type, in MiB.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    #[doc(hidden)]
    pub accelerator_total_memory_mi_b: std::option::Option<crate::model::AcceleratorTotalMemoryMiBRequest>,
    /// <p>The minimum and maximum amount of network bandwidth, in gigabits per second (Gbps).</p> 
    /// <p>Default: No minimum or maximum limits</p>
    #[doc(hidden)]
    pub network_bandwidth_gbps: std::option::Option<crate::model::NetworkBandwidthGbpsRequest>,
    /// <p>The instance types to apply your specified attributes against. All other instance types are ignored, even if they match your specified attributes.</p> 
    /// <p>You can use strings with one or more wild cards, represented by an asterisk (<code>*</code>), to allow an instance type, size, or generation. The following are examples: <code>m5.8xlarge</code>, <code>c5*.*</code>, <code>m5a.*</code>, <code>r*</code>, <code>*3*</code>.</p> 
    /// <p>For example, if you specify <code>c5*</code>, Amazon EC2 Auto Scaling will allow the entire C5 instance family, which includes all C5a and C5n instance types. If you specify <code>m5a.*</code>, Amazon EC2 Auto Scaling will allow all the M5a instance types, but not the M5n instance types.</p> <note> 
    /// <p>If you specify <code>AllowedInstanceTypes</code>, you can't specify <code>ExcludedInstanceTypes</code>.</p> 
    /// </note> 
    /// <p>Default: All instance types</p>
    #[doc(hidden)]
    pub allowed_instance_types: std::option::Option<std::vec::Vec<std::string::String>>,
}
impl InstanceRequirements {
    /// <p>The minimum and maximum number of vCPUs for an instance type.</p>
    pub fn v_cpu_count(&self) -> std::option::Option<& crate::model::VCpuCountRequest> {
        self.v_cpu_count.as_ref()
    }
    /// <p>The minimum and maximum instance memory size for an instance type, in MiB.</p>
    pub fn memory_mi_b(&self) -> std::option::Option<& crate::model::MemoryMiBRequest> {
        self.memory_mi_b.as_ref()
    }
    /// <p>Lists which specific CPU manufacturers to include.</p> 
    /// <ul> 
    /// <li> <p>For instance types with Intel CPUs, specify <code>intel</code>.</p> </li> 
    /// <li> <p>For instance types with AMD CPUs, specify <code>amd</code>.</p> </li> 
    /// <li> <p>For instance types with Amazon Web Services CPUs, specify <code>amazon-web-services</code>.</p> </li> 
    /// </ul> <note> 
    /// <p>Don't confuse the CPU hardware manufacturer with the CPU hardware architecture. Instances will be launched with a compatible CPU architecture based on the Amazon Machine Image (AMI) that you specify in your launch template. </p> 
    /// </note> 
    /// <p>Default: Any manufacturer</p>
    pub fn cpu_manufacturers(&self) -> std::option::Option<& [crate::model::CpuManufacturer]> {
        self.cpu_manufacturers.as_deref()
    }
    /// <p>The minimum and maximum amount of memory per vCPU for an instance type, in GiB.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    pub fn memory_gi_b_per_v_cpu(&self) -> std::option::Option<& crate::model::MemoryGiBPerVCpuRequest> {
        self.memory_gi_b_per_v_cpu.as_ref()
    }
    /// <p>The instance types to exclude. You can use strings with one or more wild cards, represented by an asterisk (<code>*</code>), to exclude an instance family, type, size, or generation. The following are examples: <code>m5.8xlarge</code>, <code>c5*.*</code>, <code>m5a.*</code>, <code>r*</code>, <code>*3*</code>. </p> 
    /// <p>For example, if you specify <code>c5*</code>, you are excluding the entire C5 instance family, which includes all C5a and C5n instance types. If you specify <code>m5a.*</code>, Amazon EC2 Auto Scaling will exclude all the M5a instance types, but not the M5n instance types.</p> <note> 
    /// <p>If you specify <code>ExcludedInstanceTypes</code>, you can't specify <code>AllowedInstanceTypes</code>.</p> 
    /// </note> 
    /// <p>Default: No excluded instance types</p>
    pub fn excluded_instance_types(&self) -> std::option::Option<& [std::string::String]> {
        self.excluded_instance_types.as_deref()
    }
    /// <p>Indicates whether current or previous generation instance types are included.</p> 
    /// <ul> 
    /// <li> <p>For current generation instance types, specify <code>current</code>. The current generation includes EC2 instance types currently recommended for use. This typically includes the latest two to three generations in each instance family. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">Instance types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> </li> 
    /// <li> <p>For previous generation instance types, specify <code>previous</code>.</p> </li> 
    /// </ul> 
    /// <p>Default: Any current or previous generation</p>
    pub fn instance_generations(&self) -> std::option::Option<& [crate::model::InstanceGeneration]> {
        self.instance_generations.as_deref()
    }
    /// <p>The price protection threshold for Spot Instances. This is the maximum you’ll pay for a Spot Instance, expressed as a percentage higher than the least expensive current generation M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as <code>999999</code>. </p> 
    /// <p>If you set <code>DesiredCapacityType</code> to <code>vcpu</code> or <code>memory-mib</code>, the price protection threshold is applied based on the per vCPU or per memory price instead of the per instance price. </p> 
    /// <p>Default: <code>100</code> </p>
    pub fn spot_max_price_percentage_over_lowest_price(&self) -> std::option::Option<i32> {
        self.spot_max_price_percentage_over_lowest_price
    }
    /// <p>The price protection threshold for On-Demand Instances. This is the maximum you’ll pay for an On-Demand Instance, expressed as a percentage higher than the least expensive current generation M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as <code>999999</code>. </p> 
    /// <p>If you set <code>DesiredCapacityType</code> to <code>vcpu</code> or <code>memory-mib</code>, the price protection threshold is applied based on the per vCPU or per memory price instead of the per instance price. </p> 
    /// <p>Default: <code>20</code> </p>
    pub fn on_demand_max_price_percentage_over_lowest_price(&self) -> std::option::Option<i32> {
        self.on_demand_max_price_percentage_over_lowest_price
    }
    /// <p>Indicates whether bare metal instance types are included, excluded, or required.</p> 
    /// <p>Default: <code>excluded</code> </p>
    pub fn bare_metal(&self) -> std::option::Option<& crate::model::BareMetal> {
        self.bare_metal.as_ref()
    }
    /// <p>Indicates whether burstable performance instance types are included, excluded, or required. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/burstable-performance-instances.html">Burstable performance instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
    /// <p>Default: <code>excluded</code> </p>
    pub fn burstable_performance(&self) -> std::option::Option<& crate::model::BurstablePerformance> {
        self.burstable_performance.as_ref()
    }
    /// <p>Indicates whether instance types must provide On-Demand Instance hibernation support.</p> 
    /// <p>Default: <code>false</code> </p>
    pub fn require_hibernate_support(&self) -> std::option::Option<bool> {
        self.require_hibernate_support
    }
    /// <p>The minimum and maximum number of network interfaces for an instance type.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    pub fn network_interface_count(&self) -> std::option::Option<& crate::model::NetworkInterfaceCountRequest> {
        self.network_interface_count.as_ref()
    }
    /// <p>Indicates whether instance types with instance store volumes are included, excluded, or required. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html">Amazon EC2 instance store</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
    /// <p>Default: <code>included</code> </p>
    pub fn local_storage(&self) -> std::option::Option<& crate::model::LocalStorage> {
        self.local_storage.as_ref()
    }
    /// <p>Indicates the type of local storage that is required.</p> 
    /// <ul> 
    /// <li> <p>For instance types with hard disk drive (HDD) storage, specify <code>hdd</code>.</p> </li> 
    /// <li> <p>For instance types with solid state drive (SSD) storage, specify <code>ssd</code>.</p> </li> 
    /// </ul> 
    /// <p>Default: Any local storage type</p>
    pub fn local_storage_types(&self) -> std::option::Option<& [crate::model::LocalStorageType]> {
        self.local_storage_types.as_deref()
    }
    /// <p>The minimum and maximum total local storage size for an instance type, in GB.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    pub fn total_local_storage_gb(&self) -> std::option::Option<& crate::model::TotalLocalStorageGbRequest> {
        self.total_local_storage_gb.as_ref()
    }
    /// <p>The minimum and maximum baseline bandwidth performance for an instance type, in Mbps. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html">Amazon EBS–optimized instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    pub fn baseline_ebs_bandwidth_mbps(&self) -> std::option::Option<& crate::model::BaselineEbsBandwidthMbpsRequest> {
        self.baseline_ebs_bandwidth_mbps.as_ref()
    }
    /// <p>Lists the accelerator types that must be on an instance type.</p> 
    /// <ul> 
    /// <li> <p>For instance types with GPU accelerators, specify <code>gpu</code>.</p> </li> 
    /// <li> <p>For instance types with FPGA accelerators, specify <code>fpga</code>.</p> </li> 
    /// <li> <p>For instance types with inference accelerators, specify <code>inference</code>.</p> </li> 
    /// </ul> 
    /// <p>Default: Any accelerator type</p>
    pub fn accelerator_types(&self) -> std::option::Option<& [crate::model::AcceleratorType]> {
        self.accelerator_types.as_deref()
    }
    /// <p>The minimum and maximum number of accelerators (GPUs, FPGAs, or Amazon Web Services Inferentia chips) for an instance type.</p> 
    /// <p>To exclude accelerator-enabled instance types, set <code>Max</code> to <code>0</code>.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    pub fn accelerator_count(&self) -> std::option::Option<& crate::model::AcceleratorCountRequest> {
        self.accelerator_count.as_ref()
    }
    /// <p>Indicates whether instance types must have accelerators by specific manufacturers.</p> 
    /// <ul> 
    /// <li> <p>For instance types with NVIDIA devices, specify <code>nvidia</code>.</p> </li> 
    /// <li> <p>For instance types with AMD devices, specify <code>amd</code>.</p> </li> 
    /// <li> <p>For instance types with Amazon Web Services devices, specify <code>amazon-web-services</code>.</p> </li> 
    /// <li> <p>For instance types with Xilinx devices, specify <code>xilinx</code>.</p> </li> 
    /// </ul> 
    /// <p>Default: Any manufacturer</p>
    pub fn accelerator_manufacturers(&self) -> std::option::Option<& [crate::model::AcceleratorManufacturer]> {
        self.accelerator_manufacturers.as_deref()
    }
    /// <p>Lists the accelerators that must be on an instance type.</p> 
    /// <ul> 
    /// <li> <p>For instance types with NVIDIA A100 GPUs, specify <code>a100</code>.</p> </li> 
    /// <li> <p>For instance types with NVIDIA V100 GPUs, specify <code>v100</code>.</p> </li> 
    /// <li> <p>For instance types with NVIDIA K80 GPUs, specify <code>k80</code>.</p> </li> 
    /// <li> <p>For instance types with NVIDIA T4 GPUs, specify <code>t4</code>.</p> </li> 
    /// <li> <p>For instance types with NVIDIA M60 GPUs, specify <code>m60</code>.</p> </li> 
    /// <li> <p>For instance types with AMD Radeon Pro V520 GPUs, specify <code>radeon-pro-v520</code>.</p> </li> 
    /// <li> <p>For instance types with Xilinx VU9P FPGAs, specify <code>vu9p</code>.</p> </li> 
    /// </ul> 
    /// <p>Default: Any accelerator</p>
    pub fn accelerator_names(&self) -> std::option::Option<& [crate::model::AcceleratorName]> {
        self.accelerator_names.as_deref()
    }
    /// <p>The minimum and maximum total memory size for the accelerators on an instance type, in MiB.</p> 
    /// <p>Default: No minimum or maximum limits</p>
    pub fn accelerator_total_memory_mi_b(&self) -> std::option::Option<& crate::model::AcceleratorTotalMemoryMiBRequest> {
        self.accelerator_total_memory_mi_b.as_ref()
    }
    /// <p>The minimum and maximum amount of network bandwidth, in gigabits per second (Gbps).</p> 
    /// <p>Default: No minimum or maximum limits</p>
    pub fn network_bandwidth_gbps(&self) -> std::option::Option<& crate::model::NetworkBandwidthGbpsRequest> {
        self.network_bandwidth_gbps.as_ref()
    }
    /// <p>The instance types to apply your specified attributes against. All other instance types are ignored, even if they match your specified attributes.</p> 
    /// <p>You can use strings with one or more wild cards, represented by an asterisk (<code>*</code>), to allow an instance type, size, or generation. The following are examples: <code>m5.8xlarge</code>, <code>c5*.*</code>, <code>m5a.*</code>, <code>r*</code>, <code>*3*</code>.</p> 
    /// <p>For example, if you specify <code>c5*</code>, Amazon EC2 Auto Scaling will allow the entire C5 instance family, which includes all C5a and C5n instance types. If you specify <code>m5a.*</code>, Amazon EC2 Auto Scaling will allow all the M5a instance types, but not the M5n instance types.</p> <note> 
    /// <p>If you specify <code>AllowedInstanceTypes</code>, you can't specify <code>ExcludedInstanceTypes</code>.</p> 
    /// </note> 
    /// <p>Default: All instance types</p>
    pub fn allowed_instance_types(&self) -> std::option::Option<& [std::string::String]> {
        self.allowed_instance_types.as_deref()
    }
}
/// See [`InstanceRequirements`](crate::model::InstanceRequirements).
pub mod instance_requirements {
    
    /// A builder for [`InstanceRequirements`](crate::model::InstanceRequirements).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) v_cpu_count: std::option::Option<crate::model::VCpuCountRequest>,
        pub(crate) memory_mi_b: std::option::Option<crate::model::MemoryMiBRequest>,
        pub(crate) cpu_manufacturers: std::option::Option<std::vec::Vec<crate::model::CpuManufacturer>>,
        pub(crate) memory_gi_b_per_v_cpu: std::option::Option<crate::model::MemoryGiBPerVCpuRequest>,
        pub(crate) excluded_instance_types: std::option::Option<std::vec::Vec<std::string::String>>,
        pub(crate) instance_generations: std::option::Option<std::vec::Vec<crate::model::InstanceGeneration>>,
        pub(crate) spot_max_price_percentage_over_lowest_price: std::option::Option<i32>,
        pub(crate) on_demand_max_price_percentage_over_lowest_price: std::option::Option<i32>,
        pub(crate) bare_metal: std::option::Option<crate::model::BareMetal>,
        pub(crate) burstable_performance: std::option::Option<crate::model::BurstablePerformance>,
        pub(crate) require_hibernate_support: std::option::Option<bool>,
        pub(crate) network_interface_count: std::option::Option<crate::model::NetworkInterfaceCountRequest>,
        pub(crate) local_storage: std::option::Option<crate::model::LocalStorage>,
        pub(crate) local_storage_types: std::option::Option<std::vec::Vec<crate::model::LocalStorageType>>,
        pub(crate) total_local_storage_gb: std::option::Option<crate::model::TotalLocalStorageGbRequest>,
        pub(crate) baseline_ebs_bandwidth_mbps: std::option::Option<crate::model::BaselineEbsBandwidthMbpsRequest>,
        pub(crate) accelerator_types: std::option::Option<std::vec::Vec<crate::model::AcceleratorType>>,
        pub(crate) accelerator_count: std::option::Option<crate::model::AcceleratorCountRequest>,
        pub(crate) accelerator_manufacturers: std::option::Option<std::vec::Vec<crate::model::AcceleratorManufacturer>>,
        pub(crate) accelerator_names: std::option::Option<std::vec::Vec<crate::model::AcceleratorName>>,
        pub(crate) accelerator_total_memory_mi_b: std::option::Option<crate::model::AcceleratorTotalMemoryMiBRequest>,
        pub(crate) network_bandwidth_gbps: std::option::Option<crate::model::NetworkBandwidthGbpsRequest>,
        pub(crate) allowed_instance_types: std::option::Option<std::vec::Vec<std::string::String>>,
    }
    impl Builder {
        /// <p>The minimum and maximum number of vCPUs for an instance type.</p>
        pub fn v_cpu_count(mut self, input: crate::model::VCpuCountRequest) -> Self {
            self.v_cpu_count = Some(input);
            self
        }
        /// <p>The minimum and maximum number of vCPUs for an instance type.</p>
        pub fn set_v_cpu_count(mut self, input: std::option::Option<crate::model::VCpuCountRequest>) -> Self {
            self.v_cpu_count = input; self
        }
        /// <p>The minimum and maximum instance memory size for an instance type, in MiB.</p>
        pub fn memory_mi_b(mut self, input: crate::model::MemoryMiBRequest) -> Self {
            self.memory_mi_b = Some(input);
            self
        }
        /// <p>The minimum and maximum instance memory size for an instance type, in MiB.</p>
        pub fn set_memory_mi_b(mut self, input: std::option::Option<crate::model::MemoryMiBRequest>) -> Self {
            self.memory_mi_b = input; self
        }
        /// Appends an item to `cpu_manufacturers`.
        ///
        /// To override the contents of this collection use [`set_cpu_manufacturers`](Self::set_cpu_manufacturers).
        ///
        /// <p>Lists which specific CPU manufacturers to include.</p> 
        /// <ul> 
        /// <li> <p>For instance types with Intel CPUs, specify <code>intel</code>.</p> </li> 
        /// <li> <p>For instance types with AMD CPUs, specify <code>amd</code>.</p> </li> 
        /// <li> <p>For instance types with Amazon Web Services CPUs, specify <code>amazon-web-services</code>.</p> </li> 
        /// </ul> <note> 
        /// <p>Don't confuse the CPU hardware manufacturer with the CPU hardware architecture. Instances will be launched with a compatible CPU architecture based on the Amazon Machine Image (AMI) that you specify in your launch template. </p> 
        /// </note> 
        /// <p>Default: Any manufacturer</p>
        pub fn cpu_manufacturers(mut self, input: crate::model::CpuManufacturer) -> Self {
            let mut v = self.cpu_manufacturers.unwrap_or_default();
                            v.push(input);
                            self.cpu_manufacturers = Some(v);
                            self
        }
        /// <p>Lists which specific CPU manufacturers to include.</p> 
        /// <ul> 
        /// <li> <p>For instance types with Intel CPUs, specify <code>intel</code>.</p> </li> 
        /// <li> <p>For instance types with AMD CPUs, specify <code>amd</code>.</p> </li> 
        /// <li> <p>For instance types with Amazon Web Services CPUs, specify <code>amazon-web-services</code>.</p> </li> 
        /// </ul> <note> 
        /// <p>Don't confuse the CPU hardware manufacturer with the CPU hardware architecture. Instances will be launched with a compatible CPU architecture based on the Amazon Machine Image (AMI) that you specify in your launch template. </p> 
        /// </note> 
        /// <p>Default: Any manufacturer</p>
        pub fn set_cpu_manufacturers(mut self, input: std::option::Option<std::vec::Vec<crate::model::CpuManufacturer>>) -> Self {
            self.cpu_manufacturers = input; self
        }
        /// <p>The minimum and maximum amount of memory per vCPU for an instance type, in GiB.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn memory_gi_b_per_v_cpu(mut self, input: crate::model::MemoryGiBPerVCpuRequest) -> Self {
            self.memory_gi_b_per_v_cpu = Some(input);
            self
        }
        /// <p>The minimum and maximum amount of memory per vCPU for an instance type, in GiB.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn set_memory_gi_b_per_v_cpu(mut self, input: std::option::Option<crate::model::MemoryGiBPerVCpuRequest>) -> Self {
            self.memory_gi_b_per_v_cpu = input; self
        }
        /// Appends an item to `excluded_instance_types`.
        ///
        /// To override the contents of this collection use [`set_excluded_instance_types`](Self::set_excluded_instance_types).
        ///
        /// <p>The instance types to exclude. You can use strings with one or more wild cards, represented by an asterisk (<code>*</code>), to exclude an instance family, type, size, or generation. The following are examples: <code>m5.8xlarge</code>, <code>c5*.*</code>, <code>m5a.*</code>, <code>r*</code>, <code>*3*</code>. </p> 
        /// <p>For example, if you specify <code>c5*</code>, you are excluding the entire C5 instance family, which includes all C5a and C5n instance types. If you specify <code>m5a.*</code>, Amazon EC2 Auto Scaling will exclude all the M5a instance types, but not the M5n instance types.</p> <note> 
        /// <p>If you specify <code>ExcludedInstanceTypes</code>, you can't specify <code>AllowedInstanceTypes</code>.</p> 
        /// </note> 
        /// <p>Default: No excluded instance types</p>
        pub fn excluded_instance_types(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.excluded_instance_types.unwrap_or_default();
                            v.push(input.into());
                            self.excluded_instance_types = Some(v);
                            self
        }
        /// <p>The instance types to exclude. You can use strings with one or more wild cards, represented by an asterisk (<code>*</code>), to exclude an instance family, type, size, or generation. The following are examples: <code>m5.8xlarge</code>, <code>c5*.*</code>, <code>m5a.*</code>, <code>r*</code>, <code>*3*</code>. </p> 
        /// <p>For example, if you specify <code>c5*</code>, you are excluding the entire C5 instance family, which includes all C5a and C5n instance types. If you specify <code>m5a.*</code>, Amazon EC2 Auto Scaling will exclude all the M5a instance types, but not the M5n instance types.</p> <note> 
        /// <p>If you specify <code>ExcludedInstanceTypes</code>, you can't specify <code>AllowedInstanceTypes</code>.</p> 
        /// </note> 
        /// <p>Default: No excluded instance types</p>
        pub fn set_excluded_instance_types(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.excluded_instance_types = input; self
        }
        /// Appends an item to `instance_generations`.
        ///
        /// To override the contents of this collection use [`set_instance_generations`](Self::set_instance_generations).
        ///
        /// <p>Indicates whether current or previous generation instance types are included.</p> 
        /// <ul> 
        /// <li> <p>For current generation instance types, specify <code>current</code>. The current generation includes EC2 instance types currently recommended for use. This typically includes the latest two to three generations in each instance family. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">Instance types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> </li> 
        /// <li> <p>For previous generation instance types, specify <code>previous</code>.</p> </li> 
        /// </ul> 
        /// <p>Default: Any current or previous generation</p>
        pub fn instance_generations(mut self, input: crate::model::InstanceGeneration) -> Self {
            let mut v = self.instance_generations.unwrap_or_default();
                            v.push(input);
                            self.instance_generations = Some(v);
                            self
        }
        /// <p>Indicates whether current or previous generation instance types are included.</p> 
        /// <ul> 
        /// <li> <p>For current generation instance types, specify <code>current</code>. The current generation includes EC2 instance types currently recommended for use. This typically includes the latest two to three generations in each instance family. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">Instance types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> </li> 
        /// <li> <p>For previous generation instance types, specify <code>previous</code>.</p> </li> 
        /// </ul> 
        /// <p>Default: Any current or previous generation</p>
        pub fn set_instance_generations(mut self, input: std::option::Option<std::vec::Vec<crate::model::InstanceGeneration>>) -> Self {
            self.instance_generations = input; self
        }
        /// <p>The price protection threshold for Spot Instances. This is the maximum you’ll pay for a Spot Instance, expressed as a percentage higher than the least expensive current generation M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as <code>999999</code>. </p> 
        /// <p>If you set <code>DesiredCapacityType</code> to <code>vcpu</code> or <code>memory-mib</code>, the price protection threshold is applied based on the per vCPU or per memory price instead of the per instance price. </p> 
        /// <p>Default: <code>100</code> </p>
        pub fn spot_max_price_percentage_over_lowest_price(mut self, input: i32) -> Self {
            self.spot_max_price_percentage_over_lowest_price = Some(input);
            self
        }
        /// <p>The price protection threshold for Spot Instances. This is the maximum you’ll pay for a Spot Instance, expressed as a percentage higher than the least expensive current generation M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as <code>999999</code>. </p> 
        /// <p>If you set <code>DesiredCapacityType</code> to <code>vcpu</code> or <code>memory-mib</code>, the price protection threshold is applied based on the per vCPU or per memory price instead of the per instance price. </p> 
        /// <p>Default: <code>100</code> </p>
        pub fn set_spot_max_price_percentage_over_lowest_price(mut self, input: std::option::Option<i32>) -> Self {
            self.spot_max_price_percentage_over_lowest_price = input; self
        }
        /// <p>The price protection threshold for On-Demand Instances. This is the maximum you’ll pay for an On-Demand Instance, expressed as a percentage higher than the least expensive current generation M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as <code>999999</code>. </p> 
        /// <p>If you set <code>DesiredCapacityType</code> to <code>vcpu</code> or <code>memory-mib</code>, the price protection threshold is applied based on the per vCPU or per memory price instead of the per instance price. </p> 
        /// <p>Default: <code>20</code> </p>
        pub fn on_demand_max_price_percentage_over_lowest_price(mut self, input: i32) -> Self {
            self.on_demand_max_price_percentage_over_lowest_price = Some(input);
            self
        }
        /// <p>The price protection threshold for On-Demand Instances. This is the maximum you’ll pay for an On-Demand Instance, expressed as a percentage higher than the least expensive current generation M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as <code>999999</code>. </p> 
        /// <p>If you set <code>DesiredCapacityType</code> to <code>vcpu</code> or <code>memory-mib</code>, the price protection threshold is applied based on the per vCPU or per memory price instead of the per instance price. </p> 
        /// <p>Default: <code>20</code> </p>
        pub fn set_on_demand_max_price_percentage_over_lowest_price(mut self, input: std::option::Option<i32>) -> Self {
            self.on_demand_max_price_percentage_over_lowest_price = input; self
        }
        /// <p>Indicates whether bare metal instance types are included, excluded, or required.</p> 
        /// <p>Default: <code>excluded</code> </p>
        pub fn bare_metal(mut self, input: crate::model::BareMetal) -> Self {
            self.bare_metal = Some(input);
            self
        }
        /// <p>Indicates whether bare metal instance types are included, excluded, or required.</p> 
        /// <p>Default: <code>excluded</code> </p>
        pub fn set_bare_metal(mut self, input: std::option::Option<crate::model::BareMetal>) -> Self {
            self.bare_metal = input; self
        }
        /// <p>Indicates whether burstable performance instance types are included, excluded, or required. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/burstable-performance-instances.html">Burstable performance instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
        /// <p>Default: <code>excluded</code> </p>
        pub fn burstable_performance(mut self, input: crate::model::BurstablePerformance) -> Self {
            self.burstable_performance = Some(input);
            self
        }
        /// <p>Indicates whether burstable performance instance types are included, excluded, or required. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/burstable-performance-instances.html">Burstable performance instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
        /// <p>Default: <code>excluded</code> </p>
        pub fn set_burstable_performance(mut self, input: std::option::Option<crate::model::BurstablePerformance>) -> Self {
            self.burstable_performance = input; self
        }
        /// <p>Indicates whether instance types must provide On-Demand Instance hibernation support.</p> 
        /// <p>Default: <code>false</code> </p>
        pub fn require_hibernate_support(mut self, input: bool) -> Self {
            self.require_hibernate_support = Some(input);
            self
        }
        /// <p>Indicates whether instance types must provide On-Demand Instance hibernation support.</p> 
        /// <p>Default: <code>false</code> </p>
        pub fn set_require_hibernate_support(mut self, input: std::option::Option<bool>) -> Self {
            self.require_hibernate_support = input; self
        }
        /// <p>The minimum and maximum number of network interfaces for an instance type.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn network_interface_count(mut self, input: crate::model::NetworkInterfaceCountRequest) -> Self {
            self.network_interface_count = Some(input);
            self
        }
        /// <p>The minimum and maximum number of network interfaces for an instance type.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn set_network_interface_count(mut self, input: std::option::Option<crate::model::NetworkInterfaceCountRequest>) -> Self {
            self.network_interface_count = input; self
        }
        /// <p>Indicates whether instance types with instance store volumes are included, excluded, or required. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html">Amazon EC2 instance store</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
        /// <p>Default: <code>included</code> </p>
        pub fn local_storage(mut self, input: crate::model::LocalStorage) -> Self {
            self.local_storage = Some(input);
            self
        }
        /// <p>Indicates whether instance types with instance store volumes are included, excluded, or required. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html">Amazon EC2 instance store</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
        /// <p>Default: <code>included</code> </p>
        pub fn set_local_storage(mut self, input: std::option::Option<crate::model::LocalStorage>) -> Self {
            self.local_storage = input; self
        }
        /// Appends an item to `local_storage_types`.
        ///
        /// To override the contents of this collection use [`set_local_storage_types`](Self::set_local_storage_types).
        ///
        /// <p>Indicates the type of local storage that is required.</p> 
        /// <ul> 
        /// <li> <p>For instance types with hard disk drive (HDD) storage, specify <code>hdd</code>.</p> </li> 
        /// <li> <p>For instance types with solid state drive (SSD) storage, specify <code>ssd</code>.</p> </li> 
        /// </ul> 
        /// <p>Default: Any local storage type</p>
        pub fn local_storage_types(mut self, input: crate::model::LocalStorageType) -> Self {
            let mut v = self.local_storage_types.unwrap_or_default();
                            v.push(input);
                            self.local_storage_types = Some(v);
                            self
        }
        /// <p>Indicates the type of local storage that is required.</p> 
        /// <ul> 
        /// <li> <p>For instance types with hard disk drive (HDD) storage, specify <code>hdd</code>.</p> </li> 
        /// <li> <p>For instance types with solid state drive (SSD) storage, specify <code>ssd</code>.</p> </li> 
        /// </ul> 
        /// <p>Default: Any local storage type</p>
        pub fn set_local_storage_types(mut self, input: std::option::Option<std::vec::Vec<crate::model::LocalStorageType>>) -> Self {
            self.local_storage_types = input; self
        }
        /// <p>The minimum and maximum total local storage size for an instance type, in GB.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn total_local_storage_gb(mut self, input: crate::model::TotalLocalStorageGbRequest) -> Self {
            self.total_local_storage_gb = Some(input);
            self
        }
        /// <p>The minimum and maximum total local storage size for an instance type, in GB.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn set_total_local_storage_gb(mut self, input: std::option::Option<crate::model::TotalLocalStorageGbRequest>) -> Self {
            self.total_local_storage_gb = input; self
        }
        /// <p>The minimum and maximum baseline bandwidth performance for an instance type, in Mbps. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html">Amazon EBS–optimized instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn baseline_ebs_bandwidth_mbps(mut self, input: crate::model::BaselineEbsBandwidthMbpsRequest) -> Self {
            self.baseline_ebs_bandwidth_mbps = Some(input);
            self
        }
        /// <p>The minimum and maximum baseline bandwidth performance for an instance type, in Mbps. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html">Amazon EBS–optimized instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn set_baseline_ebs_bandwidth_mbps(mut self, input: std::option::Option<crate::model::BaselineEbsBandwidthMbpsRequest>) -> Self {
            self.baseline_ebs_bandwidth_mbps = input; self
        }
        /// Appends an item to `accelerator_types`.
        ///
        /// To override the contents of this collection use [`set_accelerator_types`](Self::set_accelerator_types).
        ///
        /// <p>Lists the accelerator types that must be on an instance type.</p> 
        /// <ul> 
        /// <li> <p>For instance types with GPU accelerators, specify <code>gpu</code>.</p> </li> 
        /// <li> <p>For instance types with FPGA accelerators, specify <code>fpga</code>.</p> </li> 
        /// <li> <p>For instance types with inference accelerators, specify <code>inference</code>.</p> </li> 
        /// </ul> 
        /// <p>Default: Any accelerator type</p>
        pub fn accelerator_types(mut self, input: crate::model::AcceleratorType) -> Self {
            let mut v = self.accelerator_types.unwrap_or_default();
                            v.push(input);
                            self.accelerator_types = Some(v);
                            self
        }
        /// <p>Lists the accelerator types that must be on an instance type.</p> 
        /// <ul> 
        /// <li> <p>For instance types with GPU accelerators, specify <code>gpu</code>.</p> </li> 
        /// <li> <p>For instance types with FPGA accelerators, specify <code>fpga</code>.</p> </li> 
        /// <li> <p>For instance types with inference accelerators, specify <code>inference</code>.</p> </li> 
        /// </ul> 
        /// <p>Default: Any accelerator type</p>
        pub fn set_accelerator_types(mut self, input: std::option::Option<std::vec::Vec<crate::model::AcceleratorType>>) -> Self {
            self.accelerator_types = input; self
        }
        /// <p>The minimum and maximum number of accelerators (GPUs, FPGAs, or Amazon Web Services Inferentia chips) for an instance type.</p> 
        /// <p>To exclude accelerator-enabled instance types, set <code>Max</code> to <code>0</code>.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn accelerator_count(mut self, input: crate::model::AcceleratorCountRequest) -> Self {
            self.accelerator_count = Some(input);
            self
        }
        /// <p>The minimum and maximum number of accelerators (GPUs, FPGAs, or Amazon Web Services Inferentia chips) for an instance type.</p> 
        /// <p>To exclude accelerator-enabled instance types, set <code>Max</code> to <code>0</code>.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn set_accelerator_count(mut self, input: std::option::Option<crate::model::AcceleratorCountRequest>) -> Self {
            self.accelerator_count = input; self
        }
        /// Appends an item to `accelerator_manufacturers`.
        ///
        /// To override the contents of this collection use [`set_accelerator_manufacturers`](Self::set_accelerator_manufacturers).
        ///
        /// <p>Indicates whether instance types must have accelerators by specific manufacturers.</p> 
        /// <ul> 
        /// <li> <p>For instance types with NVIDIA devices, specify <code>nvidia</code>.</p> </li> 
        /// <li> <p>For instance types with AMD devices, specify <code>amd</code>.</p> </li> 
        /// <li> <p>For instance types with Amazon Web Services devices, specify <code>amazon-web-services</code>.</p> </li> 
        /// <li> <p>For instance types with Xilinx devices, specify <code>xilinx</code>.</p> </li> 
        /// </ul> 
        /// <p>Default: Any manufacturer</p>
        pub fn accelerator_manufacturers(mut self, input: crate::model::AcceleratorManufacturer) -> Self {
            let mut v = self.accelerator_manufacturers.unwrap_or_default();
                            v.push(input);
                            self.accelerator_manufacturers = Some(v);
                            self
        }
        /// <p>Indicates whether instance types must have accelerators by specific manufacturers.</p> 
        /// <ul> 
        /// <li> <p>For instance types with NVIDIA devices, specify <code>nvidia</code>.</p> </li> 
        /// <li> <p>For instance types with AMD devices, specify <code>amd</code>.</p> </li> 
        /// <li> <p>For instance types with Amazon Web Services devices, specify <code>amazon-web-services</code>.</p> </li> 
        /// <li> <p>For instance types with Xilinx devices, specify <code>xilinx</code>.</p> </li> 
        /// </ul> 
        /// <p>Default: Any manufacturer</p>
        pub fn set_accelerator_manufacturers(mut self, input: std::option::Option<std::vec::Vec<crate::model::AcceleratorManufacturer>>) -> Self {
            self.accelerator_manufacturers = input; self
        }
        /// Appends an item to `accelerator_names`.
        ///
        /// To override the contents of this collection use [`set_accelerator_names`](Self::set_accelerator_names).
        ///
        /// <p>Lists the accelerators that must be on an instance type.</p> 
        /// <ul> 
        /// <li> <p>For instance types with NVIDIA A100 GPUs, specify <code>a100</code>.</p> </li> 
        /// <li> <p>For instance types with NVIDIA V100 GPUs, specify <code>v100</code>.</p> </li> 
        /// <li> <p>For instance types with NVIDIA K80 GPUs, specify <code>k80</code>.</p> </li> 
        /// <li> <p>For instance types with NVIDIA T4 GPUs, specify <code>t4</code>.</p> </li> 
        /// <li> <p>For instance types with NVIDIA M60 GPUs, specify <code>m60</code>.</p> </li> 
        /// <li> <p>For instance types with AMD Radeon Pro V520 GPUs, specify <code>radeon-pro-v520</code>.</p> </li> 
        /// <li> <p>For instance types with Xilinx VU9P FPGAs, specify <code>vu9p</code>.</p> </li> 
        /// </ul> 
        /// <p>Default: Any accelerator</p>
        pub fn accelerator_names(mut self, input: crate::model::AcceleratorName) -> Self {
            let mut v = self.accelerator_names.unwrap_or_default();
                            v.push(input);
                            self.accelerator_names = Some(v);
                            self
        }
        /// <p>Lists the accelerators that must be on an instance type.</p> 
        /// <ul> 
        /// <li> <p>For instance types with NVIDIA A100 GPUs, specify <code>a100</code>.</p> </li> 
        /// <li> <p>For instance types with NVIDIA V100 GPUs, specify <code>v100</code>.</p> </li> 
        /// <li> <p>For instance types with NVIDIA K80 GPUs, specify <code>k80</code>.</p> </li> 
        /// <li> <p>For instance types with NVIDIA T4 GPUs, specify <code>t4</code>.</p> </li> 
        /// <li> <p>For instance types with NVIDIA M60 GPUs, specify <code>m60</code>.</p> </li> 
        /// <li> <p>For instance types with AMD Radeon Pro V520 GPUs, specify <code>radeon-pro-v520</code>.</p> </li> 
        /// <li> <p>For instance types with Xilinx VU9P FPGAs, specify <code>vu9p</code>.</p> </li> 
        /// </ul> 
        /// <p>Default: Any accelerator</p>
        pub fn set_accelerator_names(mut self, input: std::option::Option<std::vec::Vec<crate::model::AcceleratorName>>) -> Self {
            self.accelerator_names = input; self
        }
        /// <p>The minimum and maximum total memory size for the accelerators on an instance type, in MiB.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn accelerator_total_memory_mi_b(mut self, input: crate::model::AcceleratorTotalMemoryMiBRequest) -> Self {
            self.accelerator_total_memory_mi_b = Some(input);
            self
        }
        /// <p>The minimum and maximum total memory size for the accelerators on an instance type, in MiB.</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn set_accelerator_total_memory_mi_b(mut self, input: std::option::Option<crate::model::AcceleratorTotalMemoryMiBRequest>) -> Self {
            self.accelerator_total_memory_mi_b = input; self
        }
        /// <p>The minimum and maximum amount of network bandwidth, in gigabits per second (Gbps).</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn network_bandwidth_gbps(mut self, input: crate::model::NetworkBandwidthGbpsRequest) -> Self {
            self.network_bandwidth_gbps = Some(input);
            self
        }
        /// <p>The minimum and maximum amount of network bandwidth, in gigabits per second (Gbps).</p> 
        /// <p>Default: No minimum or maximum limits</p>
        pub fn set_network_bandwidth_gbps(mut self, input: std::option::Option<crate::model::NetworkBandwidthGbpsRequest>) -> Self {
            self.network_bandwidth_gbps = input; self
        }
        /// Appends an item to `allowed_instance_types`.
        ///
        /// To override the contents of this collection use [`set_allowed_instance_types`](Self::set_allowed_instance_types).
        ///
        /// <p>The instance types to apply your specified attributes against. All other instance types are ignored, even if they match your specified attributes.</p> 
        /// <p>You can use strings with one or more wild cards, represented by an asterisk (<code>*</code>), to allow an instance type, size, or generation. The following are examples: <code>m5.8xlarge</code>, <code>c5*.*</code>, <code>m5a.*</code>, <code>r*</code>, <code>*3*</code>.</p> 
        /// <p>For example, if you specify <code>c5*</code>, Amazon EC2 Auto Scaling will allow the entire C5 instance family, which includes all C5a and C5n instance types. If you specify <code>m5a.*</code>, Amazon EC2 Auto Scaling will allow all the M5a instance types, but not the M5n instance types.</p> <note> 
        /// <p>If you specify <code>AllowedInstanceTypes</code>, you can't specify <code>ExcludedInstanceTypes</code>.</p> 
        /// </note> 
        /// <p>Default: All instance types</p>
        pub fn allowed_instance_types(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.allowed_instance_types.unwrap_or_default();
                            v.push(input.into());
                            self.allowed_instance_types = Some(v);
                            self
        }
        /// <p>The instance types to apply your specified attributes against. All other instance types are ignored, even if they match your specified attributes.</p> 
        /// <p>You can use strings with one or more wild cards, represented by an asterisk (<code>*</code>), to allow an instance type, size, or generation. The following are examples: <code>m5.8xlarge</code>, <code>c5*.*</code>, <code>m5a.*</code>, <code>r*</code>, <code>*3*</code>.</p> 
        /// <p>For example, if you specify <code>c5*</code>, Amazon EC2 Auto Scaling will allow the entire C5 instance family, which includes all C5a and C5n instance types. If you specify <code>m5a.*</code>, Amazon EC2 Auto Scaling will allow all the M5a instance types, but not the M5n instance types.</p> <note> 
        /// <p>If you specify <code>AllowedInstanceTypes</code>, you can't specify <code>ExcludedInstanceTypes</code>.</p> 
        /// </note> 
        /// <p>Default: All instance types</p>
        pub fn set_allowed_instance_types(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.allowed_instance_types = input; self
        }
        /// Consumes the builder and constructs a [`InstanceRequirements`](crate::model::InstanceRequirements).
        pub fn build(self) -> crate::model::InstanceRequirements {
            crate::model::InstanceRequirements {
                v_cpu_count: self.v_cpu_count
                ,
                memory_mi_b: self.memory_mi_b
                ,
                cpu_manufacturers: self.cpu_manufacturers
                ,
                memory_gi_b_per_v_cpu: self.memory_gi_b_per_v_cpu
                ,
                excluded_instance_types: self.excluded_instance_types
                ,
                instance_generations: self.instance_generations
                ,
                spot_max_price_percentage_over_lowest_price: self.spot_max_price_percentage_over_lowest_price
                ,
                on_demand_max_price_percentage_over_lowest_price: self.on_demand_max_price_percentage_over_lowest_price
                ,
                bare_metal: self.bare_metal
                ,
                burstable_performance: self.burstable_performance
                ,
                require_hibernate_support: self.require_hibernate_support
                ,
                network_interface_count: self.network_interface_count
                ,
                local_storage: self.local_storage
                ,
                local_storage_types: self.local_storage_types
                ,
                total_local_storage_gb: self.total_local_storage_gb
                ,
                baseline_ebs_bandwidth_mbps: self.baseline_ebs_bandwidth_mbps
                ,
                accelerator_types: self.accelerator_types
                ,
                accelerator_count: self.accelerator_count
                ,
                accelerator_manufacturers: self.accelerator_manufacturers
                ,
                accelerator_names: self.accelerator_names
                ,
                accelerator_total_memory_mi_b: self.accelerator_total_memory_mi_b
                ,
                network_bandwidth_gbps: self.network_bandwidth_gbps
                ,
                allowed_instance_types: self.allowed_instance_types
                ,
            }
        }
    }
    
    
}
impl InstanceRequirements {
    /// Creates a new builder-style object to manufacture [`InstanceRequirements`](crate::model::InstanceRequirements).
    pub fn builder() -> crate::model::instance_requirements::Builder {
        crate::model::instance_requirements::Builder::default()
    }
}

/// <p>Specifies the minimum and maximum for the <code>NetworkBandwidthGbps</code> object when you specify <code>InstanceRequirements</code> for an Auto Scaling group.</p> <note> 
/// <p>Setting the minimum bandwidth does not guarantee that your instance will achieve the minimum bandwidth. Amazon EC2 will identify instance types that support the specified minimum bandwidth, but the actual bandwidth of your instance might go below the specified minimum at times. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-network-bandwidth.html#available-instance-bandwidth">Available instance bandwidth</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
/// </note>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct NetworkBandwidthGbpsRequest  {
    /// <p>The minimum amount of network bandwidth, in gigabits per second (Gbps).</p>
    #[doc(hidden)]
    pub min: std::option::Option<f64>,
    /// <p>The maximum amount of network bandwidth, in gigabits per second (Gbps).</p>
    #[doc(hidden)]
    pub max: std::option::Option<f64>,
}
impl NetworkBandwidthGbpsRequest {
    /// <p>The minimum amount of network bandwidth, in gigabits per second (Gbps).</p>
    pub fn min(&self) -> std::option::Option<f64> {
        self.min
    }
    /// <p>The maximum amount of network bandwidth, in gigabits per second (Gbps).</p>
    pub fn max(&self) -> std::option::Option<f64> {
        self.max
    }
}
/// See [`NetworkBandwidthGbpsRequest`](crate::model::NetworkBandwidthGbpsRequest).
pub mod network_bandwidth_gbps_request {
    
    /// A builder for [`NetworkBandwidthGbpsRequest`](crate::model::NetworkBandwidthGbpsRequest).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) min: std::option::Option<f64>,
        pub(crate) max: std::option::Option<f64>,
    }
    impl Builder {
        /// <p>The minimum amount of network bandwidth, in gigabits per second (Gbps).</p>
        pub fn min(mut self, input: f64) -> Self {
            self.min = Some(input);
            self
        }
        /// <p>The minimum amount of network bandwidth, in gigabits per second (Gbps).</p>
        pub fn set_min(mut self, input: std::option::Option<f64>) -> Self {
            self.min = input; self
        }
        /// <p>The maximum amount of network bandwidth, in gigabits per second (Gbps).</p>
        pub fn max(mut self, input: f64) -> Self {
            self.max = Some(input);
            self
        }
        /// <p>The maximum amount of network bandwidth, in gigabits per second (Gbps).</p>
        pub fn set_max(mut self, input: std::option::Option<f64>) -> Self {
            self.max = input; self
        }
        /// Consumes the builder and constructs a [`NetworkBandwidthGbpsRequest`](crate::model::NetworkBandwidthGbpsRequest).
        pub fn build(self) -> crate::model::NetworkBandwidthGbpsRequest {
            crate::model::NetworkBandwidthGbpsRequest {
                min: self.min
                ,
                max: self.max
                ,
            }
        }
    }
    
    
}
impl NetworkBandwidthGbpsRequest {
    /// Creates a new builder-style object to manufacture [`NetworkBandwidthGbpsRequest`](crate::model::NetworkBandwidthGbpsRequest).
    pub fn builder() -> crate::model::network_bandwidth_gbps_request::Builder {
        crate::model::network_bandwidth_gbps_request::Builder::default()
    }
}

/// <p>Specifies the minimum and maximum for the <code>AcceleratorTotalMemoryMiB</code> object when you specify <code>InstanceRequirements</code> for an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct AcceleratorTotalMemoryMiBRequest  {
    /// <p>The memory minimum in MiB.</p>
    #[doc(hidden)]
    pub min: std::option::Option<i32>,
    /// <p>The memory maximum in MiB.</p>
    #[doc(hidden)]
    pub max: std::option::Option<i32>,
}
impl AcceleratorTotalMemoryMiBRequest {
    /// <p>The memory minimum in MiB.</p>
    pub fn min(&self) -> std::option::Option<i32> {
        self.min
    }
    /// <p>The memory maximum in MiB.</p>
    pub fn max(&self) -> std::option::Option<i32> {
        self.max
    }
}
/// See [`AcceleratorTotalMemoryMiBRequest`](crate::model::AcceleratorTotalMemoryMiBRequest).
pub mod accelerator_total_memory_mi_b_request {
    
    /// A builder for [`AcceleratorTotalMemoryMiBRequest`](crate::model::AcceleratorTotalMemoryMiBRequest).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) min: std::option::Option<i32>,
        pub(crate) max: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The memory minimum in MiB.</p>
        pub fn min(mut self, input: i32) -> Self {
            self.min = Some(input);
            self
        }
        /// <p>The memory minimum in MiB.</p>
        pub fn set_min(mut self, input: std::option::Option<i32>) -> Self {
            self.min = input; self
        }
        /// <p>The memory maximum in MiB.</p>
        pub fn max(mut self, input: i32) -> Self {
            self.max = Some(input);
            self
        }
        /// <p>The memory maximum in MiB.</p>
        pub fn set_max(mut self, input: std::option::Option<i32>) -> Self {
            self.max = input; self
        }
        /// Consumes the builder and constructs a [`AcceleratorTotalMemoryMiBRequest`](crate::model::AcceleratorTotalMemoryMiBRequest).
        pub fn build(self) -> crate::model::AcceleratorTotalMemoryMiBRequest {
            crate::model::AcceleratorTotalMemoryMiBRequest {
                min: self.min
                ,
                max: self.max
                ,
            }
        }
    }
    
    
}
impl AcceleratorTotalMemoryMiBRequest {
    /// Creates a new builder-style object to manufacture [`AcceleratorTotalMemoryMiBRequest`](crate::model::AcceleratorTotalMemoryMiBRequest).
    pub fn builder() -> crate::model::accelerator_total_memory_mi_b_request::Builder {
        crate::model::accelerator_total_memory_mi_b_request::Builder::default()
    }
}

/// When writing a match expression against `AcceleratorName`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let acceleratorname = unimplemented!();
/// match acceleratorname {
///     AcceleratorName::A100 => { /* ... */ },
///     AcceleratorName::K80 => { /* ... */ },
///     AcceleratorName::M60 => { /* ... */ },
///     AcceleratorName::RadeonProV520 => { /* ... */ },
///     AcceleratorName::T4 => { /* ... */ },
///     AcceleratorName::V100 => { /* ... */ },
///     AcceleratorName::Vu9P => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `acceleratorname` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `AcceleratorName::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `AcceleratorName::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `AcceleratorName::NewFeature` is defined.
/// Specifically, when `acceleratorname` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `AcceleratorName::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum AcceleratorName {
    #[allow(missing_docs)] // documentation missing in model
    A100,
    #[allow(missing_docs)] // documentation missing in model
    K80,
    #[allow(missing_docs)] // documentation missing in model
    M60,
    #[allow(missing_docs)] // documentation missing in model
    RadeonProV520,
    #[allow(missing_docs)] // documentation missing in model
    T4,
    #[allow(missing_docs)] // documentation missing in model
    V100,
    #[allow(missing_docs)] // documentation missing in model
    Vu9P,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for AcceleratorName {
    fn from(s: &str) -> Self {
        match s {
            "a100" => AcceleratorName::A100,
            "k80" => AcceleratorName::K80,
            "m60" => AcceleratorName::M60,
            "radeon-pro-v520" => AcceleratorName::RadeonProV520,
            "t4" => AcceleratorName::T4,
            "v100" => AcceleratorName::V100,
            "vu9p" => AcceleratorName::Vu9P,
            other => AcceleratorName::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for AcceleratorName {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(AcceleratorName::from(s))
                }
            }
impl AcceleratorName {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            AcceleratorName::A100 => "a100",
            AcceleratorName::K80 => "k80",
            AcceleratorName::M60 => "m60",
            AcceleratorName::RadeonProV520 => "radeon-pro-v520",
            AcceleratorName::T4 => "t4",
            AcceleratorName::V100 => "v100",
            AcceleratorName::Vu9P => "vu9p",
            AcceleratorName::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "a100", "k80", "m60", "radeon-pro-v520", "t4", "v100", "vu9p"
        ]
    }
}
impl AsRef<str> for AcceleratorName {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// When writing a match expression against `AcceleratorManufacturer`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let acceleratormanufacturer = unimplemented!();
/// match acceleratormanufacturer {
///     AcceleratorManufacturer::AmazonWebServices => { /* ... */ },
///     AcceleratorManufacturer::Amd => { /* ... */ },
///     AcceleratorManufacturer::Nvidia => { /* ... */ },
///     AcceleratorManufacturer::Xilinx => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `acceleratormanufacturer` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `AcceleratorManufacturer::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `AcceleratorManufacturer::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `AcceleratorManufacturer::NewFeature` is defined.
/// Specifically, when `acceleratormanufacturer` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `AcceleratorManufacturer::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum AcceleratorManufacturer {
    #[allow(missing_docs)] // documentation missing in model
    AmazonWebServices,
    #[allow(missing_docs)] // documentation missing in model
    Amd,
    #[allow(missing_docs)] // documentation missing in model
    Nvidia,
    #[allow(missing_docs)] // documentation missing in model
    Xilinx,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for AcceleratorManufacturer {
    fn from(s: &str) -> Self {
        match s {
            "amazon-web-services" => AcceleratorManufacturer::AmazonWebServices,
            "amd" => AcceleratorManufacturer::Amd,
            "nvidia" => AcceleratorManufacturer::Nvidia,
            "xilinx" => AcceleratorManufacturer::Xilinx,
            other => AcceleratorManufacturer::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for AcceleratorManufacturer {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(AcceleratorManufacturer::from(s))
                }
            }
impl AcceleratorManufacturer {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            AcceleratorManufacturer::AmazonWebServices => "amazon-web-services",
            AcceleratorManufacturer::Amd => "amd",
            AcceleratorManufacturer::Nvidia => "nvidia",
            AcceleratorManufacturer::Xilinx => "xilinx",
            AcceleratorManufacturer::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "amazon-web-services", "amd", "nvidia", "xilinx"
        ]
    }
}
impl AsRef<str> for AcceleratorManufacturer {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Specifies the minimum and maximum for the <code>AcceleratorCount</code> object when you specify <code>InstanceRequirements</code> for an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct AcceleratorCountRequest  {
    /// <p>The minimum value.</p>
    #[doc(hidden)]
    pub min: std::option::Option<i32>,
    /// <p>The maximum value.</p>
    #[doc(hidden)]
    pub max: std::option::Option<i32>,
}
impl AcceleratorCountRequest {
    /// <p>The minimum value.</p>
    pub fn min(&self) -> std::option::Option<i32> {
        self.min
    }
    /// <p>The maximum value.</p>
    pub fn max(&self) -> std::option::Option<i32> {
        self.max
    }
}
/// See [`AcceleratorCountRequest`](crate::model::AcceleratorCountRequest).
pub mod accelerator_count_request {
    
    /// A builder for [`AcceleratorCountRequest`](crate::model::AcceleratorCountRequest).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) min: std::option::Option<i32>,
        pub(crate) max: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The minimum value.</p>
        pub fn min(mut self, input: i32) -> Self {
            self.min = Some(input);
            self
        }
        /// <p>The minimum value.</p>
        pub fn set_min(mut self, input: std::option::Option<i32>) -> Self {
            self.min = input; self
        }
        /// <p>The maximum value.</p>
        pub fn max(mut self, input: i32) -> Self {
            self.max = Some(input);
            self
        }
        /// <p>The maximum value.</p>
        pub fn set_max(mut self, input: std::option::Option<i32>) -> Self {
            self.max = input; self
        }
        /// Consumes the builder and constructs a [`AcceleratorCountRequest`](crate::model::AcceleratorCountRequest).
        pub fn build(self) -> crate::model::AcceleratorCountRequest {
            crate::model::AcceleratorCountRequest {
                min: self.min
                ,
                max: self.max
                ,
            }
        }
    }
    
    
}
impl AcceleratorCountRequest {
    /// Creates a new builder-style object to manufacture [`AcceleratorCountRequest`](crate::model::AcceleratorCountRequest).
    pub fn builder() -> crate::model::accelerator_count_request::Builder {
        crate::model::accelerator_count_request::Builder::default()
    }
}

/// When writing a match expression against `AcceleratorType`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let acceleratortype = unimplemented!();
/// match acceleratortype {
///     AcceleratorType::Fpga => { /* ... */ },
///     AcceleratorType::Gpu => { /* ... */ },
///     AcceleratorType::Inference => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `acceleratortype` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `AcceleratorType::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `AcceleratorType::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `AcceleratorType::NewFeature` is defined.
/// Specifically, when `acceleratortype` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `AcceleratorType::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum AcceleratorType {
    #[allow(missing_docs)] // documentation missing in model
    Fpga,
    #[allow(missing_docs)] // documentation missing in model
    Gpu,
    #[allow(missing_docs)] // documentation missing in model
    Inference,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for AcceleratorType {
    fn from(s: &str) -> Self {
        match s {
            "fpga" => AcceleratorType::Fpga,
            "gpu" => AcceleratorType::Gpu,
            "inference" => AcceleratorType::Inference,
            other => AcceleratorType::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for AcceleratorType {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(AcceleratorType::from(s))
                }
            }
impl AcceleratorType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            AcceleratorType::Fpga => "fpga",
            AcceleratorType::Gpu => "gpu",
            AcceleratorType::Inference => "inference",
            AcceleratorType::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "fpga", "gpu", "inference"
        ]
    }
}
impl AsRef<str> for AcceleratorType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Specifies the minimum and maximum for the <code>BaselineEbsBandwidthMbps</code> object when you specify <code>InstanceRequirements</code> for an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct BaselineEbsBandwidthMbpsRequest  {
    /// <p>The minimum value in Mbps.</p>
    #[doc(hidden)]
    pub min: std::option::Option<i32>,
    /// <p>The maximum value in Mbps.</p>
    #[doc(hidden)]
    pub max: std::option::Option<i32>,
}
impl BaselineEbsBandwidthMbpsRequest {
    /// <p>The minimum value in Mbps.</p>
    pub fn min(&self) -> std::option::Option<i32> {
        self.min
    }
    /// <p>The maximum value in Mbps.</p>
    pub fn max(&self) -> std::option::Option<i32> {
        self.max
    }
}
/// See [`BaselineEbsBandwidthMbpsRequest`](crate::model::BaselineEbsBandwidthMbpsRequest).
pub mod baseline_ebs_bandwidth_mbps_request {
    
    /// A builder for [`BaselineEbsBandwidthMbpsRequest`](crate::model::BaselineEbsBandwidthMbpsRequest).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) min: std::option::Option<i32>,
        pub(crate) max: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The minimum value in Mbps.</p>
        pub fn min(mut self, input: i32) -> Self {
            self.min = Some(input);
            self
        }
        /// <p>The minimum value in Mbps.</p>
        pub fn set_min(mut self, input: std::option::Option<i32>) -> Self {
            self.min = input; self
        }
        /// <p>The maximum value in Mbps.</p>
        pub fn max(mut self, input: i32) -> Self {
            self.max = Some(input);
            self
        }
        /// <p>The maximum value in Mbps.</p>
        pub fn set_max(mut self, input: std::option::Option<i32>) -> Self {
            self.max = input; self
        }
        /// Consumes the builder and constructs a [`BaselineEbsBandwidthMbpsRequest`](crate::model::BaselineEbsBandwidthMbpsRequest).
        pub fn build(self) -> crate::model::BaselineEbsBandwidthMbpsRequest {
            crate::model::BaselineEbsBandwidthMbpsRequest {
                min: self.min
                ,
                max: self.max
                ,
            }
        }
    }
    
    
}
impl BaselineEbsBandwidthMbpsRequest {
    /// Creates a new builder-style object to manufacture [`BaselineEbsBandwidthMbpsRequest`](crate::model::BaselineEbsBandwidthMbpsRequest).
    pub fn builder() -> crate::model::baseline_ebs_bandwidth_mbps_request::Builder {
        crate::model::baseline_ebs_bandwidth_mbps_request::Builder::default()
    }
}

/// <p>Specifies the minimum and maximum for the <code>TotalLocalStorageGB</code> object when you specify <code>InstanceRequirements</code> for an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct TotalLocalStorageGbRequest  {
    /// <p>The storage minimum in GB.</p>
    #[doc(hidden)]
    pub min: std::option::Option<f64>,
    /// <p>The storage maximum in GB.</p>
    #[doc(hidden)]
    pub max: std::option::Option<f64>,
}
impl TotalLocalStorageGbRequest {
    /// <p>The storage minimum in GB.</p>
    pub fn min(&self) -> std::option::Option<f64> {
        self.min
    }
    /// <p>The storage maximum in GB.</p>
    pub fn max(&self) -> std::option::Option<f64> {
        self.max
    }
}
/// See [`TotalLocalStorageGbRequest`](crate::model::TotalLocalStorageGbRequest).
pub mod total_local_storage_gb_request {
    
    /// A builder for [`TotalLocalStorageGbRequest`](crate::model::TotalLocalStorageGbRequest).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) min: std::option::Option<f64>,
        pub(crate) max: std::option::Option<f64>,
    }
    impl Builder {
        /// <p>The storage minimum in GB.</p>
        pub fn min(mut self, input: f64) -> Self {
            self.min = Some(input);
            self
        }
        /// <p>The storage minimum in GB.</p>
        pub fn set_min(mut self, input: std::option::Option<f64>) -> Self {
            self.min = input; self
        }
        /// <p>The storage maximum in GB.</p>
        pub fn max(mut self, input: f64) -> Self {
            self.max = Some(input);
            self
        }
        /// <p>The storage maximum in GB.</p>
        pub fn set_max(mut self, input: std::option::Option<f64>) -> Self {
            self.max = input; self
        }
        /// Consumes the builder and constructs a [`TotalLocalStorageGbRequest`](crate::model::TotalLocalStorageGbRequest).
        pub fn build(self) -> crate::model::TotalLocalStorageGbRequest {
            crate::model::TotalLocalStorageGbRequest {
                min: self.min
                ,
                max: self.max
                ,
            }
        }
    }
    
    
}
impl TotalLocalStorageGbRequest {
    /// Creates a new builder-style object to manufacture [`TotalLocalStorageGbRequest`](crate::model::TotalLocalStorageGbRequest).
    pub fn builder() -> crate::model::total_local_storage_gb_request::Builder {
        crate::model::total_local_storage_gb_request::Builder::default()
    }
}

/// When writing a match expression against `LocalStorageType`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let localstoragetype = unimplemented!();
/// match localstoragetype {
///     LocalStorageType::Hdd => { /* ... */ },
///     LocalStorageType::Ssd => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `localstoragetype` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `LocalStorageType::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `LocalStorageType::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `LocalStorageType::NewFeature` is defined.
/// Specifically, when `localstoragetype` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `LocalStorageType::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum LocalStorageType {
    #[allow(missing_docs)] // documentation missing in model
    Hdd,
    #[allow(missing_docs)] // documentation missing in model
    Ssd,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for LocalStorageType {
    fn from(s: &str) -> Self {
        match s {
            "hdd" => LocalStorageType::Hdd,
            "ssd" => LocalStorageType::Ssd,
            other => LocalStorageType::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for LocalStorageType {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(LocalStorageType::from(s))
                }
            }
impl LocalStorageType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            LocalStorageType::Hdd => "hdd",
            LocalStorageType::Ssd => "ssd",
            LocalStorageType::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "hdd", "ssd"
        ]
    }
}
impl AsRef<str> for LocalStorageType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// When writing a match expression against `LocalStorage`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let localstorage = unimplemented!();
/// match localstorage {
///     LocalStorage::Excluded => { /* ... */ },
///     LocalStorage::Included => { /* ... */ },
///     LocalStorage::Required => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `localstorage` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `LocalStorage::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `LocalStorage::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `LocalStorage::NewFeature` is defined.
/// Specifically, when `localstorage` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `LocalStorage::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum LocalStorage {
    #[allow(missing_docs)] // documentation missing in model
    Excluded,
    #[allow(missing_docs)] // documentation missing in model
    Included,
    #[allow(missing_docs)] // documentation missing in model
    Required,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for LocalStorage {
    fn from(s: &str) -> Self {
        match s {
            "excluded" => LocalStorage::Excluded,
            "included" => LocalStorage::Included,
            "required" => LocalStorage::Required,
            other => LocalStorage::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for LocalStorage {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(LocalStorage::from(s))
                }
            }
impl LocalStorage {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            LocalStorage::Excluded => "excluded",
            LocalStorage::Included => "included",
            LocalStorage::Required => "required",
            LocalStorage::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "excluded", "included", "required"
        ]
    }
}
impl AsRef<str> for LocalStorage {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Specifies the minimum and maximum for the <code>NetworkInterfaceCount</code> object when you specify <code>InstanceRequirements</code> for an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct NetworkInterfaceCountRequest  {
    /// <p>The minimum number of network interfaces.</p>
    #[doc(hidden)]
    pub min: std::option::Option<i32>,
    /// <p>The maximum number of network interfaces.</p>
    #[doc(hidden)]
    pub max: std::option::Option<i32>,
}
impl NetworkInterfaceCountRequest {
    /// <p>The minimum number of network interfaces.</p>
    pub fn min(&self) -> std::option::Option<i32> {
        self.min
    }
    /// <p>The maximum number of network interfaces.</p>
    pub fn max(&self) -> std::option::Option<i32> {
        self.max
    }
}
/// See [`NetworkInterfaceCountRequest`](crate::model::NetworkInterfaceCountRequest).
pub mod network_interface_count_request {
    
    /// A builder for [`NetworkInterfaceCountRequest`](crate::model::NetworkInterfaceCountRequest).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) min: std::option::Option<i32>,
        pub(crate) max: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The minimum number of network interfaces.</p>
        pub fn min(mut self, input: i32) -> Self {
            self.min = Some(input);
            self
        }
        /// <p>The minimum number of network interfaces.</p>
        pub fn set_min(mut self, input: std::option::Option<i32>) -> Self {
            self.min = input; self
        }
        /// <p>The maximum number of network interfaces.</p>
        pub fn max(mut self, input: i32) -> Self {
            self.max = Some(input);
            self
        }
        /// <p>The maximum number of network interfaces.</p>
        pub fn set_max(mut self, input: std::option::Option<i32>) -> Self {
            self.max = input; self
        }
        /// Consumes the builder and constructs a [`NetworkInterfaceCountRequest`](crate::model::NetworkInterfaceCountRequest).
        pub fn build(self) -> crate::model::NetworkInterfaceCountRequest {
            crate::model::NetworkInterfaceCountRequest {
                min: self.min
                ,
                max: self.max
                ,
            }
        }
    }
    
    
}
impl NetworkInterfaceCountRequest {
    /// Creates a new builder-style object to manufacture [`NetworkInterfaceCountRequest`](crate::model::NetworkInterfaceCountRequest).
    pub fn builder() -> crate::model::network_interface_count_request::Builder {
        crate::model::network_interface_count_request::Builder::default()
    }
}

/// When writing a match expression against `BurstablePerformance`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let burstableperformance = unimplemented!();
/// match burstableperformance {
///     BurstablePerformance::Excluded => { /* ... */ },
///     BurstablePerformance::Included => { /* ... */ },
///     BurstablePerformance::Required => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `burstableperformance` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `BurstablePerformance::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `BurstablePerformance::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `BurstablePerformance::NewFeature` is defined.
/// Specifically, when `burstableperformance` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `BurstablePerformance::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum BurstablePerformance {
    #[allow(missing_docs)] // documentation missing in model
    Excluded,
    #[allow(missing_docs)] // documentation missing in model
    Included,
    #[allow(missing_docs)] // documentation missing in model
    Required,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for BurstablePerformance {
    fn from(s: &str) -> Self {
        match s {
            "excluded" => BurstablePerformance::Excluded,
            "included" => BurstablePerformance::Included,
            "required" => BurstablePerformance::Required,
            other => BurstablePerformance::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for BurstablePerformance {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(BurstablePerformance::from(s))
                }
            }
impl BurstablePerformance {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            BurstablePerformance::Excluded => "excluded",
            BurstablePerformance::Included => "included",
            BurstablePerformance::Required => "required",
            BurstablePerformance::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "excluded", "included", "required"
        ]
    }
}
impl AsRef<str> for BurstablePerformance {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// When writing a match expression against `BareMetal`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let baremetal = unimplemented!();
/// match baremetal {
///     BareMetal::Excluded => { /* ... */ },
///     BareMetal::Included => { /* ... */ },
///     BareMetal::Required => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `baremetal` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `BareMetal::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `BareMetal::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `BareMetal::NewFeature` is defined.
/// Specifically, when `baremetal` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `BareMetal::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum BareMetal {
    #[allow(missing_docs)] // documentation missing in model
    Excluded,
    #[allow(missing_docs)] // documentation missing in model
    Included,
    #[allow(missing_docs)] // documentation missing in model
    Required,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for BareMetal {
    fn from(s: &str) -> Self {
        match s {
            "excluded" => BareMetal::Excluded,
            "included" => BareMetal::Included,
            "required" => BareMetal::Required,
            other => BareMetal::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for BareMetal {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(BareMetal::from(s))
                }
            }
impl BareMetal {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            BareMetal::Excluded => "excluded",
            BareMetal::Included => "included",
            BareMetal::Required => "required",
            BareMetal::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "excluded", "included", "required"
        ]
    }
}
impl AsRef<str> for BareMetal {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// When writing a match expression against `InstanceGeneration`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let instancegeneration = unimplemented!();
/// match instancegeneration {
///     InstanceGeneration::Current => { /* ... */ },
///     InstanceGeneration::Previous => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `instancegeneration` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `InstanceGeneration::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `InstanceGeneration::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `InstanceGeneration::NewFeature` is defined.
/// Specifically, when `instancegeneration` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `InstanceGeneration::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum InstanceGeneration {
    #[allow(missing_docs)] // documentation missing in model
    Current,
    #[allow(missing_docs)] // documentation missing in model
    Previous,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for InstanceGeneration {
    fn from(s: &str) -> Self {
        match s {
            "current" => InstanceGeneration::Current,
            "previous" => InstanceGeneration::Previous,
            other => InstanceGeneration::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for InstanceGeneration {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(InstanceGeneration::from(s))
                }
            }
impl InstanceGeneration {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            InstanceGeneration::Current => "current",
            InstanceGeneration::Previous => "previous",
            InstanceGeneration::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "current", "previous"
        ]
    }
}
impl AsRef<str> for InstanceGeneration {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Specifies the minimum and maximum for the <code>MemoryGiBPerVCpu</code> object when you specify <code>InstanceRequirements</code> for an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct MemoryGiBPerVCpuRequest  {
    /// <p>The memory minimum in GiB.</p>
    #[doc(hidden)]
    pub min: std::option::Option<f64>,
    /// <p>The memory maximum in GiB.</p>
    #[doc(hidden)]
    pub max: std::option::Option<f64>,
}
impl MemoryGiBPerVCpuRequest {
    /// <p>The memory minimum in GiB.</p>
    pub fn min(&self) -> std::option::Option<f64> {
        self.min
    }
    /// <p>The memory maximum in GiB.</p>
    pub fn max(&self) -> std::option::Option<f64> {
        self.max
    }
}
/// See [`MemoryGiBPerVCpuRequest`](crate::model::MemoryGiBPerVCpuRequest).
pub mod memory_gi_b_per_v_cpu_request {
    
    /// A builder for [`MemoryGiBPerVCpuRequest`](crate::model::MemoryGiBPerVCpuRequest).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) min: std::option::Option<f64>,
        pub(crate) max: std::option::Option<f64>,
    }
    impl Builder {
        /// <p>The memory minimum in GiB.</p>
        pub fn min(mut self, input: f64) -> Self {
            self.min = Some(input);
            self
        }
        /// <p>The memory minimum in GiB.</p>
        pub fn set_min(mut self, input: std::option::Option<f64>) -> Self {
            self.min = input; self
        }
        /// <p>The memory maximum in GiB.</p>
        pub fn max(mut self, input: f64) -> Self {
            self.max = Some(input);
            self
        }
        /// <p>The memory maximum in GiB.</p>
        pub fn set_max(mut self, input: std::option::Option<f64>) -> Self {
            self.max = input; self
        }
        /// Consumes the builder and constructs a [`MemoryGiBPerVCpuRequest`](crate::model::MemoryGiBPerVCpuRequest).
        pub fn build(self) -> crate::model::MemoryGiBPerVCpuRequest {
            crate::model::MemoryGiBPerVCpuRequest {
                min: self.min
                ,
                max: self.max
                ,
            }
        }
    }
    
    
}
impl MemoryGiBPerVCpuRequest {
    /// Creates a new builder-style object to manufacture [`MemoryGiBPerVCpuRequest`](crate::model::MemoryGiBPerVCpuRequest).
    pub fn builder() -> crate::model::memory_gi_b_per_v_cpu_request::Builder {
        crate::model::memory_gi_b_per_v_cpu_request::Builder::default()
    }
}

/// When writing a match expression against `CpuManufacturer`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let cpumanufacturer = unimplemented!();
/// match cpumanufacturer {
///     CpuManufacturer::AmazonWebServices => { /* ... */ },
///     CpuManufacturer::Amd => { /* ... */ },
///     CpuManufacturer::Intel => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `cpumanufacturer` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `CpuManufacturer::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `CpuManufacturer::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `CpuManufacturer::NewFeature` is defined.
/// Specifically, when `cpumanufacturer` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `CpuManufacturer::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum CpuManufacturer {
    #[allow(missing_docs)] // documentation missing in model
    AmazonWebServices,
    #[allow(missing_docs)] // documentation missing in model
    Amd,
    #[allow(missing_docs)] // documentation missing in model
    Intel,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for CpuManufacturer {
    fn from(s: &str) -> Self {
        match s {
            "amazon-web-services" => CpuManufacturer::AmazonWebServices,
            "amd" => CpuManufacturer::Amd,
            "intel" => CpuManufacturer::Intel,
            other => CpuManufacturer::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for CpuManufacturer {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(CpuManufacturer::from(s))
                }
            }
impl CpuManufacturer {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            CpuManufacturer::AmazonWebServices => "amazon-web-services",
            CpuManufacturer::Amd => "amd",
            CpuManufacturer::Intel => "intel",
            CpuManufacturer::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "amazon-web-services", "amd", "intel"
        ]
    }
}
impl AsRef<str> for CpuManufacturer {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Specifies the minimum and maximum for the <code>MemoryMiB</code> object when you specify <code>InstanceRequirements</code> for an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct MemoryMiBRequest  {
    /// <p>The memory minimum in MiB.</p>
    #[doc(hidden)]
    pub min: std::option::Option<i32>,
    /// <p>The memory maximum in MiB.</p>
    #[doc(hidden)]
    pub max: std::option::Option<i32>,
}
impl MemoryMiBRequest {
    /// <p>The memory minimum in MiB.</p>
    pub fn min(&self) -> std::option::Option<i32> {
        self.min
    }
    /// <p>The memory maximum in MiB.</p>
    pub fn max(&self) -> std::option::Option<i32> {
        self.max
    }
}
/// See [`MemoryMiBRequest`](crate::model::MemoryMiBRequest).
pub mod memory_mi_b_request {
    
    /// A builder for [`MemoryMiBRequest`](crate::model::MemoryMiBRequest).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) min: std::option::Option<i32>,
        pub(crate) max: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The memory minimum in MiB.</p>
        pub fn min(mut self, input: i32) -> Self {
            self.min = Some(input);
            self
        }
        /// <p>The memory minimum in MiB.</p>
        pub fn set_min(mut self, input: std::option::Option<i32>) -> Self {
            self.min = input; self
        }
        /// <p>The memory maximum in MiB.</p>
        pub fn max(mut self, input: i32) -> Self {
            self.max = Some(input);
            self
        }
        /// <p>The memory maximum in MiB.</p>
        pub fn set_max(mut self, input: std::option::Option<i32>) -> Self {
            self.max = input; self
        }
        /// Consumes the builder and constructs a [`MemoryMiBRequest`](crate::model::MemoryMiBRequest).
        pub fn build(self) -> crate::model::MemoryMiBRequest {
            crate::model::MemoryMiBRequest {
                min: self.min
                ,
                max: self.max
                ,
            }
        }
    }
    
    
}
impl MemoryMiBRequest {
    /// Creates a new builder-style object to manufacture [`MemoryMiBRequest`](crate::model::MemoryMiBRequest).
    pub fn builder() -> crate::model::memory_mi_b_request::Builder {
        crate::model::memory_mi_b_request::Builder::default()
    }
}

/// <p>Specifies the minimum and maximum for the <code>VCpuCount</code> object when you specify <code>InstanceRequirements</code> for an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct VCpuCountRequest  {
    /// <p>The minimum number of vCPUs.</p>
    #[doc(hidden)]
    pub min: std::option::Option<i32>,
    /// <p>The maximum number of vCPUs.</p>
    #[doc(hidden)]
    pub max: std::option::Option<i32>,
}
impl VCpuCountRequest {
    /// <p>The minimum number of vCPUs.</p>
    pub fn min(&self) -> std::option::Option<i32> {
        self.min
    }
    /// <p>The maximum number of vCPUs.</p>
    pub fn max(&self) -> std::option::Option<i32> {
        self.max
    }
}
/// See [`VCpuCountRequest`](crate::model::VCpuCountRequest).
pub mod v_cpu_count_request {
    
    /// A builder for [`VCpuCountRequest`](crate::model::VCpuCountRequest).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) min: std::option::Option<i32>,
        pub(crate) max: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The minimum number of vCPUs.</p>
        pub fn min(mut self, input: i32) -> Self {
            self.min = Some(input);
            self
        }
        /// <p>The minimum number of vCPUs.</p>
        pub fn set_min(mut self, input: std::option::Option<i32>) -> Self {
            self.min = input; self
        }
        /// <p>The maximum number of vCPUs.</p>
        pub fn max(mut self, input: i32) -> Self {
            self.max = Some(input);
            self
        }
        /// <p>The maximum number of vCPUs.</p>
        pub fn set_max(mut self, input: std::option::Option<i32>) -> Self {
            self.max = input; self
        }
        /// Consumes the builder and constructs a [`VCpuCountRequest`](crate::model::VCpuCountRequest).
        pub fn build(self) -> crate::model::VCpuCountRequest {
            crate::model::VCpuCountRequest {
                min: self.min
                ,
                max: self.max
                ,
            }
        }
    }
    
    
}
impl VCpuCountRequest {
    /// Creates a new builder-style object to manufacture [`VCpuCountRequest`](crate::model::VCpuCountRequest).
    pub fn builder() -> crate::model::v_cpu_count_request::Builder {
        crate::model::v_cpu_count_request::Builder::default()
    }
}

/// <p>Describes the launch template and the version of the launch template that Amazon EC2 Auto Scaling uses to launch Amazon EC2 instances. For more information about launch templates, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/LaunchTemplates.html">Launch templates</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct LaunchTemplateSpecification  {
    /// <p>The ID of the launch template. To get the template ID, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplates.html">DescribeLaunchTemplates</a> API operation. New launch templates can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplate.html">CreateLaunchTemplate</a> API. </p> 
    /// <p>Conditional: You must specify either a <code>LaunchTemplateId</code> or a <code>LaunchTemplateName</code>.</p>
    #[doc(hidden)]
    pub launch_template_id: std::option::Option<std::string::String>,
    /// <p>The name of the launch template. To get the template name, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplates.html">DescribeLaunchTemplates</a> API operation. New launch templates can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplate.html">CreateLaunchTemplate</a> API. </p> 
    /// <p>Conditional: You must specify either a <code>LaunchTemplateId</code> or a <code>LaunchTemplateName</code>.</p>
    #[doc(hidden)]
    pub launch_template_name: std::option::Option<std::string::String>,
    /// <p>The version number, <code>$Latest</code>, or <code>$Default</code>. To get the version number, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplateVersions.html">DescribeLaunchTemplateVersions</a> API operation. New launch template versions can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplateVersion.html">CreateLaunchTemplateVersion</a> API. If the value is <code>$Latest</code>, Amazon EC2 Auto Scaling selects the latest version of the launch template when launching instances. If the value is <code>$Default</code>, Amazon EC2 Auto Scaling selects the default version of the launch template when launching instances. The default value is <code>$Default</code>.</p>
    #[doc(hidden)]
    pub version: std::option::Option<std::string::String>,
}
impl LaunchTemplateSpecification {
    /// <p>The ID of the launch template. To get the template ID, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplates.html">DescribeLaunchTemplates</a> API operation. New launch templates can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplate.html">CreateLaunchTemplate</a> API. </p> 
    /// <p>Conditional: You must specify either a <code>LaunchTemplateId</code> or a <code>LaunchTemplateName</code>.</p>
    pub fn launch_template_id(&self) -> std::option::Option<& str> {
        self.launch_template_id.as_deref()
    }
    /// <p>The name of the launch template. To get the template name, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplates.html">DescribeLaunchTemplates</a> API operation. New launch templates can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplate.html">CreateLaunchTemplate</a> API. </p> 
    /// <p>Conditional: You must specify either a <code>LaunchTemplateId</code> or a <code>LaunchTemplateName</code>.</p>
    pub fn launch_template_name(&self) -> std::option::Option<& str> {
        self.launch_template_name.as_deref()
    }
    /// <p>The version number, <code>$Latest</code>, or <code>$Default</code>. To get the version number, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplateVersions.html">DescribeLaunchTemplateVersions</a> API operation. New launch template versions can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplateVersion.html">CreateLaunchTemplateVersion</a> API. If the value is <code>$Latest</code>, Amazon EC2 Auto Scaling selects the latest version of the launch template when launching instances. If the value is <code>$Default</code>, Amazon EC2 Auto Scaling selects the default version of the launch template when launching instances. The default value is <code>$Default</code>.</p>
    pub fn version(&self) -> std::option::Option<& str> {
        self.version.as_deref()
    }
}
/// See [`LaunchTemplateSpecification`](crate::model::LaunchTemplateSpecification).
pub mod launch_template_specification {
    
    /// A builder for [`LaunchTemplateSpecification`](crate::model::LaunchTemplateSpecification).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) launch_template_id: std::option::Option<std::string::String>,
        pub(crate) launch_template_name: std::option::Option<std::string::String>,
        pub(crate) version: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The ID of the launch template. To get the template ID, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplates.html">DescribeLaunchTemplates</a> API operation. New launch templates can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplate.html">CreateLaunchTemplate</a> API. </p> 
        /// <p>Conditional: You must specify either a <code>LaunchTemplateId</code> or a <code>LaunchTemplateName</code>.</p>
        pub fn launch_template_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.launch_template_id = Some(input.into());
            self
        }
        /// <p>The ID of the launch template. To get the template ID, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplates.html">DescribeLaunchTemplates</a> API operation. New launch templates can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplate.html">CreateLaunchTemplate</a> API. </p> 
        /// <p>Conditional: You must specify either a <code>LaunchTemplateId</code> or a <code>LaunchTemplateName</code>.</p>
        pub fn set_launch_template_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.launch_template_id = input; self
        }
        /// <p>The name of the launch template. To get the template name, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplates.html">DescribeLaunchTemplates</a> API operation. New launch templates can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplate.html">CreateLaunchTemplate</a> API. </p> 
        /// <p>Conditional: You must specify either a <code>LaunchTemplateId</code> or a <code>LaunchTemplateName</code>.</p>
        pub fn launch_template_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.launch_template_name = Some(input.into());
            self
        }
        /// <p>The name of the launch template. To get the template name, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplates.html">DescribeLaunchTemplates</a> API operation. New launch templates can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplate.html">CreateLaunchTemplate</a> API. </p> 
        /// <p>Conditional: You must specify either a <code>LaunchTemplateId</code> or a <code>LaunchTemplateName</code>.</p>
        pub fn set_launch_template_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.launch_template_name = input; self
        }
        /// <p>The version number, <code>$Latest</code>, or <code>$Default</code>. To get the version number, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplateVersions.html">DescribeLaunchTemplateVersions</a> API operation. New launch template versions can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplateVersion.html">CreateLaunchTemplateVersion</a> API. If the value is <code>$Latest</code>, Amazon EC2 Auto Scaling selects the latest version of the launch template when launching instances. If the value is <code>$Default</code>, Amazon EC2 Auto Scaling selects the default version of the launch template when launching instances. The default value is <code>$Default</code>.</p>
        pub fn version(mut self, input: impl Into<std::string::String>) -> Self {
            self.version = Some(input.into());
            self
        }
        /// <p>The version number, <code>$Latest</code>, or <code>$Default</code>. To get the version number, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeLaunchTemplateVersions.html">DescribeLaunchTemplateVersions</a> API operation. New launch template versions can be created using the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateLaunchTemplateVersion.html">CreateLaunchTemplateVersion</a> API. If the value is <code>$Latest</code>, Amazon EC2 Auto Scaling selects the latest version of the launch template when launching instances. If the value is <code>$Default</code>, Amazon EC2 Auto Scaling selects the default version of the launch template when launching instances. The default value is <code>$Default</code>.</p>
        pub fn set_version(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.version = input; self
        }
        /// Consumes the builder and constructs a [`LaunchTemplateSpecification`](crate::model::LaunchTemplateSpecification).
        pub fn build(self) -> crate::model::LaunchTemplateSpecification {
            crate::model::LaunchTemplateSpecification {
                launch_template_id: self.launch_template_id
                ,
                launch_template_name: self.launch_template_name
                ,
                version: self.version
                ,
            }
        }
    }
    
    
}
impl LaunchTemplateSpecification {
    /// Creates a new builder-style object to manufacture [`LaunchTemplateSpecification`](crate::model::LaunchTemplateSpecification).
    pub fn builder() -> crate::model::launch_template_specification::Builder {
        crate::model::launch_template_specification::Builder::default()
    }
}

/// <p>Describes scaling activity, which is a long-running process that represents a change to your Auto Scaling group, such as changing its size or replacing an instance.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct Activity  {
    /// <p>The ID of the activity.</p>
    #[doc(hidden)]
    pub activity_id: std::option::Option<std::string::String>,
    /// <p>The name of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub auto_scaling_group_name: std::option::Option<std::string::String>,
    /// <p>A friendly, more verbose description of the activity.</p>
    #[doc(hidden)]
    pub description: std::option::Option<std::string::String>,
    /// <p>The reason the activity began.</p>
    #[doc(hidden)]
    pub cause: std::option::Option<std::string::String>,
    /// <p>The start time of the activity.</p>
    #[doc(hidden)]
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The end time of the activity.</p>
    #[doc(hidden)]
    pub end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The current status of the activity.</p>
    #[doc(hidden)]
    pub status_code: std::option::Option<crate::model::ScalingActivityStatusCode>,
    /// <p>A friendly, more verbose description of the activity status.</p>
    #[doc(hidden)]
    pub status_message: std::option::Option<std::string::String>,
    /// <p>A value between 0 and 100 that indicates the progress of the activity.</p>
    #[doc(hidden)]
    pub progress: i32,
    /// <p>The details about the activity.</p>
    #[doc(hidden)]
    pub details: std::option::Option<std::string::String>,
    /// <p>The state of the Auto Scaling group, which is either <code>InService</code> or <code>Deleted</code>.</p>
    #[doc(hidden)]
    pub auto_scaling_group_state: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub auto_scaling_group_arn: std::option::Option<std::string::String>,
}
impl Activity {
    /// <p>The ID of the activity.</p>
    pub fn activity_id(&self) -> std::option::Option<& str> {
        self.activity_id.as_deref()
    }
    /// <p>The name of the Auto Scaling group.</p>
    pub fn auto_scaling_group_name(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_name.as_deref()
    }
    /// <p>A friendly, more verbose description of the activity.</p>
    pub fn description(&self) -> std::option::Option<& str> {
        self.description.as_deref()
    }
    /// <p>The reason the activity began.</p>
    pub fn cause(&self) -> std::option::Option<& str> {
        self.cause.as_deref()
    }
    /// <p>The start time of the activity.</p>
    pub fn start_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p>The end time of the activity.</p>
    pub fn end_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.end_time.as_ref()
    }
    /// <p>The current status of the activity.</p>
    pub fn status_code(&self) -> std::option::Option<& crate::model::ScalingActivityStatusCode> {
        self.status_code.as_ref()
    }
    /// <p>A friendly, more verbose description of the activity status.</p>
    pub fn status_message(&self) -> std::option::Option<& str> {
        self.status_message.as_deref()
    }
    /// <p>A value between 0 and 100 that indicates the progress of the activity.</p>
    pub fn progress(&self) -> i32 {
        self.progress
    }
    /// <p>The details about the activity.</p>
    pub fn details(&self) -> std::option::Option<& str> {
        self.details.as_deref()
    }
    /// <p>The state of the Auto Scaling group, which is either <code>InService</code> or <code>Deleted</code>.</p>
    pub fn auto_scaling_group_state(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_state.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
    pub fn auto_scaling_group_arn(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_arn.as_deref()
    }
}
/// See [`Activity`](crate::model::Activity).
pub mod activity {
    
    /// A builder for [`Activity`](crate::model::Activity).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) activity_id: std::option::Option<std::string::String>,
        pub(crate) auto_scaling_group_name: std::option::Option<std::string::String>,
        pub(crate) description: std::option::Option<std::string::String>,
        pub(crate) cause: std::option::Option<std::string::String>,
        pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) end_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) status_code: std::option::Option<crate::model::ScalingActivityStatusCode>,
        pub(crate) status_message: std::option::Option<std::string::String>,
        pub(crate) progress: std::option::Option<i32>,
        pub(crate) details: std::option::Option<std::string::String>,
        pub(crate) auto_scaling_group_state: std::option::Option<std::string::String>,
        pub(crate) auto_scaling_group_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The ID of the activity.</p>
        pub fn activity_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.activity_id = Some(input.into());
            self
        }
        /// <p>The ID of the activity.</p>
        pub fn set_activity_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.activity_id = input; self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.auto_scaling_group_name = Some(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.auto_scaling_group_name = input; self
        }
        /// <p>A friendly, more verbose description of the activity.</p>
        pub fn description(mut self, input: impl Into<std::string::String>) -> Self {
            self.description = Some(input.into());
            self
        }
        /// <p>A friendly, more verbose description of the activity.</p>
        pub fn set_description(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.description = input; self
        }
        /// <p>The reason the activity began.</p>
        pub fn cause(mut self, input: impl Into<std::string::String>) -> Self {
            self.cause = Some(input.into());
            self
        }
        /// <p>The reason the activity began.</p>
        pub fn set_cause(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.cause = input; self
        }
        /// <p>The start time of the activity.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p>The start time of the activity.</p>
        pub fn set_start_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.start_time = input; self
        }
        /// <p>The end time of the activity.</p>
        pub fn end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.end_time = Some(input);
            self
        }
        /// <p>The end time of the activity.</p>
        pub fn set_end_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.end_time = input; self
        }
        /// <p>The current status of the activity.</p>
        pub fn status_code(mut self, input: crate::model::ScalingActivityStatusCode) -> Self {
            self.status_code = Some(input);
            self
        }
        /// <p>The current status of the activity.</p>
        pub fn set_status_code(mut self, input: std::option::Option<crate::model::ScalingActivityStatusCode>) -> Self {
            self.status_code = input; self
        }
        /// <p>A friendly, more verbose description of the activity status.</p>
        pub fn status_message(mut self, input: impl Into<std::string::String>) -> Self {
            self.status_message = Some(input.into());
            self
        }
        /// <p>A friendly, more verbose description of the activity status.</p>
        pub fn set_status_message(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.status_message = input; self
        }
        /// <p>A value between 0 and 100 that indicates the progress of the activity.</p>
        pub fn progress(mut self, input: i32) -> Self {
            self.progress = Some(input);
            self
        }
        /// <p>A value between 0 and 100 that indicates the progress of the activity.</p>
        pub fn set_progress(mut self, input: std::option::Option<i32>) -> Self {
            self.progress = input; self
        }
        /// <p>The details about the activity.</p>
        pub fn details(mut self, input: impl Into<std::string::String>) -> Self {
            self.details = Some(input.into());
            self
        }
        /// <p>The details about the activity.</p>
        pub fn set_details(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.details = input; self
        }
        /// <p>The state of the Auto Scaling group, which is either <code>InService</code> or <code>Deleted</code>.</p>
        pub fn auto_scaling_group_state(mut self, input: impl Into<std::string::String>) -> Self {
            self.auto_scaling_group_state = Some(input.into());
            self
        }
        /// <p>The state of the Auto Scaling group, which is either <code>InService</code> or <code>Deleted</code>.</p>
        pub fn set_auto_scaling_group_state(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.auto_scaling_group_state = input; self
        }
        /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
        pub fn auto_scaling_group_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.auto_scaling_group_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.auto_scaling_group_arn = input; self
        }
        /// Consumes the builder and constructs a [`Activity`](crate::model::Activity).
        pub fn build(self) -> crate::model::Activity {
            crate::model::Activity {
                activity_id: self.activity_id
                ,
                auto_scaling_group_name: self.auto_scaling_group_name
                ,
                description: self.description
                ,
                cause: self.cause
                ,
                start_time: self.start_time
                ,
                end_time: self.end_time
                ,
                status_code: self.status_code
                ,
                status_message: self.status_message
                ,
                progress: self.progress
                    .unwrap_or_default()
                ,
                details: self.details
                ,
                auto_scaling_group_state: self.auto_scaling_group_state
                ,
                auto_scaling_group_arn: self.auto_scaling_group_arn
                ,
            }
        }
    }
    
    
}
impl Activity {
    /// Creates a new builder-style object to manufacture [`Activity`](crate::model::Activity).
    pub fn builder() -> crate::model::activity::Builder {
        crate::model::activity::Builder::default()
    }
}

/// When writing a match expression against `ScalingActivityStatusCode`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let scalingactivitystatuscode = unimplemented!();
/// match scalingactivitystatuscode {
///     ScalingActivityStatusCode::Cancelled => { /* ... */ },
///     ScalingActivityStatusCode::Failed => { /* ... */ },
///     ScalingActivityStatusCode::InProgress => { /* ... */ },
///     ScalingActivityStatusCode::MidLifecycleAction => { /* ... */ },
///     ScalingActivityStatusCode::PendingSpotBidPlacement => { /* ... */ },
///     ScalingActivityStatusCode::PreInService => { /* ... */ },
///     ScalingActivityStatusCode::Successful => { /* ... */ },
///     ScalingActivityStatusCode::WaitingForElbConnectionDraining => { /* ... */ },
///     ScalingActivityStatusCode::WaitingForInstanceId => { /* ... */ },
///     ScalingActivityStatusCode::WaitingForInstanceWarmup => { /* ... */ },
///     ScalingActivityStatusCode::WaitingForSpotInstanceId => { /* ... */ },
///     ScalingActivityStatusCode::WaitingForSpotInstanceRequestId => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `scalingactivitystatuscode` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `ScalingActivityStatusCode::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `ScalingActivityStatusCode::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `ScalingActivityStatusCode::NewFeature` is defined.
/// Specifically, when `scalingactivitystatuscode` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `ScalingActivityStatusCode::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum ScalingActivityStatusCode {
    #[allow(missing_docs)] // documentation missing in model
    Cancelled,
    #[allow(missing_docs)] // documentation missing in model
    Failed,
    #[allow(missing_docs)] // documentation missing in model
    InProgress,
    #[allow(missing_docs)] // documentation missing in model
    MidLifecycleAction,
    #[allow(missing_docs)] // documentation missing in model
    PendingSpotBidPlacement,
    #[allow(missing_docs)] // documentation missing in model
    PreInService,
    #[allow(missing_docs)] // documentation missing in model
    Successful,
    #[allow(missing_docs)] // documentation missing in model
    WaitingForElbConnectionDraining,
    #[allow(missing_docs)] // documentation missing in model
    WaitingForInstanceId,
    #[allow(missing_docs)] // documentation missing in model
    WaitingForInstanceWarmup,
    #[allow(missing_docs)] // documentation missing in model
    WaitingForSpotInstanceId,
    #[allow(missing_docs)] // documentation missing in model
    WaitingForSpotInstanceRequestId,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for ScalingActivityStatusCode {
    fn from(s: &str) -> Self {
        match s {
            "Cancelled" => ScalingActivityStatusCode::Cancelled,
            "Failed" => ScalingActivityStatusCode::Failed,
            "InProgress" => ScalingActivityStatusCode::InProgress,
            "MidLifecycleAction" => ScalingActivityStatusCode::MidLifecycleAction,
            "PendingSpotBidPlacement" => ScalingActivityStatusCode::PendingSpotBidPlacement,
            "PreInService" => ScalingActivityStatusCode::PreInService,
            "Successful" => ScalingActivityStatusCode::Successful,
            "WaitingForELBConnectionDraining" => ScalingActivityStatusCode::WaitingForElbConnectionDraining,
            "WaitingForInstanceId" => ScalingActivityStatusCode::WaitingForInstanceId,
            "WaitingForInstanceWarmup" => ScalingActivityStatusCode::WaitingForInstanceWarmup,
            "WaitingForSpotInstanceId" => ScalingActivityStatusCode::WaitingForSpotInstanceId,
            "WaitingForSpotInstanceRequestId" => ScalingActivityStatusCode::WaitingForSpotInstanceRequestId,
            other => ScalingActivityStatusCode::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for ScalingActivityStatusCode {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(ScalingActivityStatusCode::from(s))
                }
            }
impl ScalingActivityStatusCode {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            ScalingActivityStatusCode::Cancelled => "Cancelled",
            ScalingActivityStatusCode::Failed => "Failed",
            ScalingActivityStatusCode::InProgress => "InProgress",
            ScalingActivityStatusCode::MidLifecycleAction => "MidLifecycleAction",
            ScalingActivityStatusCode::PendingSpotBidPlacement => "PendingSpotBidPlacement",
            ScalingActivityStatusCode::PreInService => "PreInService",
            ScalingActivityStatusCode::Successful => "Successful",
            ScalingActivityStatusCode::WaitingForElbConnectionDraining => "WaitingForELBConnectionDraining",
            ScalingActivityStatusCode::WaitingForInstanceId => "WaitingForInstanceId",
            ScalingActivityStatusCode::WaitingForInstanceWarmup => "WaitingForInstanceWarmup",
            ScalingActivityStatusCode::WaitingForSpotInstanceId => "WaitingForSpotInstanceId",
            ScalingActivityStatusCode::WaitingForSpotInstanceRequestId => "WaitingForSpotInstanceRequestId",
            ScalingActivityStatusCode::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "Cancelled", "Failed", "InProgress", "MidLifecycleAction", "PendingSpotBidPlacement", "PreInService", "Successful", "WaitingForELBConnectionDraining", "WaitingForInstanceId", "WaitingForInstanceWarmup", "WaitingForSpotInstanceId", "WaitingForSpotInstanceRequestId"
        ]
    }
}
impl AsRef<str> for ScalingActivityStatusCode {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Describes the preferences for an instance refresh.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct RefreshPreferences  {
    /// <p>The amount of capacity in the Auto Scaling group that must pass your group's health checks to allow the operation to continue. The value is expressed as a percentage of the desired capacity of the Auto Scaling group (rounded up to the nearest integer). The default is <code>90</code>.</p> 
    /// <p>Setting the minimum healthy percentage to 100 percent limits the rate of replacement to one instance at a time. In contrast, setting it to 0 percent has the effect of replacing all instances at the same time. </p>
    #[doc(hidden)]
    pub min_healthy_percentage: std::option::Option<i32>,
    /// <p> <i>Not needed if the default instance warmup is defined for the group.</i> </p> 
    /// <p>The duration of the instance warmup, in seconds.</p> <note> 
    /// <p>The default is to use the value for the default instance warmup defined for the group. If default instance warmup is null, then <code>InstanceWarmup</code> falls back to the value of the health check grace period.</p> 
    /// </note>
    #[doc(hidden)]
    pub instance_warmup: std::option::Option<i32>,
    /// <p>Threshold values for each checkpoint in ascending order. Each number must be unique. To replace all instances in the Auto Scaling group, the last number in the array must be <code>100</code>.</p> 
    /// <p>For usage examples, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-adding-checkpoints-instance-refresh.html">Adding checkpoints to an instance refresh</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[doc(hidden)]
    pub checkpoint_percentages: std::option::Option<std::vec::Vec<i32>>,
    /// <p>The amount of time, in seconds, to wait after a checkpoint before continuing. This property is optional, but if you specify a value for it, you must also specify a value for <code>CheckpointPercentages</code>. If you specify a value for <code>CheckpointPercentages</code> and not for <code>CheckpointDelay</code>, the <code>CheckpointDelay</code> defaults to <code>3600</code> (1 hour). </p>
    #[doc(hidden)]
    pub checkpoint_delay: std::option::Option<i32>,
    /// <p>A boolean value that indicates whether skip matching is enabled. If true, then Amazon EC2 Auto Scaling skips replacing instances that match the desired configuration. If no desired configuration is specified, then it skips replacing instances that have the same configuration that is already set on the group. The default is <code>false</code>.</p>
    #[doc(hidden)]
    pub skip_matching: std::option::Option<bool>,
}
impl RefreshPreferences {
    /// <p>The amount of capacity in the Auto Scaling group that must pass your group's health checks to allow the operation to continue. The value is expressed as a percentage of the desired capacity of the Auto Scaling group (rounded up to the nearest integer). The default is <code>90</code>.</p> 
    /// <p>Setting the minimum healthy percentage to 100 percent limits the rate of replacement to one instance at a time. In contrast, setting it to 0 percent has the effect of replacing all instances at the same time. </p>
    pub fn min_healthy_percentage(&self) -> std::option::Option<i32> {
        self.min_healthy_percentage
    }
    /// <p> <i>Not needed if the default instance warmup is defined for the group.</i> </p> 
    /// <p>The duration of the instance warmup, in seconds.</p> <note> 
    /// <p>The default is to use the value for the default instance warmup defined for the group. If default instance warmup is null, then <code>InstanceWarmup</code> falls back to the value of the health check grace period.</p> 
    /// </note>
    pub fn instance_warmup(&self) -> std::option::Option<i32> {
        self.instance_warmup
    }
    /// <p>Threshold values for each checkpoint in ascending order. Each number must be unique. To replace all instances in the Auto Scaling group, the last number in the array must be <code>100</code>.</p> 
    /// <p>For usage examples, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-adding-checkpoints-instance-refresh.html">Adding checkpoints to an instance refresh</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    pub fn checkpoint_percentages(&self) -> std::option::Option<& [i32]> {
        self.checkpoint_percentages.as_deref()
    }
    /// <p>The amount of time, in seconds, to wait after a checkpoint before continuing. This property is optional, but if you specify a value for it, you must also specify a value for <code>CheckpointPercentages</code>. If you specify a value for <code>CheckpointPercentages</code> and not for <code>CheckpointDelay</code>, the <code>CheckpointDelay</code> defaults to <code>3600</code> (1 hour). </p>
    pub fn checkpoint_delay(&self) -> std::option::Option<i32> {
        self.checkpoint_delay
    }
    /// <p>A boolean value that indicates whether skip matching is enabled. If true, then Amazon EC2 Auto Scaling skips replacing instances that match the desired configuration. If no desired configuration is specified, then it skips replacing instances that have the same configuration that is already set on the group. The default is <code>false</code>.</p>
    pub fn skip_matching(&self) -> std::option::Option<bool> {
        self.skip_matching
    }
}
/// See [`RefreshPreferences`](crate::model::RefreshPreferences).
pub mod refresh_preferences {
    
    /// A builder for [`RefreshPreferences`](crate::model::RefreshPreferences).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) min_healthy_percentage: std::option::Option<i32>,
        pub(crate) instance_warmup: std::option::Option<i32>,
        pub(crate) checkpoint_percentages: std::option::Option<std::vec::Vec<i32>>,
        pub(crate) checkpoint_delay: std::option::Option<i32>,
        pub(crate) skip_matching: std::option::Option<bool>,
    }
    impl Builder {
        /// <p>The amount of capacity in the Auto Scaling group that must pass your group's health checks to allow the operation to continue. The value is expressed as a percentage of the desired capacity of the Auto Scaling group (rounded up to the nearest integer). The default is <code>90</code>.</p> 
        /// <p>Setting the minimum healthy percentage to 100 percent limits the rate of replacement to one instance at a time. In contrast, setting it to 0 percent has the effect of replacing all instances at the same time. </p>
        pub fn min_healthy_percentage(mut self, input: i32) -> Self {
            self.min_healthy_percentage = Some(input);
            self
        }
        /// <p>The amount of capacity in the Auto Scaling group that must pass your group's health checks to allow the operation to continue. The value is expressed as a percentage of the desired capacity of the Auto Scaling group (rounded up to the nearest integer). The default is <code>90</code>.</p> 
        /// <p>Setting the minimum healthy percentage to 100 percent limits the rate of replacement to one instance at a time. In contrast, setting it to 0 percent has the effect of replacing all instances at the same time. </p>
        pub fn set_min_healthy_percentage(mut self, input: std::option::Option<i32>) -> Self {
            self.min_healthy_percentage = input; self
        }
        /// <p> <i>Not needed if the default instance warmup is defined for the group.</i> </p> 
        /// <p>The duration of the instance warmup, in seconds.</p> <note> 
        /// <p>The default is to use the value for the default instance warmup defined for the group. If default instance warmup is null, then <code>InstanceWarmup</code> falls back to the value of the health check grace period.</p> 
        /// </note>
        pub fn instance_warmup(mut self, input: i32) -> Self {
            self.instance_warmup = Some(input);
            self
        }
        /// <p> <i>Not needed if the default instance warmup is defined for the group.</i> </p> 
        /// <p>The duration of the instance warmup, in seconds.</p> <note> 
        /// <p>The default is to use the value for the default instance warmup defined for the group. If default instance warmup is null, then <code>InstanceWarmup</code> falls back to the value of the health check grace period.</p> 
        /// </note>
        pub fn set_instance_warmup(mut self, input: std::option::Option<i32>) -> Self {
            self.instance_warmup = input; self
        }
        /// Appends an item to `checkpoint_percentages`.
        ///
        /// To override the contents of this collection use [`set_checkpoint_percentages`](Self::set_checkpoint_percentages).
        ///
        /// <p>Threshold values for each checkpoint in ascending order. Each number must be unique. To replace all instances in the Auto Scaling group, the last number in the array must be <code>100</code>.</p> 
        /// <p>For usage examples, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-adding-checkpoints-instance-refresh.html">Adding checkpoints to an instance refresh</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn checkpoint_percentages(mut self, input: i32) -> Self {
            let mut v = self.checkpoint_percentages.unwrap_or_default();
                            v.push(input);
                            self.checkpoint_percentages = Some(v);
                            self
        }
        /// <p>Threshold values for each checkpoint in ascending order. Each number must be unique. To replace all instances in the Auto Scaling group, the last number in the array must be <code>100</code>.</p> 
        /// <p>For usage examples, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-adding-checkpoints-instance-refresh.html">Adding checkpoints to an instance refresh</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_checkpoint_percentages(mut self, input: std::option::Option<std::vec::Vec<i32>>) -> Self {
            self.checkpoint_percentages = input; self
        }
        /// <p>The amount of time, in seconds, to wait after a checkpoint before continuing. This property is optional, but if you specify a value for it, you must also specify a value for <code>CheckpointPercentages</code>. If you specify a value for <code>CheckpointPercentages</code> and not for <code>CheckpointDelay</code>, the <code>CheckpointDelay</code> defaults to <code>3600</code> (1 hour). </p>
        pub fn checkpoint_delay(mut self, input: i32) -> Self {
            self.checkpoint_delay = Some(input);
            self
        }
        /// <p>The amount of time, in seconds, to wait after a checkpoint before continuing. This property is optional, but if you specify a value for it, you must also specify a value for <code>CheckpointPercentages</code>. If you specify a value for <code>CheckpointPercentages</code> and not for <code>CheckpointDelay</code>, the <code>CheckpointDelay</code> defaults to <code>3600</code> (1 hour). </p>
        pub fn set_checkpoint_delay(mut self, input: std::option::Option<i32>) -> Self {
            self.checkpoint_delay = input; self
        }
        /// <p>A boolean value that indicates whether skip matching is enabled. If true, then Amazon EC2 Auto Scaling skips replacing instances that match the desired configuration. If no desired configuration is specified, then it skips replacing instances that have the same configuration that is already set on the group. The default is <code>false</code>.</p>
        pub fn skip_matching(mut self, input: bool) -> Self {
            self.skip_matching = Some(input);
            self
        }
        /// <p>A boolean value that indicates whether skip matching is enabled. If true, then Amazon EC2 Auto Scaling skips replacing instances that match the desired configuration. If no desired configuration is specified, then it skips replacing instances that have the same configuration that is already set on the group. The default is <code>false</code>.</p>
        pub fn set_skip_matching(mut self, input: std::option::Option<bool>) -> Self {
            self.skip_matching = input; self
        }
        /// Consumes the builder and constructs a [`RefreshPreferences`](crate::model::RefreshPreferences).
        pub fn build(self) -> crate::model::RefreshPreferences {
            crate::model::RefreshPreferences {
                min_healthy_percentage: self.min_healthy_percentage
                ,
                instance_warmup: self.instance_warmup
                ,
                checkpoint_percentages: self.checkpoint_percentages
                ,
                checkpoint_delay: self.checkpoint_delay
                ,
                skip_matching: self.skip_matching
                ,
            }
        }
    }
    
    
}
impl RefreshPreferences {
    /// Creates a new builder-style object to manufacture [`RefreshPreferences`](crate::model::RefreshPreferences).
    pub fn builder() -> crate::model::refresh_preferences::Builder {
        crate::model::refresh_preferences::Builder::default()
    }
}

/// <p>Describes the desired configuration for an instance refresh. </p> 
/// <p>If you specify a desired configuration, you must specify either a <code>LaunchTemplate</code> or a <code>MixedInstancesPolicy</code>. </p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct DesiredConfiguration  {
    /// <p>Describes the launch template and the version of the launch template that Amazon EC2 Auto Scaling uses to launch Amazon EC2 instances. For more information about launch templates, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/LaunchTemplates.html">Launch templates</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[doc(hidden)]
    pub launch_template: std::option::Option<crate::model::LaunchTemplateSpecification>,
    /// <p>Use this structure to launch multiple instance types and On-Demand Instances and Spot Instances within a single Auto Scaling group.</p> 
    /// <p>A mixed instances policy contains information that Amazon EC2 Auto Scaling can use to launch instances and help optimize your costs. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html">Auto Scaling groups with multiple instance types and purchase options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[doc(hidden)]
    pub mixed_instances_policy: std::option::Option<crate::model::MixedInstancesPolicy>,
}
impl DesiredConfiguration {
    /// <p>Describes the launch template and the version of the launch template that Amazon EC2 Auto Scaling uses to launch Amazon EC2 instances. For more information about launch templates, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/LaunchTemplates.html">Launch templates</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    pub fn launch_template(&self) -> std::option::Option<& crate::model::LaunchTemplateSpecification> {
        self.launch_template.as_ref()
    }
    /// <p>Use this structure to launch multiple instance types and On-Demand Instances and Spot Instances within a single Auto Scaling group.</p> 
    /// <p>A mixed instances policy contains information that Amazon EC2 Auto Scaling can use to launch instances and help optimize your costs. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html">Auto Scaling groups with multiple instance types and purchase options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    pub fn mixed_instances_policy(&self) -> std::option::Option<& crate::model::MixedInstancesPolicy> {
        self.mixed_instances_policy.as_ref()
    }
}
/// See [`DesiredConfiguration`](crate::model::DesiredConfiguration).
pub mod desired_configuration {
    
    /// A builder for [`DesiredConfiguration`](crate::model::DesiredConfiguration).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) launch_template: std::option::Option<crate::model::LaunchTemplateSpecification>,
        pub(crate) mixed_instances_policy: std::option::Option<crate::model::MixedInstancesPolicy>,
    }
    impl Builder {
        /// <p>Describes the launch template and the version of the launch template that Amazon EC2 Auto Scaling uses to launch Amazon EC2 instances. For more information about launch templates, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/LaunchTemplates.html">Launch templates</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn launch_template(mut self, input: crate::model::LaunchTemplateSpecification) -> Self {
            self.launch_template = Some(input);
            self
        }
        /// <p>Describes the launch template and the version of the launch template that Amazon EC2 Auto Scaling uses to launch Amazon EC2 instances. For more information about launch templates, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/LaunchTemplates.html">Launch templates</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_launch_template(mut self, input: std::option::Option<crate::model::LaunchTemplateSpecification>) -> Self {
            self.launch_template = input; self
        }
        /// <p>Use this structure to launch multiple instance types and On-Demand Instances and Spot Instances within a single Auto Scaling group.</p> 
        /// <p>A mixed instances policy contains information that Amazon EC2 Auto Scaling can use to launch instances and help optimize your costs. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html">Auto Scaling groups with multiple instance types and purchase options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn mixed_instances_policy(mut self, input: crate::model::MixedInstancesPolicy) -> Self {
            self.mixed_instances_policy = Some(input);
            self
        }
        /// <p>Use this structure to launch multiple instance types and On-Demand Instances and Spot Instances within a single Auto Scaling group.</p> 
        /// <p>A mixed instances policy contains information that Amazon EC2 Auto Scaling can use to launch instances and help optimize your costs. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html">Auto Scaling groups with multiple instance types and purchase options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_mixed_instances_policy(mut self, input: std::option::Option<crate::model::MixedInstancesPolicy>) -> Self {
            self.mixed_instances_policy = input; self
        }
        /// Consumes the builder and constructs a [`DesiredConfiguration`](crate::model::DesiredConfiguration).
        pub fn build(self) -> crate::model::DesiredConfiguration {
            crate::model::DesiredConfiguration {
                launch_template: self.launch_template
                ,
                mixed_instances_policy: self.mixed_instances_policy
                ,
            }
        }
    }
    
    
}
impl DesiredConfiguration {
    /// Creates a new builder-style object to manufacture [`DesiredConfiguration`](crate::model::DesiredConfiguration).
    pub fn builder() -> crate::model::desired_configuration::Builder {
        crate::model::desired_configuration::Builder::default()
    }
}

/// When writing a match expression against `RefreshStrategy`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let refreshstrategy = unimplemented!();
/// match refreshstrategy {
///     RefreshStrategy::Rolling => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `refreshstrategy` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `RefreshStrategy::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `RefreshStrategy::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `RefreshStrategy::NewFeature` is defined.
/// Specifically, when `refreshstrategy` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `RefreshStrategy::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum RefreshStrategy {
    #[allow(missing_docs)] // documentation missing in model
    Rolling,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for RefreshStrategy {
    fn from(s: &str) -> Self {
        match s {
            "Rolling" => RefreshStrategy::Rolling,
            other => RefreshStrategy::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for RefreshStrategy {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(RefreshStrategy::from(s))
                }
            }
impl RefreshStrategy {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            RefreshStrategy::Rolling => "Rolling",
            RefreshStrategy::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "Rolling"
        ]
    }
}
impl AsRef<str> for RefreshStrategy {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Describes an instance reuse policy for a warm pool. </p> 
/// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-warm-pools.html">Warm pools for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct InstanceReusePolicy  {
    /// <p>Specifies whether instances in the Auto Scaling group can be returned to the warm pool on scale in. </p>
    #[doc(hidden)]
    pub reuse_on_scale_in: std::option::Option<bool>,
}
impl InstanceReusePolicy {
    /// <p>Specifies whether instances in the Auto Scaling group can be returned to the warm pool on scale in. </p>
    pub fn reuse_on_scale_in(&self) -> std::option::Option<bool> {
        self.reuse_on_scale_in
    }
}
/// See [`InstanceReusePolicy`](crate::model::InstanceReusePolicy).
pub mod instance_reuse_policy {
    
    /// A builder for [`InstanceReusePolicy`](crate::model::InstanceReusePolicy).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) reuse_on_scale_in: std::option::Option<bool>,
    }
    impl Builder {
        /// <p>Specifies whether instances in the Auto Scaling group can be returned to the warm pool on scale in. </p>
        pub fn reuse_on_scale_in(mut self, input: bool) -> Self {
            self.reuse_on_scale_in = Some(input);
            self
        }
        /// <p>Specifies whether instances in the Auto Scaling group can be returned to the warm pool on scale in. </p>
        pub fn set_reuse_on_scale_in(mut self, input: std::option::Option<bool>) -> Self {
            self.reuse_on_scale_in = input; self
        }
        /// Consumes the builder and constructs a [`InstanceReusePolicy`](crate::model::InstanceReusePolicy).
        pub fn build(self) -> crate::model::InstanceReusePolicy {
            crate::model::InstanceReusePolicy {
                reuse_on_scale_in: self.reuse_on_scale_in
                ,
            }
        }
    }
    
    
}
impl InstanceReusePolicy {
    /// Creates a new builder-style object to manufacture [`InstanceReusePolicy`](crate::model::InstanceReusePolicy).
    pub fn builder() -> crate::model::instance_reuse_policy::Builder {
        crate::model::instance_reuse_policy::Builder::default()
    }
}

/// When writing a match expression against `WarmPoolState`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let warmpoolstate = unimplemented!();
/// match warmpoolstate {
///     WarmPoolState::Hibernated => { /* ... */ },
///     WarmPoolState::Running => { /* ... */ },
///     WarmPoolState::Stopped => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `warmpoolstate` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `WarmPoolState::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `WarmPoolState::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `WarmPoolState::NewFeature` is defined.
/// Specifically, when `warmpoolstate` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `WarmPoolState::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum WarmPoolState {
    #[allow(missing_docs)] // documentation missing in model
    Hibernated,
    #[allow(missing_docs)] // documentation missing in model
    Running,
    #[allow(missing_docs)] // documentation missing in model
    Stopped,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for WarmPoolState {
    fn from(s: &str) -> Self {
        match s {
            "Hibernated" => WarmPoolState::Hibernated,
            "Running" => WarmPoolState::Running,
            "Stopped" => WarmPoolState::Stopped,
            other => WarmPoolState::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for WarmPoolState {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(WarmPoolState::from(s))
                }
            }
impl WarmPoolState {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            WarmPoolState::Hibernated => "Hibernated",
            WarmPoolState::Running => "Running",
            WarmPoolState::Stopped => "Stopped",
            WarmPoolState::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "Hibernated", "Running", "Stopped"
        ]
    }
}
impl AsRef<str> for WarmPoolState {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Describes an alarm.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct Alarm  {
    /// <p>The name of the alarm.</p>
    #[doc(hidden)]
    pub alarm_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the alarm.</p>
    #[doc(hidden)]
    pub alarm_arn: std::option::Option<std::string::String>,
}
impl Alarm {
    /// <p>The name of the alarm.</p>
    pub fn alarm_name(&self) -> std::option::Option<& str> {
        self.alarm_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the alarm.</p>
    pub fn alarm_arn(&self) -> std::option::Option<& str> {
        self.alarm_arn.as_deref()
    }
}
/// See [`Alarm`](crate::model::Alarm).
pub mod alarm {
    
    /// A builder for [`Alarm`](crate::model::Alarm).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) alarm_name: std::option::Option<std::string::String>,
        pub(crate) alarm_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the alarm.</p>
        pub fn alarm_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.alarm_name = Some(input.into());
            self
        }
        /// <p>The name of the alarm.</p>
        pub fn set_alarm_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.alarm_name = input; self
        }
        /// <p>The Amazon Resource Name (ARN) of the alarm.</p>
        pub fn alarm_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.alarm_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the alarm.</p>
        pub fn set_alarm_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.alarm_arn = input; self
        }
        /// Consumes the builder and constructs a [`Alarm`](crate::model::Alarm).
        pub fn build(self) -> crate::model::Alarm {
            crate::model::Alarm {
                alarm_name: self.alarm_name
                ,
                alarm_arn: self.alarm_arn
                ,
            }
        }
    }
    
    
}
impl Alarm {
    /// Creates a new builder-style object to manufacture [`Alarm`](crate::model::Alarm).
    pub fn builder() -> crate::model::alarm::Builder {
        crate::model::alarm::Builder::default()
    }
}

/// <p>Represents a predictive scaling policy configuration to use with Amazon EC2 Auto Scaling.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct PredictiveScalingConfiguration  {
    /// <p>This structure includes the metrics and target utilization to use for predictive scaling. </p> 
    /// <p>This is an array, but we currently only support a single metric specification. That is, you can specify a target value and a single metric pair, or a target value and one scaling metric and one load metric.</p>
    #[doc(hidden)]
    pub metric_specifications: std::option::Option<std::vec::Vec<crate::model::PredictiveScalingMetricSpecification>>,
    /// <p>The predictive scaling mode. Defaults to <code>ForecastOnly</code> if not specified.</p>
    #[doc(hidden)]
    pub mode: std::option::Option<crate::model::PredictiveScalingMode>,
    /// <p>The amount of time, in seconds, by which the instance launch time can be advanced. For example, the forecast says to add capacity at 10:00 AM, and you choose to pre-launch instances by 5 minutes. In that case, the instances will be launched at 9:55 AM. The intention is to give resources time to be provisioned. It can take a few minutes to launch an EC2 instance. The actual amount of time required depends on several factors, such as the size of the instance and whether there are startup scripts to complete. </p> 
    /// <p>The value must be less than the forecast interval duration of 3600 seconds (60 minutes). Defaults to 300 seconds if not specified. </p>
    #[doc(hidden)]
    pub scheduling_buffer_time: std::option::Option<i32>,
    /// <p>Defines the behavior that should be applied if the forecast capacity approaches or exceeds the maximum capacity of the Auto Scaling group. Defaults to <code>HonorMaxCapacity</code> if not specified.</p> 
    /// <p>The following are possible values:</p> 
    /// <ul> 
    /// <li> <p> <code>HonorMaxCapacity</code> - Amazon EC2 Auto Scaling cannot scale out capacity higher than the maximum capacity. The maximum capacity is enforced as a hard limit. </p> </li> 
    /// <li> <p> <code>IncreaseMaxCapacity</code> - Amazon EC2 Auto Scaling can scale out capacity higher than the maximum capacity when the forecast capacity is close to or exceeds the maximum capacity. The upper limit is determined by the forecasted capacity and the value for <code>MaxCapacityBuffer</code>.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub max_capacity_breach_behavior: std::option::Option<crate::model::PredictiveScalingMaxCapacityBreachBehavior>,
    /// <p>The size of the capacity buffer to use when the forecast capacity is close to or exceeds the maximum capacity. The value is specified as a percentage relative to the forecast capacity. For example, if the buffer is 10, this means a 10 percent buffer, such that if the forecast capacity is 50, and the maximum capacity is 40, then the effective maximum capacity is 55.</p> 
    /// <p>If set to 0, Amazon EC2 Auto Scaling may scale capacity higher than the maximum capacity to equal but not exceed forecast capacity. </p> 
    /// <p>Required if the <code>MaxCapacityBreachBehavior</code> property is set to <code>IncreaseMaxCapacity</code>, and cannot be used otherwise.</p>
    #[doc(hidden)]
    pub max_capacity_buffer: std::option::Option<i32>,
}
impl PredictiveScalingConfiguration {
    /// <p>This structure includes the metrics and target utilization to use for predictive scaling. </p> 
    /// <p>This is an array, but we currently only support a single metric specification. That is, you can specify a target value and a single metric pair, or a target value and one scaling metric and one load metric.</p>
    pub fn metric_specifications(&self) -> std::option::Option<& [crate::model::PredictiveScalingMetricSpecification]> {
        self.metric_specifications.as_deref()
    }
    /// <p>The predictive scaling mode. Defaults to <code>ForecastOnly</code> if not specified.</p>
    pub fn mode(&self) -> std::option::Option<& crate::model::PredictiveScalingMode> {
        self.mode.as_ref()
    }
    /// <p>The amount of time, in seconds, by which the instance launch time can be advanced. For example, the forecast says to add capacity at 10:00 AM, and you choose to pre-launch instances by 5 minutes. In that case, the instances will be launched at 9:55 AM. The intention is to give resources time to be provisioned. It can take a few minutes to launch an EC2 instance. The actual amount of time required depends on several factors, such as the size of the instance and whether there are startup scripts to complete. </p> 
    /// <p>The value must be less than the forecast interval duration of 3600 seconds (60 minutes). Defaults to 300 seconds if not specified. </p>
    pub fn scheduling_buffer_time(&self) -> std::option::Option<i32> {
        self.scheduling_buffer_time
    }
    /// <p>Defines the behavior that should be applied if the forecast capacity approaches or exceeds the maximum capacity of the Auto Scaling group. Defaults to <code>HonorMaxCapacity</code> if not specified.</p> 
    /// <p>The following are possible values:</p> 
    /// <ul> 
    /// <li> <p> <code>HonorMaxCapacity</code> - Amazon EC2 Auto Scaling cannot scale out capacity higher than the maximum capacity. The maximum capacity is enforced as a hard limit. </p> </li> 
    /// <li> <p> <code>IncreaseMaxCapacity</code> - Amazon EC2 Auto Scaling can scale out capacity higher than the maximum capacity when the forecast capacity is close to or exceeds the maximum capacity. The upper limit is determined by the forecasted capacity and the value for <code>MaxCapacityBuffer</code>.</p> </li> 
    /// </ul>
    pub fn max_capacity_breach_behavior(&self) -> std::option::Option<& crate::model::PredictiveScalingMaxCapacityBreachBehavior> {
        self.max_capacity_breach_behavior.as_ref()
    }
    /// <p>The size of the capacity buffer to use when the forecast capacity is close to or exceeds the maximum capacity. The value is specified as a percentage relative to the forecast capacity. For example, if the buffer is 10, this means a 10 percent buffer, such that if the forecast capacity is 50, and the maximum capacity is 40, then the effective maximum capacity is 55.</p> 
    /// <p>If set to 0, Amazon EC2 Auto Scaling may scale capacity higher than the maximum capacity to equal but not exceed forecast capacity. </p> 
    /// <p>Required if the <code>MaxCapacityBreachBehavior</code> property is set to <code>IncreaseMaxCapacity</code>, and cannot be used otherwise.</p>
    pub fn max_capacity_buffer(&self) -> std::option::Option<i32> {
        self.max_capacity_buffer
    }
}
/// See [`PredictiveScalingConfiguration`](crate::model::PredictiveScalingConfiguration).
pub mod predictive_scaling_configuration {
    
    /// A builder for [`PredictiveScalingConfiguration`](crate::model::PredictiveScalingConfiguration).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) metric_specifications: std::option::Option<std::vec::Vec<crate::model::PredictiveScalingMetricSpecification>>,
        pub(crate) mode: std::option::Option<crate::model::PredictiveScalingMode>,
        pub(crate) scheduling_buffer_time: std::option::Option<i32>,
        pub(crate) max_capacity_breach_behavior: std::option::Option<crate::model::PredictiveScalingMaxCapacityBreachBehavior>,
        pub(crate) max_capacity_buffer: std::option::Option<i32>,
    }
    impl Builder {
        /// Appends an item to `metric_specifications`.
        ///
        /// To override the contents of this collection use [`set_metric_specifications`](Self::set_metric_specifications).
        ///
        /// <p>This structure includes the metrics and target utilization to use for predictive scaling. </p> 
        /// <p>This is an array, but we currently only support a single metric specification. That is, you can specify a target value and a single metric pair, or a target value and one scaling metric and one load metric.</p>
        pub fn metric_specifications(mut self, input: crate::model::PredictiveScalingMetricSpecification) -> Self {
            let mut v = self.metric_specifications.unwrap_or_default();
                            v.push(input);
                            self.metric_specifications = Some(v);
                            self
        }
        /// <p>This structure includes the metrics and target utilization to use for predictive scaling. </p> 
        /// <p>This is an array, but we currently only support a single metric specification. That is, you can specify a target value and a single metric pair, or a target value and one scaling metric and one load metric.</p>
        pub fn set_metric_specifications(mut self, input: std::option::Option<std::vec::Vec<crate::model::PredictiveScalingMetricSpecification>>) -> Self {
            self.metric_specifications = input; self
        }
        /// <p>The predictive scaling mode. Defaults to <code>ForecastOnly</code> if not specified.</p>
        pub fn mode(mut self, input: crate::model::PredictiveScalingMode) -> Self {
            self.mode = Some(input);
            self
        }
        /// <p>The predictive scaling mode. Defaults to <code>ForecastOnly</code> if not specified.</p>
        pub fn set_mode(mut self, input: std::option::Option<crate::model::PredictiveScalingMode>) -> Self {
            self.mode = input; self
        }
        /// <p>The amount of time, in seconds, by which the instance launch time can be advanced. For example, the forecast says to add capacity at 10:00 AM, and you choose to pre-launch instances by 5 minutes. In that case, the instances will be launched at 9:55 AM. The intention is to give resources time to be provisioned. It can take a few minutes to launch an EC2 instance. The actual amount of time required depends on several factors, such as the size of the instance and whether there are startup scripts to complete. </p> 
        /// <p>The value must be less than the forecast interval duration of 3600 seconds (60 minutes). Defaults to 300 seconds if not specified. </p>
        pub fn scheduling_buffer_time(mut self, input: i32) -> Self {
            self.scheduling_buffer_time = Some(input);
            self
        }
        /// <p>The amount of time, in seconds, by which the instance launch time can be advanced. For example, the forecast says to add capacity at 10:00 AM, and you choose to pre-launch instances by 5 minutes. In that case, the instances will be launched at 9:55 AM. The intention is to give resources time to be provisioned. It can take a few minutes to launch an EC2 instance. The actual amount of time required depends on several factors, such as the size of the instance and whether there are startup scripts to complete. </p> 
        /// <p>The value must be less than the forecast interval duration of 3600 seconds (60 minutes). Defaults to 300 seconds if not specified. </p>
        pub fn set_scheduling_buffer_time(mut self, input: std::option::Option<i32>) -> Self {
            self.scheduling_buffer_time = input; self
        }
        /// <p>Defines the behavior that should be applied if the forecast capacity approaches or exceeds the maximum capacity of the Auto Scaling group. Defaults to <code>HonorMaxCapacity</code> if not specified.</p> 
        /// <p>The following are possible values:</p> 
        /// <ul> 
        /// <li> <p> <code>HonorMaxCapacity</code> - Amazon EC2 Auto Scaling cannot scale out capacity higher than the maximum capacity. The maximum capacity is enforced as a hard limit. </p> </li> 
        /// <li> <p> <code>IncreaseMaxCapacity</code> - Amazon EC2 Auto Scaling can scale out capacity higher than the maximum capacity when the forecast capacity is close to or exceeds the maximum capacity. The upper limit is determined by the forecasted capacity and the value for <code>MaxCapacityBuffer</code>.</p> </li> 
        /// </ul>
        pub fn max_capacity_breach_behavior(mut self, input: crate::model::PredictiveScalingMaxCapacityBreachBehavior) -> Self {
            self.max_capacity_breach_behavior = Some(input);
            self
        }
        /// <p>Defines the behavior that should be applied if the forecast capacity approaches or exceeds the maximum capacity of the Auto Scaling group. Defaults to <code>HonorMaxCapacity</code> if not specified.</p> 
        /// <p>The following are possible values:</p> 
        /// <ul> 
        /// <li> <p> <code>HonorMaxCapacity</code> - Amazon EC2 Auto Scaling cannot scale out capacity higher than the maximum capacity. The maximum capacity is enforced as a hard limit. </p> </li> 
        /// <li> <p> <code>IncreaseMaxCapacity</code> - Amazon EC2 Auto Scaling can scale out capacity higher than the maximum capacity when the forecast capacity is close to or exceeds the maximum capacity. The upper limit is determined by the forecasted capacity and the value for <code>MaxCapacityBuffer</code>.</p> </li> 
        /// </ul>
        pub fn set_max_capacity_breach_behavior(mut self, input: std::option::Option<crate::model::PredictiveScalingMaxCapacityBreachBehavior>) -> Self {
            self.max_capacity_breach_behavior = input; self
        }
        /// <p>The size of the capacity buffer to use when the forecast capacity is close to or exceeds the maximum capacity. The value is specified as a percentage relative to the forecast capacity. For example, if the buffer is 10, this means a 10 percent buffer, such that if the forecast capacity is 50, and the maximum capacity is 40, then the effective maximum capacity is 55.</p> 
        /// <p>If set to 0, Amazon EC2 Auto Scaling may scale capacity higher than the maximum capacity to equal but not exceed forecast capacity. </p> 
        /// <p>Required if the <code>MaxCapacityBreachBehavior</code> property is set to <code>IncreaseMaxCapacity</code>, and cannot be used otherwise.</p>
        pub fn max_capacity_buffer(mut self, input: i32) -> Self {
            self.max_capacity_buffer = Some(input);
            self
        }
        /// <p>The size of the capacity buffer to use when the forecast capacity is close to or exceeds the maximum capacity. The value is specified as a percentage relative to the forecast capacity. For example, if the buffer is 10, this means a 10 percent buffer, such that if the forecast capacity is 50, and the maximum capacity is 40, then the effective maximum capacity is 55.</p> 
        /// <p>If set to 0, Amazon EC2 Auto Scaling may scale capacity higher than the maximum capacity to equal but not exceed forecast capacity. </p> 
        /// <p>Required if the <code>MaxCapacityBreachBehavior</code> property is set to <code>IncreaseMaxCapacity</code>, and cannot be used otherwise.</p>
        pub fn set_max_capacity_buffer(mut self, input: std::option::Option<i32>) -> Self {
            self.max_capacity_buffer = input; self
        }
        /// Consumes the builder and constructs a [`PredictiveScalingConfiguration`](crate::model::PredictiveScalingConfiguration).
        pub fn build(self) -> crate::model::PredictiveScalingConfiguration {
            crate::model::PredictiveScalingConfiguration {
                metric_specifications: self.metric_specifications
                ,
                mode: self.mode
                ,
                scheduling_buffer_time: self.scheduling_buffer_time
                ,
                max_capacity_breach_behavior: self.max_capacity_breach_behavior
                ,
                max_capacity_buffer: self.max_capacity_buffer
                ,
            }
        }
    }
    
    
}
impl PredictiveScalingConfiguration {
    /// Creates a new builder-style object to manufacture [`PredictiveScalingConfiguration`](crate::model::PredictiveScalingConfiguration).
    pub fn builder() -> crate::model::predictive_scaling_configuration::Builder {
        crate::model::predictive_scaling_configuration::Builder::default()
    }
}

/// When writing a match expression against `PredictiveScalingMaxCapacityBreachBehavior`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let predictivescalingmaxcapacitybreachbehavior = unimplemented!();
/// match predictivescalingmaxcapacitybreachbehavior {
///     PredictiveScalingMaxCapacityBreachBehavior::HonorMaxCapacity => { /* ... */ },
///     PredictiveScalingMaxCapacityBreachBehavior::IncreaseMaxCapacity => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `predictivescalingmaxcapacitybreachbehavior` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `PredictiveScalingMaxCapacityBreachBehavior::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `PredictiveScalingMaxCapacityBreachBehavior::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `PredictiveScalingMaxCapacityBreachBehavior::NewFeature` is defined.
/// Specifically, when `predictivescalingmaxcapacitybreachbehavior` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `PredictiveScalingMaxCapacityBreachBehavior::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum PredictiveScalingMaxCapacityBreachBehavior {
    #[allow(missing_docs)] // documentation missing in model
    HonorMaxCapacity,
    #[allow(missing_docs)] // documentation missing in model
    IncreaseMaxCapacity,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for PredictiveScalingMaxCapacityBreachBehavior {
    fn from(s: &str) -> Self {
        match s {
            "HonorMaxCapacity" => PredictiveScalingMaxCapacityBreachBehavior::HonorMaxCapacity,
            "IncreaseMaxCapacity" => PredictiveScalingMaxCapacityBreachBehavior::IncreaseMaxCapacity,
            other => PredictiveScalingMaxCapacityBreachBehavior::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for PredictiveScalingMaxCapacityBreachBehavior {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(PredictiveScalingMaxCapacityBreachBehavior::from(s))
                }
            }
impl PredictiveScalingMaxCapacityBreachBehavior {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            PredictiveScalingMaxCapacityBreachBehavior::HonorMaxCapacity => "HonorMaxCapacity",
            PredictiveScalingMaxCapacityBreachBehavior::IncreaseMaxCapacity => "IncreaseMaxCapacity",
            PredictiveScalingMaxCapacityBreachBehavior::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "HonorMaxCapacity", "IncreaseMaxCapacity"
        ]
    }
}
impl AsRef<str> for PredictiveScalingMaxCapacityBreachBehavior {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// When writing a match expression against `PredictiveScalingMode`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let predictivescalingmode = unimplemented!();
/// match predictivescalingmode {
///     PredictiveScalingMode::ForecastAndScale => { /* ... */ },
///     PredictiveScalingMode::ForecastOnly => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `predictivescalingmode` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `PredictiveScalingMode::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `PredictiveScalingMode::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `PredictiveScalingMode::NewFeature` is defined.
/// Specifically, when `predictivescalingmode` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `PredictiveScalingMode::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum PredictiveScalingMode {
    #[allow(missing_docs)] // documentation missing in model
    ForecastAndScale,
    #[allow(missing_docs)] // documentation missing in model
    ForecastOnly,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for PredictiveScalingMode {
    fn from(s: &str) -> Self {
        match s {
            "ForecastAndScale" => PredictiveScalingMode::ForecastAndScale,
            "ForecastOnly" => PredictiveScalingMode::ForecastOnly,
            other => PredictiveScalingMode::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for PredictiveScalingMode {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(PredictiveScalingMode::from(s))
                }
            }
impl PredictiveScalingMode {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            PredictiveScalingMode::ForecastAndScale => "ForecastAndScale",
            PredictiveScalingMode::ForecastOnly => "ForecastOnly",
            PredictiveScalingMode::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "ForecastAndScale", "ForecastOnly"
        ]
    }
}
impl AsRef<str> for PredictiveScalingMode {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>This structure specifies the metrics and target utilization settings for a predictive scaling policy. </p> 
/// <p>You must specify either a metric pair, or a load metric and a scaling metric individually. Specifying a metric pair instead of individual metrics provides a simpler way to configure metrics for a scaling policy. You choose the metric pair, and the policy automatically knows the correct sum and average statistics to use for the load metric and the scaling metric.</p> 
/// <p>Example</p> 
/// <ul> 
/// <li> <p>You create a predictive scaling policy and specify <code>ALBRequestCount</code> as the value for the metric pair and <code>1000.0</code> as the target value. For this type of metric, you must provide the metric dimension for the corresponding target group, so you also provide a resource label for the Application Load Balancer target group that is attached to your Auto Scaling group.</p> </li> 
/// <li> <p>The number of requests the target group receives per minute provides the load metric, and the request count averaged between the members of the target group provides the scaling metric. In CloudWatch, this refers to the <code>RequestCount</code> and <code>RequestCountPerTarget</code> metrics, respectively.</p> </li> 
/// <li> <p>For optimal use of predictive scaling, you adhere to the best practice of using a dynamic scaling policy to automatically scale between the minimum capacity and maximum capacity in response to real-time changes in resource utilization.</p> </li> 
/// <li> <p>Amazon EC2 Auto Scaling consumes data points for the load metric over the last 14 days and creates an hourly load forecast for predictive scaling. (A minimum of 24 hours of data is required.)</p> </li> 
/// <li> <p>After creating the load forecast, Amazon EC2 Auto Scaling determines when to reduce or increase the capacity of your Auto Scaling group in each hour of the forecast period so that the average number of requests received by each instance is as close to 1000 requests per minute as possible at all times.</p> </li> 
/// </ul> 
/// <p>For information about using custom metrics with predictive scaling, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/predictive-scaling-customized-metric-specification.html">Advanced predictive scaling policy configurations using custom metrics</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct PredictiveScalingMetricSpecification  {
    /// <p>Specifies the target utilization.</p> <note> 
    /// <p>Some metrics are based on a count instead of a percentage, such as the request count for an Application Load Balancer or the number of messages in an SQS queue. If the scaling policy specifies one of these metrics, specify the target utilization as the optimal average request or message count per instance during any one-minute interval. </p> 
    /// </note>
    #[doc(hidden)]
    pub target_value: std::option::Option<f64>,
    /// <p>The predefined metric pair specification from which Amazon EC2 Auto Scaling determines the appropriate scaling metric and load metric to use.</p>
    #[doc(hidden)]
    pub predefined_metric_pair_specification: std::option::Option<crate::model::PredictiveScalingPredefinedMetricPair>,
    /// <p>The predefined scaling metric specification.</p>
    #[doc(hidden)]
    pub predefined_scaling_metric_specification: std::option::Option<crate::model::PredictiveScalingPredefinedScalingMetric>,
    /// <p>The predefined load metric specification.</p>
    #[doc(hidden)]
    pub predefined_load_metric_specification: std::option::Option<crate::model::PredictiveScalingPredefinedLoadMetric>,
    /// <p>The customized scaling metric specification.</p>
    #[doc(hidden)]
    pub customized_scaling_metric_specification: std::option::Option<crate::model::PredictiveScalingCustomizedScalingMetric>,
    /// <p>The customized load metric specification.</p>
    #[doc(hidden)]
    pub customized_load_metric_specification: std::option::Option<crate::model::PredictiveScalingCustomizedLoadMetric>,
    /// <p>The customized capacity metric specification.</p>
    #[doc(hidden)]
    pub customized_capacity_metric_specification: std::option::Option<crate::model::PredictiveScalingCustomizedCapacityMetric>,
}
impl PredictiveScalingMetricSpecification {
    /// <p>Specifies the target utilization.</p> <note> 
    /// <p>Some metrics are based on a count instead of a percentage, such as the request count for an Application Load Balancer or the number of messages in an SQS queue. If the scaling policy specifies one of these metrics, specify the target utilization as the optimal average request or message count per instance during any one-minute interval. </p> 
    /// </note>
    pub fn target_value(&self) -> std::option::Option<f64> {
        self.target_value
    }
    /// <p>The predefined metric pair specification from which Amazon EC2 Auto Scaling determines the appropriate scaling metric and load metric to use.</p>
    pub fn predefined_metric_pair_specification(&self) -> std::option::Option<& crate::model::PredictiveScalingPredefinedMetricPair> {
        self.predefined_metric_pair_specification.as_ref()
    }
    /// <p>The predefined scaling metric specification.</p>
    pub fn predefined_scaling_metric_specification(&self) -> std::option::Option<& crate::model::PredictiveScalingPredefinedScalingMetric> {
        self.predefined_scaling_metric_specification.as_ref()
    }
    /// <p>The predefined load metric specification.</p>
    pub fn predefined_load_metric_specification(&self) -> std::option::Option<& crate::model::PredictiveScalingPredefinedLoadMetric> {
        self.predefined_load_metric_specification.as_ref()
    }
    /// <p>The customized scaling metric specification.</p>
    pub fn customized_scaling_metric_specification(&self) -> std::option::Option<& crate::model::PredictiveScalingCustomizedScalingMetric> {
        self.customized_scaling_metric_specification.as_ref()
    }
    /// <p>The customized load metric specification.</p>
    pub fn customized_load_metric_specification(&self) -> std::option::Option<& crate::model::PredictiveScalingCustomizedLoadMetric> {
        self.customized_load_metric_specification.as_ref()
    }
    /// <p>The customized capacity metric specification.</p>
    pub fn customized_capacity_metric_specification(&self) -> std::option::Option<& crate::model::PredictiveScalingCustomizedCapacityMetric> {
        self.customized_capacity_metric_specification.as_ref()
    }
}
/// See [`PredictiveScalingMetricSpecification`](crate::model::PredictiveScalingMetricSpecification).
pub mod predictive_scaling_metric_specification {
    
    /// A builder for [`PredictiveScalingMetricSpecification`](crate::model::PredictiveScalingMetricSpecification).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) target_value: std::option::Option<f64>,
        pub(crate) predefined_metric_pair_specification: std::option::Option<crate::model::PredictiveScalingPredefinedMetricPair>,
        pub(crate) predefined_scaling_metric_specification: std::option::Option<crate::model::PredictiveScalingPredefinedScalingMetric>,
        pub(crate) predefined_load_metric_specification: std::option::Option<crate::model::PredictiveScalingPredefinedLoadMetric>,
        pub(crate) customized_scaling_metric_specification: std::option::Option<crate::model::PredictiveScalingCustomizedScalingMetric>,
        pub(crate) customized_load_metric_specification: std::option::Option<crate::model::PredictiveScalingCustomizedLoadMetric>,
        pub(crate) customized_capacity_metric_specification: std::option::Option<crate::model::PredictiveScalingCustomizedCapacityMetric>,
    }
    impl Builder {
        /// <p>Specifies the target utilization.</p> <note> 
        /// <p>Some metrics are based on a count instead of a percentage, such as the request count for an Application Load Balancer or the number of messages in an SQS queue. If the scaling policy specifies one of these metrics, specify the target utilization as the optimal average request or message count per instance during any one-minute interval. </p> 
        /// </note>
        pub fn target_value(mut self, input: f64) -> Self {
            self.target_value = Some(input);
            self
        }
        /// <p>Specifies the target utilization.</p> <note> 
        /// <p>Some metrics are based on a count instead of a percentage, such as the request count for an Application Load Balancer or the number of messages in an SQS queue. If the scaling policy specifies one of these metrics, specify the target utilization as the optimal average request or message count per instance during any one-minute interval. </p> 
        /// </note>
        pub fn set_target_value(mut self, input: std::option::Option<f64>) -> Self {
            self.target_value = input; self
        }
        /// <p>The predefined metric pair specification from which Amazon EC2 Auto Scaling determines the appropriate scaling metric and load metric to use.</p>
        pub fn predefined_metric_pair_specification(mut self, input: crate::model::PredictiveScalingPredefinedMetricPair) -> Self {
            self.predefined_metric_pair_specification = Some(input);
            self
        }
        /// <p>The predefined metric pair specification from which Amazon EC2 Auto Scaling determines the appropriate scaling metric and load metric to use.</p>
        pub fn set_predefined_metric_pair_specification(mut self, input: std::option::Option<crate::model::PredictiveScalingPredefinedMetricPair>) -> Self {
            self.predefined_metric_pair_specification = input; self
        }
        /// <p>The predefined scaling metric specification.</p>
        pub fn predefined_scaling_metric_specification(mut self, input: crate::model::PredictiveScalingPredefinedScalingMetric) -> Self {
            self.predefined_scaling_metric_specification = Some(input);
            self
        }
        /// <p>The predefined scaling metric specification.</p>
        pub fn set_predefined_scaling_metric_specification(mut self, input: std::option::Option<crate::model::PredictiveScalingPredefinedScalingMetric>) -> Self {
            self.predefined_scaling_metric_specification = input; self
        }
        /// <p>The predefined load metric specification.</p>
        pub fn predefined_load_metric_specification(mut self, input: crate::model::PredictiveScalingPredefinedLoadMetric) -> Self {
            self.predefined_load_metric_specification = Some(input);
            self
        }
        /// <p>The predefined load metric specification.</p>
        pub fn set_predefined_load_metric_specification(mut self, input: std::option::Option<crate::model::PredictiveScalingPredefinedLoadMetric>) -> Self {
            self.predefined_load_metric_specification = input; self
        }
        /// <p>The customized scaling metric specification.</p>
        pub fn customized_scaling_metric_specification(mut self, input: crate::model::PredictiveScalingCustomizedScalingMetric) -> Self {
            self.customized_scaling_metric_specification = Some(input);
            self
        }
        /// <p>The customized scaling metric specification.</p>
        pub fn set_customized_scaling_metric_specification(mut self, input: std::option::Option<crate::model::PredictiveScalingCustomizedScalingMetric>) -> Self {
            self.customized_scaling_metric_specification = input; self
        }
        /// <p>The customized load metric specification.</p>
        pub fn customized_load_metric_specification(mut self, input: crate::model::PredictiveScalingCustomizedLoadMetric) -> Self {
            self.customized_load_metric_specification = Some(input);
            self
        }
        /// <p>The customized load metric specification.</p>
        pub fn set_customized_load_metric_specification(mut self, input: std::option::Option<crate::model::PredictiveScalingCustomizedLoadMetric>) -> Self {
            self.customized_load_metric_specification = input; self
        }
        /// <p>The customized capacity metric specification.</p>
        pub fn customized_capacity_metric_specification(mut self, input: crate::model::PredictiveScalingCustomizedCapacityMetric) -> Self {
            self.customized_capacity_metric_specification = Some(input);
            self
        }
        /// <p>The customized capacity metric specification.</p>
        pub fn set_customized_capacity_metric_specification(mut self, input: std::option::Option<crate::model::PredictiveScalingCustomizedCapacityMetric>) -> Self {
            self.customized_capacity_metric_specification = input; self
        }
        /// Consumes the builder and constructs a [`PredictiveScalingMetricSpecification`](crate::model::PredictiveScalingMetricSpecification).
        pub fn build(self) -> crate::model::PredictiveScalingMetricSpecification {
            crate::model::PredictiveScalingMetricSpecification {
                target_value: self.target_value
                ,
                predefined_metric_pair_specification: self.predefined_metric_pair_specification
                ,
                predefined_scaling_metric_specification: self.predefined_scaling_metric_specification
                ,
                predefined_load_metric_specification: self.predefined_load_metric_specification
                ,
                customized_scaling_metric_specification: self.customized_scaling_metric_specification
                ,
                customized_load_metric_specification: self.customized_load_metric_specification
                ,
                customized_capacity_metric_specification: self.customized_capacity_metric_specification
                ,
            }
        }
    }
    
    
}
impl PredictiveScalingMetricSpecification {
    /// Creates a new builder-style object to manufacture [`PredictiveScalingMetricSpecification`](crate::model::PredictiveScalingMetricSpecification).
    pub fn builder() -> crate::model::predictive_scaling_metric_specification::Builder {
        crate::model::predictive_scaling_metric_specification::Builder::default()
    }
}

/// <p>Describes a customized capacity metric for a predictive scaling policy.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct PredictiveScalingCustomizedCapacityMetric  {
    /// <p>One or more metric data queries to provide the data points for a capacity metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
    #[doc(hidden)]
    pub metric_data_queries: std::option::Option<std::vec::Vec<crate::model::MetricDataQuery>>,
}
impl PredictiveScalingCustomizedCapacityMetric {
    /// <p>One or more metric data queries to provide the data points for a capacity metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
    pub fn metric_data_queries(&self) -> std::option::Option<& [crate::model::MetricDataQuery]> {
        self.metric_data_queries.as_deref()
    }
}
/// See [`PredictiveScalingCustomizedCapacityMetric`](crate::model::PredictiveScalingCustomizedCapacityMetric).
pub mod predictive_scaling_customized_capacity_metric {
    
    /// A builder for [`PredictiveScalingCustomizedCapacityMetric`](crate::model::PredictiveScalingCustomizedCapacityMetric).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) metric_data_queries: std::option::Option<std::vec::Vec<crate::model::MetricDataQuery>>,
    }
    impl Builder {
        /// Appends an item to `metric_data_queries`.
        ///
        /// To override the contents of this collection use [`set_metric_data_queries`](Self::set_metric_data_queries).
        ///
        /// <p>One or more metric data queries to provide the data points for a capacity metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
        pub fn metric_data_queries(mut self, input: crate::model::MetricDataQuery) -> Self {
            let mut v = self.metric_data_queries.unwrap_or_default();
                            v.push(input);
                            self.metric_data_queries = Some(v);
                            self
        }
        /// <p>One or more metric data queries to provide the data points for a capacity metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
        pub fn set_metric_data_queries(mut self, input: std::option::Option<std::vec::Vec<crate::model::MetricDataQuery>>) -> Self {
            self.metric_data_queries = input; self
        }
        /// Consumes the builder and constructs a [`PredictiveScalingCustomizedCapacityMetric`](crate::model::PredictiveScalingCustomizedCapacityMetric).
        pub fn build(self) -> crate::model::PredictiveScalingCustomizedCapacityMetric {
            crate::model::PredictiveScalingCustomizedCapacityMetric {
                metric_data_queries: self.metric_data_queries
                ,
            }
        }
    }
    
    
}
impl PredictiveScalingCustomizedCapacityMetric {
    /// Creates a new builder-style object to manufacture [`PredictiveScalingCustomizedCapacityMetric`](crate::model::PredictiveScalingCustomizedCapacityMetric).
    pub fn builder() -> crate::model::predictive_scaling_customized_capacity_metric::Builder {
        crate::model::predictive_scaling_customized_capacity_metric::Builder::default()
    }
}

/// <p>The metric data to return. Also defines whether this call is returning data for one metric only, or whether it is performing a math expression on the values of returned metric statistics to create a new time series. A time series is a series of data points, each of which is associated with a timestamp.</p> 
/// <p>For more information and examples, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/predictive-scaling-customized-metric-specification.html">Advanced predictive scaling policy configurations using custom metrics</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct MetricDataQuery  {
    /// <p>A short name that identifies the object's results in the response. This name must be unique among all <code>MetricDataQuery</code> objects specified for a single scaling policy. If you are performing math expressions on this set of data, this name represents that data and can serve as a variable in the mathematical expression. The valid characters are letters, numbers, and underscores. The first character must be a lowercase letter. </p>
    #[doc(hidden)]
    pub id: std::option::Option<std::string::String>,
    /// <p>The math expression to perform on the returned data, if this object is performing a math expression. This expression can use the <code>Id</code> of the other metrics to refer to those metrics, and can also use the <code>Id</code> of other expressions to use the result of those expressions. </p> 
    /// <p>Conditional: Within each <code>MetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
    #[doc(hidden)]
    pub expression: std::option::Option<std::string::String>,
    /// <p>Information about the metric data to return.</p> 
    /// <p>Conditional: Within each <code>MetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
    #[doc(hidden)]
    pub metric_stat: std::option::Option<crate::model::MetricStat>,
    /// <p>A human-readable label for this metric or expression. This is especially useful if this is a math expression, so that you know what the value represents.</p>
    #[doc(hidden)]
    pub label: std::option::Option<std::string::String>,
    /// <p>Indicates whether to return the timestamps and raw data values of this metric. </p> 
    /// <p>If you use any math expressions, specify <code>true</code> for this value for only the final math expression that the metric specification is based on. You must specify <code>false</code> for <code>ReturnData</code> for all the other metrics and expressions used in the metric specification.</p> 
    /// <p>If you are only retrieving metrics and not performing any math expressions, do not specify anything for <code>ReturnData</code>. This sets it to its default (<code>true</code>).</p>
    #[doc(hidden)]
    pub return_data: std::option::Option<bool>,
}
impl MetricDataQuery {
    /// <p>A short name that identifies the object's results in the response. This name must be unique among all <code>MetricDataQuery</code> objects specified for a single scaling policy. If you are performing math expressions on this set of data, this name represents that data and can serve as a variable in the mathematical expression. The valid characters are letters, numbers, and underscores. The first character must be a lowercase letter. </p>
    pub fn id(&self) -> std::option::Option<& str> {
        self.id.as_deref()
    }
    /// <p>The math expression to perform on the returned data, if this object is performing a math expression. This expression can use the <code>Id</code> of the other metrics to refer to those metrics, and can also use the <code>Id</code> of other expressions to use the result of those expressions. </p> 
    /// <p>Conditional: Within each <code>MetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
    pub fn expression(&self) -> std::option::Option<& str> {
        self.expression.as_deref()
    }
    /// <p>Information about the metric data to return.</p> 
    /// <p>Conditional: Within each <code>MetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
    pub fn metric_stat(&self) -> std::option::Option<& crate::model::MetricStat> {
        self.metric_stat.as_ref()
    }
    /// <p>A human-readable label for this metric or expression. This is especially useful if this is a math expression, so that you know what the value represents.</p>
    pub fn label(&self) -> std::option::Option<& str> {
        self.label.as_deref()
    }
    /// <p>Indicates whether to return the timestamps and raw data values of this metric. </p> 
    /// <p>If you use any math expressions, specify <code>true</code> for this value for only the final math expression that the metric specification is based on. You must specify <code>false</code> for <code>ReturnData</code> for all the other metrics and expressions used in the metric specification.</p> 
    /// <p>If you are only retrieving metrics and not performing any math expressions, do not specify anything for <code>ReturnData</code>. This sets it to its default (<code>true</code>).</p>
    pub fn return_data(&self) -> std::option::Option<bool> {
        self.return_data
    }
}
/// See [`MetricDataQuery`](crate::model::MetricDataQuery).
pub mod metric_data_query {
    
    /// A builder for [`MetricDataQuery`](crate::model::MetricDataQuery).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) id: std::option::Option<std::string::String>,
        pub(crate) expression: std::option::Option<std::string::String>,
        pub(crate) metric_stat: std::option::Option<crate::model::MetricStat>,
        pub(crate) label: std::option::Option<std::string::String>,
        pub(crate) return_data: std::option::Option<bool>,
    }
    impl Builder {
        /// <p>A short name that identifies the object's results in the response. This name must be unique among all <code>MetricDataQuery</code> objects specified for a single scaling policy. If you are performing math expressions on this set of data, this name represents that data and can serve as a variable in the mathematical expression. The valid characters are letters, numbers, and underscores. The first character must be a lowercase letter. </p>
        pub fn id(mut self, input: impl Into<std::string::String>) -> Self {
            self.id = Some(input.into());
            self
        }
        /// <p>A short name that identifies the object's results in the response. This name must be unique among all <code>MetricDataQuery</code> objects specified for a single scaling policy. If you are performing math expressions on this set of data, this name represents that data and can serve as a variable in the mathematical expression. The valid characters are letters, numbers, and underscores. The first character must be a lowercase letter. </p>
        pub fn set_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.id = input; self
        }
        /// <p>The math expression to perform on the returned data, if this object is performing a math expression. This expression can use the <code>Id</code> of the other metrics to refer to those metrics, and can also use the <code>Id</code> of other expressions to use the result of those expressions. </p> 
        /// <p>Conditional: Within each <code>MetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
        pub fn expression(mut self, input: impl Into<std::string::String>) -> Self {
            self.expression = Some(input.into());
            self
        }
        /// <p>The math expression to perform on the returned data, if this object is performing a math expression. This expression can use the <code>Id</code> of the other metrics to refer to those metrics, and can also use the <code>Id</code> of other expressions to use the result of those expressions. </p> 
        /// <p>Conditional: Within each <code>MetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
        pub fn set_expression(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.expression = input; self
        }
        /// <p>Information about the metric data to return.</p> 
        /// <p>Conditional: Within each <code>MetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
        pub fn metric_stat(mut self, input: crate::model::MetricStat) -> Self {
            self.metric_stat = Some(input);
            self
        }
        /// <p>Information about the metric data to return.</p> 
        /// <p>Conditional: Within each <code>MetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
        pub fn set_metric_stat(mut self, input: std::option::Option<crate::model::MetricStat>) -> Self {
            self.metric_stat = input; self
        }
        /// <p>A human-readable label for this metric or expression. This is especially useful if this is a math expression, so that you know what the value represents.</p>
        pub fn label(mut self, input: impl Into<std::string::String>) -> Self {
            self.label = Some(input.into());
            self
        }
        /// <p>A human-readable label for this metric or expression. This is especially useful if this is a math expression, so that you know what the value represents.</p>
        pub fn set_label(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.label = input; self
        }
        /// <p>Indicates whether to return the timestamps and raw data values of this metric. </p> 
        /// <p>If you use any math expressions, specify <code>true</code> for this value for only the final math expression that the metric specification is based on. You must specify <code>false</code> for <code>ReturnData</code> for all the other metrics and expressions used in the metric specification.</p> 
        /// <p>If you are only retrieving metrics and not performing any math expressions, do not specify anything for <code>ReturnData</code>. This sets it to its default (<code>true</code>).</p>
        pub fn return_data(mut self, input: bool) -> Self {
            self.return_data = Some(input);
            self
        }
        /// <p>Indicates whether to return the timestamps and raw data values of this metric. </p> 
        /// <p>If you use any math expressions, specify <code>true</code> for this value for only the final math expression that the metric specification is based on. You must specify <code>false</code> for <code>ReturnData</code> for all the other metrics and expressions used in the metric specification.</p> 
        /// <p>If you are only retrieving metrics and not performing any math expressions, do not specify anything for <code>ReturnData</code>. This sets it to its default (<code>true</code>).</p>
        pub fn set_return_data(mut self, input: std::option::Option<bool>) -> Self {
            self.return_data = input; self
        }
        /// Consumes the builder and constructs a [`MetricDataQuery`](crate::model::MetricDataQuery).
        pub fn build(self) -> crate::model::MetricDataQuery {
            crate::model::MetricDataQuery {
                id: self.id
                ,
                expression: self.expression
                ,
                metric_stat: self.metric_stat
                ,
                label: self.label
                ,
                return_data: self.return_data
                ,
            }
        }
    }
    
    
}
impl MetricDataQuery {
    /// Creates a new builder-style object to manufacture [`MetricDataQuery`](crate::model::MetricDataQuery).
    pub fn builder() -> crate::model::metric_data_query::Builder {
        crate::model::metric_data_query::Builder::default()
    }
}

/// <p>This structure defines the CloudWatch metric to return, along with the statistic, period, and unit.</p> 
/// <p>For more information about the CloudWatch terminology below, see <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html">Amazon CloudWatch concepts</a> in the <i>Amazon CloudWatch User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct MetricStat  {
    /// <p>The CloudWatch metric to return, including the metric name, namespace, and dimensions. To get the exact metric name, namespace, and dimensions, inspect the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Metric.html">Metric</a> object that is returned by a call to <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html">ListMetrics</a>.</p>
    #[doc(hidden)]
    pub metric: std::option::Option<crate::model::Metric>,
    /// <p>The statistic to return. It can include any CloudWatch statistic or extended statistic. For a list of valid values, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Statistic">Statistics</a> in the <i>Amazon CloudWatch User Guide</i>.</p> 
    /// <p>The most commonly used metrics for predictive scaling are <code>Average</code> and <code>Sum</code>.</p>
    #[doc(hidden)]
    pub stat: std::option::Option<std::string::String>,
    /// <p>The unit to use for the returned data points. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
    #[doc(hidden)]
    pub unit: std::option::Option<std::string::String>,
}
impl MetricStat {
    /// <p>The CloudWatch metric to return, including the metric name, namespace, and dimensions. To get the exact metric name, namespace, and dimensions, inspect the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Metric.html">Metric</a> object that is returned by a call to <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html">ListMetrics</a>.</p>
    pub fn metric(&self) -> std::option::Option<& crate::model::Metric> {
        self.metric.as_ref()
    }
    /// <p>The statistic to return. It can include any CloudWatch statistic or extended statistic. For a list of valid values, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Statistic">Statistics</a> in the <i>Amazon CloudWatch User Guide</i>.</p> 
    /// <p>The most commonly used metrics for predictive scaling are <code>Average</code> and <code>Sum</code>.</p>
    pub fn stat(&self) -> std::option::Option<& str> {
        self.stat.as_deref()
    }
    /// <p>The unit to use for the returned data points. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
    pub fn unit(&self) -> std::option::Option<& str> {
        self.unit.as_deref()
    }
}
/// See [`MetricStat`](crate::model::MetricStat).
pub mod metric_stat {
    
    /// A builder for [`MetricStat`](crate::model::MetricStat).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) metric: std::option::Option<crate::model::Metric>,
        pub(crate) stat: std::option::Option<std::string::String>,
        pub(crate) unit: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The CloudWatch metric to return, including the metric name, namespace, and dimensions. To get the exact metric name, namespace, and dimensions, inspect the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Metric.html">Metric</a> object that is returned by a call to <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html">ListMetrics</a>.</p>
        pub fn metric(mut self, input: crate::model::Metric) -> Self {
            self.metric = Some(input);
            self
        }
        /// <p>The CloudWatch metric to return, including the metric name, namespace, and dimensions. To get the exact metric name, namespace, and dimensions, inspect the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Metric.html">Metric</a> object that is returned by a call to <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html">ListMetrics</a>.</p>
        pub fn set_metric(mut self, input: std::option::Option<crate::model::Metric>) -> Self {
            self.metric = input; self
        }
        /// <p>The statistic to return. It can include any CloudWatch statistic or extended statistic. For a list of valid values, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Statistic">Statistics</a> in the <i>Amazon CloudWatch User Guide</i>.</p> 
        /// <p>The most commonly used metrics for predictive scaling are <code>Average</code> and <code>Sum</code>.</p>
        pub fn stat(mut self, input: impl Into<std::string::String>) -> Self {
            self.stat = Some(input.into());
            self
        }
        /// <p>The statistic to return. It can include any CloudWatch statistic or extended statistic. For a list of valid values, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Statistic">Statistics</a> in the <i>Amazon CloudWatch User Guide</i>.</p> 
        /// <p>The most commonly used metrics for predictive scaling are <code>Average</code> and <code>Sum</code>.</p>
        pub fn set_stat(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.stat = input; self
        }
        /// <p>The unit to use for the returned data points. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
        pub fn unit(mut self, input: impl Into<std::string::String>) -> Self {
            self.unit = Some(input.into());
            self
        }
        /// <p>The unit to use for the returned data points. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
        pub fn set_unit(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.unit = input; self
        }
        /// Consumes the builder and constructs a [`MetricStat`](crate::model::MetricStat).
        pub fn build(self) -> crate::model::MetricStat {
            crate::model::MetricStat {
                metric: self.metric
                ,
                stat: self.stat
                ,
                unit: self.unit
                ,
            }
        }
    }
    
    
}
impl MetricStat {
    /// Creates a new builder-style object to manufacture [`MetricStat`](crate::model::MetricStat).
    pub fn builder() -> crate::model::metric_stat::Builder {
        crate::model::metric_stat::Builder::default()
    }
}

/// <p>Represents a specific metric. </p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct Metric  {
    /// <p>The namespace of the metric. For more information, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html">Amazon Web Services services that publish CloudWatch metrics </a> in the <i>Amazon CloudWatch User Guide</i>.</p>
    #[doc(hidden)]
    pub namespace: std::option::Option<std::string::String>,
    /// <p>The name of the metric.</p>
    #[doc(hidden)]
    pub metric_name: std::option::Option<std::string::String>,
    /// <p>The dimensions for the metric. For the list of available dimensions, see the Amazon Web Services documentation available from the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html">Amazon Web Services services that publish CloudWatch metrics </a> in the <i>Amazon CloudWatch User Guide</i>. </p> 
    /// <p>Conditional: If you published your metric with dimensions, you must specify the same dimensions in your scaling policy.</p>
    #[doc(hidden)]
    pub dimensions: std::option::Option<std::vec::Vec<crate::model::MetricDimension>>,
}
impl Metric {
    /// <p>The namespace of the metric. For more information, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html">Amazon Web Services services that publish CloudWatch metrics </a> in the <i>Amazon CloudWatch User Guide</i>.</p>
    pub fn namespace(&self) -> std::option::Option<& str> {
        self.namespace.as_deref()
    }
    /// <p>The name of the metric.</p>
    pub fn metric_name(&self) -> std::option::Option<& str> {
        self.metric_name.as_deref()
    }
    /// <p>The dimensions for the metric. For the list of available dimensions, see the Amazon Web Services documentation available from the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html">Amazon Web Services services that publish CloudWatch metrics </a> in the <i>Amazon CloudWatch User Guide</i>. </p> 
    /// <p>Conditional: If you published your metric with dimensions, you must specify the same dimensions in your scaling policy.</p>
    pub fn dimensions(&self) -> std::option::Option<& [crate::model::MetricDimension]> {
        self.dimensions.as_deref()
    }
}
/// See [`Metric`](crate::model::Metric).
pub mod metric {
    
    /// A builder for [`Metric`](crate::model::Metric).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) namespace: std::option::Option<std::string::String>,
        pub(crate) metric_name: std::option::Option<std::string::String>,
        pub(crate) dimensions: std::option::Option<std::vec::Vec<crate::model::MetricDimension>>,
    }
    impl Builder {
        /// <p>The namespace of the metric. For more information, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html">Amazon Web Services services that publish CloudWatch metrics </a> in the <i>Amazon CloudWatch User Guide</i>.</p>
        pub fn namespace(mut self, input: impl Into<std::string::String>) -> Self {
            self.namespace = Some(input.into());
            self
        }
        /// <p>The namespace of the metric. For more information, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html">Amazon Web Services services that publish CloudWatch metrics </a> in the <i>Amazon CloudWatch User Guide</i>.</p>
        pub fn set_namespace(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.namespace = input; self
        }
        /// <p>The name of the metric.</p>
        pub fn metric_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.metric_name = Some(input.into());
            self
        }
        /// <p>The name of the metric.</p>
        pub fn set_metric_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.metric_name = input; self
        }
        /// Appends an item to `dimensions`.
        ///
        /// To override the contents of this collection use [`set_dimensions`](Self::set_dimensions).
        ///
        /// <p>The dimensions for the metric. For the list of available dimensions, see the Amazon Web Services documentation available from the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html">Amazon Web Services services that publish CloudWatch metrics </a> in the <i>Amazon CloudWatch User Guide</i>. </p> 
        /// <p>Conditional: If you published your metric with dimensions, you must specify the same dimensions in your scaling policy.</p>
        pub fn dimensions(mut self, input: crate::model::MetricDimension) -> Self {
            let mut v = self.dimensions.unwrap_or_default();
                            v.push(input);
                            self.dimensions = Some(v);
                            self
        }
        /// <p>The dimensions for the metric. For the list of available dimensions, see the Amazon Web Services documentation available from the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html">Amazon Web Services services that publish CloudWatch metrics </a> in the <i>Amazon CloudWatch User Guide</i>. </p> 
        /// <p>Conditional: If you published your metric with dimensions, you must specify the same dimensions in your scaling policy.</p>
        pub fn set_dimensions(mut self, input: std::option::Option<std::vec::Vec<crate::model::MetricDimension>>) -> Self {
            self.dimensions = input; self
        }
        /// Consumes the builder and constructs a [`Metric`](crate::model::Metric).
        pub fn build(self) -> crate::model::Metric {
            crate::model::Metric {
                namespace: self.namespace
                ,
                metric_name: self.metric_name
                ,
                dimensions: self.dimensions
                ,
            }
        }
    }
    
    
}
impl Metric {
    /// Creates a new builder-style object to manufacture [`Metric`](crate::model::Metric).
    pub fn builder() -> crate::model::metric::Builder {
        crate::model::metric::Builder::default()
    }
}

/// <p>Describes the dimension of a metric.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct MetricDimension  {
    /// <p>The name of the dimension.</p>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
    /// <p>The value of the dimension.</p>
    #[doc(hidden)]
    pub value: std::option::Option<std::string::String>,
}
impl MetricDimension {
    /// <p>The name of the dimension.</p>
    pub fn name(&self) -> std::option::Option<& str> {
        self.name.as_deref()
    }
    /// <p>The value of the dimension.</p>
    pub fn value(&self) -> std::option::Option<& str> {
        self.value.as_deref()
    }
}
/// See [`MetricDimension`](crate::model::MetricDimension).
pub mod metric_dimension {
    
    /// A builder for [`MetricDimension`](crate::model::MetricDimension).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) name: std::option::Option<std::string::String>,
        pub(crate) value: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the dimension.</p>
        pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
            self.name = Some(input.into());
            self
        }
        /// <p>The name of the dimension.</p>
        pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.name = input; self
        }
        /// <p>The value of the dimension.</p>
        pub fn value(mut self, input: impl Into<std::string::String>) -> Self {
            self.value = Some(input.into());
            self
        }
        /// <p>The value of the dimension.</p>
        pub fn set_value(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.value = input; self
        }
        /// Consumes the builder and constructs a [`MetricDimension`](crate::model::MetricDimension).
        pub fn build(self) -> crate::model::MetricDimension {
            crate::model::MetricDimension {
                name: self.name
                ,
                value: self.value
                ,
            }
        }
    }
    
    
}
impl MetricDimension {
    /// Creates a new builder-style object to manufacture [`MetricDimension`](crate::model::MetricDimension).
    pub fn builder() -> crate::model::metric_dimension::Builder {
        crate::model::metric_dimension::Builder::default()
    }
}

/// <p>Describes a custom load metric for a predictive scaling policy.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct PredictiveScalingCustomizedLoadMetric  {
    /// <p>One or more metric data queries to provide the data points for a load metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
    #[doc(hidden)]
    pub metric_data_queries: std::option::Option<std::vec::Vec<crate::model::MetricDataQuery>>,
}
impl PredictiveScalingCustomizedLoadMetric {
    /// <p>One or more metric data queries to provide the data points for a load metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
    pub fn metric_data_queries(&self) -> std::option::Option<& [crate::model::MetricDataQuery]> {
        self.metric_data_queries.as_deref()
    }
}
/// See [`PredictiveScalingCustomizedLoadMetric`](crate::model::PredictiveScalingCustomizedLoadMetric).
pub mod predictive_scaling_customized_load_metric {
    
    /// A builder for [`PredictiveScalingCustomizedLoadMetric`](crate::model::PredictiveScalingCustomizedLoadMetric).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) metric_data_queries: std::option::Option<std::vec::Vec<crate::model::MetricDataQuery>>,
    }
    impl Builder {
        /// Appends an item to `metric_data_queries`.
        ///
        /// To override the contents of this collection use [`set_metric_data_queries`](Self::set_metric_data_queries).
        ///
        /// <p>One or more metric data queries to provide the data points for a load metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
        pub fn metric_data_queries(mut self, input: crate::model::MetricDataQuery) -> Self {
            let mut v = self.metric_data_queries.unwrap_or_default();
                            v.push(input);
                            self.metric_data_queries = Some(v);
                            self
        }
        /// <p>One or more metric data queries to provide the data points for a load metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
        pub fn set_metric_data_queries(mut self, input: std::option::Option<std::vec::Vec<crate::model::MetricDataQuery>>) -> Self {
            self.metric_data_queries = input; self
        }
        /// Consumes the builder and constructs a [`PredictiveScalingCustomizedLoadMetric`](crate::model::PredictiveScalingCustomizedLoadMetric).
        pub fn build(self) -> crate::model::PredictiveScalingCustomizedLoadMetric {
            crate::model::PredictiveScalingCustomizedLoadMetric {
                metric_data_queries: self.metric_data_queries
                ,
            }
        }
    }
    
    
}
impl PredictiveScalingCustomizedLoadMetric {
    /// Creates a new builder-style object to manufacture [`PredictiveScalingCustomizedLoadMetric`](crate::model::PredictiveScalingCustomizedLoadMetric).
    pub fn builder() -> crate::model::predictive_scaling_customized_load_metric::Builder {
        crate::model::predictive_scaling_customized_load_metric::Builder::default()
    }
}

/// <p>Describes a custom scaling metric for a predictive scaling policy.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct PredictiveScalingCustomizedScalingMetric  {
    /// <p>One or more metric data queries to provide the data points for a scaling metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
    #[doc(hidden)]
    pub metric_data_queries: std::option::Option<std::vec::Vec<crate::model::MetricDataQuery>>,
}
impl PredictiveScalingCustomizedScalingMetric {
    /// <p>One or more metric data queries to provide the data points for a scaling metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
    pub fn metric_data_queries(&self) -> std::option::Option<& [crate::model::MetricDataQuery]> {
        self.metric_data_queries.as_deref()
    }
}
/// See [`PredictiveScalingCustomizedScalingMetric`](crate::model::PredictiveScalingCustomizedScalingMetric).
pub mod predictive_scaling_customized_scaling_metric {
    
    /// A builder for [`PredictiveScalingCustomizedScalingMetric`](crate::model::PredictiveScalingCustomizedScalingMetric).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) metric_data_queries: std::option::Option<std::vec::Vec<crate::model::MetricDataQuery>>,
    }
    impl Builder {
        /// Appends an item to `metric_data_queries`.
        ///
        /// To override the contents of this collection use [`set_metric_data_queries`](Self::set_metric_data_queries).
        ///
        /// <p>One or more metric data queries to provide the data points for a scaling metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
        pub fn metric_data_queries(mut self, input: crate::model::MetricDataQuery) -> Self {
            let mut v = self.metric_data_queries.unwrap_or_default();
                            v.push(input);
                            self.metric_data_queries = Some(v);
                            self
        }
        /// <p>One or more metric data queries to provide the data points for a scaling metric. Use multiple metric data queries only if you are performing a math expression on returned data. </p>
        pub fn set_metric_data_queries(mut self, input: std::option::Option<std::vec::Vec<crate::model::MetricDataQuery>>) -> Self {
            self.metric_data_queries = input; self
        }
        /// Consumes the builder and constructs a [`PredictiveScalingCustomizedScalingMetric`](crate::model::PredictiveScalingCustomizedScalingMetric).
        pub fn build(self) -> crate::model::PredictiveScalingCustomizedScalingMetric {
            crate::model::PredictiveScalingCustomizedScalingMetric {
                metric_data_queries: self.metric_data_queries
                ,
            }
        }
    }
    
    
}
impl PredictiveScalingCustomizedScalingMetric {
    /// Creates a new builder-style object to manufacture [`PredictiveScalingCustomizedScalingMetric`](crate::model::PredictiveScalingCustomizedScalingMetric).
    pub fn builder() -> crate::model::predictive_scaling_customized_scaling_metric::Builder {
        crate::model::predictive_scaling_customized_scaling_metric::Builder::default()
    }
}

/// <p>Describes a load metric for a predictive scaling policy.</p> 
/// <p>When returned in the output of <code>DescribePolicies</code>, it indicates that a predictive scaling policy uses individually specified load and scaling metrics instead of a metric pair.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct PredictiveScalingPredefinedLoadMetric  {
    /// <p>The metric type.</p>
    #[doc(hidden)]
    pub predefined_metric_type: std::option::Option<crate::model::PredefinedLoadMetricType>,
    /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
    /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
    /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
    /// <p>Where:</p> 
    /// <ul> 
    /// <li> <p>app/<load-balancer-name>
    /// /
    /// <load-balancer-id>
    /// is the final portion of the load balancer ARN
    /// </load-balancer-id>
    /// </load-balancer-name></p> </li> 
    /// <li> <p>targetgroup/<target-group-name>
    /// /
    /// <target-group-id>
    /// is the final portion of the target group ARN.
    /// </target-group-id>
    /// </target-group-name></p> </li> 
    /// </ul> 
    /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
    #[doc(hidden)]
    pub resource_label: std::option::Option<std::string::String>,
}
impl PredictiveScalingPredefinedLoadMetric {
    /// <p>The metric type.</p>
    pub fn predefined_metric_type(&self) -> std::option::Option<& crate::model::PredefinedLoadMetricType> {
        self.predefined_metric_type.as_ref()
    }
    /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
    /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
    /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
    /// <p>Where:</p> 
    /// <ul> 
    /// <li> <p>app/<load-balancer-name>
    /// /
    /// <load-balancer-id>
    /// is the final portion of the load balancer ARN
    /// </load-balancer-id>
    /// </load-balancer-name></p> </li> 
    /// <li> <p>targetgroup/<target-group-name>
    /// /
    /// <target-group-id>
    /// is the final portion of the target group ARN.
    /// </target-group-id>
    /// </target-group-name></p> </li> 
    /// </ul> 
    /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
    pub fn resource_label(&self) -> std::option::Option<& str> {
        self.resource_label.as_deref()
    }
}
/// See [`PredictiveScalingPredefinedLoadMetric`](crate::model::PredictiveScalingPredefinedLoadMetric).
pub mod predictive_scaling_predefined_load_metric {
    
    /// A builder for [`PredictiveScalingPredefinedLoadMetric`](crate::model::PredictiveScalingPredefinedLoadMetric).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) predefined_metric_type: std::option::Option<crate::model::PredefinedLoadMetricType>,
        pub(crate) resource_label: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The metric type.</p>
        pub fn predefined_metric_type(mut self, input: crate::model::PredefinedLoadMetricType) -> Self {
            self.predefined_metric_type = Some(input);
            self
        }
        /// <p>The metric type.</p>
        pub fn set_predefined_metric_type(mut self, input: std::option::Option<crate::model::PredefinedLoadMetricType>) -> Self {
            self.predefined_metric_type = input; self
        }
        /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
        /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
        /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
        /// <p>Where:</p> 
        /// <ul> 
        /// <li> <p>app/<load-balancer-name>
        /// /
        /// <load-balancer-id>
        /// is the final portion of the load balancer ARN
        /// </load-balancer-id>
        /// </load-balancer-name></p> </li> 
        /// <li> <p>targetgroup/<target-group-name>
        /// /
        /// <target-group-id>
        /// is the final portion of the target group ARN.
        /// </target-group-id>
        /// </target-group-name></p> </li> 
        /// </ul> 
        /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
        pub fn resource_label(mut self, input: impl Into<std::string::String>) -> Self {
            self.resource_label = Some(input.into());
            self
        }
        /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
        /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
        /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
        /// <p>Where:</p> 
        /// <ul> 
        /// <li> <p>app/<load-balancer-name>
        /// /
        /// <load-balancer-id>
        /// is the final portion of the load balancer ARN
        /// </load-balancer-id>
        /// </load-balancer-name></p> </li> 
        /// <li> <p>targetgroup/<target-group-name>
        /// /
        /// <target-group-id>
        /// is the final portion of the target group ARN.
        /// </target-group-id>
        /// </target-group-name></p> </li> 
        /// </ul> 
        /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
        pub fn set_resource_label(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.resource_label = input; self
        }
        /// Consumes the builder and constructs a [`PredictiveScalingPredefinedLoadMetric`](crate::model::PredictiveScalingPredefinedLoadMetric).
        pub fn build(self) -> crate::model::PredictiveScalingPredefinedLoadMetric {
            crate::model::PredictiveScalingPredefinedLoadMetric {
                predefined_metric_type: self.predefined_metric_type
                ,
                resource_label: self.resource_label
                ,
            }
        }
    }
    
    
}
impl PredictiveScalingPredefinedLoadMetric {
    /// Creates a new builder-style object to manufacture [`PredictiveScalingPredefinedLoadMetric`](crate::model::PredictiveScalingPredefinedLoadMetric).
    pub fn builder() -> crate::model::predictive_scaling_predefined_load_metric::Builder {
        crate::model::predictive_scaling_predefined_load_metric::Builder::default()
    }
}

/// When writing a match expression against `PredefinedLoadMetricType`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let predefinedloadmetrictype = unimplemented!();
/// match predefinedloadmetrictype {
///     PredefinedLoadMetricType::AlbTargetGroupRequestCount => { /* ... */ },
///     PredefinedLoadMetricType::AsgTotalCpuUtilization => { /* ... */ },
///     PredefinedLoadMetricType::AsgTotalNetworkIn => { /* ... */ },
///     PredefinedLoadMetricType::AsgTotalNetworkOut => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `predefinedloadmetrictype` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `PredefinedLoadMetricType::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `PredefinedLoadMetricType::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `PredefinedLoadMetricType::NewFeature` is defined.
/// Specifically, when `predefinedloadmetrictype` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `PredefinedLoadMetricType::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum PredefinedLoadMetricType {
    #[allow(missing_docs)] // documentation missing in model
    AlbTargetGroupRequestCount,
    #[allow(missing_docs)] // documentation missing in model
    AsgTotalCpuUtilization,
    #[allow(missing_docs)] // documentation missing in model
    AsgTotalNetworkIn,
    #[allow(missing_docs)] // documentation missing in model
    AsgTotalNetworkOut,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for PredefinedLoadMetricType {
    fn from(s: &str) -> Self {
        match s {
            "ALBTargetGroupRequestCount" => PredefinedLoadMetricType::AlbTargetGroupRequestCount,
            "ASGTotalCPUUtilization" => PredefinedLoadMetricType::AsgTotalCpuUtilization,
            "ASGTotalNetworkIn" => PredefinedLoadMetricType::AsgTotalNetworkIn,
            "ASGTotalNetworkOut" => PredefinedLoadMetricType::AsgTotalNetworkOut,
            other => PredefinedLoadMetricType::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for PredefinedLoadMetricType {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(PredefinedLoadMetricType::from(s))
                }
            }
impl PredefinedLoadMetricType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            PredefinedLoadMetricType::AlbTargetGroupRequestCount => "ALBTargetGroupRequestCount",
            PredefinedLoadMetricType::AsgTotalCpuUtilization => "ASGTotalCPUUtilization",
            PredefinedLoadMetricType::AsgTotalNetworkIn => "ASGTotalNetworkIn",
            PredefinedLoadMetricType::AsgTotalNetworkOut => "ASGTotalNetworkOut",
            PredefinedLoadMetricType::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "ALBTargetGroupRequestCount", "ASGTotalCPUUtilization", "ASGTotalNetworkIn", "ASGTotalNetworkOut"
        ]
    }
}
impl AsRef<str> for PredefinedLoadMetricType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Describes a scaling metric for a predictive scaling policy.</p> 
/// <p>When returned in the output of <code>DescribePolicies</code>, it indicates that a predictive scaling policy uses individually specified load and scaling metrics instead of a metric pair.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct PredictiveScalingPredefinedScalingMetric  {
    /// <p>The metric type.</p>
    #[doc(hidden)]
    pub predefined_metric_type: std::option::Option<crate::model::PredefinedScalingMetricType>,
    /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
    /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
    /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
    /// <p>Where:</p> 
    /// <ul> 
    /// <li> <p>app/<load-balancer-name>
    /// /
    /// <load-balancer-id>
    /// is the final portion of the load balancer ARN
    /// </load-balancer-id>
    /// </load-balancer-name></p> </li> 
    /// <li> <p>targetgroup/<target-group-name>
    /// /
    /// <target-group-id>
    /// is the final portion of the target group ARN.
    /// </target-group-id>
    /// </target-group-name></p> </li> 
    /// </ul> 
    /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
    #[doc(hidden)]
    pub resource_label: std::option::Option<std::string::String>,
}
impl PredictiveScalingPredefinedScalingMetric {
    /// <p>The metric type.</p>
    pub fn predefined_metric_type(&self) -> std::option::Option<& crate::model::PredefinedScalingMetricType> {
        self.predefined_metric_type.as_ref()
    }
    /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
    /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
    /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
    /// <p>Where:</p> 
    /// <ul> 
    /// <li> <p>app/<load-balancer-name>
    /// /
    /// <load-balancer-id>
    /// is the final portion of the load balancer ARN
    /// </load-balancer-id>
    /// </load-balancer-name></p> </li> 
    /// <li> <p>targetgroup/<target-group-name>
    /// /
    /// <target-group-id>
    /// is the final portion of the target group ARN.
    /// </target-group-id>
    /// </target-group-name></p> </li> 
    /// </ul> 
    /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
    pub fn resource_label(&self) -> std::option::Option<& str> {
        self.resource_label.as_deref()
    }
}
/// See [`PredictiveScalingPredefinedScalingMetric`](crate::model::PredictiveScalingPredefinedScalingMetric).
pub mod predictive_scaling_predefined_scaling_metric {
    
    /// A builder for [`PredictiveScalingPredefinedScalingMetric`](crate::model::PredictiveScalingPredefinedScalingMetric).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) predefined_metric_type: std::option::Option<crate::model::PredefinedScalingMetricType>,
        pub(crate) resource_label: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The metric type.</p>
        pub fn predefined_metric_type(mut self, input: crate::model::PredefinedScalingMetricType) -> Self {
            self.predefined_metric_type = Some(input);
            self
        }
        /// <p>The metric type.</p>
        pub fn set_predefined_metric_type(mut self, input: std::option::Option<crate::model::PredefinedScalingMetricType>) -> Self {
            self.predefined_metric_type = input; self
        }
        /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
        /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
        /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
        /// <p>Where:</p> 
        /// <ul> 
        /// <li> <p>app/<load-balancer-name>
        /// /
        /// <load-balancer-id>
        /// is the final portion of the load balancer ARN
        /// </load-balancer-id>
        /// </load-balancer-name></p> </li> 
        /// <li> <p>targetgroup/<target-group-name>
        /// /
        /// <target-group-id>
        /// is the final portion of the target group ARN.
        /// </target-group-id>
        /// </target-group-name></p> </li> 
        /// </ul> 
        /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
        pub fn resource_label(mut self, input: impl Into<std::string::String>) -> Self {
            self.resource_label = Some(input.into());
            self
        }
        /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
        /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
        /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
        /// <p>Where:</p> 
        /// <ul> 
        /// <li> <p>app/<load-balancer-name>
        /// /
        /// <load-balancer-id>
        /// is the final portion of the load balancer ARN
        /// </load-balancer-id>
        /// </load-balancer-name></p> </li> 
        /// <li> <p>targetgroup/<target-group-name>
        /// /
        /// <target-group-id>
        /// is the final portion of the target group ARN.
        /// </target-group-id>
        /// </target-group-name></p> </li> 
        /// </ul> 
        /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
        pub fn set_resource_label(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.resource_label = input; self
        }
        /// Consumes the builder and constructs a [`PredictiveScalingPredefinedScalingMetric`](crate::model::PredictiveScalingPredefinedScalingMetric).
        pub fn build(self) -> crate::model::PredictiveScalingPredefinedScalingMetric {
            crate::model::PredictiveScalingPredefinedScalingMetric {
                predefined_metric_type: self.predefined_metric_type
                ,
                resource_label: self.resource_label
                ,
            }
        }
    }
    
    
}
impl PredictiveScalingPredefinedScalingMetric {
    /// Creates a new builder-style object to manufacture [`PredictiveScalingPredefinedScalingMetric`](crate::model::PredictiveScalingPredefinedScalingMetric).
    pub fn builder() -> crate::model::predictive_scaling_predefined_scaling_metric::Builder {
        crate::model::predictive_scaling_predefined_scaling_metric::Builder::default()
    }
}

/// When writing a match expression against `PredefinedScalingMetricType`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let predefinedscalingmetrictype = unimplemented!();
/// match predefinedscalingmetrictype {
///     PredefinedScalingMetricType::AlbRequestCountPerTarget => { /* ... */ },
///     PredefinedScalingMetricType::AsgAverageCpuUtilization => { /* ... */ },
///     PredefinedScalingMetricType::AsgAverageNetworkIn => { /* ... */ },
///     PredefinedScalingMetricType::AsgAverageNetworkOut => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `predefinedscalingmetrictype` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `PredefinedScalingMetricType::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `PredefinedScalingMetricType::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `PredefinedScalingMetricType::NewFeature` is defined.
/// Specifically, when `predefinedscalingmetrictype` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `PredefinedScalingMetricType::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum PredefinedScalingMetricType {
    #[allow(missing_docs)] // documentation missing in model
    AlbRequestCountPerTarget,
    #[allow(missing_docs)] // documentation missing in model
    AsgAverageCpuUtilization,
    #[allow(missing_docs)] // documentation missing in model
    AsgAverageNetworkIn,
    #[allow(missing_docs)] // documentation missing in model
    AsgAverageNetworkOut,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for PredefinedScalingMetricType {
    fn from(s: &str) -> Self {
        match s {
            "ALBRequestCountPerTarget" => PredefinedScalingMetricType::AlbRequestCountPerTarget,
            "ASGAverageCPUUtilization" => PredefinedScalingMetricType::AsgAverageCpuUtilization,
            "ASGAverageNetworkIn" => PredefinedScalingMetricType::AsgAverageNetworkIn,
            "ASGAverageNetworkOut" => PredefinedScalingMetricType::AsgAverageNetworkOut,
            other => PredefinedScalingMetricType::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for PredefinedScalingMetricType {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(PredefinedScalingMetricType::from(s))
                }
            }
impl PredefinedScalingMetricType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            PredefinedScalingMetricType::AlbRequestCountPerTarget => "ALBRequestCountPerTarget",
            PredefinedScalingMetricType::AsgAverageCpuUtilization => "ASGAverageCPUUtilization",
            PredefinedScalingMetricType::AsgAverageNetworkIn => "ASGAverageNetworkIn",
            PredefinedScalingMetricType::AsgAverageNetworkOut => "ASGAverageNetworkOut",
            PredefinedScalingMetricType::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "ALBRequestCountPerTarget", "ASGAverageCPUUtilization", "ASGAverageNetworkIn", "ASGAverageNetworkOut"
        ]
    }
}
impl AsRef<str> for PredefinedScalingMetricType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Represents a metric pair for a predictive scaling policy. </p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct PredictiveScalingPredefinedMetricPair  {
    /// <p>Indicates which metrics to use. There are two different types of metrics for each metric type: one is a load metric and one is a scaling metric. For example, if the metric type is <code>ASGCPUUtilization</code>, the Auto Scaling group's total CPU metric is used as the load metric, and the average CPU metric is used for the scaling metric.</p>
    #[doc(hidden)]
    pub predefined_metric_type: std::option::Option<crate::model::PredefinedMetricPairType>,
    /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the total and average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
    /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
    /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
    /// <p>Where:</p> 
    /// <ul> 
    /// <li> <p>app/<load-balancer-name>
    /// /
    /// <load-balancer-id>
    /// is the final portion of the load balancer ARN
    /// </load-balancer-id>
    /// </load-balancer-name></p> </li> 
    /// <li> <p>targetgroup/<target-group-name>
    /// /
    /// <target-group-id>
    /// is the final portion of the target group ARN.
    /// </target-group-id>
    /// </target-group-name></p> </li> 
    /// </ul> 
    /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
    #[doc(hidden)]
    pub resource_label: std::option::Option<std::string::String>,
}
impl PredictiveScalingPredefinedMetricPair {
    /// <p>Indicates which metrics to use. There are two different types of metrics for each metric type: one is a load metric and one is a scaling metric. For example, if the metric type is <code>ASGCPUUtilization</code>, the Auto Scaling group's total CPU metric is used as the load metric, and the average CPU metric is used for the scaling metric.</p>
    pub fn predefined_metric_type(&self) -> std::option::Option<& crate::model::PredefinedMetricPairType> {
        self.predefined_metric_type.as_ref()
    }
    /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the total and average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
    /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
    /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
    /// <p>Where:</p> 
    /// <ul> 
    /// <li> <p>app/<load-balancer-name>
    /// /
    /// <load-balancer-id>
    /// is the final portion of the load balancer ARN
    /// </load-balancer-id>
    /// </load-balancer-name></p> </li> 
    /// <li> <p>targetgroup/<target-group-name>
    /// /
    /// <target-group-id>
    /// is the final portion of the target group ARN.
    /// </target-group-id>
    /// </target-group-name></p> </li> 
    /// </ul> 
    /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
    pub fn resource_label(&self) -> std::option::Option<& str> {
        self.resource_label.as_deref()
    }
}
/// See [`PredictiveScalingPredefinedMetricPair`](crate::model::PredictiveScalingPredefinedMetricPair).
pub mod predictive_scaling_predefined_metric_pair {
    
    /// A builder for [`PredictiveScalingPredefinedMetricPair`](crate::model::PredictiveScalingPredefinedMetricPair).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) predefined_metric_type: std::option::Option<crate::model::PredefinedMetricPairType>,
        pub(crate) resource_label: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>Indicates which metrics to use. There are two different types of metrics for each metric type: one is a load metric and one is a scaling metric. For example, if the metric type is <code>ASGCPUUtilization</code>, the Auto Scaling group's total CPU metric is used as the load metric, and the average CPU metric is used for the scaling metric.</p>
        pub fn predefined_metric_type(mut self, input: crate::model::PredefinedMetricPairType) -> Self {
            self.predefined_metric_type = Some(input);
            self
        }
        /// <p>Indicates which metrics to use. There are two different types of metrics for each metric type: one is a load metric and one is a scaling metric. For example, if the metric type is <code>ASGCPUUtilization</code>, the Auto Scaling group's total CPU metric is used as the load metric, and the average CPU metric is used for the scaling metric.</p>
        pub fn set_predefined_metric_type(mut self, input: std::option::Option<crate::model::PredefinedMetricPairType>) -> Self {
            self.predefined_metric_type = input; self
        }
        /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the total and average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
        /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
        /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
        /// <p>Where:</p> 
        /// <ul> 
        /// <li> <p>app/<load-balancer-name>
        /// /
        /// <load-balancer-id>
        /// is the final portion of the load balancer ARN
        /// </load-balancer-id>
        /// </load-balancer-name></p> </li> 
        /// <li> <p>targetgroup/<target-group-name>
        /// /
        /// <target-group-id>
        /// is the final portion of the target group ARN.
        /// </target-group-id>
        /// </target-group-name></p> </li> 
        /// </ul> 
        /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
        pub fn resource_label(mut self, input: impl Into<std::string::String>) -> Self {
            self.resource_label = Some(input.into());
            self
        }
        /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the total and average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
        /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
        /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
        /// <p>Where:</p> 
        /// <ul> 
        /// <li> <p>app/<load-balancer-name>
        /// /
        /// <load-balancer-id>
        /// is the final portion of the load balancer ARN
        /// </load-balancer-id>
        /// </load-balancer-name></p> </li> 
        /// <li> <p>targetgroup/<target-group-name>
        /// /
        /// <target-group-id>
        /// is the final portion of the target group ARN.
        /// </target-group-id>
        /// </target-group-name></p> </li> 
        /// </ul> 
        /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
        pub fn set_resource_label(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.resource_label = input; self
        }
        /// Consumes the builder and constructs a [`PredictiveScalingPredefinedMetricPair`](crate::model::PredictiveScalingPredefinedMetricPair).
        pub fn build(self) -> crate::model::PredictiveScalingPredefinedMetricPair {
            crate::model::PredictiveScalingPredefinedMetricPair {
                predefined_metric_type: self.predefined_metric_type
                ,
                resource_label: self.resource_label
                ,
            }
        }
    }
    
    
}
impl PredictiveScalingPredefinedMetricPair {
    /// Creates a new builder-style object to manufacture [`PredictiveScalingPredefinedMetricPair`](crate::model::PredictiveScalingPredefinedMetricPair).
    pub fn builder() -> crate::model::predictive_scaling_predefined_metric_pair::Builder {
        crate::model::predictive_scaling_predefined_metric_pair::Builder::default()
    }
}

/// When writing a match expression against `PredefinedMetricPairType`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let predefinedmetricpairtype = unimplemented!();
/// match predefinedmetricpairtype {
///     PredefinedMetricPairType::AlbRequestCount => { /* ... */ },
///     PredefinedMetricPairType::AsgcpuUtilization => { /* ... */ },
///     PredefinedMetricPairType::AsgNetworkIn => { /* ... */ },
///     PredefinedMetricPairType::AsgNetworkOut => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `predefinedmetricpairtype` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `PredefinedMetricPairType::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `PredefinedMetricPairType::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `PredefinedMetricPairType::NewFeature` is defined.
/// Specifically, when `predefinedmetricpairtype` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `PredefinedMetricPairType::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum PredefinedMetricPairType {
    #[allow(missing_docs)] // documentation missing in model
    AlbRequestCount,
    #[allow(missing_docs)] // documentation missing in model
    AsgcpuUtilization,
    #[allow(missing_docs)] // documentation missing in model
    AsgNetworkIn,
    #[allow(missing_docs)] // documentation missing in model
    AsgNetworkOut,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for PredefinedMetricPairType {
    fn from(s: &str) -> Self {
        match s {
            "ALBRequestCount" => PredefinedMetricPairType::AlbRequestCount,
            "ASGCPUUtilization" => PredefinedMetricPairType::AsgcpuUtilization,
            "ASGNetworkIn" => PredefinedMetricPairType::AsgNetworkIn,
            "ASGNetworkOut" => PredefinedMetricPairType::AsgNetworkOut,
            other => PredefinedMetricPairType::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for PredefinedMetricPairType {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(PredefinedMetricPairType::from(s))
                }
            }
impl PredefinedMetricPairType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            PredefinedMetricPairType::AlbRequestCount => "ALBRequestCount",
            PredefinedMetricPairType::AsgcpuUtilization => "ASGCPUUtilization",
            PredefinedMetricPairType::AsgNetworkIn => "ASGNetworkIn",
            PredefinedMetricPairType::AsgNetworkOut => "ASGNetworkOut",
            PredefinedMetricPairType::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "ALBRequestCount", "ASGCPUUtilization", "ASGNetworkIn", "ASGNetworkOut"
        ]
    }
}
impl AsRef<str> for PredefinedMetricPairType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Represents a target tracking scaling policy configuration to use with Amazon EC2 Auto Scaling.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct TargetTrackingConfiguration  {
    /// <p>A predefined metric. You must specify either a predefined metric or a customized metric.</p>
    #[doc(hidden)]
    pub predefined_metric_specification: std::option::Option<crate::model::PredefinedMetricSpecification>,
    /// <p>A customized metric. You must specify either a predefined metric or a customized metric.</p>
    #[doc(hidden)]
    pub customized_metric_specification: std::option::Option<crate::model::CustomizedMetricSpecification>,
    /// <p>The target value for the metric.</p> <note> 
    /// <p>Some metrics are based on a count instead of a percentage, such as the request count for an Application Load Balancer or the number of messages in an SQS queue. If the scaling policy specifies one of these metrics, specify the target utilization as the optimal average request or message count per instance during any one-minute interval. </p> 
    /// </note>
    #[doc(hidden)]
    pub target_value: std::option::Option<f64>,
    /// <p>Indicates whether scaling in by the target tracking scaling policy is disabled. If scaling in is disabled, the target tracking scaling policy doesn't remove instances from the Auto Scaling group. Otherwise, the target tracking scaling policy can remove instances from the Auto Scaling group. The default is <code>false</code>.</p>
    #[doc(hidden)]
    pub disable_scale_in: std::option::Option<bool>,
}
impl TargetTrackingConfiguration {
    /// <p>A predefined metric. You must specify either a predefined metric or a customized metric.</p>
    pub fn predefined_metric_specification(&self) -> std::option::Option<& crate::model::PredefinedMetricSpecification> {
        self.predefined_metric_specification.as_ref()
    }
    /// <p>A customized metric. You must specify either a predefined metric or a customized metric.</p>
    pub fn customized_metric_specification(&self) -> std::option::Option<& crate::model::CustomizedMetricSpecification> {
        self.customized_metric_specification.as_ref()
    }
    /// <p>The target value for the metric.</p> <note> 
    /// <p>Some metrics are based on a count instead of a percentage, such as the request count for an Application Load Balancer or the number of messages in an SQS queue. If the scaling policy specifies one of these metrics, specify the target utilization as the optimal average request or message count per instance during any one-minute interval. </p> 
    /// </note>
    pub fn target_value(&self) -> std::option::Option<f64> {
        self.target_value
    }
    /// <p>Indicates whether scaling in by the target tracking scaling policy is disabled. If scaling in is disabled, the target tracking scaling policy doesn't remove instances from the Auto Scaling group. Otherwise, the target tracking scaling policy can remove instances from the Auto Scaling group. The default is <code>false</code>.</p>
    pub fn disable_scale_in(&self) -> std::option::Option<bool> {
        self.disable_scale_in
    }
}
/// See [`TargetTrackingConfiguration`](crate::model::TargetTrackingConfiguration).
pub mod target_tracking_configuration {
    
    /// A builder for [`TargetTrackingConfiguration`](crate::model::TargetTrackingConfiguration).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) predefined_metric_specification: std::option::Option<crate::model::PredefinedMetricSpecification>,
        pub(crate) customized_metric_specification: std::option::Option<crate::model::CustomizedMetricSpecification>,
        pub(crate) target_value: std::option::Option<f64>,
        pub(crate) disable_scale_in: std::option::Option<bool>,
    }
    impl Builder {
        /// <p>A predefined metric. You must specify either a predefined metric or a customized metric.</p>
        pub fn predefined_metric_specification(mut self, input: crate::model::PredefinedMetricSpecification) -> Self {
            self.predefined_metric_specification = Some(input);
            self
        }
        /// <p>A predefined metric. You must specify either a predefined metric or a customized metric.</p>
        pub fn set_predefined_metric_specification(mut self, input: std::option::Option<crate::model::PredefinedMetricSpecification>) -> Self {
            self.predefined_metric_specification = input; self
        }
        /// <p>A customized metric. You must specify either a predefined metric or a customized metric.</p>
        pub fn customized_metric_specification(mut self, input: crate::model::CustomizedMetricSpecification) -> Self {
            self.customized_metric_specification = Some(input);
            self
        }
        /// <p>A customized metric. You must specify either a predefined metric or a customized metric.</p>
        pub fn set_customized_metric_specification(mut self, input: std::option::Option<crate::model::CustomizedMetricSpecification>) -> Self {
            self.customized_metric_specification = input; self
        }
        /// <p>The target value for the metric.</p> <note> 
        /// <p>Some metrics are based on a count instead of a percentage, such as the request count for an Application Load Balancer or the number of messages in an SQS queue. If the scaling policy specifies one of these metrics, specify the target utilization as the optimal average request or message count per instance during any one-minute interval. </p> 
        /// </note>
        pub fn target_value(mut self, input: f64) -> Self {
            self.target_value = Some(input);
            self
        }
        /// <p>The target value for the metric.</p> <note> 
        /// <p>Some metrics are based on a count instead of a percentage, such as the request count for an Application Load Balancer or the number of messages in an SQS queue. If the scaling policy specifies one of these metrics, specify the target utilization as the optimal average request or message count per instance during any one-minute interval. </p> 
        /// </note>
        pub fn set_target_value(mut self, input: std::option::Option<f64>) -> Self {
            self.target_value = input; self
        }
        /// <p>Indicates whether scaling in by the target tracking scaling policy is disabled. If scaling in is disabled, the target tracking scaling policy doesn't remove instances from the Auto Scaling group. Otherwise, the target tracking scaling policy can remove instances from the Auto Scaling group. The default is <code>false</code>.</p>
        pub fn disable_scale_in(mut self, input: bool) -> Self {
            self.disable_scale_in = Some(input);
            self
        }
        /// <p>Indicates whether scaling in by the target tracking scaling policy is disabled. If scaling in is disabled, the target tracking scaling policy doesn't remove instances from the Auto Scaling group. Otherwise, the target tracking scaling policy can remove instances from the Auto Scaling group. The default is <code>false</code>.</p>
        pub fn set_disable_scale_in(mut self, input: std::option::Option<bool>) -> Self {
            self.disable_scale_in = input; self
        }
        /// Consumes the builder and constructs a [`TargetTrackingConfiguration`](crate::model::TargetTrackingConfiguration).
        pub fn build(self) -> crate::model::TargetTrackingConfiguration {
            crate::model::TargetTrackingConfiguration {
                predefined_metric_specification: self.predefined_metric_specification
                ,
                customized_metric_specification: self.customized_metric_specification
                ,
                target_value: self.target_value
                ,
                disable_scale_in: self.disable_scale_in
                ,
            }
        }
    }
    
    
}
impl TargetTrackingConfiguration {
    /// Creates a new builder-style object to manufacture [`TargetTrackingConfiguration`](crate::model::TargetTrackingConfiguration).
    pub fn builder() -> crate::model::target_tracking_configuration::Builder {
        crate::model::target_tracking_configuration::Builder::default()
    }
}

/// <p>Represents a CloudWatch metric of your choosing for a target tracking scaling policy to use with Amazon EC2 Auto Scaling.</p> 
/// <p>To create your customized metric specification:</p> 
/// <ul> 
/// <li> <p>Add values for each required property from CloudWatch. You can use an existing metric, or a new metric that you create. To use your own metric, you must first publish the metric to CloudWatch. For more information, see <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html">Publish custom metrics</a> in the <i>Amazon CloudWatch User Guide</i>.</p> </li> 
/// <li> <p>Choose a metric that changes proportionally with capacity. The value of the metric should increase or decrease in inverse proportion to the number of capacity units. That is, the value of the metric should decrease when capacity increases.</p> </li> 
/// </ul> 
/// <p>For more information about the CloudWatch terminology below, see <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html">Amazon CloudWatch concepts</a>.</p> <note> 
/// <p>Each individual service provides information about the metrics, namespace, and dimensions they use. For more information, see <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html">Amazon Web Services services that publish CloudWatch metrics</a> in the <i>Amazon CloudWatch User Guide</i>.</p> 
/// </note>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CustomizedMetricSpecification  {
    /// <p>The name of the metric. To get the exact metric name, namespace, and dimensions, inspect the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Metric.html">Metric</a> object that is returned by a call to <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html">ListMetrics</a>.</p>
    #[doc(hidden)]
    pub metric_name: std::option::Option<std::string::String>,
    /// <p>The namespace of the metric.</p>
    #[doc(hidden)]
    pub namespace: std::option::Option<std::string::String>,
    /// <p>The dimensions of the metric.</p> 
    /// <p>Conditional: If you published your metric with dimensions, you must specify the same dimensions in your scaling policy.</p>
    #[doc(hidden)]
    pub dimensions: std::option::Option<std::vec::Vec<crate::model::MetricDimension>>,
    /// <p>The statistic of the metric.</p>
    #[doc(hidden)]
    pub statistic: std::option::Option<crate::model::MetricStatistic>,
    /// <p>The unit of the metric. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
    #[doc(hidden)]
    pub unit: std::option::Option<std::string::String>,
    /// <p>The metrics to include in the target tracking scaling policy, as a metric data query. This can include both raw metric and metric math expressions.</p>
    #[doc(hidden)]
    pub metrics: std::option::Option<std::vec::Vec<crate::model::TargetTrackingMetricDataQuery>>,
}
impl CustomizedMetricSpecification {
    /// <p>The name of the metric. To get the exact metric name, namespace, and dimensions, inspect the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Metric.html">Metric</a> object that is returned by a call to <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html">ListMetrics</a>.</p>
    pub fn metric_name(&self) -> std::option::Option<& str> {
        self.metric_name.as_deref()
    }
    /// <p>The namespace of the metric.</p>
    pub fn namespace(&self) -> std::option::Option<& str> {
        self.namespace.as_deref()
    }
    /// <p>The dimensions of the metric.</p> 
    /// <p>Conditional: If you published your metric with dimensions, you must specify the same dimensions in your scaling policy.</p>
    pub fn dimensions(&self) -> std::option::Option<& [crate::model::MetricDimension]> {
        self.dimensions.as_deref()
    }
    /// <p>The statistic of the metric.</p>
    pub fn statistic(&self) -> std::option::Option<& crate::model::MetricStatistic> {
        self.statistic.as_ref()
    }
    /// <p>The unit of the metric. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
    pub fn unit(&self) -> std::option::Option<& str> {
        self.unit.as_deref()
    }
    /// <p>The metrics to include in the target tracking scaling policy, as a metric data query. This can include both raw metric and metric math expressions.</p>
    pub fn metrics(&self) -> std::option::Option<& [crate::model::TargetTrackingMetricDataQuery]> {
        self.metrics.as_deref()
    }
}
/// See [`CustomizedMetricSpecification`](crate::model::CustomizedMetricSpecification).
pub mod customized_metric_specification {
    
    /// A builder for [`CustomizedMetricSpecification`](crate::model::CustomizedMetricSpecification).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) metric_name: std::option::Option<std::string::String>,
        pub(crate) namespace: std::option::Option<std::string::String>,
        pub(crate) dimensions: std::option::Option<std::vec::Vec<crate::model::MetricDimension>>,
        pub(crate) statistic: std::option::Option<crate::model::MetricStatistic>,
        pub(crate) unit: std::option::Option<std::string::String>,
        pub(crate) metrics: std::option::Option<std::vec::Vec<crate::model::TargetTrackingMetricDataQuery>>,
    }
    impl Builder {
        /// <p>The name of the metric. To get the exact metric name, namespace, and dimensions, inspect the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Metric.html">Metric</a> object that is returned by a call to <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html">ListMetrics</a>.</p>
        pub fn metric_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.metric_name = Some(input.into());
            self
        }
        /// <p>The name of the metric. To get the exact metric name, namespace, and dimensions, inspect the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Metric.html">Metric</a> object that is returned by a call to <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html">ListMetrics</a>.</p>
        pub fn set_metric_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.metric_name = input; self
        }
        /// <p>The namespace of the metric.</p>
        pub fn namespace(mut self, input: impl Into<std::string::String>) -> Self {
            self.namespace = Some(input.into());
            self
        }
        /// <p>The namespace of the metric.</p>
        pub fn set_namespace(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.namespace = input; self
        }
        /// Appends an item to `dimensions`.
        ///
        /// To override the contents of this collection use [`set_dimensions`](Self::set_dimensions).
        ///
        /// <p>The dimensions of the metric.</p> 
        /// <p>Conditional: If you published your metric with dimensions, you must specify the same dimensions in your scaling policy.</p>
        pub fn dimensions(mut self, input: crate::model::MetricDimension) -> Self {
            let mut v = self.dimensions.unwrap_or_default();
                            v.push(input);
                            self.dimensions = Some(v);
                            self
        }
        /// <p>The dimensions of the metric.</p> 
        /// <p>Conditional: If you published your metric with dimensions, you must specify the same dimensions in your scaling policy.</p>
        pub fn set_dimensions(mut self, input: std::option::Option<std::vec::Vec<crate::model::MetricDimension>>) -> Self {
            self.dimensions = input; self
        }
        /// <p>The statistic of the metric.</p>
        pub fn statistic(mut self, input: crate::model::MetricStatistic) -> Self {
            self.statistic = Some(input);
            self
        }
        /// <p>The statistic of the metric.</p>
        pub fn set_statistic(mut self, input: std::option::Option<crate::model::MetricStatistic>) -> Self {
            self.statistic = input; self
        }
        /// <p>The unit of the metric. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
        pub fn unit(mut self, input: impl Into<std::string::String>) -> Self {
            self.unit = Some(input.into());
            self
        }
        /// <p>The unit of the metric. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
        pub fn set_unit(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.unit = input; self
        }
        /// Appends an item to `metrics`.
        ///
        /// To override the contents of this collection use [`set_metrics`](Self::set_metrics).
        ///
        /// <p>The metrics to include in the target tracking scaling policy, as a metric data query. This can include both raw metric and metric math expressions.</p>
        pub fn metrics(mut self, input: crate::model::TargetTrackingMetricDataQuery) -> Self {
            let mut v = self.metrics.unwrap_or_default();
                            v.push(input);
                            self.metrics = Some(v);
                            self
        }
        /// <p>The metrics to include in the target tracking scaling policy, as a metric data query. This can include both raw metric and metric math expressions.</p>
        pub fn set_metrics(mut self, input: std::option::Option<std::vec::Vec<crate::model::TargetTrackingMetricDataQuery>>) -> Self {
            self.metrics = input; self
        }
        /// Consumes the builder and constructs a [`CustomizedMetricSpecification`](crate::model::CustomizedMetricSpecification).
        pub fn build(self) -> crate::model::CustomizedMetricSpecification {
            crate::model::CustomizedMetricSpecification {
                metric_name: self.metric_name
                ,
                namespace: self.namespace
                ,
                dimensions: self.dimensions
                ,
                statistic: self.statistic
                ,
                unit: self.unit
                ,
                metrics: self.metrics
                ,
            }
        }
    }
    
    
}
impl CustomizedMetricSpecification {
    /// Creates a new builder-style object to manufacture [`CustomizedMetricSpecification`](crate::model::CustomizedMetricSpecification).
    pub fn builder() -> crate::model::customized_metric_specification::Builder {
        crate::model::customized_metric_specification::Builder::default()
    }
}

/// <p>The metric data to return. Also defines whether this call is returning data for one metric only, or whether it is performing a math expression on the values of returned metric statistics to create a new time series. A time series is a series of data points, each of which is associated with a timestamp.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct TargetTrackingMetricDataQuery  {
    /// <p>A short name that identifies the object's results in the response. This name must be unique among all <code>TargetTrackingMetricDataQuery</code> objects specified for a single scaling policy. If you are performing math expressions on this set of data, this name represents that data and can serve as a variable in the mathematical expression. The valid characters are letters, numbers, and underscores. The first character must be a lowercase letter. </p>
    #[doc(hidden)]
    pub id: std::option::Option<std::string::String>,
    /// <p>The math expression to perform on the returned data, if this object is performing a math expression. This expression can use the <code>Id</code> of the other metrics to refer to those metrics, and can also use the <code>Id</code> of other expressions to use the result of those expressions. </p> 
    /// <p>Conditional: Within each <code>TargetTrackingMetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
    #[doc(hidden)]
    pub expression: std::option::Option<std::string::String>,
    /// <p>Information about the metric data to return.</p> 
    /// <p>Conditional: Within each <code>TargetTrackingMetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
    #[doc(hidden)]
    pub metric_stat: std::option::Option<crate::model::TargetTrackingMetricStat>,
    /// <p>A human-readable label for this metric or expression. This is especially useful if this is a math expression, so that you know what the value represents.</p>
    #[doc(hidden)]
    pub label: std::option::Option<std::string::String>,
    /// <p>Indicates whether to return the timestamps and raw data values of this metric. </p> 
    /// <p>If you use any math expressions, specify <code>true</code> for this value for only the final math expression that the metric specification is based on. You must specify <code>false</code> for <code>ReturnData</code> for all the other metrics and expressions used in the metric specification.</p> 
    /// <p>If you are only retrieving metrics and not performing any math expressions, do not specify anything for <code>ReturnData</code>. This sets it to its default (<code>true</code>).</p>
    #[doc(hidden)]
    pub return_data: std::option::Option<bool>,
}
impl TargetTrackingMetricDataQuery {
    /// <p>A short name that identifies the object's results in the response. This name must be unique among all <code>TargetTrackingMetricDataQuery</code> objects specified for a single scaling policy. If you are performing math expressions on this set of data, this name represents that data and can serve as a variable in the mathematical expression. The valid characters are letters, numbers, and underscores. The first character must be a lowercase letter. </p>
    pub fn id(&self) -> std::option::Option<& str> {
        self.id.as_deref()
    }
    /// <p>The math expression to perform on the returned data, if this object is performing a math expression. This expression can use the <code>Id</code> of the other metrics to refer to those metrics, and can also use the <code>Id</code> of other expressions to use the result of those expressions. </p> 
    /// <p>Conditional: Within each <code>TargetTrackingMetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
    pub fn expression(&self) -> std::option::Option<& str> {
        self.expression.as_deref()
    }
    /// <p>Information about the metric data to return.</p> 
    /// <p>Conditional: Within each <code>TargetTrackingMetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
    pub fn metric_stat(&self) -> std::option::Option<& crate::model::TargetTrackingMetricStat> {
        self.metric_stat.as_ref()
    }
    /// <p>A human-readable label for this metric or expression. This is especially useful if this is a math expression, so that you know what the value represents.</p>
    pub fn label(&self) -> std::option::Option<& str> {
        self.label.as_deref()
    }
    /// <p>Indicates whether to return the timestamps and raw data values of this metric. </p> 
    /// <p>If you use any math expressions, specify <code>true</code> for this value for only the final math expression that the metric specification is based on. You must specify <code>false</code> for <code>ReturnData</code> for all the other metrics and expressions used in the metric specification.</p> 
    /// <p>If you are only retrieving metrics and not performing any math expressions, do not specify anything for <code>ReturnData</code>. This sets it to its default (<code>true</code>).</p>
    pub fn return_data(&self) -> std::option::Option<bool> {
        self.return_data
    }
}
/// See [`TargetTrackingMetricDataQuery`](crate::model::TargetTrackingMetricDataQuery).
pub mod target_tracking_metric_data_query {
    
    /// A builder for [`TargetTrackingMetricDataQuery`](crate::model::TargetTrackingMetricDataQuery).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) id: std::option::Option<std::string::String>,
        pub(crate) expression: std::option::Option<std::string::String>,
        pub(crate) metric_stat: std::option::Option<crate::model::TargetTrackingMetricStat>,
        pub(crate) label: std::option::Option<std::string::String>,
        pub(crate) return_data: std::option::Option<bool>,
    }
    impl Builder {
        /// <p>A short name that identifies the object's results in the response. This name must be unique among all <code>TargetTrackingMetricDataQuery</code> objects specified for a single scaling policy. If you are performing math expressions on this set of data, this name represents that data and can serve as a variable in the mathematical expression. The valid characters are letters, numbers, and underscores. The first character must be a lowercase letter. </p>
        pub fn id(mut self, input: impl Into<std::string::String>) -> Self {
            self.id = Some(input.into());
            self
        }
        /// <p>A short name that identifies the object's results in the response. This name must be unique among all <code>TargetTrackingMetricDataQuery</code> objects specified for a single scaling policy. If you are performing math expressions on this set of data, this name represents that data and can serve as a variable in the mathematical expression. The valid characters are letters, numbers, and underscores. The first character must be a lowercase letter. </p>
        pub fn set_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.id = input; self
        }
        /// <p>The math expression to perform on the returned data, if this object is performing a math expression. This expression can use the <code>Id</code> of the other metrics to refer to those metrics, and can also use the <code>Id</code> of other expressions to use the result of those expressions. </p> 
        /// <p>Conditional: Within each <code>TargetTrackingMetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
        pub fn expression(mut self, input: impl Into<std::string::String>) -> Self {
            self.expression = Some(input.into());
            self
        }
        /// <p>The math expression to perform on the returned data, if this object is performing a math expression. This expression can use the <code>Id</code> of the other metrics to refer to those metrics, and can also use the <code>Id</code> of other expressions to use the result of those expressions. </p> 
        /// <p>Conditional: Within each <code>TargetTrackingMetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
        pub fn set_expression(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.expression = input; self
        }
        /// <p>Information about the metric data to return.</p> 
        /// <p>Conditional: Within each <code>TargetTrackingMetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
        pub fn metric_stat(mut self, input: crate::model::TargetTrackingMetricStat) -> Self {
            self.metric_stat = Some(input);
            self
        }
        /// <p>Information about the metric data to return.</p> 
        /// <p>Conditional: Within each <code>TargetTrackingMetricDataQuery</code> object, you must specify either <code>Expression</code> or <code>MetricStat</code>, but not both.</p>
        pub fn set_metric_stat(mut self, input: std::option::Option<crate::model::TargetTrackingMetricStat>) -> Self {
            self.metric_stat = input; self
        }
        /// <p>A human-readable label for this metric or expression. This is especially useful if this is a math expression, so that you know what the value represents.</p>
        pub fn label(mut self, input: impl Into<std::string::String>) -> Self {
            self.label = Some(input.into());
            self
        }
        /// <p>A human-readable label for this metric or expression. This is especially useful if this is a math expression, so that you know what the value represents.</p>
        pub fn set_label(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.label = input; self
        }
        /// <p>Indicates whether to return the timestamps and raw data values of this metric. </p> 
        /// <p>If you use any math expressions, specify <code>true</code> for this value for only the final math expression that the metric specification is based on. You must specify <code>false</code> for <code>ReturnData</code> for all the other metrics and expressions used in the metric specification.</p> 
        /// <p>If you are only retrieving metrics and not performing any math expressions, do not specify anything for <code>ReturnData</code>. This sets it to its default (<code>true</code>).</p>
        pub fn return_data(mut self, input: bool) -> Self {
            self.return_data = Some(input);
            self
        }
        /// <p>Indicates whether to return the timestamps and raw data values of this metric. </p> 
        /// <p>If you use any math expressions, specify <code>true</code> for this value for only the final math expression that the metric specification is based on. You must specify <code>false</code> for <code>ReturnData</code> for all the other metrics and expressions used in the metric specification.</p> 
        /// <p>If you are only retrieving metrics and not performing any math expressions, do not specify anything for <code>ReturnData</code>. This sets it to its default (<code>true</code>).</p>
        pub fn set_return_data(mut self, input: std::option::Option<bool>) -> Self {
            self.return_data = input; self
        }
        /// Consumes the builder and constructs a [`TargetTrackingMetricDataQuery`](crate::model::TargetTrackingMetricDataQuery).
        pub fn build(self) -> crate::model::TargetTrackingMetricDataQuery {
            crate::model::TargetTrackingMetricDataQuery {
                id: self.id
                ,
                expression: self.expression
                ,
                metric_stat: self.metric_stat
                ,
                label: self.label
                ,
                return_data: self.return_data
                ,
            }
        }
    }
    
    
}
impl TargetTrackingMetricDataQuery {
    /// Creates a new builder-style object to manufacture [`TargetTrackingMetricDataQuery`](crate::model::TargetTrackingMetricDataQuery).
    pub fn builder() -> crate::model::target_tracking_metric_data_query::Builder {
        crate::model::target_tracking_metric_data_query::Builder::default()
    }
}

/// <p>This structure defines the CloudWatch metric to return, along with the statistic, period, and unit.</p> 
/// <p>For more information about the CloudWatch terminology below, see <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html">Amazon CloudWatch concepts</a> in the <i>Amazon CloudWatch User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct TargetTrackingMetricStat  {
    /// <p>Represents a specific metric. </p>
    #[doc(hidden)]
    pub metric: std::option::Option<crate::model::Metric>,
    /// <p>The statistic to return. It can include any CloudWatch statistic or extended statistic. For a list of valid values, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Statistic">Statistics</a> in the <i>Amazon CloudWatch User Guide</i>.</p> 
    /// <p>The most commonly used metrics for scaling is <code>Average</code> </p>
    #[doc(hidden)]
    pub stat: std::option::Option<std::string::String>,
    /// <p>The unit to use for the returned data points. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
    #[doc(hidden)]
    pub unit: std::option::Option<std::string::String>,
}
impl TargetTrackingMetricStat {
    /// <p>Represents a specific metric. </p>
    pub fn metric(&self) -> std::option::Option<& crate::model::Metric> {
        self.metric.as_ref()
    }
    /// <p>The statistic to return. It can include any CloudWatch statistic or extended statistic. For a list of valid values, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Statistic">Statistics</a> in the <i>Amazon CloudWatch User Guide</i>.</p> 
    /// <p>The most commonly used metrics for scaling is <code>Average</code> </p>
    pub fn stat(&self) -> std::option::Option<& str> {
        self.stat.as_deref()
    }
    /// <p>The unit to use for the returned data points. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
    pub fn unit(&self) -> std::option::Option<& str> {
        self.unit.as_deref()
    }
}
/// See [`TargetTrackingMetricStat`](crate::model::TargetTrackingMetricStat).
pub mod target_tracking_metric_stat {
    
    /// A builder for [`TargetTrackingMetricStat`](crate::model::TargetTrackingMetricStat).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) metric: std::option::Option<crate::model::Metric>,
        pub(crate) stat: std::option::Option<std::string::String>,
        pub(crate) unit: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>Represents a specific metric. </p>
        pub fn metric(mut self, input: crate::model::Metric) -> Self {
            self.metric = Some(input);
            self
        }
        /// <p>Represents a specific metric. </p>
        pub fn set_metric(mut self, input: std::option::Option<crate::model::Metric>) -> Self {
            self.metric = input; self
        }
        /// <p>The statistic to return. It can include any CloudWatch statistic or extended statistic. For a list of valid values, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Statistic">Statistics</a> in the <i>Amazon CloudWatch User Guide</i>.</p> 
        /// <p>The most commonly used metrics for scaling is <code>Average</code> </p>
        pub fn stat(mut self, input: impl Into<std::string::String>) -> Self {
            self.stat = Some(input.into());
            self
        }
        /// <p>The statistic to return. It can include any CloudWatch statistic or extended statistic. For a list of valid values, see the table in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Statistic">Statistics</a> in the <i>Amazon CloudWatch User Guide</i>.</p> 
        /// <p>The most commonly used metrics for scaling is <code>Average</code> </p>
        pub fn set_stat(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.stat = input; self
        }
        /// <p>The unit to use for the returned data points. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
        pub fn unit(mut self, input: impl Into<std::string::String>) -> Self {
            self.unit = Some(input.into());
            self
        }
        /// <p>The unit to use for the returned data points. For a complete list of the units that CloudWatch supports, see the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html">MetricDatum</a> data type in the <i>Amazon CloudWatch API Reference</i>.</p>
        pub fn set_unit(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.unit = input; self
        }
        /// Consumes the builder and constructs a [`TargetTrackingMetricStat`](crate::model::TargetTrackingMetricStat).
        pub fn build(self) -> crate::model::TargetTrackingMetricStat {
            crate::model::TargetTrackingMetricStat {
                metric: self.metric
                ,
                stat: self.stat
                ,
                unit: self.unit
                ,
            }
        }
    }
    
    
}
impl TargetTrackingMetricStat {
    /// Creates a new builder-style object to manufacture [`TargetTrackingMetricStat`](crate::model::TargetTrackingMetricStat).
    pub fn builder() -> crate::model::target_tracking_metric_stat::Builder {
        crate::model::target_tracking_metric_stat::Builder::default()
    }
}

/// When writing a match expression against `MetricStatistic`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let metricstatistic = unimplemented!();
/// match metricstatistic {
///     MetricStatistic::Average => { /* ... */ },
///     MetricStatistic::Maximum => { /* ... */ },
///     MetricStatistic::Minimum => { /* ... */ },
///     MetricStatistic::SampleCount => { /* ... */ },
///     MetricStatistic::Sum => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `metricstatistic` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `MetricStatistic::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `MetricStatistic::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `MetricStatistic::NewFeature` is defined.
/// Specifically, when `metricstatistic` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `MetricStatistic::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum MetricStatistic {
    #[allow(missing_docs)] // documentation missing in model
    Average,
    #[allow(missing_docs)] // documentation missing in model
    Maximum,
    #[allow(missing_docs)] // documentation missing in model
    Minimum,
    #[allow(missing_docs)] // documentation missing in model
    SampleCount,
    #[allow(missing_docs)] // documentation missing in model
    Sum,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for MetricStatistic {
    fn from(s: &str) -> Self {
        match s {
            "Average" => MetricStatistic::Average,
            "Maximum" => MetricStatistic::Maximum,
            "Minimum" => MetricStatistic::Minimum,
            "SampleCount" => MetricStatistic::SampleCount,
            "Sum" => MetricStatistic::Sum,
            other => MetricStatistic::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for MetricStatistic {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(MetricStatistic::from(s))
                }
            }
impl MetricStatistic {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            MetricStatistic::Average => "Average",
            MetricStatistic::Maximum => "Maximum",
            MetricStatistic::Minimum => "Minimum",
            MetricStatistic::SampleCount => "SampleCount",
            MetricStatistic::Sum => "Sum",
            MetricStatistic::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "Average", "Maximum", "Minimum", "SampleCount", "Sum"
        ]
    }
}
impl AsRef<str> for MetricStatistic {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Represents a predefined metric for a target tracking scaling policy to use with Amazon EC2 Auto Scaling.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct PredefinedMetricSpecification  {
    /// <p>The metric type. The following predefined metrics are available:</p> 
    /// <ul> 
    /// <li> <p> <code>ASGAverageCPUUtilization</code> - Average CPU utilization of the Auto Scaling group.</p> </li> 
    /// <li> <p> <code>ASGAverageNetworkIn</code> - Average number of bytes received on all network interfaces by the Auto Scaling group.</p> </li> 
    /// <li> <p> <code>ASGAverageNetworkOut</code> - Average number of bytes sent out on all network interfaces by the Auto Scaling group.</p> </li> 
    /// <li> <p> <code>ALBRequestCountPerTarget</code> - Average Application Load Balancer request count per target for your Auto Scaling group.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub predefined_metric_type: std::option::Option<crate::model::MetricType>,
    /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
    /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
    /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
    /// <p>Where:</p> 
    /// <ul> 
    /// <li> <p>app/<load-balancer-name>
    /// /
    /// <load-balancer-id>
    /// is the final portion of the load balancer ARN
    /// </load-balancer-id>
    /// </load-balancer-name></p> </li> 
    /// <li> <p>targetgroup/<target-group-name>
    /// /
    /// <target-group-id>
    /// is the final portion of the target group ARN.
    /// </target-group-id>
    /// </target-group-name></p> </li> 
    /// </ul> 
    /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
    #[doc(hidden)]
    pub resource_label: std::option::Option<std::string::String>,
}
impl PredefinedMetricSpecification {
    /// <p>The metric type. The following predefined metrics are available:</p> 
    /// <ul> 
    /// <li> <p> <code>ASGAverageCPUUtilization</code> - Average CPU utilization of the Auto Scaling group.</p> </li> 
    /// <li> <p> <code>ASGAverageNetworkIn</code> - Average number of bytes received on all network interfaces by the Auto Scaling group.</p> </li> 
    /// <li> <p> <code>ASGAverageNetworkOut</code> - Average number of bytes sent out on all network interfaces by the Auto Scaling group.</p> </li> 
    /// <li> <p> <code>ALBRequestCountPerTarget</code> - Average Application Load Balancer request count per target for your Auto Scaling group.</p> </li> 
    /// </ul>
    pub fn predefined_metric_type(&self) -> std::option::Option<& crate::model::MetricType> {
        self.predefined_metric_type.as_ref()
    }
    /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
    /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
    /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
    /// <p>Where:</p> 
    /// <ul> 
    /// <li> <p>app/<load-balancer-name>
    /// /
    /// <load-balancer-id>
    /// is the final portion of the load balancer ARN
    /// </load-balancer-id>
    /// </load-balancer-name></p> </li> 
    /// <li> <p>targetgroup/<target-group-name>
    /// /
    /// <target-group-id>
    /// is the final portion of the target group ARN.
    /// </target-group-id>
    /// </target-group-name></p> </li> 
    /// </ul> 
    /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
    pub fn resource_label(&self) -> std::option::Option<& str> {
        self.resource_label.as_deref()
    }
}
/// See [`PredefinedMetricSpecification`](crate::model::PredefinedMetricSpecification).
pub mod predefined_metric_specification {
    
    /// A builder for [`PredefinedMetricSpecification`](crate::model::PredefinedMetricSpecification).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) predefined_metric_type: std::option::Option<crate::model::MetricType>,
        pub(crate) resource_label: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The metric type. The following predefined metrics are available:</p> 
        /// <ul> 
        /// <li> <p> <code>ASGAverageCPUUtilization</code> - Average CPU utilization of the Auto Scaling group.</p> </li> 
        /// <li> <p> <code>ASGAverageNetworkIn</code> - Average number of bytes received on all network interfaces by the Auto Scaling group.</p> </li> 
        /// <li> <p> <code>ASGAverageNetworkOut</code> - Average number of bytes sent out on all network interfaces by the Auto Scaling group.</p> </li> 
        /// <li> <p> <code>ALBRequestCountPerTarget</code> - Average Application Load Balancer request count per target for your Auto Scaling group.</p> </li> 
        /// </ul>
        pub fn predefined_metric_type(mut self, input: crate::model::MetricType) -> Self {
            self.predefined_metric_type = Some(input);
            self
        }
        /// <p>The metric type. The following predefined metrics are available:</p> 
        /// <ul> 
        /// <li> <p> <code>ASGAverageCPUUtilization</code> - Average CPU utilization of the Auto Scaling group.</p> </li> 
        /// <li> <p> <code>ASGAverageNetworkIn</code> - Average number of bytes received on all network interfaces by the Auto Scaling group.</p> </li> 
        /// <li> <p> <code>ASGAverageNetworkOut</code> - Average number of bytes sent out on all network interfaces by the Auto Scaling group.</p> </li> 
        /// <li> <p> <code>ALBRequestCountPerTarget</code> - Average Application Load Balancer request count per target for your Auto Scaling group.</p> </li> 
        /// </ul>
        pub fn set_predefined_metric_type(mut self, input: std::option::Option<crate::model::MetricType>) -> Self {
            self.predefined_metric_type = input; self
        }
        /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
        /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
        /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
        /// <p>Where:</p> 
        /// <ul> 
        /// <li> <p>app/<load-balancer-name>
        /// /
        /// <load-balancer-id>
        /// is the final portion of the load balancer ARN
        /// </load-balancer-id>
        /// </load-balancer-name></p> </li> 
        /// <li> <p>targetgroup/<target-group-name>
        /// /
        /// <target-group-id>
        /// is the final portion of the target group ARN.
        /// </target-group-id>
        /// </target-group-name></p> </li> 
        /// </ul> 
        /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
        pub fn resource_label(mut self, input: impl Into<std::string::String>) -> Self {
            self.resource_label = Some(input.into());
            self
        }
        /// <p>A label that uniquely identifies a specific Application Load Balancer target group from which to determine the average request count served by your Auto Scaling group. You can't specify a resource label unless the target group is attached to the Auto Scaling group.</p> 
        /// <p>You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is:</p> 
        /// <p> <code>app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff</code>.</p> 
        /// <p>Where:</p> 
        /// <ul> 
        /// <li> <p>app/<load-balancer-name>
        /// /
        /// <load-balancer-id>
        /// is the final portion of the load balancer ARN
        /// </load-balancer-id>
        /// </load-balancer-name></p> </li> 
        /// <li> <p>targetgroup/<target-group-name>
        /// /
        /// <target-group-id>
        /// is the final portion of the target group ARN.
        /// </target-group-id>
        /// </target-group-name></p> </li> 
        /// </ul> 
        /// <p>To find the ARN for an Application Load Balancer, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html">DescribeLoadBalancers</a> API operation. To find the ARN for the target group, use the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
        pub fn set_resource_label(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.resource_label = input; self
        }
        /// Consumes the builder and constructs a [`PredefinedMetricSpecification`](crate::model::PredefinedMetricSpecification).
        pub fn build(self) -> crate::model::PredefinedMetricSpecification {
            crate::model::PredefinedMetricSpecification {
                predefined_metric_type: self.predefined_metric_type
                ,
                resource_label: self.resource_label
                ,
            }
        }
    }
    
    
}
impl PredefinedMetricSpecification {
    /// Creates a new builder-style object to manufacture [`PredefinedMetricSpecification`](crate::model::PredefinedMetricSpecification).
    pub fn builder() -> crate::model::predefined_metric_specification::Builder {
        crate::model::predefined_metric_specification::Builder::default()
    }
}

/// When writing a match expression against `MetricType`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let metrictype = unimplemented!();
/// match metrictype {
///     MetricType::AlbRequestCountPerTarget => { /* ... */ },
///     MetricType::AsgAverageCpuUtilization => { /* ... */ },
///     MetricType::AsgAverageNetworkIn => { /* ... */ },
///     MetricType::AsgAverageNetworkOut => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `metrictype` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `MetricType::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `MetricType::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `MetricType::NewFeature` is defined.
/// Specifically, when `metrictype` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `MetricType::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum MetricType {
    #[allow(missing_docs)] // documentation missing in model
    AlbRequestCountPerTarget,
    #[allow(missing_docs)] // documentation missing in model
    AsgAverageCpuUtilization,
    #[allow(missing_docs)] // documentation missing in model
    AsgAverageNetworkIn,
    #[allow(missing_docs)] // documentation missing in model
    AsgAverageNetworkOut,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for MetricType {
    fn from(s: &str) -> Self {
        match s {
            "ALBRequestCountPerTarget" => MetricType::AlbRequestCountPerTarget,
            "ASGAverageCPUUtilization" => MetricType::AsgAverageCpuUtilization,
            "ASGAverageNetworkIn" => MetricType::AsgAverageNetworkIn,
            "ASGAverageNetworkOut" => MetricType::AsgAverageNetworkOut,
            other => MetricType::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for MetricType {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(MetricType::from(s))
                }
            }
impl MetricType {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            MetricType::AlbRequestCountPerTarget => "ALBRequestCountPerTarget",
            MetricType::AsgAverageCpuUtilization => "ASGAverageCPUUtilization",
            MetricType::AsgAverageNetworkIn => "ASGAverageNetworkIn",
            MetricType::AsgAverageNetworkOut => "ASGAverageNetworkOut",
            MetricType::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "ALBRequestCountPerTarget", "ASGAverageCPUUtilization", "ASGAverageNetworkIn", "ASGAverageNetworkOut"
        ]
    }
}
impl AsRef<str> for MetricType {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Describes information used to create a step adjustment for a step scaling policy.</p> 
/// <p>For the following examples, suppose that you have an alarm with a breach threshold of 50:</p> 
/// <ul> 
/// <li> <p>To trigger the adjustment when the metric is greater than or equal to 50 and less than 60, specify a lower bound of 0 and an upper bound of 10.</p> </li> 
/// <li> <p>To trigger the adjustment when the metric is greater than 40 and less than or equal to 50, specify a lower bound of -10 and an upper bound of 0.</p> </li> 
/// </ul> 
/// <p>There are a few rules for the step adjustments for your step policy:</p> 
/// <ul> 
/// <li> <p>The ranges of your step adjustments can't overlap or have a gap.</p> </li> 
/// <li> <p>At most, one step adjustment can have a null lower bound. If one step adjustment has a negative lower bound, then there must be a step adjustment with a null lower bound.</p> </li> 
/// <li> <p>At most, one step adjustment can have a null upper bound. If one step adjustment has a positive upper bound, then there must be a step adjustment with a null upper bound.</p> </li> 
/// <li> <p>The upper and lower bound can't be null in the same step adjustment.</p> </li> 
/// </ul> 
/// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-steps">Step adjustments</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct StepAdjustment  {
    /// <p>The lower bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the lower bound is inclusive (the metric must be greater than or equal to the threshold plus the lower bound). Otherwise, it is exclusive (the metric must be greater than the threshold plus the lower bound). A null value indicates negative infinity.</p>
    #[doc(hidden)]
    pub metric_interval_lower_bound: std::option::Option<f64>,
    /// <p>The upper bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the upper bound is exclusive (the metric must be less than the threshold plus the upper bound). Otherwise, it is inclusive (the metric must be less than or equal to the threshold plus the upper bound). A null value indicates positive infinity.</p> 
    /// <p>The upper bound must be greater than the lower bound.</p>
    #[doc(hidden)]
    pub metric_interval_upper_bound: std::option::Option<f64>,
    /// <p>The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity.</p> 
    /// <p>The amount by which to scale. The adjustment is based on the value that you specified in the <code>AdjustmentType</code> property (either an absolute number or a percentage). A positive value adds to the current capacity and a negative number subtracts from the current capacity. </p>
    #[doc(hidden)]
    pub scaling_adjustment: std::option::Option<i32>,
}
impl StepAdjustment {
    /// <p>The lower bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the lower bound is inclusive (the metric must be greater than or equal to the threshold plus the lower bound). Otherwise, it is exclusive (the metric must be greater than the threshold plus the lower bound). A null value indicates negative infinity.</p>
    pub fn metric_interval_lower_bound(&self) -> std::option::Option<f64> {
        self.metric_interval_lower_bound
    }
    /// <p>The upper bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the upper bound is exclusive (the metric must be less than the threshold plus the upper bound). Otherwise, it is inclusive (the metric must be less than or equal to the threshold plus the upper bound). A null value indicates positive infinity.</p> 
    /// <p>The upper bound must be greater than the lower bound.</p>
    pub fn metric_interval_upper_bound(&self) -> std::option::Option<f64> {
        self.metric_interval_upper_bound
    }
    /// <p>The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity.</p> 
    /// <p>The amount by which to scale. The adjustment is based on the value that you specified in the <code>AdjustmentType</code> property (either an absolute number or a percentage). A positive value adds to the current capacity and a negative number subtracts from the current capacity. </p>
    pub fn scaling_adjustment(&self) -> std::option::Option<i32> {
        self.scaling_adjustment
    }
}
/// See [`StepAdjustment`](crate::model::StepAdjustment).
pub mod step_adjustment {
    
    /// A builder for [`StepAdjustment`](crate::model::StepAdjustment).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) metric_interval_lower_bound: std::option::Option<f64>,
        pub(crate) metric_interval_upper_bound: std::option::Option<f64>,
        pub(crate) scaling_adjustment: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The lower bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the lower bound is inclusive (the metric must be greater than or equal to the threshold plus the lower bound). Otherwise, it is exclusive (the metric must be greater than the threshold plus the lower bound). A null value indicates negative infinity.</p>
        pub fn metric_interval_lower_bound(mut self, input: f64) -> Self {
            self.metric_interval_lower_bound = Some(input);
            self
        }
        /// <p>The lower bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the lower bound is inclusive (the metric must be greater than or equal to the threshold plus the lower bound). Otherwise, it is exclusive (the metric must be greater than the threshold plus the lower bound). A null value indicates negative infinity.</p>
        pub fn set_metric_interval_lower_bound(mut self, input: std::option::Option<f64>) -> Self {
            self.metric_interval_lower_bound = input; self
        }
        /// <p>The upper bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the upper bound is exclusive (the metric must be less than the threshold plus the upper bound). Otherwise, it is inclusive (the metric must be less than or equal to the threshold plus the upper bound). A null value indicates positive infinity.</p> 
        /// <p>The upper bound must be greater than the lower bound.</p>
        pub fn metric_interval_upper_bound(mut self, input: f64) -> Self {
            self.metric_interval_upper_bound = Some(input);
            self
        }
        /// <p>The upper bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the upper bound is exclusive (the metric must be less than the threshold plus the upper bound). Otherwise, it is inclusive (the metric must be less than or equal to the threshold plus the upper bound). A null value indicates positive infinity.</p> 
        /// <p>The upper bound must be greater than the lower bound.</p>
        pub fn set_metric_interval_upper_bound(mut self, input: std::option::Option<f64>) -> Self {
            self.metric_interval_upper_bound = input; self
        }
        /// <p>The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity.</p> 
        /// <p>The amount by which to scale. The adjustment is based on the value that you specified in the <code>AdjustmentType</code> property (either an absolute number or a percentage). A positive value adds to the current capacity and a negative number subtracts from the current capacity. </p>
        pub fn scaling_adjustment(mut self, input: i32) -> Self {
            self.scaling_adjustment = Some(input);
            self
        }
        /// <p>The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity.</p> 
        /// <p>The amount by which to scale. The adjustment is based on the value that you specified in the <code>AdjustmentType</code> property (either an absolute number or a percentage). A positive value adds to the current capacity and a negative number subtracts from the current capacity. </p>
        pub fn set_scaling_adjustment(mut self, input: std::option::Option<i32>) -> Self {
            self.scaling_adjustment = input; self
        }
        /// Consumes the builder and constructs a [`StepAdjustment`](crate::model::StepAdjustment).
        pub fn build(self) -> crate::model::StepAdjustment {
            crate::model::StepAdjustment {
                metric_interval_lower_bound: self.metric_interval_lower_bound
                ,
                metric_interval_upper_bound: self.metric_interval_upper_bound
                ,
                scaling_adjustment: self.scaling_adjustment
                ,
            }
        }
    }
    
    
}
impl StepAdjustment {
    /// Creates a new builder-style object to manufacture [`StepAdjustment`](crate::model::StepAdjustment).
    pub fn builder() -> crate::model::step_adjustment::Builder {
        crate::model::step_adjustment::Builder::default()
    }
}

/// <p>A <code>GetPredictiveScalingForecast</code> call returns the capacity forecast for a predictive scaling policy. This structure includes the data points for that capacity forecast, along with the timestamps of those data points. </p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct CapacityForecast  {
    /// <p>The timestamps for the data points, in UTC format.</p>
    #[doc(hidden)]
    pub timestamps: std::option::Option<std::vec::Vec<aws_smithy_types::DateTime>>,
    /// <p>The values of the data points.</p>
    #[doc(hidden)]
    pub values: std::option::Option<std::vec::Vec<f64>>,
}
impl CapacityForecast {
    /// <p>The timestamps for the data points, in UTC format.</p>
    pub fn timestamps(&self) -> std::option::Option<& [aws_smithy_types::DateTime]> {
        self.timestamps.as_deref()
    }
    /// <p>The values of the data points.</p>
    pub fn values(&self) -> std::option::Option<& [f64]> {
        self.values.as_deref()
    }
}
/// See [`CapacityForecast`](crate::model::CapacityForecast).
pub mod capacity_forecast {
    
    /// A builder for [`CapacityForecast`](crate::model::CapacityForecast).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) timestamps: std::option::Option<std::vec::Vec<aws_smithy_types::DateTime>>,
        pub(crate) values: std::option::Option<std::vec::Vec<f64>>,
    }
    impl Builder {
        /// Appends an item to `timestamps`.
        ///
        /// To override the contents of this collection use [`set_timestamps`](Self::set_timestamps).
        ///
        /// <p>The timestamps for the data points, in UTC format.</p>
        pub fn timestamps(mut self, input: aws_smithy_types::DateTime) -> Self {
            let mut v = self.timestamps.unwrap_or_default();
                            v.push(input);
                            self.timestamps = Some(v);
                            self
        }
        /// <p>The timestamps for the data points, in UTC format.</p>
        pub fn set_timestamps(mut self, input: std::option::Option<std::vec::Vec<aws_smithy_types::DateTime>>) -> Self {
            self.timestamps = input; self
        }
        /// Appends an item to `values`.
        ///
        /// To override the contents of this collection use [`set_values`](Self::set_values).
        ///
        /// <p>The values of the data points.</p>
        pub fn values(mut self, input: f64) -> Self {
            let mut v = self.values.unwrap_or_default();
                            v.push(input);
                            self.values = Some(v);
                            self
        }
        /// <p>The values of the data points.</p>
        pub fn set_values(mut self, input: std::option::Option<std::vec::Vec<f64>>) -> Self {
            self.values = input; self
        }
        /// Consumes the builder and constructs a [`CapacityForecast`](crate::model::CapacityForecast).
        pub fn build(self) -> crate::model::CapacityForecast {
            crate::model::CapacityForecast {
                timestamps: self.timestamps
                ,
                values: self.values
                ,
            }
        }
    }
    
    
}
impl CapacityForecast {
    /// Creates a new builder-style object to manufacture [`CapacityForecast`](crate::model::CapacityForecast).
    pub fn builder() -> crate::model::capacity_forecast::Builder {
        crate::model::capacity_forecast::Builder::default()
    }
}

/// <p>A <code>GetPredictiveScalingForecast</code> call returns the load forecast for a predictive scaling policy. This structure includes the data points for that load forecast, along with the timestamps of those data points and the metric specification. </p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct LoadForecast  {
    /// <p>The timestamps for the data points, in UTC format.</p>
    #[doc(hidden)]
    pub timestamps: std::option::Option<std::vec::Vec<aws_smithy_types::DateTime>>,
    /// <p>The values of the data points.</p>
    #[doc(hidden)]
    pub values: std::option::Option<std::vec::Vec<f64>>,
    /// <p>The metric specification for the load forecast.</p>
    #[doc(hidden)]
    pub metric_specification: std::option::Option<crate::model::PredictiveScalingMetricSpecification>,
}
impl LoadForecast {
    /// <p>The timestamps for the data points, in UTC format.</p>
    pub fn timestamps(&self) -> std::option::Option<& [aws_smithy_types::DateTime]> {
        self.timestamps.as_deref()
    }
    /// <p>The values of the data points.</p>
    pub fn values(&self) -> std::option::Option<& [f64]> {
        self.values.as_deref()
    }
    /// <p>The metric specification for the load forecast.</p>
    pub fn metric_specification(&self) -> std::option::Option<& crate::model::PredictiveScalingMetricSpecification> {
        self.metric_specification.as_ref()
    }
}
/// See [`LoadForecast`](crate::model::LoadForecast).
pub mod load_forecast {
    
    /// A builder for [`LoadForecast`](crate::model::LoadForecast).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) timestamps: std::option::Option<std::vec::Vec<aws_smithy_types::DateTime>>,
        pub(crate) values: std::option::Option<std::vec::Vec<f64>>,
        pub(crate) metric_specification: std::option::Option<crate::model::PredictiveScalingMetricSpecification>,
    }
    impl Builder {
        /// Appends an item to `timestamps`.
        ///
        /// To override the contents of this collection use [`set_timestamps`](Self::set_timestamps).
        ///
        /// <p>The timestamps for the data points, in UTC format.</p>
        pub fn timestamps(mut self, input: aws_smithy_types::DateTime) -> Self {
            let mut v = self.timestamps.unwrap_or_default();
                            v.push(input);
                            self.timestamps = Some(v);
                            self
        }
        /// <p>The timestamps for the data points, in UTC format.</p>
        pub fn set_timestamps(mut self, input: std::option::Option<std::vec::Vec<aws_smithy_types::DateTime>>) -> Self {
            self.timestamps = input; self
        }
        /// Appends an item to `values`.
        ///
        /// To override the contents of this collection use [`set_values`](Self::set_values).
        ///
        /// <p>The values of the data points.</p>
        pub fn values(mut self, input: f64) -> Self {
            let mut v = self.values.unwrap_or_default();
                            v.push(input);
                            self.values = Some(v);
                            self
        }
        /// <p>The values of the data points.</p>
        pub fn set_values(mut self, input: std::option::Option<std::vec::Vec<f64>>) -> Self {
            self.values = input; self
        }
        /// <p>The metric specification for the load forecast.</p>
        pub fn metric_specification(mut self, input: crate::model::PredictiveScalingMetricSpecification) -> Self {
            self.metric_specification = Some(input);
            self
        }
        /// <p>The metric specification for the load forecast.</p>
        pub fn set_metric_specification(mut self, input: std::option::Option<crate::model::PredictiveScalingMetricSpecification>) -> Self {
            self.metric_specification = input; self
        }
        /// Consumes the builder and constructs a [`LoadForecast`](crate::model::LoadForecast).
        pub fn build(self) -> crate::model::LoadForecast {
            crate::model::LoadForecast {
                timestamps: self.timestamps
                ,
                values: self.values
                ,
                metric_specification: self.metric_specification
                ,
            }
        }
    }
    
    
}
impl LoadForecast {
    /// Creates a new builder-style object to manufacture [`LoadForecast`](crate::model::LoadForecast).
    pub fn builder() -> crate::model::load_forecast::Builder {
        crate::model::load_forecast::Builder::default()
    }
}

/// <p>Describes the identifier of a traffic source.</p> 
/// <p>Currently, you must specify an Amazon Resource Name (ARN) for an existing VPC Lattice target group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct TrafficSourceIdentifier  {
    /// <p>The unique identifier of the traffic source.</p>
    #[doc(hidden)]
    pub identifier: std::option::Option<std::string::String>,
}
impl TrafficSourceIdentifier {
    /// <p>The unique identifier of the traffic source.</p>
    pub fn identifier(&self) -> std::option::Option<& str> {
        self.identifier.as_deref()
    }
}
/// See [`TrafficSourceIdentifier`](crate::model::TrafficSourceIdentifier).
pub mod traffic_source_identifier {
    
    /// A builder for [`TrafficSourceIdentifier`](crate::model::TrafficSourceIdentifier).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) identifier: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The unique identifier of the traffic source.</p>
        pub fn identifier(mut self, input: impl Into<std::string::String>) -> Self {
            self.identifier = Some(input.into());
            self
        }
        /// <p>The unique identifier of the traffic source.</p>
        pub fn set_identifier(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.identifier = input; self
        }
        /// Consumes the builder and constructs a [`TrafficSourceIdentifier`](crate::model::TrafficSourceIdentifier).
        pub fn build(self) -> crate::model::TrafficSourceIdentifier {
            crate::model::TrafficSourceIdentifier {
                identifier: self.identifier
                ,
            }
        }
    }
    
    
}
impl TrafficSourceIdentifier {
    /// Creates a new builder-style object to manufacture [`TrafficSourceIdentifier`](crate::model::TrafficSourceIdentifier).
    pub fn builder() -> crate::model::traffic_source_identifier::Builder {
        crate::model::traffic_source_identifier::Builder::default()
    }
}

/// <p>Describes an EC2 instance.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct Instance  {
    /// <p>The ID of the instance.</p>
    #[doc(hidden)]
    pub instance_id: std::option::Option<std::string::String>,
    /// <p>The instance type of the EC2 instance.</p>
    #[doc(hidden)]
    pub instance_type: std::option::Option<std::string::String>,
    /// <p>The Availability Zone in which the instance is running.</p>
    #[doc(hidden)]
    pub availability_zone: std::option::Option<std::string::String>,
    /// <p>A description of the current lifecycle state. The <code>Quarantined</code> state is not used. For information about lifecycle states, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroupLifecycle.html">Instance lifecycle</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p>
    #[doc(hidden)]
    pub lifecycle_state: std::option::Option<crate::model::LifecycleState>,
    /// <p>The last reported health status of the instance. "Healthy" means that the instance is healthy and should remain in service. "Unhealthy" means that the instance is unhealthy and that Amazon EC2 Auto Scaling should terminate and replace it.</p>
    #[doc(hidden)]
    pub health_status: std::option::Option<std::string::String>,
    /// <p>The launch configuration associated with the instance.</p>
    #[doc(hidden)]
    pub launch_configuration_name: std::option::Option<std::string::String>,
    /// <p>The launch template for the instance.</p>
    #[doc(hidden)]
    pub launch_template: std::option::Option<crate::model::LaunchTemplateSpecification>,
    /// <p>Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
    #[doc(hidden)]
    pub protected_from_scale_in: std::option::Option<bool>,
    /// <p>The number of capacity units contributed by the instance based on its instance type.</p> 
    /// <p>Valid Range: Minimum value of 1. Maximum value of 999.</p>
    #[doc(hidden)]
    pub weighted_capacity: std::option::Option<std::string::String>,
}
impl Instance {
    /// <p>The ID of the instance.</p>
    pub fn instance_id(&self) -> std::option::Option<& str> {
        self.instance_id.as_deref()
    }
    /// <p>The instance type of the EC2 instance.</p>
    pub fn instance_type(&self) -> std::option::Option<& str> {
        self.instance_type.as_deref()
    }
    /// <p>The Availability Zone in which the instance is running.</p>
    pub fn availability_zone(&self) -> std::option::Option<& str> {
        self.availability_zone.as_deref()
    }
    /// <p>A description of the current lifecycle state. The <code>Quarantined</code> state is not used. For information about lifecycle states, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroupLifecycle.html">Instance lifecycle</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p>
    pub fn lifecycle_state(&self) -> std::option::Option<& crate::model::LifecycleState> {
        self.lifecycle_state.as_ref()
    }
    /// <p>The last reported health status of the instance. "Healthy" means that the instance is healthy and should remain in service. "Unhealthy" means that the instance is unhealthy and that Amazon EC2 Auto Scaling should terminate and replace it.</p>
    pub fn health_status(&self) -> std::option::Option<& str> {
        self.health_status.as_deref()
    }
    /// <p>The launch configuration associated with the instance.</p>
    pub fn launch_configuration_name(&self) -> std::option::Option<& str> {
        self.launch_configuration_name.as_deref()
    }
    /// <p>The launch template for the instance.</p>
    pub fn launch_template(&self) -> std::option::Option<& crate::model::LaunchTemplateSpecification> {
        self.launch_template.as_ref()
    }
    /// <p>Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
    pub fn protected_from_scale_in(&self) -> std::option::Option<bool> {
        self.protected_from_scale_in
    }
    /// <p>The number of capacity units contributed by the instance based on its instance type.</p> 
    /// <p>Valid Range: Minimum value of 1. Maximum value of 999.</p>
    pub fn weighted_capacity(&self) -> std::option::Option<& str> {
        self.weighted_capacity.as_deref()
    }
}
/// See [`Instance`](crate::model::Instance).
pub mod instance {
    
    /// A builder for [`Instance`](crate::model::Instance).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) instance_id: std::option::Option<std::string::String>,
        pub(crate) instance_type: std::option::Option<std::string::String>,
        pub(crate) availability_zone: std::option::Option<std::string::String>,
        pub(crate) lifecycle_state: std::option::Option<crate::model::LifecycleState>,
        pub(crate) health_status: std::option::Option<std::string::String>,
        pub(crate) launch_configuration_name: std::option::Option<std::string::String>,
        pub(crate) launch_template: std::option::Option<crate::model::LaunchTemplateSpecification>,
        pub(crate) protected_from_scale_in: std::option::Option<bool>,
        pub(crate) weighted_capacity: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The ID of the instance.</p>
        pub fn instance_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.instance_id = Some(input.into());
            self
        }
        /// <p>The ID of the instance.</p>
        pub fn set_instance_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.instance_id = input; self
        }
        /// <p>The instance type of the EC2 instance.</p>
        pub fn instance_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.instance_type = Some(input.into());
            self
        }
        /// <p>The instance type of the EC2 instance.</p>
        pub fn set_instance_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.instance_type = input; self
        }
        /// <p>The Availability Zone in which the instance is running.</p>
        pub fn availability_zone(mut self, input: impl Into<std::string::String>) -> Self {
            self.availability_zone = Some(input.into());
            self
        }
        /// <p>The Availability Zone in which the instance is running.</p>
        pub fn set_availability_zone(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.availability_zone = input; self
        }
        /// <p>A description of the current lifecycle state. The <code>Quarantined</code> state is not used. For information about lifecycle states, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroupLifecycle.html">Instance lifecycle</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p>
        pub fn lifecycle_state(mut self, input: crate::model::LifecycleState) -> Self {
            self.lifecycle_state = Some(input);
            self
        }
        /// <p>A description of the current lifecycle state. The <code>Quarantined</code> state is not used. For information about lifecycle states, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroupLifecycle.html">Instance lifecycle</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p>
        pub fn set_lifecycle_state(mut self, input: std::option::Option<crate::model::LifecycleState>) -> Self {
            self.lifecycle_state = input; self
        }
        /// <p>The last reported health status of the instance. "Healthy" means that the instance is healthy and should remain in service. "Unhealthy" means that the instance is unhealthy and that Amazon EC2 Auto Scaling should terminate and replace it.</p>
        pub fn health_status(mut self, input: impl Into<std::string::String>) -> Self {
            self.health_status = Some(input.into());
            self
        }
        /// <p>The last reported health status of the instance. "Healthy" means that the instance is healthy and should remain in service. "Unhealthy" means that the instance is unhealthy and that Amazon EC2 Auto Scaling should terminate and replace it.</p>
        pub fn set_health_status(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.health_status = input; self
        }
        /// <p>The launch configuration associated with the instance.</p>
        pub fn launch_configuration_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.launch_configuration_name = Some(input.into());
            self
        }
        /// <p>The launch configuration associated with the instance.</p>
        pub fn set_launch_configuration_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.launch_configuration_name = input; self
        }
        /// <p>The launch template for the instance.</p>
        pub fn launch_template(mut self, input: crate::model::LaunchTemplateSpecification) -> Self {
            self.launch_template = Some(input);
            self
        }
        /// <p>The launch template for the instance.</p>
        pub fn set_launch_template(mut self, input: std::option::Option<crate::model::LaunchTemplateSpecification>) -> Self {
            self.launch_template = input; self
        }
        /// <p>Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
        pub fn protected_from_scale_in(mut self, input: bool) -> Self {
            self.protected_from_scale_in = Some(input);
            self
        }
        /// <p>Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
        pub fn set_protected_from_scale_in(mut self, input: std::option::Option<bool>) -> Self {
            self.protected_from_scale_in = input; self
        }
        /// <p>The number of capacity units contributed by the instance based on its instance type.</p> 
        /// <p>Valid Range: Minimum value of 1. Maximum value of 999.</p>
        pub fn weighted_capacity(mut self, input: impl Into<std::string::String>) -> Self {
            self.weighted_capacity = Some(input.into());
            self
        }
        /// <p>The number of capacity units contributed by the instance based on its instance type.</p> 
        /// <p>Valid Range: Minimum value of 1. Maximum value of 999.</p>
        pub fn set_weighted_capacity(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.weighted_capacity = input; self
        }
        /// Consumes the builder and constructs a [`Instance`](crate::model::Instance).
        pub fn build(self) -> crate::model::Instance {
            crate::model::Instance {
                instance_id: self.instance_id
                ,
                instance_type: self.instance_type
                ,
                availability_zone: self.availability_zone
                ,
                lifecycle_state: self.lifecycle_state
                ,
                health_status: self.health_status
                ,
                launch_configuration_name: self.launch_configuration_name
                ,
                launch_template: self.launch_template
                ,
                protected_from_scale_in: self.protected_from_scale_in
                ,
                weighted_capacity: self.weighted_capacity
                ,
            }
        }
    }
    
    
}
impl Instance {
    /// Creates a new builder-style object to manufacture [`Instance`](crate::model::Instance).
    pub fn builder() -> crate::model::instance::Builder {
        crate::model::instance::Builder::default()
    }
}

/// When writing a match expression against `LifecycleState`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let lifecyclestate = unimplemented!();
/// match lifecyclestate {
///     LifecycleState::Detached => { /* ... */ },
///     LifecycleState::Detaching => { /* ... */ },
///     LifecycleState::EnteringStandby => { /* ... */ },
///     LifecycleState::InService => { /* ... */ },
///     LifecycleState::Pending => { /* ... */ },
///     LifecycleState::PendingProceed => { /* ... */ },
///     LifecycleState::PendingWait => { /* ... */ },
///     LifecycleState::Quarantined => { /* ... */ },
///     LifecycleState::Standby => { /* ... */ },
///     LifecycleState::Terminated => { /* ... */ },
///     LifecycleState::Terminating => { /* ... */ },
///     LifecycleState::TerminatingProceed => { /* ... */ },
///     LifecycleState::TerminatingWait => { /* ... */ },
///     LifecycleState::WarmedHibernated => { /* ... */ },
///     LifecycleState::WarmedPending => { /* ... */ },
///     LifecycleState::WarmedPendingProceed => { /* ... */ },
///     LifecycleState::WarmedPendingWait => { /* ... */ },
///     LifecycleState::WarmedRunning => { /* ... */ },
///     LifecycleState::WarmedStopped => { /* ... */ },
///     LifecycleState::WarmedTerminated => { /* ... */ },
///     LifecycleState::WarmedTerminating => { /* ... */ },
///     LifecycleState::WarmedTerminatingProceed => { /* ... */ },
///     LifecycleState::WarmedTerminatingWait => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `lifecyclestate` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `LifecycleState::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `LifecycleState::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `LifecycleState::NewFeature` is defined.
/// Specifically, when `lifecyclestate` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `LifecycleState::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum LifecycleState {
    #[allow(missing_docs)] // documentation missing in model
    Detached,
    #[allow(missing_docs)] // documentation missing in model
    Detaching,
    #[allow(missing_docs)] // documentation missing in model
    EnteringStandby,
    #[allow(missing_docs)] // documentation missing in model
    InService,
    #[allow(missing_docs)] // documentation missing in model
    Pending,
    #[allow(missing_docs)] // documentation missing in model
    PendingProceed,
    #[allow(missing_docs)] // documentation missing in model
    PendingWait,
    #[allow(missing_docs)] // documentation missing in model
    Quarantined,
    #[allow(missing_docs)] // documentation missing in model
    Standby,
    #[allow(missing_docs)] // documentation missing in model
    Terminated,
    #[allow(missing_docs)] // documentation missing in model
    Terminating,
    #[allow(missing_docs)] // documentation missing in model
    TerminatingProceed,
    #[allow(missing_docs)] // documentation missing in model
    TerminatingWait,
    #[allow(missing_docs)] // documentation missing in model
    WarmedHibernated,
    #[allow(missing_docs)] // documentation missing in model
    WarmedPending,
    #[allow(missing_docs)] // documentation missing in model
    WarmedPendingProceed,
    #[allow(missing_docs)] // documentation missing in model
    WarmedPendingWait,
    #[allow(missing_docs)] // documentation missing in model
    WarmedRunning,
    #[allow(missing_docs)] // documentation missing in model
    WarmedStopped,
    #[allow(missing_docs)] // documentation missing in model
    WarmedTerminated,
    #[allow(missing_docs)] // documentation missing in model
    WarmedTerminating,
    #[allow(missing_docs)] // documentation missing in model
    WarmedTerminatingProceed,
    #[allow(missing_docs)] // documentation missing in model
    WarmedTerminatingWait,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for LifecycleState {
    fn from(s: &str) -> Self {
        match s {
            "Detached" => LifecycleState::Detached,
            "Detaching" => LifecycleState::Detaching,
            "EnteringStandby" => LifecycleState::EnteringStandby,
            "InService" => LifecycleState::InService,
            "Pending" => LifecycleState::Pending,
            "Pending:Proceed" => LifecycleState::PendingProceed,
            "Pending:Wait" => LifecycleState::PendingWait,
            "Quarantined" => LifecycleState::Quarantined,
            "Standby" => LifecycleState::Standby,
            "Terminated" => LifecycleState::Terminated,
            "Terminating" => LifecycleState::Terminating,
            "Terminating:Proceed" => LifecycleState::TerminatingProceed,
            "Terminating:Wait" => LifecycleState::TerminatingWait,
            "Warmed:Hibernated" => LifecycleState::WarmedHibernated,
            "Warmed:Pending" => LifecycleState::WarmedPending,
            "Warmed:Pending:Proceed" => LifecycleState::WarmedPendingProceed,
            "Warmed:Pending:Wait" => LifecycleState::WarmedPendingWait,
            "Warmed:Running" => LifecycleState::WarmedRunning,
            "Warmed:Stopped" => LifecycleState::WarmedStopped,
            "Warmed:Terminated" => LifecycleState::WarmedTerminated,
            "Warmed:Terminating" => LifecycleState::WarmedTerminating,
            "Warmed:Terminating:Proceed" => LifecycleState::WarmedTerminatingProceed,
            "Warmed:Terminating:Wait" => LifecycleState::WarmedTerminatingWait,
            other => LifecycleState::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for LifecycleState {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(LifecycleState::from(s))
                }
            }
impl LifecycleState {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            LifecycleState::Detached => "Detached",
            LifecycleState::Detaching => "Detaching",
            LifecycleState::EnteringStandby => "EnteringStandby",
            LifecycleState::InService => "InService",
            LifecycleState::Pending => "Pending",
            LifecycleState::PendingProceed => "Pending:Proceed",
            LifecycleState::PendingWait => "Pending:Wait",
            LifecycleState::Quarantined => "Quarantined",
            LifecycleState::Standby => "Standby",
            LifecycleState::Terminated => "Terminated",
            LifecycleState::Terminating => "Terminating",
            LifecycleState::TerminatingProceed => "Terminating:Proceed",
            LifecycleState::TerminatingWait => "Terminating:Wait",
            LifecycleState::WarmedHibernated => "Warmed:Hibernated",
            LifecycleState::WarmedPending => "Warmed:Pending",
            LifecycleState::WarmedPendingProceed => "Warmed:Pending:Proceed",
            LifecycleState::WarmedPendingWait => "Warmed:Pending:Wait",
            LifecycleState::WarmedRunning => "Warmed:Running",
            LifecycleState::WarmedStopped => "Warmed:Stopped",
            LifecycleState::WarmedTerminated => "Warmed:Terminated",
            LifecycleState::WarmedTerminating => "Warmed:Terminating",
            LifecycleState::WarmedTerminatingProceed => "Warmed:Terminating:Proceed",
            LifecycleState::WarmedTerminatingWait => "Warmed:Terminating:Wait",
            LifecycleState::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "Detached", "Detaching", "EnteringStandby", "InService", "Pending", "Pending:Proceed", "Pending:Wait", "Quarantined", "Standby", "Terminated", "Terminating", "Terminating:Proceed", "Terminating:Wait", "Warmed:Hibernated", "Warmed:Pending", "Warmed:Pending:Proceed", "Warmed:Pending:Wait", "Warmed:Running", "Warmed:Stopped", "Warmed:Terminated", "Warmed:Terminating", "Warmed:Terminating:Proceed", "Warmed:Terminating:Wait"
        ]
    }
}
impl AsRef<str> for LifecycleState {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Describes a warm pool configuration. </p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct WarmPoolConfiguration  {
    /// <p>The maximum number of instances that are allowed to be in the warm pool or in any state except <code>Terminated</code> for the Auto Scaling group.</p>
    #[doc(hidden)]
    pub max_group_prepared_capacity: std::option::Option<i32>,
    /// <p>The minimum number of instances to maintain in the warm pool.</p>
    #[doc(hidden)]
    pub min_size: std::option::Option<i32>,
    /// <p>The instance state to transition to after the lifecycle actions are complete.</p>
    #[doc(hidden)]
    pub pool_state: std::option::Option<crate::model::WarmPoolState>,
    /// <p>The status of a warm pool that is marked for deletion.</p>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::WarmPoolStatus>,
    /// <p>The instance reuse policy.</p>
    #[doc(hidden)]
    pub instance_reuse_policy: std::option::Option<crate::model::InstanceReusePolicy>,
}
impl WarmPoolConfiguration {
    /// <p>The maximum number of instances that are allowed to be in the warm pool or in any state except <code>Terminated</code> for the Auto Scaling group.</p>
    pub fn max_group_prepared_capacity(&self) -> std::option::Option<i32> {
        self.max_group_prepared_capacity
    }
    /// <p>The minimum number of instances to maintain in the warm pool.</p>
    pub fn min_size(&self) -> std::option::Option<i32> {
        self.min_size
    }
    /// <p>The instance state to transition to after the lifecycle actions are complete.</p>
    pub fn pool_state(&self) -> std::option::Option<& crate::model::WarmPoolState> {
        self.pool_state.as_ref()
    }
    /// <p>The status of a warm pool that is marked for deletion.</p>
    pub fn status(&self) -> std::option::Option<& crate::model::WarmPoolStatus> {
        self.status.as_ref()
    }
    /// <p>The instance reuse policy.</p>
    pub fn instance_reuse_policy(&self) -> std::option::Option<& crate::model::InstanceReusePolicy> {
        self.instance_reuse_policy.as_ref()
    }
}
/// See [`WarmPoolConfiguration`](crate::model::WarmPoolConfiguration).
pub mod warm_pool_configuration {
    
    /// A builder for [`WarmPoolConfiguration`](crate::model::WarmPoolConfiguration).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) max_group_prepared_capacity: std::option::Option<i32>,
        pub(crate) min_size: std::option::Option<i32>,
        pub(crate) pool_state: std::option::Option<crate::model::WarmPoolState>,
        pub(crate) status: std::option::Option<crate::model::WarmPoolStatus>,
        pub(crate) instance_reuse_policy: std::option::Option<crate::model::InstanceReusePolicy>,
    }
    impl Builder {
        /// <p>The maximum number of instances that are allowed to be in the warm pool or in any state except <code>Terminated</code> for the Auto Scaling group.</p>
        pub fn max_group_prepared_capacity(mut self, input: i32) -> Self {
            self.max_group_prepared_capacity = Some(input);
            self
        }
        /// <p>The maximum number of instances that are allowed to be in the warm pool or in any state except <code>Terminated</code> for the Auto Scaling group.</p>
        pub fn set_max_group_prepared_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.max_group_prepared_capacity = input; self
        }
        /// <p>The minimum number of instances to maintain in the warm pool.</p>
        pub fn min_size(mut self, input: i32) -> Self {
            self.min_size = Some(input);
            self
        }
        /// <p>The minimum number of instances to maintain in the warm pool.</p>
        pub fn set_min_size(mut self, input: std::option::Option<i32>) -> Self {
            self.min_size = input; self
        }
        /// <p>The instance state to transition to after the lifecycle actions are complete.</p>
        pub fn pool_state(mut self, input: crate::model::WarmPoolState) -> Self {
            self.pool_state = Some(input);
            self
        }
        /// <p>The instance state to transition to after the lifecycle actions are complete.</p>
        pub fn set_pool_state(mut self, input: std::option::Option<crate::model::WarmPoolState>) -> Self {
            self.pool_state = input; self
        }
        /// <p>The status of a warm pool that is marked for deletion.</p>
        pub fn status(mut self, input: crate::model::WarmPoolStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>The status of a warm pool that is marked for deletion.</p>
        pub fn set_status(mut self, input: std::option::Option<crate::model::WarmPoolStatus>) -> Self {
            self.status = input; self
        }
        /// <p>The instance reuse policy.</p>
        pub fn instance_reuse_policy(mut self, input: crate::model::InstanceReusePolicy) -> Self {
            self.instance_reuse_policy = Some(input);
            self
        }
        /// <p>The instance reuse policy.</p>
        pub fn set_instance_reuse_policy(mut self, input: std::option::Option<crate::model::InstanceReusePolicy>) -> Self {
            self.instance_reuse_policy = input; self
        }
        /// Consumes the builder and constructs a [`WarmPoolConfiguration`](crate::model::WarmPoolConfiguration).
        pub fn build(self) -> crate::model::WarmPoolConfiguration {
            crate::model::WarmPoolConfiguration {
                max_group_prepared_capacity: self.max_group_prepared_capacity
                ,
                min_size: self.min_size
                ,
                pool_state: self.pool_state
                ,
                status: self.status
                ,
                instance_reuse_policy: self.instance_reuse_policy
                ,
            }
        }
    }
    
    
}
impl WarmPoolConfiguration {
    /// Creates a new builder-style object to manufacture [`WarmPoolConfiguration`](crate::model::WarmPoolConfiguration).
    pub fn builder() -> crate::model::warm_pool_configuration::Builder {
        crate::model::warm_pool_configuration::Builder::default()
    }
}

/// When writing a match expression against `WarmPoolStatus`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let warmpoolstatus = unimplemented!();
/// match warmpoolstatus {
///     WarmPoolStatus::PendingDelete => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `warmpoolstatus` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `WarmPoolStatus::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `WarmPoolStatus::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `WarmPoolStatus::NewFeature` is defined.
/// Specifically, when `warmpoolstatus` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `WarmPoolStatus::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum WarmPoolStatus {
    #[allow(missing_docs)] // documentation missing in model
    PendingDelete,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for WarmPoolStatus {
    fn from(s: &str) -> Self {
        match s {
            "PendingDelete" => WarmPoolStatus::PendingDelete,
            other => WarmPoolStatus::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for WarmPoolStatus {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(WarmPoolStatus::from(s))
                }
            }
impl WarmPoolStatus {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            WarmPoolStatus::PendingDelete => "PendingDelete",
            WarmPoolStatus::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "PendingDelete"
        ]
    }
}
impl AsRef<str> for WarmPoolStatus {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Describes the state of a traffic source.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct TrafficSourceState  {
    /// <p>The unique identifier of the traffic source. Currently, this is the Amazon Resource Name (ARN) for a VPC Lattice target group.</p>
    #[doc(hidden)]
    pub traffic_source: std::option::Option<std::string::String>,
    /// <p>The following are the possible states for a VPC Lattice target group:</p> 
    /// <ul> 
    /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the target group.</p> </li> 
    /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the target group.</p> </li> 
    /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed the <code>VPC_LATTICE</code> health check.</p> </li> 
    /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the target group. If connection draining is enabled, VPC Lattice waits for in-flight requests to complete before deregistering the instances.</p> </li> 
    /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the target group.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub state: std::option::Option<std::string::String>,
}
impl TrafficSourceState {
    /// <p>The unique identifier of the traffic source. Currently, this is the Amazon Resource Name (ARN) for a VPC Lattice target group.</p>
    pub fn traffic_source(&self) -> std::option::Option<& str> {
        self.traffic_source.as_deref()
    }
    /// <p>The following are the possible states for a VPC Lattice target group:</p> 
    /// <ul> 
    /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the target group.</p> </li> 
    /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the target group.</p> </li> 
    /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed the <code>VPC_LATTICE</code> health check.</p> </li> 
    /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the target group. If connection draining is enabled, VPC Lattice waits for in-flight requests to complete before deregistering the instances.</p> </li> 
    /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the target group.</p> </li> 
    /// </ul>
    pub fn state(&self) -> std::option::Option<& str> {
        self.state.as_deref()
    }
}
/// See [`TrafficSourceState`](crate::model::TrafficSourceState).
pub mod traffic_source_state {
    
    /// A builder for [`TrafficSourceState`](crate::model::TrafficSourceState).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) traffic_source: std::option::Option<std::string::String>,
        pub(crate) state: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The unique identifier of the traffic source. Currently, this is the Amazon Resource Name (ARN) for a VPC Lattice target group.</p>
        pub fn traffic_source(mut self, input: impl Into<std::string::String>) -> Self {
            self.traffic_source = Some(input.into());
            self
        }
        /// <p>The unique identifier of the traffic source. Currently, this is the Amazon Resource Name (ARN) for a VPC Lattice target group.</p>
        pub fn set_traffic_source(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.traffic_source = input; self
        }
        /// <p>The following are the possible states for a VPC Lattice target group:</p> 
        /// <ul> 
        /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the target group.</p> </li> 
        /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the target group.</p> </li> 
        /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed the <code>VPC_LATTICE</code> health check.</p> </li> 
        /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the target group. If connection draining is enabled, VPC Lattice waits for in-flight requests to complete before deregistering the instances.</p> </li> 
        /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the target group.</p> </li> 
        /// </ul>
        pub fn state(mut self, input: impl Into<std::string::String>) -> Self {
            self.state = Some(input.into());
            self
        }
        /// <p>The following are the possible states for a VPC Lattice target group:</p> 
        /// <ul> 
        /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the target group.</p> </li> 
        /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the target group.</p> </li> 
        /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed the <code>VPC_LATTICE</code> health check.</p> </li> 
        /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the target group. If connection draining is enabled, VPC Lattice waits for in-flight requests to complete before deregistering the instances.</p> </li> 
        /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the target group.</p> </li> 
        /// </ul>
        pub fn set_state(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.state = input; self
        }
        /// Consumes the builder and constructs a [`TrafficSourceState`](crate::model::TrafficSourceState).
        pub fn build(self) -> crate::model::TrafficSourceState {
            crate::model::TrafficSourceState {
                traffic_source: self.traffic_source
                ,
                state: self.state
                ,
            }
        }
    }
    
    
}
impl TrafficSourceState {
    /// Creates a new builder-style object to manufacture [`TrafficSourceState`](crate::model::TrafficSourceState).
    pub fn builder() -> crate::model::traffic_source_state::Builder {
        crate::model::traffic_source_state::Builder::default()
    }
}

/// <p>Describes a tag for an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct TagDescription  {
    /// <p>The name of the group.</p>
    #[doc(hidden)]
    pub resource_id: std::option::Option<std::string::String>,
    /// <p>The type of resource. The only supported value is <code>auto-scaling-group</code>.</p>
    #[doc(hidden)]
    pub resource_type: std::option::Option<std::string::String>,
    /// <p>The tag key.</p>
    #[doc(hidden)]
    pub key: std::option::Option<std::string::String>,
    /// <p>The tag value.</p>
    #[doc(hidden)]
    pub value: std::option::Option<std::string::String>,
    /// <p>Determines whether the tag is added to new instances as they are launched in the group.</p>
    #[doc(hidden)]
    pub propagate_at_launch: std::option::Option<bool>,
}
impl TagDescription {
    /// <p>The name of the group.</p>
    pub fn resource_id(&self) -> std::option::Option<& str> {
        self.resource_id.as_deref()
    }
    /// <p>The type of resource. The only supported value is <code>auto-scaling-group</code>.</p>
    pub fn resource_type(&self) -> std::option::Option<& str> {
        self.resource_type.as_deref()
    }
    /// <p>The tag key.</p>
    pub fn key(&self) -> std::option::Option<& str> {
        self.key.as_deref()
    }
    /// <p>The tag value.</p>
    pub fn value(&self) -> std::option::Option<& str> {
        self.value.as_deref()
    }
    /// <p>Determines whether the tag is added to new instances as they are launched in the group.</p>
    pub fn propagate_at_launch(&self) -> std::option::Option<bool> {
        self.propagate_at_launch
    }
}
/// See [`TagDescription`](crate::model::TagDescription).
pub mod tag_description {
    
    /// A builder for [`TagDescription`](crate::model::TagDescription).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) resource_id: std::option::Option<std::string::String>,
        pub(crate) resource_type: std::option::Option<std::string::String>,
        pub(crate) key: std::option::Option<std::string::String>,
        pub(crate) value: std::option::Option<std::string::String>,
        pub(crate) propagate_at_launch: std::option::Option<bool>,
    }
    impl Builder {
        /// <p>The name of the group.</p>
        pub fn resource_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.resource_id = Some(input.into());
            self
        }
        /// <p>The name of the group.</p>
        pub fn set_resource_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.resource_id = input; self
        }
        /// <p>The type of resource. The only supported value is <code>auto-scaling-group</code>.</p>
        pub fn resource_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.resource_type = Some(input.into());
            self
        }
        /// <p>The type of resource. The only supported value is <code>auto-scaling-group</code>.</p>
        pub fn set_resource_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.resource_type = input; self
        }
        /// <p>The tag key.</p>
        pub fn key(mut self, input: impl Into<std::string::String>) -> Self {
            self.key = Some(input.into());
            self
        }
        /// <p>The tag key.</p>
        pub fn set_key(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.key = input; self
        }
        /// <p>The tag value.</p>
        pub fn value(mut self, input: impl Into<std::string::String>) -> Self {
            self.value = Some(input.into());
            self
        }
        /// <p>The tag value.</p>
        pub fn set_value(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.value = input; self
        }
        /// <p>Determines whether the tag is added to new instances as they are launched in the group.</p>
        pub fn propagate_at_launch(mut self, input: bool) -> Self {
            self.propagate_at_launch = Some(input);
            self
        }
        /// <p>Determines whether the tag is added to new instances as they are launched in the group.</p>
        pub fn set_propagate_at_launch(mut self, input: std::option::Option<bool>) -> Self {
            self.propagate_at_launch = input; self
        }
        /// Consumes the builder and constructs a [`TagDescription`](crate::model::TagDescription).
        pub fn build(self) -> crate::model::TagDescription {
            crate::model::TagDescription {
                resource_id: self.resource_id
                ,
                resource_type: self.resource_type
                ,
                key: self.key
                ,
                value: self.value
                ,
                propagate_at_launch: self.propagate_at_launch
                ,
            }
        }
    }
    
    
}
impl TagDescription {
    /// Creates a new builder-style object to manufacture [`TagDescription`](crate::model::TagDescription).
    pub fn builder() -> crate::model::tag_description::Builder {
        crate::model::tag_description::Builder::default()
    }
}

/// <p>Describes a filter that is used to return a more specific list of results from a describe operation.</p> 
/// <p>If you specify multiple filters, the filters are automatically logically joined with an <code>AND</code>, and the request returns only the results that match all of the specified filters. </p> 
/// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-tagging.html">Tag Auto Scaling groups and instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct Filter  {
    /// <p>The name of the filter.</p> 
    /// <p>The valid values for <code>Name</code> depend on which API operation you're using with the filter (<code>DescribeAutoScalingGroups</code> or <code>DescribeTags</code>).</p> 
    /// <p> <b>DescribeAutoScalingGroups</b> </p> 
    /// <p>Valid values for <code>Name</code> include the following: </p> 
    /// <ul> 
    /// <li> <p> <code>tag-key</code> - Accepts tag keys. The results only include information about the Auto Scaling groups associated with these tag keys. </p> </li> 
    /// <li> <p> <code>tag-value</code> - Accepts tag values. The results only include information about the Auto Scaling groups associated with these tag values. </p> </li> 
    /// <li> <p> <code>tag:
    /// <key></key></code> - Accepts the key/value combination of the tag. Use the tag key in the filter name and the tag value as the filter value. The results only include information about the Auto Scaling groups associated with the specified key/value combination. </p> </li> 
    /// </ul> 
    /// <p> <b>DescribeTags</b> </p> 
    /// <p>Valid values for <code>Name</code> include the following: </p> 
    /// <ul> 
    /// <li> <p> <code>auto-scaling-group</code> - Accepts the names of Auto Scaling groups. The results only include information about the tags associated with these Auto Scaling groups. </p> </li> 
    /// <li> <p> <code>key</code> - Accepts tag keys. The results only include information about the tags associated with these tag keys. </p> </li> 
    /// <li> <p> <code>value</code> - Accepts tag values. The results only include information about the tags associated with these tag values. </p> </li> 
    /// <li> <p> <code>propagate-at-launch</code> - Accepts a Boolean value, which specifies whether tags propagate to instances at launch. The results only include information about the tags associated with the specified Boolean value. </p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub name: std::option::Option<std::string::String>,
    /// <p>One or more filter values. Filter values are case-sensitive. </p> 
    /// <p>If you specify multiple values for a filter, the values are automatically logically joined with an <code>OR</code>, and the request returns all results that match any of the specified values. For example, specify "tag:environment" for the filter name and "production,development" for the filter values to find Auto Scaling groups with the tag "environment=production" or "environment=development".</p>
    #[doc(hidden)]
    pub values: std::option::Option<std::vec::Vec<std::string::String>>,
}
impl Filter {
    /// <p>The name of the filter.</p> 
    /// <p>The valid values for <code>Name</code> depend on which API operation you're using with the filter (<code>DescribeAutoScalingGroups</code> or <code>DescribeTags</code>).</p> 
    /// <p> <b>DescribeAutoScalingGroups</b> </p> 
    /// <p>Valid values for <code>Name</code> include the following: </p> 
    /// <ul> 
    /// <li> <p> <code>tag-key</code> - Accepts tag keys. The results only include information about the Auto Scaling groups associated with these tag keys. </p> </li> 
    /// <li> <p> <code>tag-value</code> - Accepts tag values. The results only include information about the Auto Scaling groups associated with these tag values. </p> </li> 
    /// <li> <p> <code>tag:
    /// <key></key></code> - Accepts the key/value combination of the tag. Use the tag key in the filter name and the tag value as the filter value. The results only include information about the Auto Scaling groups associated with the specified key/value combination. </p> </li> 
    /// </ul> 
    /// <p> <b>DescribeTags</b> </p> 
    /// <p>Valid values for <code>Name</code> include the following: </p> 
    /// <ul> 
    /// <li> <p> <code>auto-scaling-group</code> - Accepts the names of Auto Scaling groups. The results only include information about the tags associated with these Auto Scaling groups. </p> </li> 
    /// <li> <p> <code>key</code> - Accepts tag keys. The results only include information about the tags associated with these tag keys. </p> </li> 
    /// <li> <p> <code>value</code> - Accepts tag values. The results only include information about the tags associated with these tag values. </p> </li> 
    /// <li> <p> <code>propagate-at-launch</code> - Accepts a Boolean value, which specifies whether tags propagate to instances at launch. The results only include information about the tags associated with the specified Boolean value. </p> </li> 
    /// </ul>
    pub fn name(&self) -> std::option::Option<& str> {
        self.name.as_deref()
    }
    /// <p>One or more filter values. Filter values are case-sensitive. </p> 
    /// <p>If you specify multiple values for a filter, the values are automatically logically joined with an <code>OR</code>, and the request returns all results that match any of the specified values. For example, specify "tag:environment" for the filter name and "production,development" for the filter values to find Auto Scaling groups with the tag "environment=production" or "environment=development".</p>
    pub fn values(&self) -> std::option::Option<& [std::string::String]> {
        self.values.as_deref()
    }
}
/// See [`Filter`](crate::model::Filter).
pub mod filter {
    
    /// A builder for [`Filter`](crate::model::Filter).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) name: std::option::Option<std::string::String>,
        pub(crate) values: std::option::Option<std::vec::Vec<std::string::String>>,
    }
    impl Builder {
        /// <p>The name of the filter.</p> 
        /// <p>The valid values for <code>Name</code> depend on which API operation you're using with the filter (<code>DescribeAutoScalingGroups</code> or <code>DescribeTags</code>).</p> 
        /// <p> <b>DescribeAutoScalingGroups</b> </p> 
        /// <p>Valid values for <code>Name</code> include the following: </p> 
        /// <ul> 
        /// <li> <p> <code>tag-key</code> - Accepts tag keys. The results only include information about the Auto Scaling groups associated with these tag keys. </p> </li> 
        /// <li> <p> <code>tag-value</code> - Accepts tag values. The results only include information about the Auto Scaling groups associated with these tag values. </p> </li> 
        /// <li> <p> <code>tag:
        /// <key></key></code> - Accepts the key/value combination of the tag. Use the tag key in the filter name and the tag value as the filter value. The results only include information about the Auto Scaling groups associated with the specified key/value combination. </p> </li> 
        /// </ul> 
        /// <p> <b>DescribeTags</b> </p> 
        /// <p>Valid values for <code>Name</code> include the following: </p> 
        /// <ul> 
        /// <li> <p> <code>auto-scaling-group</code> - Accepts the names of Auto Scaling groups. The results only include information about the tags associated with these Auto Scaling groups. </p> </li> 
        /// <li> <p> <code>key</code> - Accepts tag keys. The results only include information about the tags associated with these tag keys. </p> </li> 
        /// <li> <p> <code>value</code> - Accepts tag values. The results only include information about the tags associated with these tag values. </p> </li> 
        /// <li> <p> <code>propagate-at-launch</code> - Accepts a Boolean value, which specifies whether tags propagate to instances at launch. The results only include information about the tags associated with the specified Boolean value. </p> </li> 
        /// </ul>
        pub fn name(mut self, input: impl Into<std::string::String>) -> Self {
            self.name = Some(input.into());
            self
        }
        /// <p>The name of the filter.</p> 
        /// <p>The valid values for <code>Name</code> depend on which API operation you're using with the filter (<code>DescribeAutoScalingGroups</code> or <code>DescribeTags</code>).</p> 
        /// <p> <b>DescribeAutoScalingGroups</b> </p> 
        /// <p>Valid values for <code>Name</code> include the following: </p> 
        /// <ul> 
        /// <li> <p> <code>tag-key</code> - Accepts tag keys. The results only include information about the Auto Scaling groups associated with these tag keys. </p> </li> 
        /// <li> <p> <code>tag-value</code> - Accepts tag values. The results only include information about the Auto Scaling groups associated with these tag values. </p> </li> 
        /// <li> <p> <code>tag:
        /// <key></key></code> - Accepts the key/value combination of the tag. Use the tag key in the filter name and the tag value as the filter value. The results only include information about the Auto Scaling groups associated with the specified key/value combination. </p> </li> 
        /// </ul> 
        /// <p> <b>DescribeTags</b> </p> 
        /// <p>Valid values for <code>Name</code> include the following: </p> 
        /// <ul> 
        /// <li> <p> <code>auto-scaling-group</code> - Accepts the names of Auto Scaling groups. The results only include information about the tags associated with these Auto Scaling groups. </p> </li> 
        /// <li> <p> <code>key</code> - Accepts tag keys. The results only include information about the tags associated with these tag keys. </p> </li> 
        /// <li> <p> <code>value</code> - Accepts tag values. The results only include information about the tags associated with these tag values. </p> </li> 
        /// <li> <p> <code>propagate-at-launch</code> - Accepts a Boolean value, which specifies whether tags propagate to instances at launch. The results only include information about the tags associated with the specified Boolean value. </p> </li> 
        /// </ul>
        pub fn set_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.name = input; self
        }
        /// Appends an item to `values`.
        ///
        /// To override the contents of this collection use [`set_values`](Self::set_values).
        ///
        /// <p>One or more filter values. Filter values are case-sensitive. </p> 
        /// <p>If you specify multiple values for a filter, the values are automatically logically joined with an <code>OR</code>, and the request returns all results that match any of the specified values. For example, specify "tag:environment" for the filter name and "production,development" for the filter values to find Auto Scaling groups with the tag "environment=production" or "environment=development".</p>
        pub fn values(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.values.unwrap_or_default();
                            v.push(input.into());
                            self.values = Some(v);
                            self
        }
        /// <p>One or more filter values. Filter values are case-sensitive. </p> 
        /// <p>If you specify multiple values for a filter, the values are automatically logically joined with an <code>OR</code>, and the request returns all results that match any of the specified values. For example, specify "tag:environment" for the filter name and "production,development" for the filter values to find Auto Scaling groups with the tag "environment=production" or "environment=development".</p>
        pub fn set_values(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.values = input; self
        }
        /// Consumes the builder and constructs a [`Filter`](crate::model::Filter).
        pub fn build(self) -> crate::model::Filter {
            crate::model::Filter {
                name: self.name
                ,
                values: self.values
                ,
            }
        }
    }
    
    
}
impl Filter {
    /// Creates a new builder-style object to manufacture [`Filter`](crate::model::Filter).
    pub fn builder() -> crate::model::filter::Builder {
        crate::model::filter::Builder::default()
    }
}

/// <p>Describes a scheduled scaling action.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ScheduledUpdateGroupAction  {
    /// <p>The name of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub auto_scaling_group_name: std::option::Option<std::string::String>,
    /// <p>The name of the scheduled action.</p>
    #[doc(hidden)]
    pub scheduled_action_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the scheduled action.</p>
    #[doc(hidden)]
    pub scheduled_action_arn: std::option::Option<std::string::String>,
    /// <p>This property is no longer used.</p>
    #[doc(hidden)]
    pub time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time in UTC for this action to start. For example, <code>"2019-06-01T00:00:00Z"</code>. </p>
    #[doc(hidden)]
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time in UTC for the recurring schedule to end. For example, <code>"2019-06-01T00:00:00Z"</code>. </p>
    #[doc(hidden)]
    pub end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The recurring schedule for the action, in Unix cron syntax format.</p> 
    /// <p>When <code>StartTime</code> and <code>EndTime</code> are specified with <code>Recurrence</code>, they form the boundaries of when the recurring action starts and stops.</p>
    #[doc(hidden)]
    pub recurrence: std::option::Option<std::string::String>,
    /// <p>The minimum size of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub min_size: std::option::Option<i32>,
    /// <p>The maximum size of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub max_size: std::option::Option<i32>,
    /// <p>The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain.</p>
    #[doc(hidden)]
    pub desired_capacity: std::option::Option<i32>,
    /// <p>The time zone for the cron expression.</p>
    #[doc(hidden)]
    pub time_zone: std::option::Option<std::string::String>,
}
impl ScheduledUpdateGroupAction {
    /// <p>The name of the Auto Scaling group.</p>
    pub fn auto_scaling_group_name(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_name.as_deref()
    }
    /// <p>The name of the scheduled action.</p>
    pub fn scheduled_action_name(&self) -> std::option::Option<& str> {
        self.scheduled_action_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the scheduled action.</p>
    pub fn scheduled_action_arn(&self) -> std::option::Option<& str> {
        self.scheduled_action_arn.as_deref()
    }
    /// <p>This property is no longer used.</p>
    pub fn time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.time.as_ref()
    }
    /// <p>The date and time in UTC for this action to start. For example, <code>"2019-06-01T00:00:00Z"</code>. </p>
    pub fn start_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p>The date and time in UTC for the recurring schedule to end. For example, <code>"2019-06-01T00:00:00Z"</code>. </p>
    pub fn end_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.end_time.as_ref()
    }
    /// <p>The recurring schedule for the action, in Unix cron syntax format.</p> 
    /// <p>When <code>StartTime</code> and <code>EndTime</code> are specified with <code>Recurrence</code>, they form the boundaries of when the recurring action starts and stops.</p>
    pub fn recurrence(&self) -> std::option::Option<& str> {
        self.recurrence.as_deref()
    }
    /// <p>The minimum size of the Auto Scaling group.</p>
    pub fn min_size(&self) -> std::option::Option<i32> {
        self.min_size
    }
    /// <p>The maximum size of the Auto Scaling group.</p>
    pub fn max_size(&self) -> std::option::Option<i32> {
        self.max_size
    }
    /// <p>The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain.</p>
    pub fn desired_capacity(&self) -> std::option::Option<i32> {
        self.desired_capacity
    }
    /// <p>The time zone for the cron expression.</p>
    pub fn time_zone(&self) -> std::option::Option<& str> {
        self.time_zone.as_deref()
    }
}
/// See [`ScheduledUpdateGroupAction`](crate::model::ScheduledUpdateGroupAction).
pub mod scheduled_update_group_action {
    
    /// A builder for [`ScheduledUpdateGroupAction`](crate::model::ScheduledUpdateGroupAction).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) auto_scaling_group_name: std::option::Option<std::string::String>,
        pub(crate) scheduled_action_name: std::option::Option<std::string::String>,
        pub(crate) scheduled_action_arn: std::option::Option<std::string::String>,
        pub(crate) time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) end_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) recurrence: std::option::Option<std::string::String>,
        pub(crate) min_size: std::option::Option<i32>,
        pub(crate) max_size: std::option::Option<i32>,
        pub(crate) desired_capacity: std::option::Option<i32>,
        pub(crate) time_zone: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.auto_scaling_group_name = Some(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.auto_scaling_group_name = input; self
        }
        /// <p>The name of the scheduled action.</p>
        pub fn scheduled_action_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.scheduled_action_name = Some(input.into());
            self
        }
        /// <p>The name of the scheduled action.</p>
        pub fn set_scheduled_action_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.scheduled_action_name = input; self
        }
        /// <p>The Amazon Resource Name (ARN) of the scheduled action.</p>
        pub fn scheduled_action_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.scheduled_action_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the scheduled action.</p>
        pub fn set_scheduled_action_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.scheduled_action_arn = input; self
        }
        /// <p>This property is no longer used.</p>
        pub fn time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.time = Some(input);
            self
        }
        /// <p>This property is no longer used.</p>
        pub fn set_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.time = input; self
        }
        /// <p>The date and time in UTC for this action to start. For example, <code>"2019-06-01T00:00:00Z"</code>. </p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p>The date and time in UTC for this action to start. For example, <code>"2019-06-01T00:00:00Z"</code>. </p>
        pub fn set_start_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.start_time = input; self
        }
        /// <p>The date and time in UTC for the recurring schedule to end. For example, <code>"2019-06-01T00:00:00Z"</code>. </p>
        pub fn end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.end_time = Some(input);
            self
        }
        /// <p>The date and time in UTC for the recurring schedule to end. For example, <code>"2019-06-01T00:00:00Z"</code>. </p>
        pub fn set_end_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.end_time = input; self
        }
        /// <p>The recurring schedule for the action, in Unix cron syntax format.</p> 
        /// <p>When <code>StartTime</code> and <code>EndTime</code> are specified with <code>Recurrence</code>, they form the boundaries of when the recurring action starts and stops.</p>
        pub fn recurrence(mut self, input: impl Into<std::string::String>) -> Self {
            self.recurrence = Some(input.into());
            self
        }
        /// <p>The recurring schedule for the action, in Unix cron syntax format.</p> 
        /// <p>When <code>StartTime</code> and <code>EndTime</code> are specified with <code>Recurrence</code>, they form the boundaries of when the recurring action starts and stops.</p>
        pub fn set_recurrence(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.recurrence = input; self
        }
        /// <p>The minimum size of the Auto Scaling group.</p>
        pub fn min_size(mut self, input: i32) -> Self {
            self.min_size = Some(input);
            self
        }
        /// <p>The minimum size of the Auto Scaling group.</p>
        pub fn set_min_size(mut self, input: std::option::Option<i32>) -> Self {
            self.min_size = input; self
        }
        /// <p>The maximum size of the Auto Scaling group.</p>
        pub fn max_size(mut self, input: i32) -> Self {
            self.max_size = Some(input);
            self
        }
        /// <p>The maximum size of the Auto Scaling group.</p>
        pub fn set_max_size(mut self, input: std::option::Option<i32>) -> Self {
            self.max_size = input; self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain.</p>
        pub fn desired_capacity(mut self, input: i32) -> Self {
            self.desired_capacity = Some(input);
            self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain.</p>
        pub fn set_desired_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.desired_capacity = input; self
        }
        /// <p>The time zone for the cron expression.</p>
        pub fn time_zone(mut self, input: impl Into<std::string::String>) -> Self {
            self.time_zone = Some(input.into());
            self
        }
        /// <p>The time zone for the cron expression.</p>
        pub fn set_time_zone(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.time_zone = input; self
        }
        /// Consumes the builder and constructs a [`ScheduledUpdateGroupAction`](crate::model::ScheduledUpdateGroupAction).
        pub fn build(self) -> crate::model::ScheduledUpdateGroupAction {
            crate::model::ScheduledUpdateGroupAction {
                auto_scaling_group_name: self.auto_scaling_group_name
                ,
                scheduled_action_name: self.scheduled_action_name
                ,
                scheduled_action_arn: self.scheduled_action_arn
                ,
                time: self.time
                ,
                start_time: self.start_time
                ,
                end_time: self.end_time
                ,
                recurrence: self.recurrence
                ,
                min_size: self.min_size
                ,
                max_size: self.max_size
                ,
                desired_capacity: self.desired_capacity
                ,
                time_zone: self.time_zone
                ,
            }
        }
    }
    
    
}
impl ScheduledUpdateGroupAction {
    /// Creates a new builder-style object to manufacture [`ScheduledUpdateGroupAction`](crate::model::ScheduledUpdateGroupAction).
    pub fn builder() -> crate::model::scheduled_update_group_action::Builder {
        crate::model::scheduled_update_group_action::Builder::default()
    }
}

/// <p>Describes a process type.</p> 
/// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-suspend-resume-processes.html#process-types">Scaling processes</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ProcessType  {
    /// <p>One of the following processes:</p> 
    /// <ul> 
    /// <li> <p> <code>Launch</code> </p> </li> 
    /// <li> <p> <code>Terminate</code> </p> </li> 
    /// <li> <p> <code>AddToLoadBalancer</code> </p> </li> 
    /// <li> <p> <code>AlarmNotification</code> </p> </li> 
    /// <li> <p> <code>AZRebalance</code> </p> </li> 
    /// <li> <p> <code>HealthCheck</code> </p> </li> 
    /// <li> <p> <code>InstanceRefresh</code> </p> </li> 
    /// <li> <p> <code>ReplaceUnhealthy</code> </p> </li> 
    /// <li> <p> <code>ScheduledActions</code> </p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub process_name: std::option::Option<std::string::String>,
}
impl ProcessType {
    /// <p>One of the following processes:</p> 
    /// <ul> 
    /// <li> <p> <code>Launch</code> </p> </li> 
    /// <li> <p> <code>Terminate</code> </p> </li> 
    /// <li> <p> <code>AddToLoadBalancer</code> </p> </li> 
    /// <li> <p> <code>AlarmNotification</code> </p> </li> 
    /// <li> <p> <code>AZRebalance</code> </p> </li> 
    /// <li> <p> <code>HealthCheck</code> </p> </li> 
    /// <li> <p> <code>InstanceRefresh</code> </p> </li> 
    /// <li> <p> <code>ReplaceUnhealthy</code> </p> </li> 
    /// <li> <p> <code>ScheduledActions</code> </p> </li> 
    /// </ul>
    pub fn process_name(&self) -> std::option::Option<& str> {
        self.process_name.as_deref()
    }
}
/// See [`ProcessType`](crate::model::ProcessType).
pub mod process_type {
    
    /// A builder for [`ProcessType`](crate::model::ProcessType).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) process_name: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>One of the following processes:</p> 
        /// <ul> 
        /// <li> <p> <code>Launch</code> </p> </li> 
        /// <li> <p> <code>Terminate</code> </p> </li> 
        /// <li> <p> <code>AddToLoadBalancer</code> </p> </li> 
        /// <li> <p> <code>AlarmNotification</code> </p> </li> 
        /// <li> <p> <code>AZRebalance</code> </p> </li> 
        /// <li> <p> <code>HealthCheck</code> </p> </li> 
        /// <li> <p> <code>InstanceRefresh</code> </p> </li> 
        /// <li> <p> <code>ReplaceUnhealthy</code> </p> </li> 
        /// <li> <p> <code>ScheduledActions</code> </p> </li> 
        /// </ul>
        pub fn process_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.process_name = Some(input.into());
            self
        }
        /// <p>One of the following processes:</p> 
        /// <ul> 
        /// <li> <p> <code>Launch</code> </p> </li> 
        /// <li> <p> <code>Terminate</code> </p> </li> 
        /// <li> <p> <code>AddToLoadBalancer</code> </p> </li> 
        /// <li> <p> <code>AlarmNotification</code> </p> </li> 
        /// <li> <p> <code>AZRebalance</code> </p> </li> 
        /// <li> <p> <code>HealthCheck</code> </p> </li> 
        /// <li> <p> <code>InstanceRefresh</code> </p> </li> 
        /// <li> <p> <code>ReplaceUnhealthy</code> </p> </li> 
        /// <li> <p> <code>ScheduledActions</code> </p> </li> 
        /// </ul>
        pub fn set_process_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.process_name = input; self
        }
        /// Consumes the builder and constructs a [`ProcessType`](crate::model::ProcessType).
        pub fn build(self) -> crate::model::ProcessType {
            crate::model::ProcessType {
                process_name: self.process_name
                ,
            }
        }
    }
    
    
}
impl ProcessType {
    /// Creates a new builder-style object to manufacture [`ProcessType`](crate::model::ProcessType).
    pub fn builder() -> crate::model::process_type::Builder {
        crate::model::process_type::Builder::default()
    }
}

/// <p>Describes a scaling policy.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ScalingPolicy  {
    /// <p>The name of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub auto_scaling_group_name: std::option::Option<std::string::String>,
    /// <p>The name of the scaling policy.</p>
    #[doc(hidden)]
    pub policy_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the policy.</p>
    #[doc(hidden)]
    pub policy_arn: std::option::Option<std::string::String>,
    /// <p>One of the following policy types: </p> 
    /// <ul> 
    /// <li> <p> <code>TargetTrackingScaling</code> </p> </li> 
    /// <li> <p> <code>StepScaling</code> </p> </li> 
    /// <li> <p> <code>SimpleScaling</code> (default)</p> </li> 
    /// <li> <p> <code>PredictiveScaling</code> </p> </li> 
    /// </ul> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-target-tracking.html">Target tracking scaling policies</a> and <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html">Step and simple scaling policies</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[doc(hidden)]
    pub policy_type: std::option::Option<std::string::String>,
    /// <p>Specifies how the scaling adjustment is interpreted (for example, an absolute number or a percentage). The valid values are <code>ChangeInCapacity</code>, <code>ExactCapacity</code>, and <code>PercentChangeInCapacity</code>.</p>
    #[doc(hidden)]
    pub adjustment_type: std::option::Option<std::string::String>,
    /// <p>Available for backward compatibility. Use <code>MinAdjustmentMagnitude</code> instead.</p>
    #[doc(hidden)]
    pub min_adjustment_step: std::option::Option<i32>,
    /// <p>The minimum value to scale by when the adjustment type is <code>PercentChangeInCapacity</code>. </p>
    #[doc(hidden)]
    pub min_adjustment_magnitude: std::option::Option<i32>,
    /// <p>The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity.</p>
    #[doc(hidden)]
    pub scaling_adjustment: std::option::Option<i32>,
    /// <p>The duration of the policy's cooldown period, in seconds.</p>
    #[doc(hidden)]
    pub cooldown: std::option::Option<i32>,
    /// <p>A set of adjustments that enable you to scale based on the size of the alarm breach.</p>
    #[doc(hidden)]
    pub step_adjustments: std::option::Option<std::vec::Vec<crate::model::StepAdjustment>>,
    /// <p>The aggregation type for the CloudWatch metrics. The valid values are <code>Minimum</code>, <code>Maximum</code>, and <code>Average</code>.</p>
    #[doc(hidden)]
    pub metric_aggregation_type: std::option::Option<std::string::String>,
    /// <p>The estimated time, in seconds, until a newly launched instance can contribute to the CloudWatch metrics.</p>
    #[doc(hidden)]
    pub estimated_instance_warmup: std::option::Option<i32>,
    /// <p>The CloudWatch alarms related to the policy.</p>
    #[doc(hidden)]
    pub alarms: std::option::Option<std::vec::Vec<crate::model::Alarm>>,
    /// <p>A target tracking scaling policy.</p>
    #[doc(hidden)]
    pub target_tracking_configuration: std::option::Option<crate::model::TargetTrackingConfiguration>,
    /// <p>Indicates whether the policy is enabled (<code>true</code>) or disabled (<code>false</code>).</p>
    #[doc(hidden)]
    pub enabled: std::option::Option<bool>,
    /// <p>A predictive scaling policy.</p>
    #[doc(hidden)]
    pub predictive_scaling_configuration: std::option::Option<crate::model::PredictiveScalingConfiguration>,
}
impl ScalingPolicy {
    /// <p>The name of the Auto Scaling group.</p>
    pub fn auto_scaling_group_name(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_name.as_deref()
    }
    /// <p>The name of the scaling policy.</p>
    pub fn policy_name(&self) -> std::option::Option<& str> {
        self.policy_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the policy.</p>
    pub fn policy_arn(&self) -> std::option::Option<& str> {
        self.policy_arn.as_deref()
    }
    /// <p>One of the following policy types: </p> 
    /// <ul> 
    /// <li> <p> <code>TargetTrackingScaling</code> </p> </li> 
    /// <li> <p> <code>StepScaling</code> </p> </li> 
    /// <li> <p> <code>SimpleScaling</code> (default)</p> </li> 
    /// <li> <p> <code>PredictiveScaling</code> </p> </li> 
    /// </ul> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-target-tracking.html">Target tracking scaling policies</a> and <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html">Step and simple scaling policies</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    pub fn policy_type(&self) -> std::option::Option<& str> {
        self.policy_type.as_deref()
    }
    /// <p>Specifies how the scaling adjustment is interpreted (for example, an absolute number or a percentage). The valid values are <code>ChangeInCapacity</code>, <code>ExactCapacity</code>, and <code>PercentChangeInCapacity</code>.</p>
    pub fn adjustment_type(&self) -> std::option::Option<& str> {
        self.adjustment_type.as_deref()
    }
    /// <p>Available for backward compatibility. Use <code>MinAdjustmentMagnitude</code> instead.</p>
    pub fn min_adjustment_step(&self) -> std::option::Option<i32> {
        self.min_adjustment_step
    }
    /// <p>The minimum value to scale by when the adjustment type is <code>PercentChangeInCapacity</code>. </p>
    pub fn min_adjustment_magnitude(&self) -> std::option::Option<i32> {
        self.min_adjustment_magnitude
    }
    /// <p>The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity.</p>
    pub fn scaling_adjustment(&self) -> std::option::Option<i32> {
        self.scaling_adjustment
    }
    /// <p>The duration of the policy's cooldown period, in seconds.</p>
    pub fn cooldown(&self) -> std::option::Option<i32> {
        self.cooldown
    }
    /// <p>A set of adjustments that enable you to scale based on the size of the alarm breach.</p>
    pub fn step_adjustments(&self) -> std::option::Option<& [crate::model::StepAdjustment]> {
        self.step_adjustments.as_deref()
    }
    /// <p>The aggregation type for the CloudWatch metrics. The valid values are <code>Minimum</code>, <code>Maximum</code>, and <code>Average</code>.</p>
    pub fn metric_aggregation_type(&self) -> std::option::Option<& str> {
        self.metric_aggregation_type.as_deref()
    }
    /// <p>The estimated time, in seconds, until a newly launched instance can contribute to the CloudWatch metrics.</p>
    pub fn estimated_instance_warmup(&self) -> std::option::Option<i32> {
        self.estimated_instance_warmup
    }
    /// <p>The CloudWatch alarms related to the policy.</p>
    pub fn alarms(&self) -> std::option::Option<& [crate::model::Alarm]> {
        self.alarms.as_deref()
    }
    /// <p>A target tracking scaling policy.</p>
    pub fn target_tracking_configuration(&self) -> std::option::Option<& crate::model::TargetTrackingConfiguration> {
        self.target_tracking_configuration.as_ref()
    }
    /// <p>Indicates whether the policy is enabled (<code>true</code>) or disabled (<code>false</code>).</p>
    pub fn enabled(&self) -> std::option::Option<bool> {
        self.enabled
    }
    /// <p>A predictive scaling policy.</p>
    pub fn predictive_scaling_configuration(&self) -> std::option::Option<& crate::model::PredictiveScalingConfiguration> {
        self.predictive_scaling_configuration.as_ref()
    }
}
/// See [`ScalingPolicy`](crate::model::ScalingPolicy).
pub mod scaling_policy {
    
    /// A builder for [`ScalingPolicy`](crate::model::ScalingPolicy).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) auto_scaling_group_name: std::option::Option<std::string::String>,
        pub(crate) policy_name: std::option::Option<std::string::String>,
        pub(crate) policy_arn: std::option::Option<std::string::String>,
        pub(crate) policy_type: std::option::Option<std::string::String>,
        pub(crate) adjustment_type: std::option::Option<std::string::String>,
        pub(crate) min_adjustment_step: std::option::Option<i32>,
        pub(crate) min_adjustment_magnitude: std::option::Option<i32>,
        pub(crate) scaling_adjustment: std::option::Option<i32>,
        pub(crate) cooldown: std::option::Option<i32>,
        pub(crate) step_adjustments: std::option::Option<std::vec::Vec<crate::model::StepAdjustment>>,
        pub(crate) metric_aggregation_type: std::option::Option<std::string::String>,
        pub(crate) estimated_instance_warmup: std::option::Option<i32>,
        pub(crate) alarms: std::option::Option<std::vec::Vec<crate::model::Alarm>>,
        pub(crate) target_tracking_configuration: std::option::Option<crate::model::TargetTrackingConfiguration>,
        pub(crate) enabled: std::option::Option<bool>,
        pub(crate) predictive_scaling_configuration: std::option::Option<crate::model::PredictiveScalingConfiguration>,
    }
    impl Builder {
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.auto_scaling_group_name = Some(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.auto_scaling_group_name = input; self
        }
        /// <p>The name of the scaling policy.</p>
        pub fn policy_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.policy_name = Some(input.into());
            self
        }
        /// <p>The name of the scaling policy.</p>
        pub fn set_policy_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.policy_name = input; self
        }
        /// <p>The Amazon Resource Name (ARN) of the policy.</p>
        pub fn policy_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.policy_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the policy.</p>
        pub fn set_policy_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.policy_arn = input; self
        }
        /// <p>One of the following policy types: </p> 
        /// <ul> 
        /// <li> <p> <code>TargetTrackingScaling</code> </p> </li> 
        /// <li> <p> <code>StepScaling</code> </p> </li> 
        /// <li> <p> <code>SimpleScaling</code> (default)</p> </li> 
        /// <li> <p> <code>PredictiveScaling</code> </p> </li> 
        /// </ul> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-target-tracking.html">Target tracking scaling policies</a> and <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html">Step and simple scaling policies</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn policy_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.policy_type = Some(input.into());
            self
        }
        /// <p>One of the following policy types: </p> 
        /// <ul> 
        /// <li> <p> <code>TargetTrackingScaling</code> </p> </li> 
        /// <li> <p> <code>StepScaling</code> </p> </li> 
        /// <li> <p> <code>SimpleScaling</code> (default)</p> </li> 
        /// <li> <p> <code>PredictiveScaling</code> </p> </li> 
        /// </ul> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-target-tracking.html">Target tracking scaling policies</a> and <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html">Step and simple scaling policies</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_policy_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.policy_type = input; self
        }
        /// <p>Specifies how the scaling adjustment is interpreted (for example, an absolute number or a percentage). The valid values are <code>ChangeInCapacity</code>, <code>ExactCapacity</code>, and <code>PercentChangeInCapacity</code>.</p>
        pub fn adjustment_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.adjustment_type = Some(input.into());
            self
        }
        /// <p>Specifies how the scaling adjustment is interpreted (for example, an absolute number or a percentage). The valid values are <code>ChangeInCapacity</code>, <code>ExactCapacity</code>, and <code>PercentChangeInCapacity</code>.</p>
        pub fn set_adjustment_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.adjustment_type = input; self
        }
        /// <p>Available for backward compatibility. Use <code>MinAdjustmentMagnitude</code> instead.</p>
        pub fn min_adjustment_step(mut self, input: i32) -> Self {
            self.min_adjustment_step = Some(input);
            self
        }
        /// <p>Available for backward compatibility. Use <code>MinAdjustmentMagnitude</code> instead.</p>
        pub fn set_min_adjustment_step(mut self, input: std::option::Option<i32>) -> Self {
            self.min_adjustment_step = input; self
        }
        /// <p>The minimum value to scale by when the adjustment type is <code>PercentChangeInCapacity</code>. </p>
        pub fn min_adjustment_magnitude(mut self, input: i32) -> Self {
            self.min_adjustment_magnitude = Some(input);
            self
        }
        /// <p>The minimum value to scale by when the adjustment type is <code>PercentChangeInCapacity</code>. </p>
        pub fn set_min_adjustment_magnitude(mut self, input: std::option::Option<i32>) -> Self {
            self.min_adjustment_magnitude = input; self
        }
        /// <p>The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity.</p>
        pub fn scaling_adjustment(mut self, input: i32) -> Self {
            self.scaling_adjustment = Some(input);
            self
        }
        /// <p>The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity.</p>
        pub fn set_scaling_adjustment(mut self, input: std::option::Option<i32>) -> Self {
            self.scaling_adjustment = input; self
        }
        /// <p>The duration of the policy's cooldown period, in seconds.</p>
        pub fn cooldown(mut self, input: i32) -> Self {
            self.cooldown = Some(input);
            self
        }
        /// <p>The duration of the policy's cooldown period, in seconds.</p>
        pub fn set_cooldown(mut self, input: std::option::Option<i32>) -> Self {
            self.cooldown = input; self
        }
        /// Appends an item to `step_adjustments`.
        ///
        /// To override the contents of this collection use [`set_step_adjustments`](Self::set_step_adjustments).
        ///
        /// <p>A set of adjustments that enable you to scale based on the size of the alarm breach.</p>
        pub fn step_adjustments(mut self, input: crate::model::StepAdjustment) -> Self {
            let mut v = self.step_adjustments.unwrap_or_default();
                            v.push(input);
                            self.step_adjustments = Some(v);
                            self
        }
        /// <p>A set of adjustments that enable you to scale based on the size of the alarm breach.</p>
        pub fn set_step_adjustments(mut self, input: std::option::Option<std::vec::Vec<crate::model::StepAdjustment>>) -> Self {
            self.step_adjustments = input; self
        }
        /// <p>The aggregation type for the CloudWatch metrics. The valid values are <code>Minimum</code>, <code>Maximum</code>, and <code>Average</code>.</p>
        pub fn metric_aggregation_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.metric_aggregation_type = Some(input.into());
            self
        }
        /// <p>The aggregation type for the CloudWatch metrics. The valid values are <code>Minimum</code>, <code>Maximum</code>, and <code>Average</code>.</p>
        pub fn set_metric_aggregation_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.metric_aggregation_type = input; self
        }
        /// <p>The estimated time, in seconds, until a newly launched instance can contribute to the CloudWatch metrics.</p>
        pub fn estimated_instance_warmup(mut self, input: i32) -> Self {
            self.estimated_instance_warmup = Some(input);
            self
        }
        /// <p>The estimated time, in seconds, until a newly launched instance can contribute to the CloudWatch metrics.</p>
        pub fn set_estimated_instance_warmup(mut self, input: std::option::Option<i32>) -> Self {
            self.estimated_instance_warmup = input; self
        }
        /// Appends an item to `alarms`.
        ///
        /// To override the contents of this collection use [`set_alarms`](Self::set_alarms).
        ///
        /// <p>The CloudWatch alarms related to the policy.</p>
        pub fn alarms(mut self, input: crate::model::Alarm) -> Self {
            let mut v = self.alarms.unwrap_or_default();
                            v.push(input);
                            self.alarms = Some(v);
                            self
        }
        /// <p>The CloudWatch alarms related to the policy.</p>
        pub fn set_alarms(mut self, input: std::option::Option<std::vec::Vec<crate::model::Alarm>>) -> Self {
            self.alarms = input; self
        }
        /// <p>A target tracking scaling policy.</p>
        pub fn target_tracking_configuration(mut self, input: crate::model::TargetTrackingConfiguration) -> Self {
            self.target_tracking_configuration = Some(input);
            self
        }
        /// <p>A target tracking scaling policy.</p>
        pub fn set_target_tracking_configuration(mut self, input: std::option::Option<crate::model::TargetTrackingConfiguration>) -> Self {
            self.target_tracking_configuration = input; self
        }
        /// <p>Indicates whether the policy is enabled (<code>true</code>) or disabled (<code>false</code>).</p>
        pub fn enabled(mut self, input: bool) -> Self {
            self.enabled = Some(input);
            self
        }
        /// <p>Indicates whether the policy is enabled (<code>true</code>) or disabled (<code>false</code>).</p>
        pub fn set_enabled(mut self, input: std::option::Option<bool>) -> Self {
            self.enabled = input; self
        }
        /// <p>A predictive scaling policy.</p>
        pub fn predictive_scaling_configuration(mut self, input: crate::model::PredictiveScalingConfiguration) -> Self {
            self.predictive_scaling_configuration = Some(input);
            self
        }
        /// <p>A predictive scaling policy.</p>
        pub fn set_predictive_scaling_configuration(mut self, input: std::option::Option<crate::model::PredictiveScalingConfiguration>) -> Self {
            self.predictive_scaling_configuration = input; self
        }
        /// Consumes the builder and constructs a [`ScalingPolicy`](crate::model::ScalingPolicy).
        pub fn build(self) -> crate::model::ScalingPolicy {
            crate::model::ScalingPolicy {
                auto_scaling_group_name: self.auto_scaling_group_name
                ,
                policy_name: self.policy_name
                ,
                policy_arn: self.policy_arn
                ,
                policy_type: self.policy_type
                ,
                adjustment_type: self.adjustment_type
                ,
                min_adjustment_step: self.min_adjustment_step
                ,
                min_adjustment_magnitude: self.min_adjustment_magnitude
                ,
                scaling_adjustment: self.scaling_adjustment
                ,
                cooldown: self.cooldown
                ,
                step_adjustments: self.step_adjustments
                ,
                metric_aggregation_type: self.metric_aggregation_type
                ,
                estimated_instance_warmup: self.estimated_instance_warmup
                ,
                alarms: self.alarms
                ,
                target_tracking_configuration: self.target_tracking_configuration
                ,
                enabled: self.enabled
                ,
                predictive_scaling_configuration: self.predictive_scaling_configuration
                ,
            }
        }
    }
    
    
}
impl ScalingPolicy {
    /// Creates a new builder-style object to manufacture [`ScalingPolicy`](crate::model::ScalingPolicy).
    pub fn builder() -> crate::model::scaling_policy::Builder {
        crate::model::scaling_policy::Builder::default()
    }
}

/// <p>Describes a notification.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct NotificationConfiguration  {
    /// <p>The name of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub auto_scaling_group_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the Amazon SNS topic.</p>
    #[doc(hidden)]
    pub topic_arn: std::option::Option<std::string::String>,
    /// <p>One of the following event notification types:</p> 
    /// <ul> 
    /// <li> <p> <code>autoscaling:EC2_INSTANCE_LAUNCH</code> </p> </li> 
    /// <li> <p> <code>autoscaling:EC2_INSTANCE_LAUNCH_ERROR</code> </p> </li> 
    /// <li> <p> <code>autoscaling:EC2_INSTANCE_TERMINATE</code> </p> </li> 
    /// <li> <p> <code>autoscaling:EC2_INSTANCE_TERMINATE_ERROR</code> </p> </li> 
    /// <li> <p> <code>autoscaling:TEST_NOTIFICATION</code> </p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub notification_type: std::option::Option<std::string::String>,
}
impl NotificationConfiguration {
    /// <p>The name of the Auto Scaling group.</p>
    pub fn auto_scaling_group_name(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the Amazon SNS topic.</p>
    pub fn topic_arn(&self) -> std::option::Option<& str> {
        self.topic_arn.as_deref()
    }
    /// <p>One of the following event notification types:</p> 
    /// <ul> 
    /// <li> <p> <code>autoscaling:EC2_INSTANCE_LAUNCH</code> </p> </li> 
    /// <li> <p> <code>autoscaling:EC2_INSTANCE_LAUNCH_ERROR</code> </p> </li> 
    /// <li> <p> <code>autoscaling:EC2_INSTANCE_TERMINATE</code> </p> </li> 
    /// <li> <p> <code>autoscaling:EC2_INSTANCE_TERMINATE_ERROR</code> </p> </li> 
    /// <li> <p> <code>autoscaling:TEST_NOTIFICATION</code> </p> </li> 
    /// </ul>
    pub fn notification_type(&self) -> std::option::Option<& str> {
        self.notification_type.as_deref()
    }
}
/// See [`NotificationConfiguration`](crate::model::NotificationConfiguration).
pub mod notification_configuration {
    
    /// A builder for [`NotificationConfiguration`](crate::model::NotificationConfiguration).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) auto_scaling_group_name: std::option::Option<std::string::String>,
        pub(crate) topic_arn: std::option::Option<std::string::String>,
        pub(crate) notification_type: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.auto_scaling_group_name = Some(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.auto_scaling_group_name = input; self
        }
        /// <p>The Amazon Resource Name (ARN) of the Amazon SNS topic.</p>
        pub fn topic_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.topic_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the Amazon SNS topic.</p>
        pub fn set_topic_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.topic_arn = input; self
        }
        /// <p>One of the following event notification types:</p> 
        /// <ul> 
        /// <li> <p> <code>autoscaling:EC2_INSTANCE_LAUNCH</code> </p> </li> 
        /// <li> <p> <code>autoscaling:EC2_INSTANCE_LAUNCH_ERROR</code> </p> </li> 
        /// <li> <p> <code>autoscaling:EC2_INSTANCE_TERMINATE</code> </p> </li> 
        /// <li> <p> <code>autoscaling:EC2_INSTANCE_TERMINATE_ERROR</code> </p> </li> 
        /// <li> <p> <code>autoscaling:TEST_NOTIFICATION</code> </p> </li> 
        /// </ul>
        pub fn notification_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.notification_type = Some(input.into());
            self
        }
        /// <p>One of the following event notification types:</p> 
        /// <ul> 
        /// <li> <p> <code>autoscaling:EC2_INSTANCE_LAUNCH</code> </p> </li> 
        /// <li> <p> <code>autoscaling:EC2_INSTANCE_LAUNCH_ERROR</code> </p> </li> 
        /// <li> <p> <code>autoscaling:EC2_INSTANCE_TERMINATE</code> </p> </li> 
        /// <li> <p> <code>autoscaling:EC2_INSTANCE_TERMINATE_ERROR</code> </p> </li> 
        /// <li> <p> <code>autoscaling:TEST_NOTIFICATION</code> </p> </li> 
        /// </ul>
        pub fn set_notification_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.notification_type = input; self
        }
        /// Consumes the builder and constructs a [`NotificationConfiguration`](crate::model::NotificationConfiguration).
        pub fn build(self) -> crate::model::NotificationConfiguration {
            crate::model::NotificationConfiguration {
                auto_scaling_group_name: self.auto_scaling_group_name
                ,
                topic_arn: self.topic_arn
                ,
                notification_type: self.notification_type
                ,
            }
        }
    }
    
    
}
impl NotificationConfiguration {
    /// Creates a new builder-style object to manufacture [`NotificationConfiguration`](crate::model::NotificationConfiguration).
    pub fn builder() -> crate::model::notification_configuration::Builder {
        crate::model::notification_configuration::Builder::default()
    }
}

/// <p>Describes a granularity of a metric.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct MetricGranularityType  {
    /// <p>The granularity. The only valid value is <code>1Minute</code>.</p>
    #[doc(hidden)]
    pub granularity: std::option::Option<std::string::String>,
}
impl MetricGranularityType {
    /// <p>The granularity. The only valid value is <code>1Minute</code>.</p>
    pub fn granularity(&self) -> std::option::Option<& str> {
        self.granularity.as_deref()
    }
}
/// See [`MetricGranularityType`](crate::model::MetricGranularityType).
pub mod metric_granularity_type {
    
    /// A builder for [`MetricGranularityType`](crate::model::MetricGranularityType).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) granularity: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The granularity. The only valid value is <code>1Minute</code>.</p>
        pub fn granularity(mut self, input: impl Into<std::string::String>) -> Self {
            self.granularity = Some(input.into());
            self
        }
        /// <p>The granularity. The only valid value is <code>1Minute</code>.</p>
        pub fn set_granularity(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.granularity = input; self
        }
        /// Consumes the builder and constructs a [`MetricGranularityType`](crate::model::MetricGranularityType).
        pub fn build(self) -> crate::model::MetricGranularityType {
            crate::model::MetricGranularityType {
                granularity: self.granularity
                ,
            }
        }
    }
    
    
}
impl MetricGranularityType {
    /// Creates a new builder-style object to manufacture [`MetricGranularityType`](crate::model::MetricGranularityType).
    pub fn builder() -> crate::model::metric_granularity_type::Builder {
        crate::model::metric_granularity_type::Builder::default()
    }
}

/// <p>Describes a metric.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct MetricCollectionType  {
    /// <p>One of the following metrics:</p> 
    /// <ul> 
    /// <li> <p> <code>GroupMinSize</code> </p> </li> 
    /// <li> <p> <code>GroupMaxSize</code> </p> </li> 
    /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupInServiceInstances</code> </p> </li> 
    /// <li> <p> <code>GroupPendingInstances</code> </p> </li> 
    /// <li> <p> <code>GroupStandbyInstances</code> </p> </li> 
    /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li> 
    /// <li> <p> <code>GroupTotalInstances</code> </p> </li> 
    /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupPendingCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupTotalCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub metric: std::option::Option<std::string::String>,
}
impl MetricCollectionType {
    /// <p>One of the following metrics:</p> 
    /// <ul> 
    /// <li> <p> <code>GroupMinSize</code> </p> </li> 
    /// <li> <p> <code>GroupMaxSize</code> </p> </li> 
    /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupInServiceInstances</code> </p> </li> 
    /// <li> <p> <code>GroupPendingInstances</code> </p> </li> 
    /// <li> <p> <code>GroupStandbyInstances</code> </p> </li> 
    /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li> 
    /// <li> <p> <code>GroupTotalInstances</code> </p> </li> 
    /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupPendingCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupTotalCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li> 
    /// </ul>
    pub fn metric(&self) -> std::option::Option<& str> {
        self.metric.as_deref()
    }
}
/// See [`MetricCollectionType`](crate::model::MetricCollectionType).
pub mod metric_collection_type {
    
    /// A builder for [`MetricCollectionType`](crate::model::MetricCollectionType).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) metric: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>One of the following metrics:</p> 
        /// <ul> 
        /// <li> <p> <code>GroupMinSize</code> </p> </li> 
        /// <li> <p> <code>GroupMaxSize</code> </p> </li> 
        /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupInServiceInstances</code> </p> </li> 
        /// <li> <p> <code>GroupPendingInstances</code> </p> </li> 
        /// <li> <p> <code>GroupStandbyInstances</code> </p> </li> 
        /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li> 
        /// <li> <p> <code>GroupTotalInstances</code> </p> </li> 
        /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupPendingCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupTotalCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li> 
        /// </ul>
        pub fn metric(mut self, input: impl Into<std::string::String>) -> Self {
            self.metric = Some(input.into());
            self
        }
        /// <p>One of the following metrics:</p> 
        /// <ul> 
        /// <li> <p> <code>GroupMinSize</code> </p> </li> 
        /// <li> <p> <code>GroupMaxSize</code> </p> </li> 
        /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupInServiceInstances</code> </p> </li> 
        /// <li> <p> <code>GroupPendingInstances</code> </p> </li> 
        /// <li> <p> <code>GroupStandbyInstances</code> </p> </li> 
        /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li> 
        /// <li> <p> <code>GroupTotalInstances</code> </p> </li> 
        /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupPendingCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupTotalCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li> 
        /// </ul>
        pub fn set_metric(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.metric = input; self
        }
        /// Consumes the builder and constructs a [`MetricCollectionType`](crate::model::MetricCollectionType).
        pub fn build(self) -> crate::model::MetricCollectionType {
            crate::model::MetricCollectionType {
                metric: self.metric
                ,
            }
        }
    }
    
    
}
impl MetricCollectionType {
    /// Creates a new builder-style object to manufacture [`MetricCollectionType`](crate::model::MetricCollectionType).
    pub fn builder() -> crate::model::metric_collection_type::Builder {
        crate::model::metric_collection_type::Builder::default()
    }
}

/// <p>Describes the state of a target group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct LoadBalancerTargetGroupState  {
    /// <p>The Amazon Resource Name (ARN) of the target group.</p>
    #[doc(hidden)]
    pub load_balancer_target_group_arn: std::option::Option<std::string::String>,
    /// <p>The state of the target group.</p> 
    /// <ul> 
    /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the target group.</p> </li> 
    /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the target group.</p> </li> 
    /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed an <code>ELB</code> health check.</p> </li> 
    /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the target group. If connection draining is enabled, Elastic Load Balancing waits for in-flight requests to complete before deregistering the instances.</p> </li> 
    /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the target group.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub state: std::option::Option<std::string::String>,
}
impl LoadBalancerTargetGroupState {
    /// <p>The Amazon Resource Name (ARN) of the target group.</p>
    pub fn load_balancer_target_group_arn(&self) -> std::option::Option<& str> {
        self.load_balancer_target_group_arn.as_deref()
    }
    /// <p>The state of the target group.</p> 
    /// <ul> 
    /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the target group.</p> </li> 
    /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the target group.</p> </li> 
    /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed an <code>ELB</code> health check.</p> </li> 
    /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the target group. If connection draining is enabled, Elastic Load Balancing waits for in-flight requests to complete before deregistering the instances.</p> </li> 
    /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the target group.</p> </li> 
    /// </ul>
    pub fn state(&self) -> std::option::Option<& str> {
        self.state.as_deref()
    }
}
/// See [`LoadBalancerTargetGroupState`](crate::model::LoadBalancerTargetGroupState).
pub mod load_balancer_target_group_state {
    
    /// A builder for [`LoadBalancerTargetGroupState`](crate::model::LoadBalancerTargetGroupState).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) load_balancer_target_group_arn: std::option::Option<std::string::String>,
        pub(crate) state: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The Amazon Resource Name (ARN) of the target group.</p>
        pub fn load_balancer_target_group_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.load_balancer_target_group_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the target group.</p>
        pub fn set_load_balancer_target_group_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.load_balancer_target_group_arn = input; self
        }
        /// <p>The state of the target group.</p> 
        /// <ul> 
        /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the target group.</p> </li> 
        /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the target group.</p> </li> 
        /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed an <code>ELB</code> health check.</p> </li> 
        /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the target group. If connection draining is enabled, Elastic Load Balancing waits for in-flight requests to complete before deregistering the instances.</p> </li> 
        /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the target group.</p> </li> 
        /// </ul>
        pub fn state(mut self, input: impl Into<std::string::String>) -> Self {
            self.state = Some(input.into());
            self
        }
        /// <p>The state of the target group.</p> 
        /// <ul> 
        /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the target group.</p> </li> 
        /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the target group.</p> </li> 
        /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed an <code>ELB</code> health check.</p> </li> 
        /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the target group. If connection draining is enabled, Elastic Load Balancing waits for in-flight requests to complete before deregistering the instances.</p> </li> 
        /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the target group.</p> </li> 
        /// </ul>
        pub fn set_state(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.state = input; self
        }
        /// Consumes the builder and constructs a [`LoadBalancerTargetGroupState`](crate::model::LoadBalancerTargetGroupState).
        pub fn build(self) -> crate::model::LoadBalancerTargetGroupState {
            crate::model::LoadBalancerTargetGroupState {
                load_balancer_target_group_arn: self.load_balancer_target_group_arn
                ,
                state: self.state
                ,
            }
        }
    }
    
    
}
impl LoadBalancerTargetGroupState {
    /// Creates a new builder-style object to manufacture [`LoadBalancerTargetGroupState`](crate::model::LoadBalancerTargetGroupState).
    pub fn builder() -> crate::model::load_balancer_target_group_state::Builder {
        crate::model::load_balancer_target_group_state::Builder::default()
    }
}

/// <p>Describes the state of a Classic Load Balancer.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct LoadBalancerState  {
    /// <p>The name of the load balancer.</p>
    #[doc(hidden)]
    pub load_balancer_name: std::option::Option<std::string::String>,
    /// <p>One of the following load balancer states:</p> 
    /// <ul> 
    /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the load balancer.</p> </li> 
    /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the load balancer.</p> </li> 
    /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed an <code>ELB</code> health check.</p> </li> 
    /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the load balancer. If connection draining is enabled, Elastic Load Balancing waits for in-flight requests to complete before deregistering the instances.</p> </li> 
    /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the load balancer.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub state: std::option::Option<std::string::String>,
}
impl LoadBalancerState {
    /// <p>The name of the load balancer.</p>
    pub fn load_balancer_name(&self) -> std::option::Option<& str> {
        self.load_balancer_name.as_deref()
    }
    /// <p>One of the following load balancer states:</p> 
    /// <ul> 
    /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the load balancer.</p> </li> 
    /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the load balancer.</p> </li> 
    /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed an <code>ELB</code> health check.</p> </li> 
    /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the load balancer. If connection draining is enabled, Elastic Load Balancing waits for in-flight requests to complete before deregistering the instances.</p> </li> 
    /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the load balancer.</p> </li> 
    /// </ul>
    pub fn state(&self) -> std::option::Option<& str> {
        self.state.as_deref()
    }
}
/// See [`LoadBalancerState`](crate::model::LoadBalancerState).
pub mod load_balancer_state {
    
    /// A builder for [`LoadBalancerState`](crate::model::LoadBalancerState).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) load_balancer_name: std::option::Option<std::string::String>,
        pub(crate) state: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the load balancer.</p>
        pub fn load_balancer_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.load_balancer_name = Some(input.into());
            self
        }
        /// <p>The name of the load balancer.</p>
        pub fn set_load_balancer_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.load_balancer_name = input; self
        }
        /// <p>One of the following load balancer states:</p> 
        /// <ul> 
        /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the load balancer.</p> </li> 
        /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the load balancer.</p> </li> 
        /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed an <code>ELB</code> health check.</p> </li> 
        /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the load balancer. If connection draining is enabled, Elastic Load Balancing waits for in-flight requests to complete before deregistering the instances.</p> </li> 
        /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the load balancer.</p> </li> 
        /// </ul>
        pub fn state(mut self, input: impl Into<std::string::String>) -> Self {
            self.state = Some(input.into());
            self
        }
        /// <p>One of the following load balancer states:</p> 
        /// <ul> 
        /// <li> <p> <code>Adding</code> - The Auto Scaling instances are being registered with the load balancer.</p> </li> 
        /// <li> <p> <code>Added</code> - All Auto Scaling instances are registered with the load balancer.</p> </li> 
        /// <li> <p> <code>InService</code> - At least one Auto Scaling instance passed an <code>ELB</code> health check.</p> </li> 
        /// <li> <p> <code>Removing</code> - The Auto Scaling instances are being deregistered from the load balancer. If connection draining is enabled, Elastic Load Balancing waits for in-flight requests to complete before deregistering the instances.</p> </li> 
        /// <li> <p> <code>Removed</code> - All Auto Scaling instances are deregistered from the load balancer.</p> </li> 
        /// </ul>
        pub fn set_state(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.state = input; self
        }
        /// Consumes the builder and constructs a [`LoadBalancerState`](crate::model::LoadBalancerState).
        pub fn build(self) -> crate::model::LoadBalancerState {
            crate::model::LoadBalancerState {
                load_balancer_name: self.load_balancer_name
                ,
                state: self.state
                ,
            }
        }
    }
    
    
}
impl LoadBalancerState {
    /// Creates a new builder-style object to manufacture [`LoadBalancerState`](crate::model::LoadBalancerState).
    pub fn builder() -> crate::model::load_balancer_state::Builder {
        crate::model::load_balancer_state::Builder::default()
    }
}

/// <p>Describes a lifecycle hook. A lifecycle hook lets you create solutions that are aware of events in the Auto Scaling instance lifecycle, and then perform a custom action on instances when the corresponding lifecycle event occurs.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct LifecycleHook  {
    /// <p>The name of the lifecycle hook.</p>
    #[doc(hidden)]
    pub lifecycle_hook_name: std::option::Option<std::string::String>,
    /// <p>The name of the Auto Scaling group for the lifecycle hook.</p>
    #[doc(hidden)]
    pub auto_scaling_group_name: std::option::Option<std::string::String>,
    /// <p>The lifecycle transition.</p> 
    /// <p>Valid values: <code>autoscaling:EC2_INSTANCE_LAUNCHING</code> | <code>autoscaling:EC2_INSTANCE_TERMINATING</code> </p>
    #[doc(hidden)]
    pub lifecycle_transition: std::option::Option<std::string::String>,
    /// <p>The ARN of the target that Amazon EC2 Auto Scaling sends notifications to when an instance is in a wait state for the lifecycle hook.</p>
    #[doc(hidden)]
    pub notification_target_arn: std::option::Option<std::string::String>,
    /// <p>The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target (an Amazon SNS topic or an Amazon SQS queue).</p>
    #[doc(hidden)]
    pub role_arn: std::option::Option<std::string::String>,
    /// <p>Additional information that is included any time Amazon EC2 Auto Scaling sends a message to the notification target.</p>
    #[doc(hidden)]
    pub notification_metadata: std::option::Option<std::string::String>,
    /// <p>The maximum time, in seconds, that can elapse before the lifecycle hook times out. If the lifecycle hook times out, Amazon EC2 Auto Scaling performs the action that you specified in the <code>DefaultResult</code> property.</p>
    #[doc(hidden)]
    pub heartbeat_timeout: std::option::Option<i32>,
    /// <p>The maximum time, in seconds, that an instance can remain in a wait state. The maximum is 172800 seconds (48 hours) or 100 times <code>HeartbeatTimeout</code>, whichever is smaller.</p>
    #[doc(hidden)]
    pub global_timeout: std::option::Option<i32>,
    /// <p>The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs.</p> 
    /// <p>Valid values: <code>CONTINUE</code> | <code>ABANDON</code> </p>
    #[doc(hidden)]
    pub default_result: std::option::Option<std::string::String>,
}
impl LifecycleHook {
    /// <p>The name of the lifecycle hook.</p>
    pub fn lifecycle_hook_name(&self) -> std::option::Option<& str> {
        self.lifecycle_hook_name.as_deref()
    }
    /// <p>The name of the Auto Scaling group for the lifecycle hook.</p>
    pub fn auto_scaling_group_name(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_name.as_deref()
    }
    /// <p>The lifecycle transition.</p> 
    /// <p>Valid values: <code>autoscaling:EC2_INSTANCE_LAUNCHING</code> | <code>autoscaling:EC2_INSTANCE_TERMINATING</code> </p>
    pub fn lifecycle_transition(&self) -> std::option::Option<& str> {
        self.lifecycle_transition.as_deref()
    }
    /// <p>The ARN of the target that Amazon EC2 Auto Scaling sends notifications to when an instance is in a wait state for the lifecycle hook.</p>
    pub fn notification_target_arn(&self) -> std::option::Option<& str> {
        self.notification_target_arn.as_deref()
    }
    /// <p>The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target (an Amazon SNS topic or an Amazon SQS queue).</p>
    pub fn role_arn(&self) -> std::option::Option<& str> {
        self.role_arn.as_deref()
    }
    /// <p>Additional information that is included any time Amazon EC2 Auto Scaling sends a message to the notification target.</p>
    pub fn notification_metadata(&self) -> std::option::Option<& str> {
        self.notification_metadata.as_deref()
    }
    /// <p>The maximum time, in seconds, that can elapse before the lifecycle hook times out. If the lifecycle hook times out, Amazon EC2 Auto Scaling performs the action that you specified in the <code>DefaultResult</code> property.</p>
    pub fn heartbeat_timeout(&self) -> std::option::Option<i32> {
        self.heartbeat_timeout
    }
    /// <p>The maximum time, in seconds, that an instance can remain in a wait state. The maximum is 172800 seconds (48 hours) or 100 times <code>HeartbeatTimeout</code>, whichever is smaller.</p>
    pub fn global_timeout(&self) -> std::option::Option<i32> {
        self.global_timeout
    }
    /// <p>The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs.</p> 
    /// <p>Valid values: <code>CONTINUE</code> | <code>ABANDON</code> </p>
    pub fn default_result(&self) -> std::option::Option<& str> {
        self.default_result.as_deref()
    }
}
/// See [`LifecycleHook`](crate::model::LifecycleHook).
pub mod lifecycle_hook {
    
    /// A builder for [`LifecycleHook`](crate::model::LifecycleHook).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) lifecycle_hook_name: std::option::Option<std::string::String>,
        pub(crate) auto_scaling_group_name: std::option::Option<std::string::String>,
        pub(crate) lifecycle_transition: std::option::Option<std::string::String>,
        pub(crate) notification_target_arn: std::option::Option<std::string::String>,
        pub(crate) role_arn: std::option::Option<std::string::String>,
        pub(crate) notification_metadata: std::option::Option<std::string::String>,
        pub(crate) heartbeat_timeout: std::option::Option<i32>,
        pub(crate) global_timeout: std::option::Option<i32>,
        pub(crate) default_result: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the lifecycle hook.</p>
        pub fn lifecycle_hook_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.lifecycle_hook_name = Some(input.into());
            self
        }
        /// <p>The name of the lifecycle hook.</p>
        pub fn set_lifecycle_hook_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.lifecycle_hook_name = input; self
        }
        /// <p>The name of the Auto Scaling group for the lifecycle hook.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.auto_scaling_group_name = Some(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group for the lifecycle hook.</p>
        pub fn set_auto_scaling_group_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.auto_scaling_group_name = input; self
        }
        /// <p>The lifecycle transition.</p> 
        /// <p>Valid values: <code>autoscaling:EC2_INSTANCE_LAUNCHING</code> | <code>autoscaling:EC2_INSTANCE_TERMINATING</code> </p>
        pub fn lifecycle_transition(mut self, input: impl Into<std::string::String>) -> Self {
            self.lifecycle_transition = Some(input.into());
            self
        }
        /// <p>The lifecycle transition.</p> 
        /// <p>Valid values: <code>autoscaling:EC2_INSTANCE_LAUNCHING</code> | <code>autoscaling:EC2_INSTANCE_TERMINATING</code> </p>
        pub fn set_lifecycle_transition(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.lifecycle_transition = input; self
        }
        /// <p>The ARN of the target that Amazon EC2 Auto Scaling sends notifications to when an instance is in a wait state for the lifecycle hook.</p>
        pub fn notification_target_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.notification_target_arn = Some(input.into());
            self
        }
        /// <p>The ARN of the target that Amazon EC2 Auto Scaling sends notifications to when an instance is in a wait state for the lifecycle hook.</p>
        pub fn set_notification_target_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.notification_target_arn = input; self
        }
        /// <p>The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target (an Amazon SNS topic or an Amazon SQS queue).</p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.role_arn = Some(input.into());
            self
        }
        /// <p>The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target (an Amazon SNS topic or an Amazon SQS queue).</p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.role_arn = input; self
        }
        /// <p>Additional information that is included any time Amazon EC2 Auto Scaling sends a message to the notification target.</p>
        pub fn notification_metadata(mut self, input: impl Into<std::string::String>) -> Self {
            self.notification_metadata = Some(input.into());
            self
        }
        /// <p>Additional information that is included any time Amazon EC2 Auto Scaling sends a message to the notification target.</p>
        pub fn set_notification_metadata(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.notification_metadata = input; self
        }
        /// <p>The maximum time, in seconds, that can elapse before the lifecycle hook times out. If the lifecycle hook times out, Amazon EC2 Auto Scaling performs the action that you specified in the <code>DefaultResult</code> property.</p>
        pub fn heartbeat_timeout(mut self, input: i32) -> Self {
            self.heartbeat_timeout = Some(input);
            self
        }
        /// <p>The maximum time, in seconds, that can elapse before the lifecycle hook times out. If the lifecycle hook times out, Amazon EC2 Auto Scaling performs the action that you specified in the <code>DefaultResult</code> property.</p>
        pub fn set_heartbeat_timeout(mut self, input: std::option::Option<i32>) -> Self {
            self.heartbeat_timeout = input; self
        }
        /// <p>The maximum time, in seconds, that an instance can remain in a wait state. The maximum is 172800 seconds (48 hours) or 100 times <code>HeartbeatTimeout</code>, whichever is smaller.</p>
        pub fn global_timeout(mut self, input: i32) -> Self {
            self.global_timeout = Some(input);
            self
        }
        /// <p>The maximum time, in seconds, that an instance can remain in a wait state. The maximum is 172800 seconds (48 hours) or 100 times <code>HeartbeatTimeout</code>, whichever is smaller.</p>
        pub fn set_global_timeout(mut self, input: std::option::Option<i32>) -> Self {
            self.global_timeout = input; self
        }
        /// <p>The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs.</p> 
        /// <p>Valid values: <code>CONTINUE</code> | <code>ABANDON</code> </p>
        pub fn default_result(mut self, input: impl Into<std::string::String>) -> Self {
            self.default_result = Some(input.into());
            self
        }
        /// <p>The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs.</p> 
        /// <p>Valid values: <code>CONTINUE</code> | <code>ABANDON</code> </p>
        pub fn set_default_result(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.default_result = input; self
        }
        /// Consumes the builder and constructs a [`LifecycleHook`](crate::model::LifecycleHook).
        pub fn build(self) -> crate::model::LifecycleHook {
            crate::model::LifecycleHook {
                lifecycle_hook_name: self.lifecycle_hook_name
                ,
                auto_scaling_group_name: self.auto_scaling_group_name
                ,
                lifecycle_transition: self.lifecycle_transition
                ,
                notification_target_arn: self.notification_target_arn
                ,
                role_arn: self.role_arn
                ,
                notification_metadata: self.notification_metadata
                ,
                heartbeat_timeout: self.heartbeat_timeout
                ,
                global_timeout: self.global_timeout
                ,
                default_result: self.default_result
                ,
            }
        }
    }
    
    
}
impl LifecycleHook {
    /// Creates a new builder-style object to manufacture [`LifecycleHook`](crate::model::LifecycleHook).
    pub fn builder() -> crate::model::lifecycle_hook::Builder {
        crate::model::lifecycle_hook::Builder::default()
    }
}

/// <p>Describes a launch configuration.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct LaunchConfiguration  {
    /// <p>The name of the launch configuration.</p>
    #[doc(hidden)]
    pub launch_configuration_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the launch configuration.</p>
    #[doc(hidden)]
    pub launch_configuration_arn: std::option::Option<std::string::String>,
    /// <p>The ID of the Amazon Machine Image (AMI) to use to launch your EC2 instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html">Find a Linux AMI</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    #[doc(hidden)]
    pub image_id: std::option::Option<std::string::String>,
    /// <p>The name of the key pair.</p> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html">Amazon EC2 Key Pairs</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    #[doc(hidden)]
    pub key_name: std::option::Option<std::string::String>,
    /// <p>A list that contains the security groups to assign to the instances in the Auto Scaling group. For more information, see <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html">Security Groups for Your VPC</a> in the <i>Amazon Virtual Private Cloud User Guide</i>.</p>
    #[doc(hidden)]
    pub security_groups: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>Available for backward compatibility.</p>
    #[doc(hidden)]
    pub classic_link_vpc_id: std::option::Option<std::string::String>,
    /// <p>Available for backward compatibility.</p>
    #[doc(hidden)]
    pub classic_link_vpc_security_groups: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>The user data to make available to the launched EC2 instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Linux) and <a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Windows). If you are using a command line tool, base64-encoding is performed for you, and you can load the text from a file. Otherwise, you must provide base64-encoded text. User data is limited to 16 KB.</p>
    #[doc(hidden)]
    pub user_data: std::option::Option<std::string::String>,
    /// <p>The instance type for the instances. For information about available instance types, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#AvailableInstanceTypes">Available instance types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    #[doc(hidden)]
    pub instance_type: std::option::Option<std::string::String>,
    /// <p>The ID of the kernel associated with the AMI.</p>
    #[doc(hidden)]
    pub kernel_id: std::option::Option<std::string::String>,
    /// <p>The ID of the RAM disk associated with the AMI.</p>
    #[doc(hidden)]
    pub ramdisk_id: std::option::Option<std::string::String>,
    /// <p>The block device mapping entries that define the block devices to attach to the instances at launch. By default, the block devices specified in the block device mapping for the AMI are used. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html">Block Device Mapping</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    #[doc(hidden)]
    pub block_device_mappings: std::option::Option<std::vec::Vec<crate::model::BlockDeviceMapping>>,
    /// <p>Controls whether instances in this group are launched with detailed (<code>true</code>) or basic (<code>false</code>) monitoring.</p> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/latest/userguide/enable-as-instance-metrics.html">Configure Monitoring for Auto Scaling Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[doc(hidden)]
    pub instance_monitoring: std::option::Option<crate::model::InstanceMonitoring>,
    /// <p>The maximum hourly price to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot price. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-launch-spot-instances.html">Requesting Spot Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[doc(hidden)]
    pub spot_price: std::option::Option<std::string::String>,
    /// <p>The name or the Amazon Resource Name (ARN) of the instance profile associated with the IAM role for the instance. The instance profile contains the IAM role. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/us-iam-role.html">IAM role for applications that run on Amazon EC2 instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[doc(hidden)]
    pub iam_instance_profile: std::option::Option<std::string::String>,
    /// <p>The creation date and time for the launch configuration.</p>
    #[doc(hidden)]
    pub created_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>Specifies whether the launch configuration is optimized for EBS I/O (<code>true</code>) or not (<code>false</code>). For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html">Amazon EBS-Optimized Instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    #[doc(hidden)]
    pub ebs_optimized: std::option::Option<bool>,
    /// <p>Specifies whether to assign a public IPv4 address to the group's instances. If the instance is launched into a default subnet, the default is to assign a public IPv4 address, unless you disabled the option to assign a public IPv4 address on the subnet. If the instance is launched into a nondefault subnet, the default is not to assign a public IPv4 address, unless you enabled the option to assign a public IPv4 address on the subnet. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-in-vpc.html">Launching Auto Scaling instances in a VPC</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[doc(hidden)]
    pub associate_public_ip_address: std::option::Option<bool>,
    /// <p>The tenancy of the instance, either <code>default</code> or <code>dedicated</code>. An instance with <code>dedicated</code> tenancy runs on isolated, single-tenant hardware and can only be launched into a VPC.</p> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-dedicated-instances.html">Configuring instance tenancy with Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[doc(hidden)]
    pub placement_tenancy: std::option::Option<std::string::String>,
    /// <p>The metadata options for the instances. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-config.html#launch-configurations-imds">Configuring the Instance Metadata Options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[doc(hidden)]
    pub metadata_options: std::option::Option<crate::model::InstanceMetadataOptions>,
}
impl LaunchConfiguration {
    /// <p>The name of the launch configuration.</p>
    pub fn launch_configuration_name(&self) -> std::option::Option<& str> {
        self.launch_configuration_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the launch configuration.</p>
    pub fn launch_configuration_arn(&self) -> std::option::Option<& str> {
        self.launch_configuration_arn.as_deref()
    }
    /// <p>The ID of the Amazon Machine Image (AMI) to use to launch your EC2 instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html">Find a Linux AMI</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    pub fn image_id(&self) -> std::option::Option<& str> {
        self.image_id.as_deref()
    }
    /// <p>The name of the key pair.</p> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html">Amazon EC2 Key Pairs</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    pub fn key_name(&self) -> std::option::Option<& str> {
        self.key_name.as_deref()
    }
    /// <p>A list that contains the security groups to assign to the instances in the Auto Scaling group. For more information, see <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html">Security Groups for Your VPC</a> in the <i>Amazon Virtual Private Cloud User Guide</i>.</p>
    pub fn security_groups(&self) -> std::option::Option<& [std::string::String]> {
        self.security_groups.as_deref()
    }
    /// <p>Available for backward compatibility.</p>
    pub fn classic_link_vpc_id(&self) -> std::option::Option<& str> {
        self.classic_link_vpc_id.as_deref()
    }
    /// <p>Available for backward compatibility.</p>
    pub fn classic_link_vpc_security_groups(&self) -> std::option::Option<& [std::string::String]> {
        self.classic_link_vpc_security_groups.as_deref()
    }
    /// <p>The user data to make available to the launched EC2 instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Linux) and <a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Windows). If you are using a command line tool, base64-encoding is performed for you, and you can load the text from a file. Otherwise, you must provide base64-encoded text. User data is limited to 16 KB.</p>
    pub fn user_data(&self) -> std::option::Option<& str> {
        self.user_data.as_deref()
    }
    /// <p>The instance type for the instances. For information about available instance types, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#AvailableInstanceTypes">Available instance types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    pub fn instance_type(&self) -> std::option::Option<& str> {
        self.instance_type.as_deref()
    }
    /// <p>The ID of the kernel associated with the AMI.</p>
    pub fn kernel_id(&self) -> std::option::Option<& str> {
        self.kernel_id.as_deref()
    }
    /// <p>The ID of the RAM disk associated with the AMI.</p>
    pub fn ramdisk_id(&self) -> std::option::Option<& str> {
        self.ramdisk_id.as_deref()
    }
    /// <p>The block device mapping entries that define the block devices to attach to the instances at launch. By default, the block devices specified in the block device mapping for the AMI are used. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html">Block Device Mapping</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    pub fn block_device_mappings(&self) -> std::option::Option<& [crate::model::BlockDeviceMapping]> {
        self.block_device_mappings.as_deref()
    }
    /// <p>Controls whether instances in this group are launched with detailed (<code>true</code>) or basic (<code>false</code>) monitoring.</p> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/latest/userguide/enable-as-instance-metrics.html">Configure Monitoring for Auto Scaling Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    pub fn instance_monitoring(&self) -> std::option::Option<& crate::model::InstanceMonitoring> {
        self.instance_monitoring.as_ref()
    }
    /// <p>The maximum hourly price to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot price. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-launch-spot-instances.html">Requesting Spot Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    pub fn spot_price(&self) -> std::option::Option<& str> {
        self.spot_price.as_deref()
    }
    /// <p>The name or the Amazon Resource Name (ARN) of the instance profile associated with the IAM role for the instance. The instance profile contains the IAM role. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/us-iam-role.html">IAM role for applications that run on Amazon EC2 instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    pub fn iam_instance_profile(&self) -> std::option::Option<& str> {
        self.iam_instance_profile.as_deref()
    }
    /// <p>The creation date and time for the launch configuration.</p>
    pub fn created_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.created_time.as_ref()
    }
    /// <p>Specifies whether the launch configuration is optimized for EBS I/O (<code>true</code>) or not (<code>false</code>). For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html">Amazon EBS-Optimized Instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    pub fn ebs_optimized(&self) -> std::option::Option<bool> {
        self.ebs_optimized
    }
    /// <p>Specifies whether to assign a public IPv4 address to the group's instances. If the instance is launched into a default subnet, the default is to assign a public IPv4 address, unless you disabled the option to assign a public IPv4 address on the subnet. If the instance is launched into a nondefault subnet, the default is not to assign a public IPv4 address, unless you enabled the option to assign a public IPv4 address on the subnet. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-in-vpc.html">Launching Auto Scaling instances in a VPC</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    pub fn associate_public_ip_address(&self) -> std::option::Option<bool> {
        self.associate_public_ip_address
    }
    /// <p>The tenancy of the instance, either <code>default</code> or <code>dedicated</code>. An instance with <code>dedicated</code> tenancy runs on isolated, single-tenant hardware and can only be launched into a VPC.</p> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-dedicated-instances.html">Configuring instance tenancy with Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    pub fn placement_tenancy(&self) -> std::option::Option<& str> {
        self.placement_tenancy.as_deref()
    }
    /// <p>The metadata options for the instances. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-config.html#launch-configurations-imds">Configuring the Instance Metadata Options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    pub fn metadata_options(&self) -> std::option::Option<& crate::model::InstanceMetadataOptions> {
        self.metadata_options.as_ref()
    }
}
/// See [`LaunchConfiguration`](crate::model::LaunchConfiguration).
pub mod launch_configuration {
    
    /// A builder for [`LaunchConfiguration`](crate::model::LaunchConfiguration).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) launch_configuration_name: std::option::Option<std::string::String>,
        pub(crate) launch_configuration_arn: std::option::Option<std::string::String>,
        pub(crate) image_id: std::option::Option<std::string::String>,
        pub(crate) key_name: std::option::Option<std::string::String>,
        pub(crate) security_groups: std::option::Option<std::vec::Vec<std::string::String>>,
        pub(crate) classic_link_vpc_id: std::option::Option<std::string::String>,
        pub(crate) classic_link_vpc_security_groups: std::option::Option<std::vec::Vec<std::string::String>>,
        pub(crate) user_data: std::option::Option<std::string::String>,
        pub(crate) instance_type: std::option::Option<std::string::String>,
        pub(crate) kernel_id: std::option::Option<std::string::String>,
        pub(crate) ramdisk_id: std::option::Option<std::string::String>,
        pub(crate) block_device_mappings: std::option::Option<std::vec::Vec<crate::model::BlockDeviceMapping>>,
        pub(crate) instance_monitoring: std::option::Option<crate::model::InstanceMonitoring>,
        pub(crate) spot_price: std::option::Option<std::string::String>,
        pub(crate) iam_instance_profile: std::option::Option<std::string::String>,
        pub(crate) created_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) ebs_optimized: std::option::Option<bool>,
        pub(crate) associate_public_ip_address: std::option::Option<bool>,
        pub(crate) placement_tenancy: std::option::Option<std::string::String>,
        pub(crate) metadata_options: std::option::Option<crate::model::InstanceMetadataOptions>,
    }
    impl Builder {
        /// <p>The name of the launch configuration.</p>
        pub fn launch_configuration_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.launch_configuration_name = Some(input.into());
            self
        }
        /// <p>The name of the launch configuration.</p>
        pub fn set_launch_configuration_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.launch_configuration_name = input; self
        }
        /// <p>The Amazon Resource Name (ARN) of the launch configuration.</p>
        pub fn launch_configuration_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.launch_configuration_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the launch configuration.</p>
        pub fn set_launch_configuration_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.launch_configuration_arn = input; self
        }
        /// <p>The ID of the Amazon Machine Image (AMI) to use to launch your EC2 instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html">Find a Linux AMI</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn image_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.image_id = Some(input.into());
            self
        }
        /// <p>The ID of the Amazon Machine Image (AMI) to use to launch your EC2 instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html">Find a Linux AMI</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn set_image_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.image_id = input; self
        }
        /// <p>The name of the key pair.</p> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html">Amazon EC2 Key Pairs</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn key_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.key_name = Some(input.into());
            self
        }
        /// <p>The name of the key pair.</p> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html">Amazon EC2 Key Pairs</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn set_key_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.key_name = input; self
        }
        /// Appends an item to `security_groups`.
        ///
        /// To override the contents of this collection use [`set_security_groups`](Self::set_security_groups).
        ///
        /// <p>A list that contains the security groups to assign to the instances in the Auto Scaling group. For more information, see <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html">Security Groups for Your VPC</a> in the <i>Amazon Virtual Private Cloud User Guide</i>.</p>
        pub fn security_groups(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.security_groups.unwrap_or_default();
                            v.push(input.into());
                            self.security_groups = Some(v);
                            self
        }
        /// <p>A list that contains the security groups to assign to the instances in the Auto Scaling group. For more information, see <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html">Security Groups for Your VPC</a> in the <i>Amazon Virtual Private Cloud User Guide</i>.</p>
        pub fn set_security_groups(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.security_groups = input; self
        }
        /// <p>Available for backward compatibility.</p>
        pub fn classic_link_vpc_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.classic_link_vpc_id = Some(input.into());
            self
        }
        /// <p>Available for backward compatibility.</p>
        pub fn set_classic_link_vpc_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.classic_link_vpc_id = input; self
        }
        /// Appends an item to `classic_link_vpc_security_groups`.
        ///
        /// To override the contents of this collection use [`set_classic_link_vpc_security_groups`](Self::set_classic_link_vpc_security_groups).
        ///
        /// <p>Available for backward compatibility.</p>
        pub fn classic_link_vpc_security_groups(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.classic_link_vpc_security_groups.unwrap_or_default();
                            v.push(input.into());
                            self.classic_link_vpc_security_groups = Some(v);
                            self
        }
        /// <p>Available for backward compatibility.</p>
        pub fn set_classic_link_vpc_security_groups(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.classic_link_vpc_security_groups = input; self
        }
        /// <p>The user data to make available to the launched EC2 instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Linux) and <a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Windows). If you are using a command line tool, base64-encoding is performed for you, and you can load the text from a file. Otherwise, you must provide base64-encoded text. User data is limited to 16 KB.</p>
        pub fn user_data(mut self, input: impl Into<std::string::String>) -> Self {
            self.user_data = Some(input.into());
            self
        }
        /// <p>The user data to make available to the launched EC2 instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Linux) and <a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Windows). If you are using a command line tool, base64-encoding is performed for you, and you can load the text from a file. Otherwise, you must provide base64-encoded text. User data is limited to 16 KB.</p>
        pub fn set_user_data(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.user_data = input; self
        }
        /// <p>The instance type for the instances. For information about available instance types, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#AvailableInstanceTypes">Available instance types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn instance_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.instance_type = Some(input.into());
            self
        }
        /// <p>The instance type for the instances. For information about available instance types, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#AvailableInstanceTypes">Available instance types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn set_instance_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.instance_type = input; self
        }
        /// <p>The ID of the kernel associated with the AMI.</p>
        pub fn kernel_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.kernel_id = Some(input.into());
            self
        }
        /// <p>The ID of the kernel associated with the AMI.</p>
        pub fn set_kernel_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.kernel_id = input; self
        }
        /// <p>The ID of the RAM disk associated with the AMI.</p>
        pub fn ramdisk_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.ramdisk_id = Some(input.into());
            self
        }
        /// <p>The ID of the RAM disk associated with the AMI.</p>
        pub fn set_ramdisk_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.ramdisk_id = input; self
        }
        /// Appends an item to `block_device_mappings`.
        ///
        /// To override the contents of this collection use [`set_block_device_mappings`](Self::set_block_device_mappings).
        ///
        /// <p>The block device mapping entries that define the block devices to attach to the instances at launch. By default, the block devices specified in the block device mapping for the AMI are used. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html">Block Device Mapping</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn block_device_mappings(mut self, input: crate::model::BlockDeviceMapping) -> Self {
            let mut v = self.block_device_mappings.unwrap_or_default();
                            v.push(input);
                            self.block_device_mappings = Some(v);
                            self
        }
        /// <p>The block device mapping entries that define the block devices to attach to the instances at launch. By default, the block devices specified in the block device mapping for the AMI are used. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html">Block Device Mapping</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn set_block_device_mappings(mut self, input: std::option::Option<std::vec::Vec<crate::model::BlockDeviceMapping>>) -> Self {
            self.block_device_mappings = input; self
        }
        /// <p>Controls whether instances in this group are launched with detailed (<code>true</code>) or basic (<code>false</code>) monitoring.</p> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/latest/userguide/enable-as-instance-metrics.html">Configure Monitoring for Auto Scaling Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn instance_monitoring(mut self, input: crate::model::InstanceMonitoring) -> Self {
            self.instance_monitoring = Some(input);
            self
        }
        /// <p>Controls whether instances in this group are launched with detailed (<code>true</code>) or basic (<code>false</code>) monitoring.</p> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/latest/userguide/enable-as-instance-metrics.html">Configure Monitoring for Auto Scaling Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_instance_monitoring(mut self, input: std::option::Option<crate::model::InstanceMonitoring>) -> Self {
            self.instance_monitoring = input; self
        }
        /// <p>The maximum hourly price to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot price. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-launch-spot-instances.html">Requesting Spot Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn spot_price(mut self, input: impl Into<std::string::String>) -> Self {
            self.spot_price = Some(input.into());
            self
        }
        /// <p>The maximum hourly price to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot price. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-launch-spot-instances.html">Requesting Spot Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_spot_price(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.spot_price = input; self
        }
        /// <p>The name or the Amazon Resource Name (ARN) of the instance profile associated with the IAM role for the instance. The instance profile contains the IAM role. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/us-iam-role.html">IAM role for applications that run on Amazon EC2 instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn iam_instance_profile(mut self, input: impl Into<std::string::String>) -> Self {
            self.iam_instance_profile = Some(input.into());
            self
        }
        /// <p>The name or the Amazon Resource Name (ARN) of the instance profile associated with the IAM role for the instance. The instance profile contains the IAM role. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/us-iam-role.html">IAM role for applications that run on Amazon EC2 instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_iam_instance_profile(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.iam_instance_profile = input; self
        }
        /// <p>The creation date and time for the launch configuration.</p>
        pub fn created_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_time = Some(input);
            self
        }
        /// <p>The creation date and time for the launch configuration.</p>
        pub fn set_created_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.created_time = input; self
        }
        /// <p>Specifies whether the launch configuration is optimized for EBS I/O (<code>true</code>) or not (<code>false</code>). For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html">Amazon EBS-Optimized Instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn ebs_optimized(mut self, input: bool) -> Self {
            self.ebs_optimized = Some(input);
            self
        }
        /// <p>Specifies whether the launch configuration is optimized for EBS I/O (<code>true</code>) or not (<code>false</code>). For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html">Amazon EBS-Optimized Instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn set_ebs_optimized(mut self, input: std::option::Option<bool>) -> Self {
            self.ebs_optimized = input; self
        }
        /// <p>Specifies whether to assign a public IPv4 address to the group's instances. If the instance is launched into a default subnet, the default is to assign a public IPv4 address, unless you disabled the option to assign a public IPv4 address on the subnet. If the instance is launched into a nondefault subnet, the default is not to assign a public IPv4 address, unless you enabled the option to assign a public IPv4 address on the subnet. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-in-vpc.html">Launching Auto Scaling instances in a VPC</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn associate_public_ip_address(mut self, input: bool) -> Self {
            self.associate_public_ip_address = Some(input);
            self
        }
        /// <p>Specifies whether to assign a public IPv4 address to the group's instances. If the instance is launched into a default subnet, the default is to assign a public IPv4 address, unless you disabled the option to assign a public IPv4 address on the subnet. If the instance is launched into a nondefault subnet, the default is not to assign a public IPv4 address, unless you enabled the option to assign a public IPv4 address on the subnet. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-in-vpc.html">Launching Auto Scaling instances in a VPC</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_associate_public_ip_address(mut self, input: std::option::Option<bool>) -> Self {
            self.associate_public_ip_address = input; self
        }
        /// <p>The tenancy of the instance, either <code>default</code> or <code>dedicated</code>. An instance with <code>dedicated</code> tenancy runs on isolated, single-tenant hardware and can only be launched into a VPC.</p> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-dedicated-instances.html">Configuring instance tenancy with Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn placement_tenancy(mut self, input: impl Into<std::string::String>) -> Self {
            self.placement_tenancy = Some(input.into());
            self
        }
        /// <p>The tenancy of the instance, either <code>default</code> or <code>dedicated</code>. An instance with <code>dedicated</code> tenancy runs on isolated, single-tenant hardware and can only be launched into a VPC.</p> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-dedicated-instances.html">Configuring instance tenancy with Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_placement_tenancy(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.placement_tenancy = input; self
        }
        /// <p>The metadata options for the instances. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-config.html#launch-configurations-imds">Configuring the Instance Metadata Options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn metadata_options(mut self, input: crate::model::InstanceMetadataOptions) -> Self {
            self.metadata_options = Some(input);
            self
        }
        /// <p>The metadata options for the instances. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-config.html#launch-configurations-imds">Configuring the Instance Metadata Options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_metadata_options(mut self, input: std::option::Option<crate::model::InstanceMetadataOptions>) -> Self {
            self.metadata_options = input; self
        }
        /// Consumes the builder and constructs a [`LaunchConfiguration`](crate::model::LaunchConfiguration).
        pub fn build(self) -> crate::model::LaunchConfiguration {
            crate::model::LaunchConfiguration {
                launch_configuration_name: self.launch_configuration_name
                ,
                launch_configuration_arn: self.launch_configuration_arn
                ,
                image_id: self.image_id
                ,
                key_name: self.key_name
                ,
                security_groups: self.security_groups
                ,
                classic_link_vpc_id: self.classic_link_vpc_id
                ,
                classic_link_vpc_security_groups: self.classic_link_vpc_security_groups
                ,
                user_data: self.user_data
                ,
                instance_type: self.instance_type
                ,
                kernel_id: self.kernel_id
                ,
                ramdisk_id: self.ramdisk_id
                ,
                block_device_mappings: self.block_device_mappings
                ,
                instance_monitoring: self.instance_monitoring
                ,
                spot_price: self.spot_price
                ,
                iam_instance_profile: self.iam_instance_profile
                ,
                created_time: self.created_time
                ,
                ebs_optimized: self.ebs_optimized
                ,
                associate_public_ip_address: self.associate_public_ip_address
                ,
                placement_tenancy: self.placement_tenancy
                ,
                metadata_options: self.metadata_options
                ,
            }
        }
    }
    
    
}
impl LaunchConfiguration {
    /// Creates a new builder-style object to manufacture [`LaunchConfiguration`](crate::model::LaunchConfiguration).
    pub fn builder() -> crate::model::launch_configuration::Builder {
        crate::model::launch_configuration::Builder::default()
    }
}

/// <p>The metadata options for the instances. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-config.html#launch-configurations-imds">Configuring the Instance Metadata Options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct InstanceMetadataOptions  {
    /// <p>The state of token usage for your instance metadata requests. If the parameter is not specified in the request, the default state is <code>optional</code>.</p> 
    /// <p>If the state is <code>optional</code>, you can choose to retrieve instance metadata with or without a signed token header on your request. If you retrieve the IAM role credentials without a token, the version 1.0 role credentials are returned. If you retrieve the IAM role credentials using a valid signed token, the version 2.0 role credentials are returned.</p> 
    /// <p>If the state is <code>required</code>, you must send a signed token header with any instance metadata retrieval requests. In this state, retrieving the IAM role credentials always returns the version 2.0 credentials; the version 1.0 credentials are not available.</p>
    #[doc(hidden)]
    pub http_tokens: std::option::Option<crate::model::InstanceMetadataHttpTokensState>,
    /// <p>The desired HTTP PUT response hop limit for instance metadata requests. The larger the number, the further instance metadata requests can travel.</p> 
    /// <p>Default: 1</p>
    #[doc(hidden)]
    pub http_put_response_hop_limit: std::option::Option<i32>,
    /// <p>This parameter enables or disables the HTTP metadata endpoint on your instances. If the parameter is not specified, the default state is <code>enabled</code>.</p> <note> 
    /// <p>If you specify a value of <code>disabled</code>, you will not be able to access your instance metadata. </p> 
    /// </note>
    #[doc(hidden)]
    pub http_endpoint: std::option::Option<crate::model::InstanceMetadataEndpointState>,
}
impl InstanceMetadataOptions {
    /// <p>The state of token usage for your instance metadata requests. If the parameter is not specified in the request, the default state is <code>optional</code>.</p> 
    /// <p>If the state is <code>optional</code>, you can choose to retrieve instance metadata with or without a signed token header on your request. If you retrieve the IAM role credentials without a token, the version 1.0 role credentials are returned. If you retrieve the IAM role credentials using a valid signed token, the version 2.0 role credentials are returned.</p> 
    /// <p>If the state is <code>required</code>, you must send a signed token header with any instance metadata retrieval requests. In this state, retrieving the IAM role credentials always returns the version 2.0 credentials; the version 1.0 credentials are not available.</p>
    pub fn http_tokens(&self) -> std::option::Option<& crate::model::InstanceMetadataHttpTokensState> {
        self.http_tokens.as_ref()
    }
    /// <p>The desired HTTP PUT response hop limit for instance metadata requests. The larger the number, the further instance metadata requests can travel.</p> 
    /// <p>Default: 1</p>
    pub fn http_put_response_hop_limit(&self) -> std::option::Option<i32> {
        self.http_put_response_hop_limit
    }
    /// <p>This parameter enables or disables the HTTP metadata endpoint on your instances. If the parameter is not specified, the default state is <code>enabled</code>.</p> <note> 
    /// <p>If you specify a value of <code>disabled</code>, you will not be able to access your instance metadata. </p> 
    /// </note>
    pub fn http_endpoint(&self) -> std::option::Option<& crate::model::InstanceMetadataEndpointState> {
        self.http_endpoint.as_ref()
    }
}
/// See [`InstanceMetadataOptions`](crate::model::InstanceMetadataOptions).
pub mod instance_metadata_options {
    
    /// A builder for [`InstanceMetadataOptions`](crate::model::InstanceMetadataOptions).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) http_tokens: std::option::Option<crate::model::InstanceMetadataHttpTokensState>,
        pub(crate) http_put_response_hop_limit: std::option::Option<i32>,
        pub(crate) http_endpoint: std::option::Option<crate::model::InstanceMetadataEndpointState>,
    }
    impl Builder {
        /// <p>The state of token usage for your instance metadata requests. If the parameter is not specified in the request, the default state is <code>optional</code>.</p> 
        /// <p>If the state is <code>optional</code>, you can choose to retrieve instance metadata with or without a signed token header on your request. If you retrieve the IAM role credentials without a token, the version 1.0 role credentials are returned. If you retrieve the IAM role credentials using a valid signed token, the version 2.0 role credentials are returned.</p> 
        /// <p>If the state is <code>required</code>, you must send a signed token header with any instance metadata retrieval requests. In this state, retrieving the IAM role credentials always returns the version 2.0 credentials; the version 1.0 credentials are not available.</p>
        pub fn http_tokens(mut self, input: crate::model::InstanceMetadataHttpTokensState) -> Self {
            self.http_tokens = Some(input);
            self
        }
        /// <p>The state of token usage for your instance metadata requests. If the parameter is not specified in the request, the default state is <code>optional</code>.</p> 
        /// <p>If the state is <code>optional</code>, you can choose to retrieve instance metadata with or without a signed token header on your request. If you retrieve the IAM role credentials without a token, the version 1.0 role credentials are returned. If you retrieve the IAM role credentials using a valid signed token, the version 2.0 role credentials are returned.</p> 
        /// <p>If the state is <code>required</code>, you must send a signed token header with any instance metadata retrieval requests. In this state, retrieving the IAM role credentials always returns the version 2.0 credentials; the version 1.0 credentials are not available.</p>
        pub fn set_http_tokens(mut self, input: std::option::Option<crate::model::InstanceMetadataHttpTokensState>) -> Self {
            self.http_tokens = input; self
        }
        /// <p>The desired HTTP PUT response hop limit for instance metadata requests. The larger the number, the further instance metadata requests can travel.</p> 
        /// <p>Default: 1</p>
        pub fn http_put_response_hop_limit(mut self, input: i32) -> Self {
            self.http_put_response_hop_limit = Some(input);
            self
        }
        /// <p>The desired HTTP PUT response hop limit for instance metadata requests. The larger the number, the further instance metadata requests can travel.</p> 
        /// <p>Default: 1</p>
        pub fn set_http_put_response_hop_limit(mut self, input: std::option::Option<i32>) -> Self {
            self.http_put_response_hop_limit = input; self
        }
        /// <p>This parameter enables or disables the HTTP metadata endpoint on your instances. If the parameter is not specified, the default state is <code>enabled</code>.</p> <note> 
        /// <p>If you specify a value of <code>disabled</code>, you will not be able to access your instance metadata. </p> 
        /// </note>
        pub fn http_endpoint(mut self, input: crate::model::InstanceMetadataEndpointState) -> Self {
            self.http_endpoint = Some(input);
            self
        }
        /// <p>This parameter enables or disables the HTTP metadata endpoint on your instances. If the parameter is not specified, the default state is <code>enabled</code>.</p> <note> 
        /// <p>If you specify a value of <code>disabled</code>, you will not be able to access your instance metadata. </p> 
        /// </note>
        pub fn set_http_endpoint(mut self, input: std::option::Option<crate::model::InstanceMetadataEndpointState>) -> Self {
            self.http_endpoint = input; self
        }
        /// Consumes the builder and constructs a [`InstanceMetadataOptions`](crate::model::InstanceMetadataOptions).
        pub fn build(self) -> crate::model::InstanceMetadataOptions {
            crate::model::InstanceMetadataOptions {
                http_tokens: self.http_tokens
                ,
                http_put_response_hop_limit: self.http_put_response_hop_limit
                ,
                http_endpoint: self.http_endpoint
                ,
            }
        }
    }
    
    
}
impl InstanceMetadataOptions {
    /// Creates a new builder-style object to manufacture [`InstanceMetadataOptions`](crate::model::InstanceMetadataOptions).
    pub fn builder() -> crate::model::instance_metadata_options::Builder {
        crate::model::instance_metadata_options::Builder::default()
    }
}

/// When writing a match expression against `InstanceMetadataEndpointState`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let instancemetadataendpointstate = unimplemented!();
/// match instancemetadataendpointstate {
///     InstanceMetadataEndpointState::Disabled => { /* ... */ },
///     InstanceMetadataEndpointState::Enabled => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `instancemetadataendpointstate` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `InstanceMetadataEndpointState::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `InstanceMetadataEndpointState::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `InstanceMetadataEndpointState::NewFeature` is defined.
/// Specifically, when `instancemetadataendpointstate` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `InstanceMetadataEndpointState::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum InstanceMetadataEndpointState {
    #[allow(missing_docs)] // documentation missing in model
    Disabled,
    #[allow(missing_docs)] // documentation missing in model
    Enabled,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for InstanceMetadataEndpointState {
    fn from(s: &str) -> Self {
        match s {
            "disabled" => InstanceMetadataEndpointState::Disabled,
            "enabled" => InstanceMetadataEndpointState::Enabled,
            other => InstanceMetadataEndpointState::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for InstanceMetadataEndpointState {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(InstanceMetadataEndpointState::from(s))
                }
            }
impl InstanceMetadataEndpointState {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            InstanceMetadataEndpointState::Disabled => "disabled",
            InstanceMetadataEndpointState::Enabled => "enabled",
            InstanceMetadataEndpointState::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "disabled", "enabled"
        ]
    }
}
impl AsRef<str> for InstanceMetadataEndpointState {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// When writing a match expression against `InstanceMetadataHttpTokensState`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let instancemetadatahttptokensstate = unimplemented!();
/// match instancemetadatahttptokensstate {
///     InstanceMetadataHttpTokensState::Optional => { /* ... */ },
///     InstanceMetadataHttpTokensState::Required => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `instancemetadatahttptokensstate` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `InstanceMetadataHttpTokensState::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `InstanceMetadataHttpTokensState::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `InstanceMetadataHttpTokensState::NewFeature` is defined.
/// Specifically, when `instancemetadatahttptokensstate` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `InstanceMetadataHttpTokensState::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum InstanceMetadataHttpTokensState {
    #[allow(missing_docs)] // documentation missing in model
    Optional,
    #[allow(missing_docs)] // documentation missing in model
    Required,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for InstanceMetadataHttpTokensState {
    fn from(s: &str) -> Self {
        match s {
            "optional" => InstanceMetadataHttpTokensState::Optional,
            "required" => InstanceMetadataHttpTokensState::Required,
            other => InstanceMetadataHttpTokensState::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for InstanceMetadataHttpTokensState {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(InstanceMetadataHttpTokensState::from(s))
                }
            }
impl InstanceMetadataHttpTokensState {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            InstanceMetadataHttpTokensState::Optional => "optional",
            InstanceMetadataHttpTokensState::Required => "required",
            InstanceMetadataHttpTokensState::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "optional", "required"
        ]
    }
}
impl AsRef<str> for InstanceMetadataHttpTokensState {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Describes whether detailed monitoring is enabled for the Auto Scaling instances.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct InstanceMonitoring  {
    /// <p>If <code>true</code>, detailed monitoring is enabled. Otherwise, basic monitoring is enabled.</p>
    #[doc(hidden)]
    pub enabled: std::option::Option<bool>,
}
impl InstanceMonitoring {
    /// <p>If <code>true</code>, detailed monitoring is enabled. Otherwise, basic monitoring is enabled.</p>
    pub fn enabled(&self) -> std::option::Option<bool> {
        self.enabled
    }
}
/// See [`InstanceMonitoring`](crate::model::InstanceMonitoring).
pub mod instance_monitoring {
    
    /// A builder for [`InstanceMonitoring`](crate::model::InstanceMonitoring).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) enabled: std::option::Option<bool>,
    }
    impl Builder {
        /// <p>If <code>true</code>, detailed monitoring is enabled. Otherwise, basic monitoring is enabled.</p>
        pub fn enabled(mut self, input: bool) -> Self {
            self.enabled = Some(input);
            self
        }
        /// <p>If <code>true</code>, detailed monitoring is enabled. Otherwise, basic monitoring is enabled.</p>
        pub fn set_enabled(mut self, input: std::option::Option<bool>) -> Self {
            self.enabled = input; self
        }
        /// Consumes the builder and constructs a [`InstanceMonitoring`](crate::model::InstanceMonitoring).
        pub fn build(self) -> crate::model::InstanceMonitoring {
            crate::model::InstanceMonitoring {
                enabled: self.enabled
                ,
            }
        }
    }
    
    
}
impl InstanceMonitoring {
    /// Creates a new builder-style object to manufacture [`InstanceMonitoring`](crate::model::InstanceMonitoring).
    pub fn builder() -> crate::model::instance_monitoring::Builder {
        crate::model::instance_monitoring::Builder::default()
    }
}

/// <p>Describes a block device mapping.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct BlockDeviceMapping  {
    /// <p>The name of the instance store volume (virtual device) to attach to an instance at launch. The name must be in the form ephemeral<i>X</i> where <i>X</i> is a number starting from zero (0), for example, <code>ephemeral0</code>.</p>
    #[doc(hidden)]
    pub virtual_name: std::option::Option<std::string::String>,
    /// <p>The device name assigned to the volume (for example, <code>/dev/sdh</code> or <code>xvdh</code>). For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/device_naming.html">Device naming on Linux instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> <note> 
    /// <p>To define a block device mapping, set the device name and exactly one of the following properties: <code>Ebs</code>, <code>NoDevice</code>, or <code>VirtualName</code>.</p> 
    /// </note>
    #[doc(hidden)]
    pub device_name: std::option::Option<std::string::String>,
    /// <p>Information to attach an EBS volume to an instance at launch.</p>
    #[doc(hidden)]
    pub ebs: std::option::Option<crate::model::Ebs>,
    /// <p>Setting this value to <code>true</code> prevents a volume that is included in the block device mapping of the AMI from being mapped to the specified device name at launch.</p> 
    /// <p>If <code>NoDevice</code> is <code>true</code> for the root device, instances might fail the EC2 health check. In that case, Amazon EC2 Auto Scaling launches replacement instances.</p>
    #[doc(hidden)]
    pub no_device: std::option::Option<bool>,
}
impl BlockDeviceMapping {
    /// <p>The name of the instance store volume (virtual device) to attach to an instance at launch. The name must be in the form ephemeral<i>X</i> where <i>X</i> is a number starting from zero (0), for example, <code>ephemeral0</code>.</p>
    pub fn virtual_name(&self) -> std::option::Option<& str> {
        self.virtual_name.as_deref()
    }
    /// <p>The device name assigned to the volume (for example, <code>/dev/sdh</code> or <code>xvdh</code>). For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/device_naming.html">Device naming on Linux instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> <note> 
    /// <p>To define a block device mapping, set the device name and exactly one of the following properties: <code>Ebs</code>, <code>NoDevice</code>, or <code>VirtualName</code>.</p> 
    /// </note>
    pub fn device_name(&self) -> std::option::Option<& str> {
        self.device_name.as_deref()
    }
    /// <p>Information to attach an EBS volume to an instance at launch.</p>
    pub fn ebs(&self) -> std::option::Option<& crate::model::Ebs> {
        self.ebs.as_ref()
    }
    /// <p>Setting this value to <code>true</code> prevents a volume that is included in the block device mapping of the AMI from being mapped to the specified device name at launch.</p> 
    /// <p>If <code>NoDevice</code> is <code>true</code> for the root device, instances might fail the EC2 health check. In that case, Amazon EC2 Auto Scaling launches replacement instances.</p>
    pub fn no_device(&self) -> std::option::Option<bool> {
        self.no_device
    }
}
/// See [`BlockDeviceMapping`](crate::model::BlockDeviceMapping).
pub mod block_device_mapping {
    
    /// A builder for [`BlockDeviceMapping`](crate::model::BlockDeviceMapping).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) virtual_name: std::option::Option<std::string::String>,
        pub(crate) device_name: std::option::Option<std::string::String>,
        pub(crate) ebs: std::option::Option<crate::model::Ebs>,
        pub(crate) no_device: std::option::Option<bool>,
    }
    impl Builder {
        /// <p>The name of the instance store volume (virtual device) to attach to an instance at launch. The name must be in the form ephemeral<i>X</i> where <i>X</i> is a number starting from zero (0), for example, <code>ephemeral0</code>.</p>
        pub fn virtual_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.virtual_name = Some(input.into());
            self
        }
        /// <p>The name of the instance store volume (virtual device) to attach to an instance at launch. The name must be in the form ephemeral<i>X</i> where <i>X</i> is a number starting from zero (0), for example, <code>ephemeral0</code>.</p>
        pub fn set_virtual_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.virtual_name = input; self
        }
        /// <p>The device name assigned to the volume (for example, <code>/dev/sdh</code> or <code>xvdh</code>). For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/device_naming.html">Device naming on Linux instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> <note> 
        /// <p>To define a block device mapping, set the device name and exactly one of the following properties: <code>Ebs</code>, <code>NoDevice</code>, or <code>VirtualName</code>.</p> 
        /// </note>
        pub fn device_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.device_name = Some(input.into());
            self
        }
        /// <p>The device name assigned to the volume (for example, <code>/dev/sdh</code> or <code>xvdh</code>). For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/device_naming.html">Device naming on Linux instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> <note> 
        /// <p>To define a block device mapping, set the device name and exactly one of the following properties: <code>Ebs</code>, <code>NoDevice</code>, or <code>VirtualName</code>.</p> 
        /// </note>
        pub fn set_device_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.device_name = input; self
        }
        /// <p>Information to attach an EBS volume to an instance at launch.</p>
        pub fn ebs(mut self, input: crate::model::Ebs) -> Self {
            self.ebs = Some(input);
            self
        }
        /// <p>Information to attach an EBS volume to an instance at launch.</p>
        pub fn set_ebs(mut self, input: std::option::Option<crate::model::Ebs>) -> Self {
            self.ebs = input; self
        }
        /// <p>Setting this value to <code>true</code> prevents a volume that is included in the block device mapping of the AMI from being mapped to the specified device name at launch.</p> 
        /// <p>If <code>NoDevice</code> is <code>true</code> for the root device, instances might fail the EC2 health check. In that case, Amazon EC2 Auto Scaling launches replacement instances.</p>
        pub fn no_device(mut self, input: bool) -> Self {
            self.no_device = Some(input);
            self
        }
        /// <p>Setting this value to <code>true</code> prevents a volume that is included in the block device mapping of the AMI from being mapped to the specified device name at launch.</p> 
        /// <p>If <code>NoDevice</code> is <code>true</code> for the root device, instances might fail the EC2 health check. In that case, Amazon EC2 Auto Scaling launches replacement instances.</p>
        pub fn set_no_device(mut self, input: std::option::Option<bool>) -> Self {
            self.no_device = input; self
        }
        /// Consumes the builder and constructs a [`BlockDeviceMapping`](crate::model::BlockDeviceMapping).
        pub fn build(self) -> crate::model::BlockDeviceMapping {
            crate::model::BlockDeviceMapping {
                virtual_name: self.virtual_name
                ,
                device_name: self.device_name
                ,
                ebs: self.ebs
                ,
                no_device: self.no_device
                ,
            }
        }
    }
    
    
}
impl BlockDeviceMapping {
    /// Creates a new builder-style object to manufacture [`BlockDeviceMapping`](crate::model::BlockDeviceMapping).
    pub fn builder() -> crate::model::block_device_mapping::Builder {
        crate::model::block_device_mapping::Builder::default()
    }
}

/// <p>Describes information used to set up an Amazon EBS volume specified in a block device mapping.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct Ebs  {
    /// <p>The snapshot ID of the volume to use.</p> 
    /// <p>You must specify either a <code>VolumeSize</code> or a <code>SnapshotId</code>.</p>
    #[doc(hidden)]
    pub snapshot_id: std::option::Option<std::string::String>,
    /// <p>The volume size, in GiBs. The following are the supported volumes sizes for each volume type: </p> 
    /// <ul> 
    /// <li> <p> <code>gp2</code> and <code>gp3</code>: 1-16,384</p> </li> 
    /// <li> <p> <code>io1</code>: 4-16,384</p> </li> 
    /// <li> <p> <code>st1</code> and <code>sc1</code>: 125-16,384</p> </li> 
    /// <li> <p> <code>standard</code>: 1-1,024</p> </li> 
    /// </ul> 
    /// <p>You must specify either a <code>SnapshotId</code> or a <code>VolumeSize</code>. If you specify both <code>SnapshotId</code> and <code>VolumeSize</code>, the volume size must be equal or greater than the size of the snapshot.</p>
    #[doc(hidden)]
    pub volume_size: std::option::Option<i32>,
    /// <p>The volume type. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html">Amazon EBS volume types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
    /// <p>Valid values: <code>standard</code> | <code>io1</code> | <code>gp2</code> | <code>st1</code> | <code>sc1</code> | <code>gp3</code> </p>
    #[doc(hidden)]
    pub volume_type: std::option::Option<std::string::String>,
    /// <p>Indicates whether the volume is deleted on instance termination. For Amazon EC2 Auto Scaling, the default value is <code>true</code>.</p>
    #[doc(hidden)]
    pub delete_on_termination: std::option::Option<bool>,
    /// <p>The number of input/output (I/O) operations per second (IOPS) to provision for the volume. For <code>gp3</code> and <code>io1</code> volumes, this represents the number of IOPS that are provisioned for the volume. For <code>gp2</code> volumes, this represents the baseline performance of the volume and the rate at which the volume accumulates I/O credits for bursting. </p> 
    /// <p>The following are the supported values for each volume type: </p> 
    /// <ul> 
    /// <li> <p> <code>gp3</code>: 3,000-16,000 IOPS</p> </li> 
    /// <li> <p> <code>io1</code>: 100-64,000 IOPS</p> </li> 
    /// </ul> 
    /// <p>For <code>io1</code> volumes, we guarantee 64,000 IOPS only for <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#ec2-nitro-instances">Instances built on the Nitro System</a>. Other instance families guarantee performance up to 32,000 IOPS. </p> 
    /// <p> <code>Iops</code> is supported when the volume type is <code>gp3</code> or <code>io1</code> and required only when the volume type is <code>io1</code>. (Not used with <code>standard</code>, <code>gp2</code>, <code>st1</code>, or <code>sc1</code> volumes.) </p>
    #[doc(hidden)]
    pub iops: std::option::Option<i32>,
    /// <p>Specifies whether the volume should be encrypted. Encrypted EBS volumes can only be attached to instances that support Amazon EBS encryption. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#EBSEncryption_supported_instances">Supported instance types</a>. If your AMI uses encrypted volumes, you can also only launch it on supported instance types.</p> <note> 
    /// <p>If you are creating a volume from a snapshot, you cannot create an unencrypted volume from an encrypted snapshot. Also, you cannot specify a KMS key ID when using a launch configuration.</p> 
    /// <p>If you enable encryption by default, the EBS volumes that you create are always encrypted, either using the Amazon Web Services managed KMS key or a customer-managed KMS key, regardless of whether the snapshot was encrypted. </p> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-data-protection.html#encryption">Use Amazon Web Services KMS keys to encrypt Amazon EBS volumes</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> 
    /// </note>
    #[doc(hidden)]
    pub encrypted: std::option::Option<bool>,
    /// <p>The throughput (MiBps) to provision for a <code>gp3</code> volume.</p>
    #[doc(hidden)]
    pub throughput: std::option::Option<i32>,
}
impl Ebs {
    /// <p>The snapshot ID of the volume to use.</p> 
    /// <p>You must specify either a <code>VolumeSize</code> or a <code>SnapshotId</code>.</p>
    pub fn snapshot_id(&self) -> std::option::Option<& str> {
        self.snapshot_id.as_deref()
    }
    /// <p>The volume size, in GiBs. The following are the supported volumes sizes for each volume type: </p> 
    /// <ul> 
    /// <li> <p> <code>gp2</code> and <code>gp3</code>: 1-16,384</p> </li> 
    /// <li> <p> <code>io1</code>: 4-16,384</p> </li> 
    /// <li> <p> <code>st1</code> and <code>sc1</code>: 125-16,384</p> </li> 
    /// <li> <p> <code>standard</code>: 1-1,024</p> </li> 
    /// </ul> 
    /// <p>You must specify either a <code>SnapshotId</code> or a <code>VolumeSize</code>. If you specify both <code>SnapshotId</code> and <code>VolumeSize</code>, the volume size must be equal or greater than the size of the snapshot.</p>
    pub fn volume_size(&self) -> std::option::Option<i32> {
        self.volume_size
    }
    /// <p>The volume type. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html">Amazon EBS volume types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
    /// <p>Valid values: <code>standard</code> | <code>io1</code> | <code>gp2</code> | <code>st1</code> | <code>sc1</code> | <code>gp3</code> </p>
    pub fn volume_type(&self) -> std::option::Option<& str> {
        self.volume_type.as_deref()
    }
    /// <p>Indicates whether the volume is deleted on instance termination. For Amazon EC2 Auto Scaling, the default value is <code>true</code>.</p>
    pub fn delete_on_termination(&self) -> std::option::Option<bool> {
        self.delete_on_termination
    }
    /// <p>The number of input/output (I/O) operations per second (IOPS) to provision for the volume. For <code>gp3</code> and <code>io1</code> volumes, this represents the number of IOPS that are provisioned for the volume. For <code>gp2</code> volumes, this represents the baseline performance of the volume and the rate at which the volume accumulates I/O credits for bursting. </p> 
    /// <p>The following are the supported values for each volume type: </p> 
    /// <ul> 
    /// <li> <p> <code>gp3</code>: 3,000-16,000 IOPS</p> </li> 
    /// <li> <p> <code>io1</code>: 100-64,000 IOPS</p> </li> 
    /// </ul> 
    /// <p>For <code>io1</code> volumes, we guarantee 64,000 IOPS only for <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#ec2-nitro-instances">Instances built on the Nitro System</a>. Other instance families guarantee performance up to 32,000 IOPS. </p> 
    /// <p> <code>Iops</code> is supported when the volume type is <code>gp3</code> or <code>io1</code> and required only when the volume type is <code>io1</code>. (Not used with <code>standard</code>, <code>gp2</code>, <code>st1</code>, or <code>sc1</code> volumes.) </p>
    pub fn iops(&self) -> std::option::Option<i32> {
        self.iops
    }
    /// <p>Specifies whether the volume should be encrypted. Encrypted EBS volumes can only be attached to instances that support Amazon EBS encryption. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#EBSEncryption_supported_instances">Supported instance types</a>. If your AMI uses encrypted volumes, you can also only launch it on supported instance types.</p> <note> 
    /// <p>If you are creating a volume from a snapshot, you cannot create an unencrypted volume from an encrypted snapshot. Also, you cannot specify a KMS key ID when using a launch configuration.</p> 
    /// <p>If you enable encryption by default, the EBS volumes that you create are always encrypted, either using the Amazon Web Services managed KMS key or a customer-managed KMS key, regardless of whether the snapshot was encrypted. </p> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-data-protection.html#encryption">Use Amazon Web Services KMS keys to encrypt Amazon EBS volumes</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> 
    /// </note>
    pub fn encrypted(&self) -> std::option::Option<bool> {
        self.encrypted
    }
    /// <p>The throughput (MiBps) to provision for a <code>gp3</code> volume.</p>
    pub fn throughput(&self) -> std::option::Option<i32> {
        self.throughput
    }
}
/// See [`Ebs`](crate::model::Ebs).
pub mod ebs {
    
    /// A builder for [`Ebs`](crate::model::Ebs).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) snapshot_id: std::option::Option<std::string::String>,
        pub(crate) volume_size: std::option::Option<i32>,
        pub(crate) volume_type: std::option::Option<std::string::String>,
        pub(crate) delete_on_termination: std::option::Option<bool>,
        pub(crate) iops: std::option::Option<i32>,
        pub(crate) encrypted: std::option::Option<bool>,
        pub(crate) throughput: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The snapshot ID of the volume to use.</p> 
        /// <p>You must specify either a <code>VolumeSize</code> or a <code>SnapshotId</code>.</p>
        pub fn snapshot_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.snapshot_id = Some(input.into());
            self
        }
        /// <p>The snapshot ID of the volume to use.</p> 
        /// <p>You must specify either a <code>VolumeSize</code> or a <code>SnapshotId</code>.</p>
        pub fn set_snapshot_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.snapshot_id = input; self
        }
        /// <p>The volume size, in GiBs. The following are the supported volumes sizes for each volume type: </p> 
        /// <ul> 
        /// <li> <p> <code>gp2</code> and <code>gp3</code>: 1-16,384</p> </li> 
        /// <li> <p> <code>io1</code>: 4-16,384</p> </li> 
        /// <li> <p> <code>st1</code> and <code>sc1</code>: 125-16,384</p> </li> 
        /// <li> <p> <code>standard</code>: 1-1,024</p> </li> 
        /// </ul> 
        /// <p>You must specify either a <code>SnapshotId</code> or a <code>VolumeSize</code>. If you specify both <code>SnapshotId</code> and <code>VolumeSize</code>, the volume size must be equal or greater than the size of the snapshot.</p>
        pub fn volume_size(mut self, input: i32) -> Self {
            self.volume_size = Some(input);
            self
        }
        /// <p>The volume size, in GiBs. The following are the supported volumes sizes for each volume type: </p> 
        /// <ul> 
        /// <li> <p> <code>gp2</code> and <code>gp3</code>: 1-16,384</p> </li> 
        /// <li> <p> <code>io1</code>: 4-16,384</p> </li> 
        /// <li> <p> <code>st1</code> and <code>sc1</code>: 125-16,384</p> </li> 
        /// <li> <p> <code>standard</code>: 1-1,024</p> </li> 
        /// </ul> 
        /// <p>You must specify either a <code>SnapshotId</code> or a <code>VolumeSize</code>. If you specify both <code>SnapshotId</code> and <code>VolumeSize</code>, the volume size must be equal or greater than the size of the snapshot.</p>
        pub fn set_volume_size(mut self, input: std::option::Option<i32>) -> Self {
            self.volume_size = input; self
        }
        /// <p>The volume type. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html">Amazon EBS volume types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
        /// <p>Valid values: <code>standard</code> | <code>io1</code> | <code>gp2</code> | <code>st1</code> | <code>sc1</code> | <code>gp3</code> </p>
        pub fn volume_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.volume_type = Some(input.into());
            self
        }
        /// <p>The volume type. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html">Amazon EBS volume types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> 
        /// <p>Valid values: <code>standard</code> | <code>io1</code> | <code>gp2</code> | <code>st1</code> | <code>sc1</code> | <code>gp3</code> </p>
        pub fn set_volume_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.volume_type = input; self
        }
        /// <p>Indicates whether the volume is deleted on instance termination. For Amazon EC2 Auto Scaling, the default value is <code>true</code>.</p>
        pub fn delete_on_termination(mut self, input: bool) -> Self {
            self.delete_on_termination = Some(input);
            self
        }
        /// <p>Indicates whether the volume is deleted on instance termination. For Amazon EC2 Auto Scaling, the default value is <code>true</code>.</p>
        pub fn set_delete_on_termination(mut self, input: std::option::Option<bool>) -> Self {
            self.delete_on_termination = input; self
        }
        /// <p>The number of input/output (I/O) operations per second (IOPS) to provision for the volume. For <code>gp3</code> and <code>io1</code> volumes, this represents the number of IOPS that are provisioned for the volume. For <code>gp2</code> volumes, this represents the baseline performance of the volume and the rate at which the volume accumulates I/O credits for bursting. </p> 
        /// <p>The following are the supported values for each volume type: </p> 
        /// <ul> 
        /// <li> <p> <code>gp3</code>: 3,000-16,000 IOPS</p> </li> 
        /// <li> <p> <code>io1</code>: 100-64,000 IOPS</p> </li> 
        /// </ul> 
        /// <p>For <code>io1</code> volumes, we guarantee 64,000 IOPS only for <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#ec2-nitro-instances">Instances built on the Nitro System</a>. Other instance families guarantee performance up to 32,000 IOPS. </p> 
        /// <p> <code>Iops</code> is supported when the volume type is <code>gp3</code> or <code>io1</code> and required only when the volume type is <code>io1</code>. (Not used with <code>standard</code>, <code>gp2</code>, <code>st1</code>, or <code>sc1</code> volumes.) </p>
        pub fn iops(mut self, input: i32) -> Self {
            self.iops = Some(input);
            self
        }
        /// <p>The number of input/output (I/O) operations per second (IOPS) to provision for the volume. For <code>gp3</code> and <code>io1</code> volumes, this represents the number of IOPS that are provisioned for the volume. For <code>gp2</code> volumes, this represents the baseline performance of the volume and the rate at which the volume accumulates I/O credits for bursting. </p> 
        /// <p>The following are the supported values for each volume type: </p> 
        /// <ul> 
        /// <li> <p> <code>gp3</code>: 3,000-16,000 IOPS</p> </li> 
        /// <li> <p> <code>io1</code>: 100-64,000 IOPS</p> </li> 
        /// </ul> 
        /// <p>For <code>io1</code> volumes, we guarantee 64,000 IOPS only for <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#ec2-nitro-instances">Instances built on the Nitro System</a>. Other instance families guarantee performance up to 32,000 IOPS. </p> 
        /// <p> <code>Iops</code> is supported when the volume type is <code>gp3</code> or <code>io1</code> and required only when the volume type is <code>io1</code>. (Not used with <code>standard</code>, <code>gp2</code>, <code>st1</code>, or <code>sc1</code> volumes.) </p>
        pub fn set_iops(mut self, input: std::option::Option<i32>) -> Self {
            self.iops = input; self
        }
        /// <p>Specifies whether the volume should be encrypted. Encrypted EBS volumes can only be attached to instances that support Amazon EBS encryption. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#EBSEncryption_supported_instances">Supported instance types</a>. If your AMI uses encrypted volumes, you can also only launch it on supported instance types.</p> <note> 
        /// <p>If you are creating a volume from a snapshot, you cannot create an unencrypted volume from an encrypted snapshot. Also, you cannot specify a KMS key ID when using a launch configuration.</p> 
        /// <p>If you enable encryption by default, the EBS volumes that you create are always encrypted, either using the Amazon Web Services managed KMS key or a customer-managed KMS key, regardless of whether the snapshot was encrypted. </p> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-data-protection.html#encryption">Use Amazon Web Services KMS keys to encrypt Amazon EBS volumes</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> 
        /// </note>
        pub fn encrypted(mut self, input: bool) -> Self {
            self.encrypted = Some(input);
            self
        }
        /// <p>Specifies whether the volume should be encrypted. Encrypted EBS volumes can only be attached to instances that support Amazon EBS encryption. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#EBSEncryption_supported_instances">Supported instance types</a>. If your AMI uses encrypted volumes, you can also only launch it on supported instance types.</p> <note> 
        /// <p>If you are creating a volume from a snapshot, you cannot create an unencrypted volume from an encrypted snapshot. Also, you cannot specify a KMS key ID when using a launch configuration.</p> 
        /// <p>If you enable encryption by default, the EBS volumes that you create are always encrypted, either using the Amazon Web Services managed KMS key or a customer-managed KMS key, regardless of whether the snapshot was encrypted. </p> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-data-protection.html#encryption">Use Amazon Web Services KMS keys to encrypt Amazon EBS volumes</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> 
        /// </note>
        pub fn set_encrypted(mut self, input: std::option::Option<bool>) -> Self {
            self.encrypted = input; self
        }
        /// <p>The throughput (MiBps) to provision for a <code>gp3</code> volume.</p>
        pub fn throughput(mut self, input: i32) -> Self {
            self.throughput = Some(input);
            self
        }
        /// <p>The throughput (MiBps) to provision for a <code>gp3</code> volume.</p>
        pub fn set_throughput(mut self, input: std::option::Option<i32>) -> Self {
            self.throughput = input; self
        }
        /// Consumes the builder and constructs a [`Ebs`](crate::model::Ebs).
        pub fn build(self) -> crate::model::Ebs {
            crate::model::Ebs {
                snapshot_id: self.snapshot_id
                ,
                volume_size: self.volume_size
                ,
                volume_type: self.volume_type
                ,
                delete_on_termination: self.delete_on_termination
                ,
                iops: self.iops
                ,
                encrypted: self.encrypted
                ,
                throughput: self.throughput
                ,
            }
        }
    }
    
    
}
impl Ebs {
    /// Creates a new builder-style object to manufacture [`Ebs`](crate::model::Ebs).
    pub fn builder() -> crate::model::ebs::Builder {
        crate::model::ebs::Builder::default()
    }
}

/// <p>Describes an instance refresh for an Auto Scaling group. </p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct InstanceRefresh  {
    /// <p>The instance refresh ID.</p>
    #[doc(hidden)]
    pub instance_refresh_id: std::option::Option<std::string::String>,
    /// <p>The name of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub auto_scaling_group_name: std::option::Option<std::string::String>,
    /// <p>The current status for the instance refresh operation:</p> 
    /// <ul> 
    /// <li> <p> <code>Pending</code> - The request was created, but the operation has not started.</p> </li> 
    /// <li> <p> <code>InProgress</code> - The operation is in progress.</p> </li> 
    /// <li> <p> <code>Successful</code> - The operation completed successfully.</p> </li> 
    /// <li> <p> <code>Failed</code> - The operation failed to complete. You can troubleshoot using the status reason and the scaling activities. </p> </li> 
    /// <li> <p> <code>Cancelling</code> - An ongoing operation is being cancelled. Cancellation does not roll back any replacements that have already been completed, but it prevents new replacements from being started. </p> </li> 
    /// <li> <p> <code>Cancelled</code> - The operation is cancelled. </p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub status: std::option::Option<crate::model::InstanceRefreshStatus>,
    /// <p>Provides more details about the current status of the instance refresh. </p>
    #[doc(hidden)]
    pub status_reason: std::option::Option<std::string::String>,
    /// <p>The date and time at which the instance refresh began.</p>
    #[doc(hidden)]
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time at which the instance refresh ended.</p>
    #[doc(hidden)]
    pub end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The percentage of the instance refresh that is complete. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
    #[doc(hidden)]
    pub percentage_complete: std::option::Option<i32>,
    /// <p>The number of instances remaining to update before the instance refresh is complete.</p>
    #[doc(hidden)]
    pub instances_to_update: std::option::Option<i32>,
    /// <p>Additional progress details for an Auto Scaling group that has a warm pool.</p>
    #[doc(hidden)]
    pub progress_details: std::option::Option<crate::model::InstanceRefreshProgressDetails>,
    /// <p>Describes the preferences for an instance refresh.</p>
    #[doc(hidden)]
    pub preferences: std::option::Option<crate::model::RefreshPreferences>,
    /// <p>Describes the specific update you want to deploy.</p>
    #[doc(hidden)]
    pub desired_configuration: std::option::Option<crate::model::DesiredConfiguration>,
}
impl InstanceRefresh {
    /// <p>The instance refresh ID.</p>
    pub fn instance_refresh_id(&self) -> std::option::Option<& str> {
        self.instance_refresh_id.as_deref()
    }
    /// <p>The name of the Auto Scaling group.</p>
    pub fn auto_scaling_group_name(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_name.as_deref()
    }
    /// <p>The current status for the instance refresh operation:</p> 
    /// <ul> 
    /// <li> <p> <code>Pending</code> - The request was created, but the operation has not started.</p> </li> 
    /// <li> <p> <code>InProgress</code> - The operation is in progress.</p> </li> 
    /// <li> <p> <code>Successful</code> - The operation completed successfully.</p> </li> 
    /// <li> <p> <code>Failed</code> - The operation failed to complete. You can troubleshoot using the status reason and the scaling activities. </p> </li> 
    /// <li> <p> <code>Cancelling</code> - An ongoing operation is being cancelled. Cancellation does not roll back any replacements that have already been completed, but it prevents new replacements from being started. </p> </li> 
    /// <li> <p> <code>Cancelled</code> - The operation is cancelled. </p> </li> 
    /// </ul>
    pub fn status(&self) -> std::option::Option<& crate::model::InstanceRefreshStatus> {
        self.status.as_ref()
    }
    /// <p>Provides more details about the current status of the instance refresh. </p>
    pub fn status_reason(&self) -> std::option::Option<& str> {
        self.status_reason.as_deref()
    }
    /// <p>The date and time at which the instance refresh began.</p>
    pub fn start_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p>The date and time at which the instance refresh ended.</p>
    pub fn end_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.end_time.as_ref()
    }
    /// <p>The percentage of the instance refresh that is complete. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
    pub fn percentage_complete(&self) -> std::option::Option<i32> {
        self.percentage_complete
    }
    /// <p>The number of instances remaining to update before the instance refresh is complete.</p>
    pub fn instances_to_update(&self) -> std::option::Option<i32> {
        self.instances_to_update
    }
    /// <p>Additional progress details for an Auto Scaling group that has a warm pool.</p>
    pub fn progress_details(&self) -> std::option::Option<& crate::model::InstanceRefreshProgressDetails> {
        self.progress_details.as_ref()
    }
    /// <p>Describes the preferences for an instance refresh.</p>
    pub fn preferences(&self) -> std::option::Option<& crate::model::RefreshPreferences> {
        self.preferences.as_ref()
    }
    /// <p>Describes the specific update you want to deploy.</p>
    pub fn desired_configuration(&self) -> std::option::Option<& crate::model::DesiredConfiguration> {
        self.desired_configuration.as_ref()
    }
}
/// See [`InstanceRefresh`](crate::model::InstanceRefresh).
pub mod instance_refresh {
    
    /// A builder for [`InstanceRefresh`](crate::model::InstanceRefresh).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) instance_refresh_id: std::option::Option<std::string::String>,
        pub(crate) auto_scaling_group_name: std::option::Option<std::string::String>,
        pub(crate) status: std::option::Option<crate::model::InstanceRefreshStatus>,
        pub(crate) status_reason: std::option::Option<std::string::String>,
        pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) end_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) percentage_complete: std::option::Option<i32>,
        pub(crate) instances_to_update: std::option::Option<i32>,
        pub(crate) progress_details: std::option::Option<crate::model::InstanceRefreshProgressDetails>,
        pub(crate) preferences: std::option::Option<crate::model::RefreshPreferences>,
        pub(crate) desired_configuration: std::option::Option<crate::model::DesiredConfiguration>,
    }
    impl Builder {
        /// <p>The instance refresh ID.</p>
        pub fn instance_refresh_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.instance_refresh_id = Some(input.into());
            self
        }
        /// <p>The instance refresh ID.</p>
        pub fn set_instance_refresh_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.instance_refresh_id = input; self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.auto_scaling_group_name = Some(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.auto_scaling_group_name = input; self
        }
        /// <p>The current status for the instance refresh operation:</p> 
        /// <ul> 
        /// <li> <p> <code>Pending</code> - The request was created, but the operation has not started.</p> </li> 
        /// <li> <p> <code>InProgress</code> - The operation is in progress.</p> </li> 
        /// <li> <p> <code>Successful</code> - The operation completed successfully.</p> </li> 
        /// <li> <p> <code>Failed</code> - The operation failed to complete. You can troubleshoot using the status reason and the scaling activities. </p> </li> 
        /// <li> <p> <code>Cancelling</code> - An ongoing operation is being cancelled. Cancellation does not roll back any replacements that have already been completed, but it prevents new replacements from being started. </p> </li> 
        /// <li> <p> <code>Cancelled</code> - The operation is cancelled. </p> </li> 
        /// </ul>
        pub fn status(mut self, input: crate::model::InstanceRefreshStatus) -> Self {
            self.status = Some(input);
            self
        }
        /// <p>The current status for the instance refresh operation:</p> 
        /// <ul> 
        /// <li> <p> <code>Pending</code> - The request was created, but the operation has not started.</p> </li> 
        /// <li> <p> <code>InProgress</code> - The operation is in progress.</p> </li> 
        /// <li> <p> <code>Successful</code> - The operation completed successfully.</p> </li> 
        /// <li> <p> <code>Failed</code> - The operation failed to complete. You can troubleshoot using the status reason and the scaling activities. </p> </li> 
        /// <li> <p> <code>Cancelling</code> - An ongoing operation is being cancelled. Cancellation does not roll back any replacements that have already been completed, but it prevents new replacements from being started. </p> </li> 
        /// <li> <p> <code>Cancelled</code> - The operation is cancelled. </p> </li> 
        /// </ul>
        pub fn set_status(mut self, input: std::option::Option<crate::model::InstanceRefreshStatus>) -> Self {
            self.status = input; self
        }
        /// <p>Provides more details about the current status of the instance refresh. </p>
        pub fn status_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.status_reason = Some(input.into());
            self
        }
        /// <p>Provides more details about the current status of the instance refresh. </p>
        pub fn set_status_reason(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.status_reason = input; self
        }
        /// <p>The date and time at which the instance refresh began.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p>The date and time at which the instance refresh began.</p>
        pub fn set_start_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.start_time = input; self
        }
        /// <p>The date and time at which the instance refresh ended.</p>
        pub fn end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.end_time = Some(input);
            self
        }
        /// <p>The date and time at which the instance refresh ended.</p>
        pub fn set_end_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.end_time = input; self
        }
        /// <p>The percentage of the instance refresh that is complete. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
        pub fn percentage_complete(mut self, input: i32) -> Self {
            self.percentage_complete = Some(input);
            self
        }
        /// <p>The percentage of the instance refresh that is complete. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
        pub fn set_percentage_complete(mut self, input: std::option::Option<i32>) -> Self {
            self.percentage_complete = input; self
        }
        /// <p>The number of instances remaining to update before the instance refresh is complete.</p>
        pub fn instances_to_update(mut self, input: i32) -> Self {
            self.instances_to_update = Some(input);
            self
        }
        /// <p>The number of instances remaining to update before the instance refresh is complete.</p>
        pub fn set_instances_to_update(mut self, input: std::option::Option<i32>) -> Self {
            self.instances_to_update = input; self
        }
        /// <p>Additional progress details for an Auto Scaling group that has a warm pool.</p>
        pub fn progress_details(mut self, input: crate::model::InstanceRefreshProgressDetails) -> Self {
            self.progress_details = Some(input);
            self
        }
        /// <p>Additional progress details for an Auto Scaling group that has a warm pool.</p>
        pub fn set_progress_details(mut self, input: std::option::Option<crate::model::InstanceRefreshProgressDetails>) -> Self {
            self.progress_details = input; self
        }
        /// <p>Describes the preferences for an instance refresh.</p>
        pub fn preferences(mut self, input: crate::model::RefreshPreferences) -> Self {
            self.preferences = Some(input);
            self
        }
        /// <p>Describes the preferences for an instance refresh.</p>
        pub fn set_preferences(mut self, input: std::option::Option<crate::model::RefreshPreferences>) -> Self {
            self.preferences = input; self
        }
        /// <p>Describes the specific update you want to deploy.</p>
        pub fn desired_configuration(mut self, input: crate::model::DesiredConfiguration) -> Self {
            self.desired_configuration = Some(input);
            self
        }
        /// <p>Describes the specific update you want to deploy.</p>
        pub fn set_desired_configuration(mut self, input: std::option::Option<crate::model::DesiredConfiguration>) -> Self {
            self.desired_configuration = input; self
        }
        /// Consumes the builder and constructs a [`InstanceRefresh`](crate::model::InstanceRefresh).
        pub fn build(self) -> crate::model::InstanceRefresh {
            crate::model::InstanceRefresh {
                instance_refresh_id: self.instance_refresh_id
                ,
                auto_scaling_group_name: self.auto_scaling_group_name
                ,
                status: self.status
                ,
                status_reason: self.status_reason
                ,
                start_time: self.start_time
                ,
                end_time: self.end_time
                ,
                percentage_complete: self.percentage_complete
                ,
                instances_to_update: self.instances_to_update
                ,
                progress_details: self.progress_details
                ,
                preferences: self.preferences
                ,
                desired_configuration: self.desired_configuration
                ,
            }
        }
    }
    
    
}
impl InstanceRefresh {
    /// Creates a new builder-style object to manufacture [`InstanceRefresh`](crate::model::InstanceRefresh).
    pub fn builder() -> crate::model::instance_refresh::Builder {
        crate::model::instance_refresh::Builder::default()
    }
}

/// <p>Reports the progress of an instance refresh on an Auto Scaling group that has a warm pool. This includes separate details for instances in the warm pool and instances in the Auto Scaling group (the live pool).</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct InstanceRefreshProgressDetails  {
    /// <p>Indicates the progress of an instance refresh on instances that are in the Auto Scaling group.</p>
    #[doc(hidden)]
    pub live_pool_progress: std::option::Option<crate::model::InstanceRefreshLivePoolProgress>,
    /// <p>Indicates the progress of an instance refresh on instances that are in the warm pool.</p>
    #[doc(hidden)]
    pub warm_pool_progress: std::option::Option<crate::model::InstanceRefreshWarmPoolProgress>,
}
impl InstanceRefreshProgressDetails {
    /// <p>Indicates the progress of an instance refresh on instances that are in the Auto Scaling group.</p>
    pub fn live_pool_progress(&self) -> std::option::Option<& crate::model::InstanceRefreshLivePoolProgress> {
        self.live_pool_progress.as_ref()
    }
    /// <p>Indicates the progress of an instance refresh on instances that are in the warm pool.</p>
    pub fn warm_pool_progress(&self) -> std::option::Option<& crate::model::InstanceRefreshWarmPoolProgress> {
        self.warm_pool_progress.as_ref()
    }
}
/// See [`InstanceRefreshProgressDetails`](crate::model::InstanceRefreshProgressDetails).
pub mod instance_refresh_progress_details {
    
    /// A builder for [`InstanceRefreshProgressDetails`](crate::model::InstanceRefreshProgressDetails).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) live_pool_progress: std::option::Option<crate::model::InstanceRefreshLivePoolProgress>,
        pub(crate) warm_pool_progress: std::option::Option<crate::model::InstanceRefreshWarmPoolProgress>,
    }
    impl Builder {
        /// <p>Indicates the progress of an instance refresh on instances that are in the Auto Scaling group.</p>
        pub fn live_pool_progress(mut self, input: crate::model::InstanceRefreshLivePoolProgress) -> Self {
            self.live_pool_progress = Some(input);
            self
        }
        /// <p>Indicates the progress of an instance refresh on instances that are in the Auto Scaling group.</p>
        pub fn set_live_pool_progress(mut self, input: std::option::Option<crate::model::InstanceRefreshLivePoolProgress>) -> Self {
            self.live_pool_progress = input; self
        }
        /// <p>Indicates the progress of an instance refresh on instances that are in the warm pool.</p>
        pub fn warm_pool_progress(mut self, input: crate::model::InstanceRefreshWarmPoolProgress) -> Self {
            self.warm_pool_progress = Some(input);
            self
        }
        /// <p>Indicates the progress of an instance refresh on instances that are in the warm pool.</p>
        pub fn set_warm_pool_progress(mut self, input: std::option::Option<crate::model::InstanceRefreshWarmPoolProgress>) -> Self {
            self.warm_pool_progress = input; self
        }
        /// Consumes the builder and constructs a [`InstanceRefreshProgressDetails`](crate::model::InstanceRefreshProgressDetails).
        pub fn build(self) -> crate::model::InstanceRefreshProgressDetails {
            crate::model::InstanceRefreshProgressDetails {
                live_pool_progress: self.live_pool_progress
                ,
                warm_pool_progress: self.warm_pool_progress
                ,
            }
        }
    }
    
    
}
impl InstanceRefreshProgressDetails {
    /// Creates a new builder-style object to manufacture [`InstanceRefreshProgressDetails`](crate::model::InstanceRefreshProgressDetails).
    pub fn builder() -> crate::model::instance_refresh_progress_details::Builder {
        crate::model::instance_refresh_progress_details::Builder::default()
    }
}

/// <p>Reports the progress of an instance refresh on instances that are in the warm pool.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct InstanceRefreshWarmPoolProgress  {
    /// <p>The percentage of instances in the warm pool that have been replaced. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
    #[doc(hidden)]
    pub percentage_complete: std::option::Option<i32>,
    /// <p>The number of instances remaining to update.</p>
    #[doc(hidden)]
    pub instances_to_update: std::option::Option<i32>,
}
impl InstanceRefreshWarmPoolProgress {
    /// <p>The percentage of instances in the warm pool that have been replaced. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
    pub fn percentage_complete(&self) -> std::option::Option<i32> {
        self.percentage_complete
    }
    /// <p>The number of instances remaining to update.</p>
    pub fn instances_to_update(&self) -> std::option::Option<i32> {
        self.instances_to_update
    }
}
/// See [`InstanceRefreshWarmPoolProgress`](crate::model::InstanceRefreshWarmPoolProgress).
pub mod instance_refresh_warm_pool_progress {
    
    /// A builder for [`InstanceRefreshWarmPoolProgress`](crate::model::InstanceRefreshWarmPoolProgress).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) percentage_complete: std::option::Option<i32>,
        pub(crate) instances_to_update: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The percentage of instances in the warm pool that have been replaced. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
        pub fn percentage_complete(mut self, input: i32) -> Self {
            self.percentage_complete = Some(input);
            self
        }
        /// <p>The percentage of instances in the warm pool that have been replaced. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
        pub fn set_percentage_complete(mut self, input: std::option::Option<i32>) -> Self {
            self.percentage_complete = input; self
        }
        /// <p>The number of instances remaining to update.</p>
        pub fn instances_to_update(mut self, input: i32) -> Self {
            self.instances_to_update = Some(input);
            self
        }
        /// <p>The number of instances remaining to update.</p>
        pub fn set_instances_to_update(mut self, input: std::option::Option<i32>) -> Self {
            self.instances_to_update = input; self
        }
        /// Consumes the builder and constructs a [`InstanceRefreshWarmPoolProgress`](crate::model::InstanceRefreshWarmPoolProgress).
        pub fn build(self) -> crate::model::InstanceRefreshWarmPoolProgress {
            crate::model::InstanceRefreshWarmPoolProgress {
                percentage_complete: self.percentage_complete
                ,
                instances_to_update: self.instances_to_update
                ,
            }
        }
    }
    
    
}
impl InstanceRefreshWarmPoolProgress {
    /// Creates a new builder-style object to manufacture [`InstanceRefreshWarmPoolProgress`](crate::model::InstanceRefreshWarmPoolProgress).
    pub fn builder() -> crate::model::instance_refresh_warm_pool_progress::Builder {
        crate::model::instance_refresh_warm_pool_progress::Builder::default()
    }
}

/// <p>Reports the progress of an instance refresh on instances that are in the Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct InstanceRefreshLivePoolProgress  {
    /// <p>The percentage of instances in the Auto Scaling group that have been replaced. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
    #[doc(hidden)]
    pub percentage_complete: std::option::Option<i32>,
    /// <p>The number of instances remaining to update.</p>
    #[doc(hidden)]
    pub instances_to_update: std::option::Option<i32>,
}
impl InstanceRefreshLivePoolProgress {
    /// <p>The percentage of instances in the Auto Scaling group that have been replaced. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
    pub fn percentage_complete(&self) -> std::option::Option<i32> {
        self.percentage_complete
    }
    /// <p>The number of instances remaining to update.</p>
    pub fn instances_to_update(&self) -> std::option::Option<i32> {
        self.instances_to_update
    }
}
/// See [`InstanceRefreshLivePoolProgress`](crate::model::InstanceRefreshLivePoolProgress).
pub mod instance_refresh_live_pool_progress {
    
    /// A builder for [`InstanceRefreshLivePoolProgress`](crate::model::InstanceRefreshLivePoolProgress).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) percentage_complete: std::option::Option<i32>,
        pub(crate) instances_to_update: std::option::Option<i32>,
    }
    impl Builder {
        /// <p>The percentage of instances in the Auto Scaling group that have been replaced. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
        pub fn percentage_complete(mut self, input: i32) -> Self {
            self.percentage_complete = Some(input);
            self
        }
        /// <p>The percentage of instances in the Auto Scaling group that have been replaced. For each instance replacement, Amazon EC2 Auto Scaling tracks the instance's health status and warm-up time. When the instance's health status changes to healthy and the specified warm-up time passes, the instance is considered updated and is added to the percentage complete.</p>
        pub fn set_percentage_complete(mut self, input: std::option::Option<i32>) -> Self {
            self.percentage_complete = input; self
        }
        /// <p>The number of instances remaining to update.</p>
        pub fn instances_to_update(mut self, input: i32) -> Self {
            self.instances_to_update = Some(input);
            self
        }
        /// <p>The number of instances remaining to update.</p>
        pub fn set_instances_to_update(mut self, input: std::option::Option<i32>) -> Self {
            self.instances_to_update = input; self
        }
        /// Consumes the builder and constructs a [`InstanceRefreshLivePoolProgress`](crate::model::InstanceRefreshLivePoolProgress).
        pub fn build(self) -> crate::model::InstanceRefreshLivePoolProgress {
            crate::model::InstanceRefreshLivePoolProgress {
                percentage_complete: self.percentage_complete
                ,
                instances_to_update: self.instances_to_update
                ,
            }
        }
    }
    
    
}
impl InstanceRefreshLivePoolProgress {
    /// Creates a new builder-style object to manufacture [`InstanceRefreshLivePoolProgress`](crate::model::InstanceRefreshLivePoolProgress).
    pub fn builder() -> crate::model::instance_refresh_live_pool_progress::Builder {
        crate::model::instance_refresh_live_pool_progress::Builder::default()
    }
}

/// When writing a match expression against `InstanceRefreshStatus`, it is important to ensure
/// your code is forward-compatible. That is, if a match arm handles a case for a
/// feature that is supported by the service but has not been represented as an enum
/// variant in a current version of SDK, your code should continue to work when you
/// upgrade SDK to a future version in which the enum does include a variant for that
/// feature.
/// 
/// Here is an example of how you can make a match expression forward-compatible:
/// 
/// ```text
/// # let instancerefreshstatus = unimplemented!();
/// match instancerefreshstatus {
///     InstanceRefreshStatus::Cancelled => { /* ... */ },
///     InstanceRefreshStatus::Cancelling => { /* ... */ },
///     InstanceRefreshStatus::Failed => { /* ... */ },
///     InstanceRefreshStatus::InProgress => { /* ... */ },
///     InstanceRefreshStatus::Pending => { /* ... */ },
///     InstanceRefreshStatus::Successful => { /* ... */ },
///     other @ _ if other.as_str() == "NewFeature" => { /* handles a case for `NewFeature` */ },
///     _ => { /* ... */ },
/// }
/// ```
/// The above code demonstrates that when `instancerefreshstatus` represents
/// `NewFeature`, the execution path will lead to the second last match arm,
/// even though the enum does not contain a variant `InstanceRefreshStatus::NewFeature`
/// in the current version of SDK. The reason is that the variable `other`,
/// created by the `@` operator, is bound to
/// `InstanceRefreshStatus::Unknown(UnknownVariantValue("NewFeature".to_owned()))`
/// and calling `as_str` on it yields `"NewFeature"`.
/// This match expression is forward-compatible when executed with a newer
/// version of SDK where the variant `InstanceRefreshStatus::NewFeature` is defined.
/// Specifically, when `instancerefreshstatus` represents `NewFeature`,
/// the execution path will hit the second last match arm as before by virtue of
/// calling `as_str` on `InstanceRefreshStatus::NewFeature` also yielding `"NewFeature"`.
/// 
/// Explicitly matching on the `Unknown` variant should
/// be avoided for two reasons:
/// - The inner data `UnknownVariantValue` is opaque, and no further information can be extracted.
/// - It might inadvertently shadow other intended match arms.
#[allow(missing_docs)] // documentation missing in model
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::Eq, std::cmp::Ord, std::cmp::PartialEq, std::cmp::PartialOrd, std::fmt::Debug, std::hash::Hash)]
pub enum InstanceRefreshStatus {
    #[allow(missing_docs)] // documentation missing in model
    Cancelled,
    #[allow(missing_docs)] // documentation missing in model
    Cancelling,
    #[allow(missing_docs)] // documentation missing in model
    Failed,
    #[allow(missing_docs)] // documentation missing in model
    InProgress,
    #[allow(missing_docs)] // documentation missing in model
    Pending,
    #[allow(missing_docs)] // documentation missing in model
    Successful,
    /// `Unknown` contains new variants that have been added since this code was generated.
    Unknown(crate::types::UnknownVariantValue)
}
impl std::convert::From<&str> for InstanceRefreshStatus {
    fn from(s: &str) -> Self {
        match s {
            "Cancelled" => InstanceRefreshStatus::Cancelled,
            "Cancelling" => InstanceRefreshStatus::Cancelling,
            "Failed" => InstanceRefreshStatus::Failed,
            "InProgress" => InstanceRefreshStatus::InProgress,
            "Pending" => InstanceRefreshStatus::Pending,
            "Successful" => InstanceRefreshStatus::Successful,
            other => InstanceRefreshStatus::Unknown(crate::types::UnknownVariantValue(other.to_owned()))
        }
    }
}
impl std::str::FromStr for InstanceRefreshStatus {
                type Err = std::convert::Infallible;

                fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
                    Ok(InstanceRefreshStatus::from(s))
                }
            }
impl InstanceRefreshStatus {
    /// Returns the `&str` value of the enum member.
    pub fn as_str(&self) -> &str {
        match self {
            InstanceRefreshStatus::Cancelled => "Cancelled",
            InstanceRefreshStatus::Cancelling => "Cancelling",
            InstanceRefreshStatus::Failed => "Failed",
            InstanceRefreshStatus::InProgress => "InProgress",
            InstanceRefreshStatus::Pending => "Pending",
            InstanceRefreshStatus::Successful => "Successful",
            InstanceRefreshStatus::Unknown(value) => value.as_str()
        }
    }
    /// Returns all the `&str` values of the enum members.
    pub const fn values() -> &'static [&'static str] {
        &[
            "Cancelled", "Cancelling", "Failed", "InProgress", "Pending", "Successful"
        ]
    }
}
impl AsRef<str> for InstanceRefreshStatus {
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

/// <p>Describes an EC2 instance associated with an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct AutoScalingInstanceDetails  {
    /// <p>The ID of the instance.</p>
    #[doc(hidden)]
    pub instance_id: std::option::Option<std::string::String>,
    /// <p>The instance type of the EC2 instance.</p>
    #[doc(hidden)]
    pub instance_type: std::option::Option<std::string::String>,
    /// <p>The name of the Auto Scaling group for the instance.</p>
    #[doc(hidden)]
    pub auto_scaling_group_name: std::option::Option<std::string::String>,
    /// <p>The Availability Zone for the instance.</p>
    #[doc(hidden)]
    pub availability_zone: std::option::Option<std::string::String>,
    /// <p>The lifecycle state for the instance. The <code>Quarantined</code> state is not used. For information about lifecycle states, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroupLifecycle.html">Instance lifecycle</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p> 
    /// <p>Valid values: <code>Pending</code> | <code>Pending:Wait</code> | <code>Pending:Proceed</code> | <code>Quarantined</code> | <code>InService</code> | <code>Terminating</code> | <code>Terminating:Wait</code> | <code>Terminating:Proceed</code> | <code>Terminated</code> | <code>Detaching</code> | <code>Detached</code> | <code>EnteringStandby</code> | <code>Standby</code> | <code>Warmed:Pending</code> | <code>Warmed:Pending:Wait</code> | <code>Warmed:Pending:Proceed</code> | <code>Warmed:Terminating</code> | <code>Warmed:Terminating:Wait</code> | <code>Warmed:Terminating:Proceed</code> | <code>Warmed:Terminated</code> | <code>Warmed:Stopped</code> | <code>Warmed:Running</code> </p>
    #[doc(hidden)]
    pub lifecycle_state: std::option::Option<std::string::String>,
    /// <p>The last reported health status of this instance. "Healthy" means that the instance is healthy and should remain in service. "Unhealthy" means that the instance is unhealthy and Amazon EC2 Auto Scaling should terminate and replace it.</p>
    #[doc(hidden)]
    pub health_status: std::option::Option<std::string::String>,
    /// <p>The launch configuration used to launch the instance. This value is not available if you attached the instance to the Auto Scaling group.</p>
    #[doc(hidden)]
    pub launch_configuration_name: std::option::Option<std::string::String>,
    /// <p>The launch template for the instance.</p>
    #[doc(hidden)]
    pub launch_template: std::option::Option<crate::model::LaunchTemplateSpecification>,
    /// <p>Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
    #[doc(hidden)]
    pub protected_from_scale_in: std::option::Option<bool>,
    /// <p>The number of capacity units contributed by the instance based on its instance type.</p> 
    /// <p>Valid Range: Minimum value of 1. Maximum value of 999.</p>
    #[doc(hidden)]
    pub weighted_capacity: std::option::Option<std::string::String>,
}
impl AutoScalingInstanceDetails {
    /// <p>The ID of the instance.</p>
    pub fn instance_id(&self) -> std::option::Option<& str> {
        self.instance_id.as_deref()
    }
    /// <p>The instance type of the EC2 instance.</p>
    pub fn instance_type(&self) -> std::option::Option<& str> {
        self.instance_type.as_deref()
    }
    /// <p>The name of the Auto Scaling group for the instance.</p>
    pub fn auto_scaling_group_name(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_name.as_deref()
    }
    /// <p>The Availability Zone for the instance.</p>
    pub fn availability_zone(&self) -> std::option::Option<& str> {
        self.availability_zone.as_deref()
    }
    /// <p>The lifecycle state for the instance. The <code>Quarantined</code> state is not used. For information about lifecycle states, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroupLifecycle.html">Instance lifecycle</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p> 
    /// <p>Valid values: <code>Pending</code> | <code>Pending:Wait</code> | <code>Pending:Proceed</code> | <code>Quarantined</code> | <code>InService</code> | <code>Terminating</code> | <code>Terminating:Wait</code> | <code>Terminating:Proceed</code> | <code>Terminated</code> | <code>Detaching</code> | <code>Detached</code> | <code>EnteringStandby</code> | <code>Standby</code> | <code>Warmed:Pending</code> | <code>Warmed:Pending:Wait</code> | <code>Warmed:Pending:Proceed</code> | <code>Warmed:Terminating</code> | <code>Warmed:Terminating:Wait</code> | <code>Warmed:Terminating:Proceed</code> | <code>Warmed:Terminated</code> | <code>Warmed:Stopped</code> | <code>Warmed:Running</code> </p>
    pub fn lifecycle_state(&self) -> std::option::Option<& str> {
        self.lifecycle_state.as_deref()
    }
    /// <p>The last reported health status of this instance. "Healthy" means that the instance is healthy and should remain in service. "Unhealthy" means that the instance is unhealthy and Amazon EC2 Auto Scaling should terminate and replace it.</p>
    pub fn health_status(&self) -> std::option::Option<& str> {
        self.health_status.as_deref()
    }
    /// <p>The launch configuration used to launch the instance. This value is not available if you attached the instance to the Auto Scaling group.</p>
    pub fn launch_configuration_name(&self) -> std::option::Option<& str> {
        self.launch_configuration_name.as_deref()
    }
    /// <p>The launch template for the instance.</p>
    pub fn launch_template(&self) -> std::option::Option<& crate::model::LaunchTemplateSpecification> {
        self.launch_template.as_ref()
    }
    /// <p>Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
    pub fn protected_from_scale_in(&self) -> std::option::Option<bool> {
        self.protected_from_scale_in
    }
    /// <p>The number of capacity units contributed by the instance based on its instance type.</p> 
    /// <p>Valid Range: Minimum value of 1. Maximum value of 999.</p>
    pub fn weighted_capacity(&self) -> std::option::Option<& str> {
        self.weighted_capacity.as_deref()
    }
}
/// See [`AutoScalingInstanceDetails`](crate::model::AutoScalingInstanceDetails).
pub mod auto_scaling_instance_details {
    
    /// A builder for [`AutoScalingInstanceDetails`](crate::model::AutoScalingInstanceDetails).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) instance_id: std::option::Option<std::string::String>,
        pub(crate) instance_type: std::option::Option<std::string::String>,
        pub(crate) auto_scaling_group_name: std::option::Option<std::string::String>,
        pub(crate) availability_zone: std::option::Option<std::string::String>,
        pub(crate) lifecycle_state: std::option::Option<std::string::String>,
        pub(crate) health_status: std::option::Option<std::string::String>,
        pub(crate) launch_configuration_name: std::option::Option<std::string::String>,
        pub(crate) launch_template: std::option::Option<crate::model::LaunchTemplateSpecification>,
        pub(crate) protected_from_scale_in: std::option::Option<bool>,
        pub(crate) weighted_capacity: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The ID of the instance.</p>
        pub fn instance_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.instance_id = Some(input.into());
            self
        }
        /// <p>The ID of the instance.</p>
        pub fn set_instance_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.instance_id = input; self
        }
        /// <p>The instance type of the EC2 instance.</p>
        pub fn instance_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.instance_type = Some(input.into());
            self
        }
        /// <p>The instance type of the EC2 instance.</p>
        pub fn set_instance_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.instance_type = input; self
        }
        /// <p>The name of the Auto Scaling group for the instance.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.auto_scaling_group_name = Some(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group for the instance.</p>
        pub fn set_auto_scaling_group_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.auto_scaling_group_name = input; self
        }
        /// <p>The Availability Zone for the instance.</p>
        pub fn availability_zone(mut self, input: impl Into<std::string::String>) -> Self {
            self.availability_zone = Some(input.into());
            self
        }
        /// <p>The Availability Zone for the instance.</p>
        pub fn set_availability_zone(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.availability_zone = input; self
        }
        /// <p>The lifecycle state for the instance. The <code>Quarantined</code> state is not used. For information about lifecycle states, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroupLifecycle.html">Instance lifecycle</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p> 
        /// <p>Valid values: <code>Pending</code> | <code>Pending:Wait</code> | <code>Pending:Proceed</code> | <code>Quarantined</code> | <code>InService</code> | <code>Terminating</code> | <code>Terminating:Wait</code> | <code>Terminating:Proceed</code> | <code>Terminated</code> | <code>Detaching</code> | <code>Detached</code> | <code>EnteringStandby</code> | <code>Standby</code> | <code>Warmed:Pending</code> | <code>Warmed:Pending:Wait</code> | <code>Warmed:Pending:Proceed</code> | <code>Warmed:Terminating</code> | <code>Warmed:Terminating:Wait</code> | <code>Warmed:Terminating:Proceed</code> | <code>Warmed:Terminated</code> | <code>Warmed:Stopped</code> | <code>Warmed:Running</code> </p>
        pub fn lifecycle_state(mut self, input: impl Into<std::string::String>) -> Self {
            self.lifecycle_state = Some(input.into());
            self
        }
        /// <p>The lifecycle state for the instance. The <code>Quarantined</code> state is not used. For information about lifecycle states, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroupLifecycle.html">Instance lifecycle</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p> 
        /// <p>Valid values: <code>Pending</code> | <code>Pending:Wait</code> | <code>Pending:Proceed</code> | <code>Quarantined</code> | <code>InService</code> | <code>Terminating</code> | <code>Terminating:Wait</code> | <code>Terminating:Proceed</code> | <code>Terminated</code> | <code>Detaching</code> | <code>Detached</code> | <code>EnteringStandby</code> | <code>Standby</code> | <code>Warmed:Pending</code> | <code>Warmed:Pending:Wait</code> | <code>Warmed:Pending:Proceed</code> | <code>Warmed:Terminating</code> | <code>Warmed:Terminating:Wait</code> | <code>Warmed:Terminating:Proceed</code> | <code>Warmed:Terminated</code> | <code>Warmed:Stopped</code> | <code>Warmed:Running</code> </p>
        pub fn set_lifecycle_state(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.lifecycle_state = input; self
        }
        /// <p>The last reported health status of this instance. "Healthy" means that the instance is healthy and should remain in service. "Unhealthy" means that the instance is unhealthy and Amazon EC2 Auto Scaling should terminate and replace it.</p>
        pub fn health_status(mut self, input: impl Into<std::string::String>) -> Self {
            self.health_status = Some(input.into());
            self
        }
        /// <p>The last reported health status of this instance. "Healthy" means that the instance is healthy and should remain in service. "Unhealthy" means that the instance is unhealthy and Amazon EC2 Auto Scaling should terminate and replace it.</p>
        pub fn set_health_status(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.health_status = input; self
        }
        /// <p>The launch configuration used to launch the instance. This value is not available if you attached the instance to the Auto Scaling group.</p>
        pub fn launch_configuration_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.launch_configuration_name = Some(input.into());
            self
        }
        /// <p>The launch configuration used to launch the instance. This value is not available if you attached the instance to the Auto Scaling group.</p>
        pub fn set_launch_configuration_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.launch_configuration_name = input; self
        }
        /// <p>The launch template for the instance.</p>
        pub fn launch_template(mut self, input: crate::model::LaunchTemplateSpecification) -> Self {
            self.launch_template = Some(input);
            self
        }
        /// <p>The launch template for the instance.</p>
        pub fn set_launch_template(mut self, input: std::option::Option<crate::model::LaunchTemplateSpecification>) -> Self {
            self.launch_template = input; self
        }
        /// <p>Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
        pub fn protected_from_scale_in(mut self, input: bool) -> Self {
            self.protected_from_scale_in = Some(input);
            self
        }
        /// <p>Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
        pub fn set_protected_from_scale_in(mut self, input: std::option::Option<bool>) -> Self {
            self.protected_from_scale_in = input; self
        }
        /// <p>The number of capacity units contributed by the instance based on its instance type.</p> 
        /// <p>Valid Range: Minimum value of 1. Maximum value of 999.</p>
        pub fn weighted_capacity(mut self, input: impl Into<std::string::String>) -> Self {
            self.weighted_capacity = Some(input.into());
            self
        }
        /// <p>The number of capacity units contributed by the instance based on its instance type.</p> 
        /// <p>Valid Range: Minimum value of 1. Maximum value of 999.</p>
        pub fn set_weighted_capacity(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.weighted_capacity = input; self
        }
        /// Consumes the builder and constructs a [`AutoScalingInstanceDetails`](crate::model::AutoScalingInstanceDetails).
        pub fn build(self) -> crate::model::AutoScalingInstanceDetails {
            crate::model::AutoScalingInstanceDetails {
                instance_id: self.instance_id
                ,
                instance_type: self.instance_type
                ,
                auto_scaling_group_name: self.auto_scaling_group_name
                ,
                availability_zone: self.availability_zone
                ,
                lifecycle_state: self.lifecycle_state
                ,
                health_status: self.health_status
                ,
                launch_configuration_name: self.launch_configuration_name
                ,
                launch_template: self.launch_template
                ,
                protected_from_scale_in: self.protected_from_scale_in
                ,
                weighted_capacity: self.weighted_capacity
                ,
            }
        }
    }
    
    
}
impl AutoScalingInstanceDetails {
    /// Creates a new builder-style object to manufacture [`AutoScalingInstanceDetails`](crate::model::AutoScalingInstanceDetails).
    pub fn builder() -> crate::model::auto_scaling_instance_details::Builder {
        crate::model::auto_scaling_instance_details::Builder::default()
    }
}

/// <p>Describes an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct AutoScalingGroup  {
    /// <p>The name of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub auto_scaling_group_name: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub auto_scaling_group_arn: std::option::Option<std::string::String>,
    /// <p>The name of the associated launch configuration.</p>
    #[doc(hidden)]
    pub launch_configuration_name: std::option::Option<std::string::String>,
    /// <p>The launch template for the group.</p>
    #[doc(hidden)]
    pub launch_template: std::option::Option<crate::model::LaunchTemplateSpecification>,
    /// <p>The mixed instances policy for the group.</p>
    #[doc(hidden)]
    pub mixed_instances_policy: std::option::Option<crate::model::MixedInstancesPolicy>,
    /// <p>The minimum size of the group.</p>
    #[doc(hidden)]
    pub min_size: std::option::Option<i32>,
    /// <p>The maximum size of the group.</p>
    #[doc(hidden)]
    pub max_size: std::option::Option<i32>,
    /// <p>The desired size of the group.</p>
    #[doc(hidden)]
    pub desired_capacity: std::option::Option<i32>,
    /// <p>The predicted capacity of the group when it has a predictive scaling policy.</p>
    #[doc(hidden)]
    pub predicted_capacity: std::option::Option<i32>,
    /// <p>The duration of the default cooldown period, in seconds.</p>
    #[doc(hidden)]
    pub default_cooldown: std::option::Option<i32>,
    /// <p>One or more Availability Zones for the group.</p>
    #[doc(hidden)]
    pub availability_zones: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>One or more load balancers associated with the group.</p>
    #[doc(hidden)]
    pub load_balancer_names: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>The Amazon Resource Names (ARN) of the target groups for your load balancer.</p>
    #[doc(hidden)]
    pub target_group_ar_ns: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>Determines whether any additional health checks are performed on the instances in this group. Amazon EC2 health checks are always on.</p> 
    /// <p>The valid values are <code>EC2</code> (default), <code>ELB</code>, and <code>VPC_LATTICE</code>. The <code>VPC_LATTICE</code> health check type is reserved for use with VPC Lattice, which is in preview release and is subject to change.</p>
    #[doc(hidden)]
    pub health_check_type: std::option::Option<std::string::String>,
    /// <p>The duration of the health check grace period, in seconds.</p>
    #[doc(hidden)]
    pub health_check_grace_period: std::option::Option<i32>,
    /// <p>The EC2 instances associated with the group.</p>
    #[doc(hidden)]
    pub instances: std::option::Option<std::vec::Vec<crate::model::Instance>>,
    /// <p>The date and time the group was created.</p>
    #[doc(hidden)]
    pub created_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The suspended processes associated with the group.</p>
    #[doc(hidden)]
    pub suspended_processes: std::option::Option<std::vec::Vec<crate::model::SuspendedProcess>>,
    /// <p>The name of the placement group into which to launch your instances, if any.</p>
    #[doc(hidden)]
    pub placement_group: std::option::Option<std::string::String>,
    /// <p>One or more subnet IDs, if applicable, separated by commas.</p>
    #[doc(hidden)]
    pub vpc_zone_identifier: std::option::Option<std::string::String>,
    /// <p>The metrics enabled for the group.</p>
    #[doc(hidden)]
    pub enabled_metrics: std::option::Option<std::vec::Vec<crate::model::EnabledMetric>>,
    /// <p>The current state of the group when the <code>DeleteAutoScalingGroup</code> operation is in progress.</p>
    #[doc(hidden)]
    pub status: std::option::Option<std::string::String>,
    /// <p>The tags for the group.</p>
    #[doc(hidden)]
    pub tags: std::option::Option<std::vec::Vec<crate::model::TagDescription>>,
    /// <p>The termination policies for the group.</p>
    #[doc(hidden)]
    pub termination_policies: std::option::Option<std::vec::Vec<std::string::String>>,
    /// <p>Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
    #[doc(hidden)]
    pub new_instances_protected_from_scale_in: std::option::Option<bool>,
    /// <p>The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services on your behalf.</p>
    #[doc(hidden)]
    pub service_linked_role_arn: std::option::Option<std::string::String>,
    /// <p>The maximum amount of time, in seconds, that an instance can be in service.</p> 
    /// <p>Valid Range: Minimum value of 0.</p>
    #[doc(hidden)]
    pub max_instance_lifetime: std::option::Option<i32>,
    /// <p>Indicates whether Capacity Rebalancing is enabled.</p>
    #[doc(hidden)]
    pub capacity_rebalance: std::option::Option<bool>,
    /// <p>The warm pool for the group.</p>
    #[doc(hidden)]
    pub warm_pool_configuration: std::option::Option<crate::model::WarmPoolConfiguration>,
    /// <p>The current size of the warm pool.</p>
    #[doc(hidden)]
    pub warm_pool_size: std::option::Option<i32>,
    /// <p>Reserved.</p>
    #[doc(hidden)]
    pub context: std::option::Option<std::string::String>,
    /// <p>The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports <code>DesiredCapacityType</code> for attribute-based instance type selection only.</p>
    #[doc(hidden)]
    pub desired_capacity_type: std::option::Option<std::string::String>,
    /// <p>The duration of the default instance warmup, in seconds.</p>
    #[doc(hidden)]
    pub default_instance_warmup: std::option::Option<i32>,
    /// <p>The unique identifiers of the traffic sources.</p>
    #[doc(hidden)]
    pub traffic_sources: std::option::Option<std::vec::Vec<crate::model::TrafficSourceIdentifier>>,
}
impl AutoScalingGroup {
    /// <p>The name of the Auto Scaling group.</p>
    pub fn auto_scaling_group_name(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_name.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
    pub fn auto_scaling_group_arn(&self) -> std::option::Option<& str> {
        self.auto_scaling_group_arn.as_deref()
    }
    /// <p>The name of the associated launch configuration.</p>
    pub fn launch_configuration_name(&self) -> std::option::Option<& str> {
        self.launch_configuration_name.as_deref()
    }
    /// <p>The launch template for the group.</p>
    pub fn launch_template(&self) -> std::option::Option<& crate::model::LaunchTemplateSpecification> {
        self.launch_template.as_ref()
    }
    /// <p>The mixed instances policy for the group.</p>
    pub fn mixed_instances_policy(&self) -> std::option::Option<& crate::model::MixedInstancesPolicy> {
        self.mixed_instances_policy.as_ref()
    }
    /// <p>The minimum size of the group.</p>
    pub fn min_size(&self) -> std::option::Option<i32> {
        self.min_size
    }
    /// <p>The maximum size of the group.</p>
    pub fn max_size(&self) -> std::option::Option<i32> {
        self.max_size
    }
    /// <p>The desired size of the group.</p>
    pub fn desired_capacity(&self) -> std::option::Option<i32> {
        self.desired_capacity
    }
    /// <p>The predicted capacity of the group when it has a predictive scaling policy.</p>
    pub fn predicted_capacity(&self) -> std::option::Option<i32> {
        self.predicted_capacity
    }
    /// <p>The duration of the default cooldown period, in seconds.</p>
    pub fn default_cooldown(&self) -> std::option::Option<i32> {
        self.default_cooldown
    }
    /// <p>One or more Availability Zones for the group.</p>
    pub fn availability_zones(&self) -> std::option::Option<& [std::string::String]> {
        self.availability_zones.as_deref()
    }
    /// <p>One or more load balancers associated with the group.</p>
    pub fn load_balancer_names(&self) -> std::option::Option<& [std::string::String]> {
        self.load_balancer_names.as_deref()
    }
    /// <p>The Amazon Resource Names (ARN) of the target groups for your load balancer.</p>
    pub fn target_group_ar_ns(&self) -> std::option::Option<& [std::string::String]> {
        self.target_group_ar_ns.as_deref()
    }
    /// <p>Determines whether any additional health checks are performed on the instances in this group. Amazon EC2 health checks are always on.</p> 
    /// <p>The valid values are <code>EC2</code> (default), <code>ELB</code>, and <code>VPC_LATTICE</code>. The <code>VPC_LATTICE</code> health check type is reserved for use with VPC Lattice, which is in preview release and is subject to change.</p>
    pub fn health_check_type(&self) -> std::option::Option<& str> {
        self.health_check_type.as_deref()
    }
    /// <p>The duration of the health check grace period, in seconds.</p>
    pub fn health_check_grace_period(&self) -> std::option::Option<i32> {
        self.health_check_grace_period
    }
    /// <p>The EC2 instances associated with the group.</p>
    pub fn instances(&self) -> std::option::Option<& [crate::model::Instance]> {
        self.instances.as_deref()
    }
    /// <p>The date and time the group was created.</p>
    pub fn created_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.created_time.as_ref()
    }
    /// <p>The suspended processes associated with the group.</p>
    pub fn suspended_processes(&self) -> std::option::Option<& [crate::model::SuspendedProcess]> {
        self.suspended_processes.as_deref()
    }
    /// <p>The name of the placement group into which to launch your instances, if any.</p>
    pub fn placement_group(&self) -> std::option::Option<& str> {
        self.placement_group.as_deref()
    }
    /// <p>One or more subnet IDs, if applicable, separated by commas.</p>
    pub fn vpc_zone_identifier(&self) -> std::option::Option<& str> {
        self.vpc_zone_identifier.as_deref()
    }
    /// <p>The metrics enabled for the group.</p>
    pub fn enabled_metrics(&self) -> std::option::Option<& [crate::model::EnabledMetric]> {
        self.enabled_metrics.as_deref()
    }
    /// <p>The current state of the group when the <code>DeleteAutoScalingGroup</code> operation is in progress.</p>
    pub fn status(&self) -> std::option::Option<& str> {
        self.status.as_deref()
    }
    /// <p>The tags for the group.</p>
    pub fn tags(&self) -> std::option::Option<& [crate::model::TagDescription]> {
        self.tags.as_deref()
    }
    /// <p>The termination policies for the group.</p>
    pub fn termination_policies(&self) -> std::option::Option<& [std::string::String]> {
        self.termination_policies.as_deref()
    }
    /// <p>Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
    pub fn new_instances_protected_from_scale_in(&self) -> std::option::Option<bool> {
        self.new_instances_protected_from_scale_in
    }
    /// <p>The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services on your behalf.</p>
    pub fn service_linked_role_arn(&self) -> std::option::Option<& str> {
        self.service_linked_role_arn.as_deref()
    }
    /// <p>The maximum amount of time, in seconds, that an instance can be in service.</p> 
    /// <p>Valid Range: Minimum value of 0.</p>
    pub fn max_instance_lifetime(&self) -> std::option::Option<i32> {
        self.max_instance_lifetime
    }
    /// <p>Indicates whether Capacity Rebalancing is enabled.</p>
    pub fn capacity_rebalance(&self) -> std::option::Option<bool> {
        self.capacity_rebalance
    }
    /// <p>The warm pool for the group.</p>
    pub fn warm_pool_configuration(&self) -> std::option::Option<& crate::model::WarmPoolConfiguration> {
        self.warm_pool_configuration.as_ref()
    }
    /// <p>The current size of the warm pool.</p>
    pub fn warm_pool_size(&self) -> std::option::Option<i32> {
        self.warm_pool_size
    }
    /// <p>Reserved.</p>
    pub fn context(&self) -> std::option::Option<& str> {
        self.context.as_deref()
    }
    /// <p>The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports <code>DesiredCapacityType</code> for attribute-based instance type selection only.</p>
    pub fn desired_capacity_type(&self) -> std::option::Option<& str> {
        self.desired_capacity_type.as_deref()
    }
    /// <p>The duration of the default instance warmup, in seconds.</p>
    pub fn default_instance_warmup(&self) -> std::option::Option<i32> {
        self.default_instance_warmup
    }
    /// <p>The unique identifiers of the traffic sources.</p>
    pub fn traffic_sources(&self) -> std::option::Option<& [crate::model::TrafficSourceIdentifier]> {
        self.traffic_sources.as_deref()
    }
}
/// See [`AutoScalingGroup`](crate::model::AutoScalingGroup).
pub mod auto_scaling_group {
    
    /// A builder for [`AutoScalingGroup`](crate::model::AutoScalingGroup).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) auto_scaling_group_name: std::option::Option<std::string::String>,
        pub(crate) auto_scaling_group_arn: std::option::Option<std::string::String>,
        pub(crate) launch_configuration_name: std::option::Option<std::string::String>,
        pub(crate) launch_template: std::option::Option<crate::model::LaunchTemplateSpecification>,
        pub(crate) mixed_instances_policy: std::option::Option<crate::model::MixedInstancesPolicy>,
        pub(crate) min_size: std::option::Option<i32>,
        pub(crate) max_size: std::option::Option<i32>,
        pub(crate) desired_capacity: std::option::Option<i32>,
        pub(crate) predicted_capacity: std::option::Option<i32>,
        pub(crate) default_cooldown: std::option::Option<i32>,
        pub(crate) availability_zones: std::option::Option<std::vec::Vec<std::string::String>>,
        pub(crate) load_balancer_names: std::option::Option<std::vec::Vec<std::string::String>>,
        pub(crate) target_group_ar_ns: std::option::Option<std::vec::Vec<std::string::String>>,
        pub(crate) health_check_type: std::option::Option<std::string::String>,
        pub(crate) health_check_grace_period: std::option::Option<i32>,
        pub(crate) instances: std::option::Option<std::vec::Vec<crate::model::Instance>>,
        pub(crate) created_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) suspended_processes: std::option::Option<std::vec::Vec<crate::model::SuspendedProcess>>,
        pub(crate) placement_group: std::option::Option<std::string::String>,
        pub(crate) vpc_zone_identifier: std::option::Option<std::string::String>,
        pub(crate) enabled_metrics: std::option::Option<std::vec::Vec<crate::model::EnabledMetric>>,
        pub(crate) status: std::option::Option<std::string::String>,
        pub(crate) tags: std::option::Option<std::vec::Vec<crate::model::TagDescription>>,
        pub(crate) termination_policies: std::option::Option<std::vec::Vec<std::string::String>>,
        pub(crate) new_instances_protected_from_scale_in: std::option::Option<bool>,
        pub(crate) service_linked_role_arn: std::option::Option<std::string::String>,
        pub(crate) max_instance_lifetime: std::option::Option<i32>,
        pub(crate) capacity_rebalance: std::option::Option<bool>,
        pub(crate) warm_pool_configuration: std::option::Option<crate::model::WarmPoolConfiguration>,
        pub(crate) warm_pool_size: std::option::Option<i32>,
        pub(crate) context: std::option::Option<std::string::String>,
        pub(crate) desired_capacity_type: std::option::Option<std::string::String>,
        pub(crate) default_instance_warmup: std::option::Option<i32>,
        pub(crate) traffic_sources: std::option::Option<std::vec::Vec<crate::model::TrafficSourceIdentifier>>,
    }
    impl Builder {
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.auto_scaling_group_name = Some(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.auto_scaling_group_name = input; self
        }
        /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
        pub fn auto_scaling_group_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.auto_scaling_group_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.auto_scaling_group_arn = input; self
        }
        /// <p>The name of the associated launch configuration.</p>
        pub fn launch_configuration_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.launch_configuration_name = Some(input.into());
            self
        }
        /// <p>The name of the associated launch configuration.</p>
        pub fn set_launch_configuration_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.launch_configuration_name = input; self
        }
        /// <p>The launch template for the group.</p>
        pub fn launch_template(mut self, input: crate::model::LaunchTemplateSpecification) -> Self {
            self.launch_template = Some(input);
            self
        }
        /// <p>The launch template for the group.</p>
        pub fn set_launch_template(mut self, input: std::option::Option<crate::model::LaunchTemplateSpecification>) -> Self {
            self.launch_template = input; self
        }
        /// <p>The mixed instances policy for the group.</p>
        pub fn mixed_instances_policy(mut self, input: crate::model::MixedInstancesPolicy) -> Self {
            self.mixed_instances_policy = Some(input);
            self
        }
        /// <p>The mixed instances policy for the group.</p>
        pub fn set_mixed_instances_policy(mut self, input: std::option::Option<crate::model::MixedInstancesPolicy>) -> Self {
            self.mixed_instances_policy = input; self
        }
        /// <p>The minimum size of the group.</p>
        pub fn min_size(mut self, input: i32) -> Self {
            self.min_size = Some(input);
            self
        }
        /// <p>The minimum size of the group.</p>
        pub fn set_min_size(mut self, input: std::option::Option<i32>) -> Self {
            self.min_size = input; self
        }
        /// <p>The maximum size of the group.</p>
        pub fn max_size(mut self, input: i32) -> Self {
            self.max_size = Some(input);
            self
        }
        /// <p>The maximum size of the group.</p>
        pub fn set_max_size(mut self, input: std::option::Option<i32>) -> Self {
            self.max_size = input; self
        }
        /// <p>The desired size of the group.</p>
        pub fn desired_capacity(mut self, input: i32) -> Self {
            self.desired_capacity = Some(input);
            self
        }
        /// <p>The desired size of the group.</p>
        pub fn set_desired_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.desired_capacity = input; self
        }
        /// <p>The predicted capacity of the group when it has a predictive scaling policy.</p>
        pub fn predicted_capacity(mut self, input: i32) -> Self {
            self.predicted_capacity = Some(input);
            self
        }
        /// <p>The predicted capacity of the group when it has a predictive scaling policy.</p>
        pub fn set_predicted_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.predicted_capacity = input; self
        }
        /// <p>The duration of the default cooldown period, in seconds.</p>
        pub fn default_cooldown(mut self, input: i32) -> Self {
            self.default_cooldown = Some(input);
            self
        }
        /// <p>The duration of the default cooldown period, in seconds.</p>
        pub fn set_default_cooldown(mut self, input: std::option::Option<i32>) -> Self {
            self.default_cooldown = input; self
        }
        /// Appends an item to `availability_zones`.
        ///
        /// To override the contents of this collection use [`set_availability_zones`](Self::set_availability_zones).
        ///
        /// <p>One or more Availability Zones for the group.</p>
        pub fn availability_zones(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.availability_zones.unwrap_or_default();
                            v.push(input.into());
                            self.availability_zones = Some(v);
                            self
        }
        /// <p>One or more Availability Zones for the group.</p>
        pub fn set_availability_zones(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.availability_zones = input; self
        }
        /// Appends an item to `load_balancer_names`.
        ///
        /// To override the contents of this collection use [`set_load_balancer_names`](Self::set_load_balancer_names).
        ///
        /// <p>One or more load balancers associated with the group.</p>
        pub fn load_balancer_names(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.load_balancer_names.unwrap_or_default();
                            v.push(input.into());
                            self.load_balancer_names = Some(v);
                            self
        }
        /// <p>One or more load balancers associated with the group.</p>
        pub fn set_load_balancer_names(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.load_balancer_names = input; self
        }
        /// Appends an item to `target_group_ar_ns`.
        ///
        /// To override the contents of this collection use [`set_target_group_ar_ns`](Self::set_target_group_ar_ns).
        ///
        /// <p>The Amazon Resource Names (ARN) of the target groups for your load balancer.</p>
        pub fn target_group_ar_ns(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.target_group_ar_ns.unwrap_or_default();
                            v.push(input.into());
                            self.target_group_ar_ns = Some(v);
                            self
        }
        /// <p>The Amazon Resource Names (ARN) of the target groups for your load balancer.</p>
        pub fn set_target_group_ar_ns(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.target_group_ar_ns = input; self
        }
        /// <p>Determines whether any additional health checks are performed on the instances in this group. Amazon EC2 health checks are always on.</p> 
        /// <p>The valid values are <code>EC2</code> (default), <code>ELB</code>, and <code>VPC_LATTICE</code>. The <code>VPC_LATTICE</code> health check type is reserved for use with VPC Lattice, which is in preview release and is subject to change.</p>
        pub fn health_check_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.health_check_type = Some(input.into());
            self
        }
        /// <p>Determines whether any additional health checks are performed on the instances in this group. Amazon EC2 health checks are always on.</p> 
        /// <p>The valid values are <code>EC2</code> (default), <code>ELB</code>, and <code>VPC_LATTICE</code>. The <code>VPC_LATTICE</code> health check type is reserved for use with VPC Lattice, which is in preview release and is subject to change.</p>
        pub fn set_health_check_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.health_check_type = input; self
        }
        /// <p>The duration of the health check grace period, in seconds.</p>
        pub fn health_check_grace_period(mut self, input: i32) -> Self {
            self.health_check_grace_period = Some(input);
            self
        }
        /// <p>The duration of the health check grace period, in seconds.</p>
        pub fn set_health_check_grace_period(mut self, input: std::option::Option<i32>) -> Self {
            self.health_check_grace_period = input; self
        }
        /// Appends an item to `instances`.
        ///
        /// To override the contents of this collection use [`set_instances`](Self::set_instances).
        ///
        /// <p>The EC2 instances associated with the group.</p>
        pub fn instances(mut self, input: crate::model::Instance) -> Self {
            let mut v = self.instances.unwrap_or_default();
                            v.push(input);
                            self.instances = Some(v);
                            self
        }
        /// <p>The EC2 instances associated with the group.</p>
        pub fn set_instances(mut self, input: std::option::Option<std::vec::Vec<crate::model::Instance>>) -> Self {
            self.instances = input; self
        }
        /// <p>The date and time the group was created.</p>
        pub fn created_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.created_time = Some(input);
            self
        }
        /// <p>The date and time the group was created.</p>
        pub fn set_created_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.created_time = input; self
        }
        /// Appends an item to `suspended_processes`.
        ///
        /// To override the contents of this collection use [`set_suspended_processes`](Self::set_suspended_processes).
        ///
        /// <p>The suspended processes associated with the group.</p>
        pub fn suspended_processes(mut self, input: crate::model::SuspendedProcess) -> Self {
            let mut v = self.suspended_processes.unwrap_or_default();
                            v.push(input);
                            self.suspended_processes = Some(v);
                            self
        }
        /// <p>The suspended processes associated with the group.</p>
        pub fn set_suspended_processes(mut self, input: std::option::Option<std::vec::Vec<crate::model::SuspendedProcess>>) -> Self {
            self.suspended_processes = input; self
        }
        /// <p>The name of the placement group into which to launch your instances, if any.</p>
        pub fn placement_group(mut self, input: impl Into<std::string::String>) -> Self {
            self.placement_group = Some(input.into());
            self
        }
        /// <p>The name of the placement group into which to launch your instances, if any.</p>
        pub fn set_placement_group(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.placement_group = input; self
        }
        /// <p>One or more subnet IDs, if applicable, separated by commas.</p>
        pub fn vpc_zone_identifier(mut self, input: impl Into<std::string::String>) -> Self {
            self.vpc_zone_identifier = Some(input.into());
            self
        }
        /// <p>One or more subnet IDs, if applicable, separated by commas.</p>
        pub fn set_vpc_zone_identifier(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.vpc_zone_identifier = input; self
        }
        /// Appends an item to `enabled_metrics`.
        ///
        /// To override the contents of this collection use [`set_enabled_metrics`](Self::set_enabled_metrics).
        ///
        /// <p>The metrics enabled for the group.</p>
        pub fn enabled_metrics(mut self, input: crate::model::EnabledMetric) -> Self {
            let mut v = self.enabled_metrics.unwrap_or_default();
                            v.push(input);
                            self.enabled_metrics = Some(v);
                            self
        }
        /// <p>The metrics enabled for the group.</p>
        pub fn set_enabled_metrics(mut self, input: std::option::Option<std::vec::Vec<crate::model::EnabledMetric>>) -> Self {
            self.enabled_metrics = input; self
        }
        /// <p>The current state of the group when the <code>DeleteAutoScalingGroup</code> operation is in progress.</p>
        pub fn status(mut self, input: impl Into<std::string::String>) -> Self {
            self.status = Some(input.into());
            self
        }
        /// <p>The current state of the group when the <code>DeleteAutoScalingGroup</code> operation is in progress.</p>
        pub fn set_status(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.status = input; self
        }
        /// Appends an item to `tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p>The tags for the group.</p>
        pub fn tags(mut self, input: crate::model::TagDescription) -> Self {
            let mut v = self.tags.unwrap_or_default();
                            v.push(input);
                            self.tags = Some(v);
                            self
        }
        /// <p>The tags for the group.</p>
        pub fn set_tags(mut self, input: std::option::Option<std::vec::Vec<crate::model::TagDescription>>) -> Self {
            self.tags = input; self
        }
        /// Appends an item to `termination_policies`.
        ///
        /// To override the contents of this collection use [`set_termination_policies`](Self::set_termination_policies).
        ///
        /// <p>The termination policies for the group.</p>
        pub fn termination_policies(mut self, input: impl Into<std::string::String>) -> Self {
            let mut v = self.termination_policies.unwrap_or_default();
                            v.push(input.into());
                            self.termination_policies = Some(v);
                            self
        }
        /// <p>The termination policies for the group.</p>
        pub fn set_termination_policies(mut self, input: std::option::Option<std::vec::Vec<std::string::String>>) -> Self {
            self.termination_policies = input; self
        }
        /// <p>Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
        pub fn new_instances_protected_from_scale_in(mut self, input: bool) -> Self {
            self.new_instances_protected_from_scale_in = Some(input);
            self
        }
        /// <p>Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
        pub fn set_new_instances_protected_from_scale_in(mut self, input: std::option::Option<bool>) -> Self {
            self.new_instances_protected_from_scale_in = input; self
        }
        /// <p>The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services on your behalf.</p>
        pub fn service_linked_role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.service_linked_role_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services on your behalf.</p>
        pub fn set_service_linked_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.service_linked_role_arn = input; self
        }
        /// <p>The maximum amount of time, in seconds, that an instance can be in service.</p> 
        /// <p>Valid Range: Minimum value of 0.</p>
        pub fn max_instance_lifetime(mut self, input: i32) -> Self {
            self.max_instance_lifetime = Some(input);
            self
        }
        /// <p>The maximum amount of time, in seconds, that an instance can be in service.</p> 
        /// <p>Valid Range: Minimum value of 0.</p>
        pub fn set_max_instance_lifetime(mut self, input: std::option::Option<i32>) -> Self {
            self.max_instance_lifetime = input; self
        }
        /// <p>Indicates whether Capacity Rebalancing is enabled.</p>
        pub fn capacity_rebalance(mut self, input: bool) -> Self {
            self.capacity_rebalance = Some(input);
            self
        }
        /// <p>Indicates whether Capacity Rebalancing is enabled.</p>
        pub fn set_capacity_rebalance(mut self, input: std::option::Option<bool>) -> Self {
            self.capacity_rebalance = input; self
        }
        /// <p>The warm pool for the group.</p>
        pub fn warm_pool_configuration(mut self, input: crate::model::WarmPoolConfiguration) -> Self {
            self.warm_pool_configuration = Some(input);
            self
        }
        /// <p>The warm pool for the group.</p>
        pub fn set_warm_pool_configuration(mut self, input: std::option::Option<crate::model::WarmPoolConfiguration>) -> Self {
            self.warm_pool_configuration = input; self
        }
        /// <p>The current size of the warm pool.</p>
        pub fn warm_pool_size(mut self, input: i32) -> Self {
            self.warm_pool_size = Some(input);
            self
        }
        /// <p>The current size of the warm pool.</p>
        pub fn set_warm_pool_size(mut self, input: std::option::Option<i32>) -> Self {
            self.warm_pool_size = input; self
        }
        /// <p>Reserved.</p>
        pub fn context(mut self, input: impl Into<std::string::String>) -> Self {
            self.context = Some(input.into());
            self
        }
        /// <p>Reserved.</p>
        pub fn set_context(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.context = input; self
        }
        /// <p>The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports <code>DesiredCapacityType</code> for attribute-based instance type selection only.</p>
        pub fn desired_capacity_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.desired_capacity_type = Some(input.into());
            self
        }
        /// <p>The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports <code>DesiredCapacityType</code> for attribute-based instance type selection only.</p>
        pub fn set_desired_capacity_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.desired_capacity_type = input; self
        }
        /// <p>The duration of the default instance warmup, in seconds.</p>
        pub fn default_instance_warmup(mut self, input: i32) -> Self {
            self.default_instance_warmup = Some(input);
            self
        }
        /// <p>The duration of the default instance warmup, in seconds.</p>
        pub fn set_default_instance_warmup(mut self, input: std::option::Option<i32>) -> Self {
            self.default_instance_warmup = input; self
        }
        /// Appends an item to `traffic_sources`.
        ///
        /// To override the contents of this collection use [`set_traffic_sources`](Self::set_traffic_sources).
        ///
        /// <p>The unique identifiers of the traffic sources.</p>
        pub fn traffic_sources(mut self, input: crate::model::TrafficSourceIdentifier) -> Self {
            let mut v = self.traffic_sources.unwrap_or_default();
                            v.push(input);
                            self.traffic_sources = Some(v);
                            self
        }
        /// <p>The unique identifiers of the traffic sources.</p>
        pub fn set_traffic_sources(mut self, input: std::option::Option<std::vec::Vec<crate::model::TrafficSourceIdentifier>>) -> Self {
            self.traffic_sources = input; self
        }
        /// Consumes the builder and constructs a [`AutoScalingGroup`](crate::model::AutoScalingGroup).
        pub fn build(self) -> crate::model::AutoScalingGroup {
            crate::model::AutoScalingGroup {
                auto_scaling_group_name: self.auto_scaling_group_name
                ,
                auto_scaling_group_arn: self.auto_scaling_group_arn
                ,
                launch_configuration_name: self.launch_configuration_name
                ,
                launch_template: self.launch_template
                ,
                mixed_instances_policy: self.mixed_instances_policy
                ,
                min_size: self.min_size
                ,
                max_size: self.max_size
                ,
                desired_capacity: self.desired_capacity
                ,
                predicted_capacity: self.predicted_capacity
                ,
                default_cooldown: self.default_cooldown
                ,
                availability_zones: self.availability_zones
                ,
                load_balancer_names: self.load_balancer_names
                ,
                target_group_ar_ns: self.target_group_ar_ns
                ,
                health_check_type: self.health_check_type
                ,
                health_check_grace_period: self.health_check_grace_period
                ,
                instances: self.instances
                ,
                created_time: self.created_time
                ,
                suspended_processes: self.suspended_processes
                ,
                placement_group: self.placement_group
                ,
                vpc_zone_identifier: self.vpc_zone_identifier
                ,
                enabled_metrics: self.enabled_metrics
                ,
                status: self.status
                ,
                tags: self.tags
                ,
                termination_policies: self.termination_policies
                ,
                new_instances_protected_from_scale_in: self.new_instances_protected_from_scale_in
                ,
                service_linked_role_arn: self.service_linked_role_arn
                ,
                max_instance_lifetime: self.max_instance_lifetime
                ,
                capacity_rebalance: self.capacity_rebalance
                ,
                warm_pool_configuration: self.warm_pool_configuration
                ,
                warm_pool_size: self.warm_pool_size
                ,
                context: self.context
                ,
                desired_capacity_type: self.desired_capacity_type
                ,
                default_instance_warmup: self.default_instance_warmup
                ,
                traffic_sources: self.traffic_sources
                ,
            }
        }
    }
    
    
}
impl AutoScalingGroup {
    /// Creates a new builder-style object to manufacture [`AutoScalingGroup`](crate::model::AutoScalingGroup).
    pub fn builder() -> crate::model::auto_scaling_group::Builder {
        crate::model::auto_scaling_group::Builder::default()
    }
}

/// <p>Describes an enabled Auto Scaling group metric.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct EnabledMetric  {
    /// <p>One of the following metrics:</p> 
    /// <ul> 
    /// <li> <p> <code>GroupMinSize</code> </p> </li> 
    /// <li> <p> <code>GroupMaxSize</code> </p> </li> 
    /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupInServiceInstances</code> </p> </li> 
    /// <li> <p> <code>GroupPendingInstances</code> </p> </li> 
    /// <li> <p> <code>GroupStandbyInstances</code> </p> </li> 
    /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li> 
    /// <li> <p> <code>GroupTotalInstances</code> </p> </li> 
    /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupPendingCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupTotalCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li> 
    /// </ul> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-cloudwatch-monitoring.html#as-group-metrics">Auto Scaling group metrics</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[doc(hidden)]
    pub metric: std::option::Option<std::string::String>,
    /// <p>The granularity of the metric. The only valid value is <code>1Minute</code>.</p>
    #[doc(hidden)]
    pub granularity: std::option::Option<std::string::String>,
}
impl EnabledMetric {
    /// <p>One of the following metrics:</p> 
    /// <ul> 
    /// <li> <p> <code>GroupMinSize</code> </p> </li> 
    /// <li> <p> <code>GroupMaxSize</code> </p> </li> 
    /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupInServiceInstances</code> </p> </li> 
    /// <li> <p> <code>GroupPendingInstances</code> </p> </li> 
    /// <li> <p> <code>GroupStandbyInstances</code> </p> </li> 
    /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li> 
    /// <li> <p> <code>GroupTotalInstances</code> </p> </li> 
    /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupPendingCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupTotalCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li> 
    /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li> 
    /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li> 
    /// </ul> 
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-cloudwatch-monitoring.html#as-group-metrics">Auto Scaling group metrics</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    pub fn metric(&self) -> std::option::Option<& str> {
        self.metric.as_deref()
    }
    /// <p>The granularity of the metric. The only valid value is <code>1Minute</code>.</p>
    pub fn granularity(&self) -> std::option::Option<& str> {
        self.granularity.as_deref()
    }
}
/// See [`EnabledMetric`](crate::model::EnabledMetric).
pub mod enabled_metric {
    
    /// A builder for [`EnabledMetric`](crate::model::EnabledMetric).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) metric: std::option::Option<std::string::String>,
        pub(crate) granularity: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>One of the following metrics:</p> 
        /// <ul> 
        /// <li> <p> <code>GroupMinSize</code> </p> </li> 
        /// <li> <p> <code>GroupMaxSize</code> </p> </li> 
        /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupInServiceInstances</code> </p> </li> 
        /// <li> <p> <code>GroupPendingInstances</code> </p> </li> 
        /// <li> <p> <code>GroupStandbyInstances</code> </p> </li> 
        /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li> 
        /// <li> <p> <code>GroupTotalInstances</code> </p> </li> 
        /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupPendingCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupTotalCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li> 
        /// </ul> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-cloudwatch-monitoring.html#as-group-metrics">Auto Scaling group metrics</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn metric(mut self, input: impl Into<std::string::String>) -> Self {
            self.metric = Some(input.into());
            self
        }
        /// <p>One of the following metrics:</p> 
        /// <ul> 
        /// <li> <p> <code>GroupMinSize</code> </p> </li> 
        /// <li> <p> <code>GroupMaxSize</code> </p> </li> 
        /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupInServiceInstances</code> </p> </li> 
        /// <li> <p> <code>GroupPendingInstances</code> </p> </li> 
        /// <li> <p> <code>GroupStandbyInstances</code> </p> </li> 
        /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li> 
        /// <li> <p> <code>GroupTotalInstances</code> </p> </li> 
        /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupPendingCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupTotalCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li> 
        /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li> 
        /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li> 
        /// </ul> 
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-cloudwatch-monitoring.html#as-group-metrics">Auto Scaling group metrics</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_metric(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.metric = input; self
        }
        /// <p>The granularity of the metric. The only valid value is <code>1Minute</code>.</p>
        pub fn granularity(mut self, input: impl Into<std::string::String>) -> Self {
            self.granularity = Some(input.into());
            self
        }
        /// <p>The granularity of the metric. The only valid value is <code>1Minute</code>.</p>
        pub fn set_granularity(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.granularity = input; self
        }
        /// Consumes the builder and constructs a [`EnabledMetric`](crate::model::EnabledMetric).
        pub fn build(self) -> crate::model::EnabledMetric {
            crate::model::EnabledMetric {
                metric: self.metric
                ,
                granularity: self.granularity
                ,
            }
        }
    }
    
    
}
impl EnabledMetric {
    /// Creates a new builder-style object to manufacture [`EnabledMetric`](crate::model::EnabledMetric).
    pub fn builder() -> crate::model::enabled_metric::Builder {
        crate::model::enabled_metric::Builder::default()
    }
}

/// <p>Describes an auto scaling process that has been suspended.</p> 
/// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-suspend-resume-processes.html#process-types">Scaling processes</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct SuspendedProcess  {
    /// <p>The name of the suspended process.</p>
    #[doc(hidden)]
    pub process_name: std::option::Option<std::string::String>,
    /// <p>The reason that the process was suspended.</p>
    #[doc(hidden)]
    pub suspension_reason: std::option::Option<std::string::String>,
}
impl SuspendedProcess {
    /// <p>The name of the suspended process.</p>
    pub fn process_name(&self) -> std::option::Option<& str> {
        self.process_name.as_deref()
    }
    /// <p>The reason that the process was suspended.</p>
    pub fn suspension_reason(&self) -> std::option::Option<& str> {
        self.suspension_reason.as_deref()
    }
}
/// See [`SuspendedProcess`](crate::model::SuspendedProcess).
pub mod suspended_process {
    
    /// A builder for [`SuspendedProcess`](crate::model::SuspendedProcess).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) process_name: std::option::Option<std::string::String>,
        pub(crate) suspension_reason: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the suspended process.</p>
        pub fn process_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.process_name = Some(input.into());
            self
        }
        /// <p>The name of the suspended process.</p>
        pub fn set_process_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.process_name = input; self
        }
        /// <p>The reason that the process was suspended.</p>
        pub fn suspension_reason(mut self, input: impl Into<std::string::String>) -> Self {
            self.suspension_reason = Some(input.into());
            self
        }
        /// <p>The reason that the process was suspended.</p>
        pub fn set_suspension_reason(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.suspension_reason = input; self
        }
        /// Consumes the builder and constructs a [`SuspendedProcess`](crate::model::SuspendedProcess).
        pub fn build(self) -> crate::model::SuspendedProcess {
            crate::model::SuspendedProcess {
                process_name: self.process_name
                ,
                suspension_reason: self.suspension_reason
                ,
            }
        }
    }
    
    
}
impl SuspendedProcess {
    /// Creates a new builder-style object to manufacture [`SuspendedProcess`](crate::model::SuspendedProcess).
    pub fn builder() -> crate::model::suspended_process::Builder {
        crate::model::suspended_process::Builder::default()
    }
}

/// <p>Describes a policy adjustment type.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct AdjustmentType  {
    /// <p>The policy adjustment type. The valid values are <code>ChangeInCapacity</code>, <code>ExactCapacity</code>, and <code>PercentChangeInCapacity</code>.</p>
    #[doc(hidden)]
    pub adjustment_type: std::option::Option<std::string::String>,
}
impl AdjustmentType {
    /// <p>The policy adjustment type. The valid values are <code>ChangeInCapacity</code>, <code>ExactCapacity</code>, and <code>PercentChangeInCapacity</code>.</p>
    pub fn adjustment_type(&self) -> std::option::Option<& str> {
        self.adjustment_type.as_deref()
    }
}
/// See [`AdjustmentType`](crate::model::AdjustmentType).
pub mod adjustment_type {
    
    /// A builder for [`AdjustmentType`](crate::model::AdjustmentType).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) adjustment_type: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The policy adjustment type. The valid values are <code>ChangeInCapacity</code>, <code>ExactCapacity</code>, and <code>PercentChangeInCapacity</code>.</p>
        pub fn adjustment_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.adjustment_type = Some(input.into());
            self
        }
        /// <p>The policy adjustment type. The valid values are <code>ChangeInCapacity</code>, <code>ExactCapacity</code>, and <code>PercentChangeInCapacity</code>.</p>
        pub fn set_adjustment_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.adjustment_type = input; self
        }
        /// Consumes the builder and constructs a [`AdjustmentType`](crate::model::AdjustmentType).
        pub fn build(self) -> crate::model::AdjustmentType {
            crate::model::AdjustmentType {
                adjustment_type: self.adjustment_type
                ,
            }
        }
    }
    
    
}
impl AdjustmentType {
    /// Creates a new builder-style object to manufacture [`AdjustmentType`](crate::model::AdjustmentType).
    pub fn builder() -> crate::model::adjustment_type::Builder {
        crate::model::adjustment_type::Builder::default()
    }
}

/// <p>Describes a tag for an Auto Scaling group.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct Tag  {
    /// <p>The name of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub resource_id: std::option::Option<std::string::String>,
    /// <p>The type of resource. The only supported value is <code>auto-scaling-group</code>.</p>
    #[doc(hidden)]
    pub resource_type: std::option::Option<std::string::String>,
    /// <p>The tag key.</p>
    #[doc(hidden)]
    pub key: std::option::Option<std::string::String>,
    /// <p>The tag value.</p>
    #[doc(hidden)]
    pub value: std::option::Option<std::string::String>,
    /// <p>Determines whether the tag is added to new instances as they are launched in the group.</p>
    #[doc(hidden)]
    pub propagate_at_launch: std::option::Option<bool>,
}
impl Tag {
    /// <p>The name of the Auto Scaling group.</p>
    pub fn resource_id(&self) -> std::option::Option<& str> {
        self.resource_id.as_deref()
    }
    /// <p>The type of resource. The only supported value is <code>auto-scaling-group</code>.</p>
    pub fn resource_type(&self) -> std::option::Option<& str> {
        self.resource_type.as_deref()
    }
    /// <p>The tag key.</p>
    pub fn key(&self) -> std::option::Option<& str> {
        self.key.as_deref()
    }
    /// <p>The tag value.</p>
    pub fn value(&self) -> std::option::Option<& str> {
        self.value.as_deref()
    }
    /// <p>Determines whether the tag is added to new instances as they are launched in the group.</p>
    pub fn propagate_at_launch(&self) -> std::option::Option<bool> {
        self.propagate_at_launch
    }
}
/// See [`Tag`](crate::model::Tag).
pub mod tag {
    
    /// A builder for [`Tag`](crate::model::Tag).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) resource_id: std::option::Option<std::string::String>,
        pub(crate) resource_type: std::option::Option<std::string::String>,
        pub(crate) key: std::option::Option<std::string::String>,
        pub(crate) value: std::option::Option<std::string::String>,
        pub(crate) propagate_at_launch: std::option::Option<bool>,
    }
    impl Builder {
        /// <p>The name of the Auto Scaling group.</p>
        pub fn resource_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.resource_id = Some(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_resource_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.resource_id = input; self
        }
        /// <p>The type of resource. The only supported value is <code>auto-scaling-group</code>.</p>
        pub fn resource_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.resource_type = Some(input.into());
            self
        }
        /// <p>The type of resource. The only supported value is <code>auto-scaling-group</code>.</p>
        pub fn set_resource_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.resource_type = input; self
        }
        /// <p>The tag key.</p>
        pub fn key(mut self, input: impl Into<std::string::String>) -> Self {
            self.key = Some(input.into());
            self
        }
        /// <p>The tag key.</p>
        pub fn set_key(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.key = input; self
        }
        /// <p>The tag value.</p>
        pub fn value(mut self, input: impl Into<std::string::String>) -> Self {
            self.value = Some(input.into());
            self
        }
        /// <p>The tag value.</p>
        pub fn set_value(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.value = input; self
        }
        /// <p>Determines whether the tag is added to new instances as they are launched in the group.</p>
        pub fn propagate_at_launch(mut self, input: bool) -> Self {
            self.propagate_at_launch = Some(input);
            self
        }
        /// <p>Determines whether the tag is added to new instances as they are launched in the group.</p>
        pub fn set_propagate_at_launch(mut self, input: std::option::Option<bool>) -> Self {
            self.propagate_at_launch = input; self
        }
        /// Consumes the builder and constructs a [`Tag`](crate::model::Tag).
        pub fn build(self) -> crate::model::Tag {
            crate::model::Tag {
                resource_id: self.resource_id
                ,
                resource_type: self.resource_type
                ,
                key: self.key
                ,
                value: self.value
                ,
                propagate_at_launch: self.propagate_at_launch
                ,
            }
        }
    }
    
    
}
impl Tag {
    /// Creates a new builder-style object to manufacture [`Tag`](crate::model::Tag).
    pub fn builder() -> crate::model::tag::Builder {
        crate::model::tag::Builder::default()
    }
}

/// <p>Describes information used to specify a lifecycle hook for an Auto Scaling group.</p> 
/// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html">Amazon EC2 Auto Scaling lifecycle hooks</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct LifecycleHookSpecification  {
    /// <p>The name of the lifecycle hook.</p>
    #[doc(hidden)]
    pub lifecycle_hook_name: std::option::Option<std::string::String>,
    /// <p>The lifecycle transition. For Auto Scaling groups, there are two major lifecycle transitions.</p> 
    /// <ul> 
    /// <li> <p>To create a lifecycle hook for scale-out events, specify <code>autoscaling:EC2_INSTANCE_LAUNCHING</code>.</p> </li> 
    /// <li> <p>To create a lifecycle hook for scale-in events, specify <code>autoscaling:EC2_INSTANCE_TERMINATING</code>.</p> </li> 
    /// </ul>
    #[doc(hidden)]
    pub lifecycle_transition: std::option::Option<std::string::String>,
    /// <p>Additional information that you want to include any time Amazon EC2 Auto Scaling sends a message to the notification target.</p>
    #[doc(hidden)]
    pub notification_metadata: std::option::Option<std::string::String>,
    /// <p>The maximum time, in seconds, that can elapse before the lifecycle hook times out. The range is from <code>30</code> to <code>7200</code> seconds. The default value is <code>3600</code> seconds (1 hour).</p>
    #[doc(hidden)]
    pub heartbeat_timeout: std::option::Option<i32>,
    /// <p>The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. The default value is <code>ABANDON</code>.</p> 
    /// <p>Valid values: <code>CONTINUE</code> | <code>ABANDON</code> </p>
    #[doc(hidden)]
    pub default_result: std::option::Option<std::string::String>,
    /// <p>The Amazon Resource Name (ARN) of the notification target that Amazon EC2 Auto Scaling sends notifications to when an instance is in a wait state for the lifecycle hook. You can specify an Amazon SNS topic or an Amazon SQS queue.</p>
    #[doc(hidden)]
    pub notification_target_arn: std::option::Option<std::string::String>,
    /// <p>The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target. For information about creating this role, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/prepare-for-lifecycle-notifications.html#lifecycle-hook-notification-target">Configure a notification target for a lifecycle hook</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> 
    /// <p>Valid only if the notification target is an Amazon SNS topic or an Amazon SQS queue.</p>
    #[doc(hidden)]
    pub role_arn: std::option::Option<std::string::String>,
}
impl LifecycleHookSpecification {
    /// <p>The name of the lifecycle hook.</p>
    pub fn lifecycle_hook_name(&self) -> std::option::Option<& str> {
        self.lifecycle_hook_name.as_deref()
    }
    /// <p>The lifecycle transition. For Auto Scaling groups, there are two major lifecycle transitions.</p> 
    /// <ul> 
    /// <li> <p>To create a lifecycle hook for scale-out events, specify <code>autoscaling:EC2_INSTANCE_LAUNCHING</code>.</p> </li> 
    /// <li> <p>To create a lifecycle hook for scale-in events, specify <code>autoscaling:EC2_INSTANCE_TERMINATING</code>.</p> </li> 
    /// </ul>
    pub fn lifecycle_transition(&self) -> std::option::Option<& str> {
        self.lifecycle_transition.as_deref()
    }
    /// <p>Additional information that you want to include any time Amazon EC2 Auto Scaling sends a message to the notification target.</p>
    pub fn notification_metadata(&self) -> std::option::Option<& str> {
        self.notification_metadata.as_deref()
    }
    /// <p>The maximum time, in seconds, that can elapse before the lifecycle hook times out. The range is from <code>30</code> to <code>7200</code> seconds. The default value is <code>3600</code> seconds (1 hour).</p>
    pub fn heartbeat_timeout(&self) -> std::option::Option<i32> {
        self.heartbeat_timeout
    }
    /// <p>The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. The default value is <code>ABANDON</code>.</p> 
    /// <p>Valid values: <code>CONTINUE</code> | <code>ABANDON</code> </p>
    pub fn default_result(&self) -> std::option::Option<& str> {
        self.default_result.as_deref()
    }
    /// <p>The Amazon Resource Name (ARN) of the notification target that Amazon EC2 Auto Scaling sends notifications to when an instance is in a wait state for the lifecycle hook. You can specify an Amazon SNS topic or an Amazon SQS queue.</p>
    pub fn notification_target_arn(&self) -> std::option::Option<& str> {
        self.notification_target_arn.as_deref()
    }
    /// <p>The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target. For information about creating this role, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/prepare-for-lifecycle-notifications.html#lifecycle-hook-notification-target">Configure a notification target for a lifecycle hook</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> 
    /// <p>Valid only if the notification target is an Amazon SNS topic or an Amazon SQS queue.</p>
    pub fn role_arn(&self) -> std::option::Option<& str> {
        self.role_arn.as_deref()
    }
}
/// See [`LifecycleHookSpecification`](crate::model::LifecycleHookSpecification).
pub mod lifecycle_hook_specification {
    
    /// A builder for [`LifecycleHookSpecification`](crate::model::LifecycleHookSpecification).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) lifecycle_hook_name: std::option::Option<std::string::String>,
        pub(crate) lifecycle_transition: std::option::Option<std::string::String>,
        pub(crate) notification_metadata: std::option::Option<std::string::String>,
        pub(crate) heartbeat_timeout: std::option::Option<i32>,
        pub(crate) default_result: std::option::Option<std::string::String>,
        pub(crate) notification_target_arn: std::option::Option<std::string::String>,
        pub(crate) role_arn: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the lifecycle hook.</p>
        pub fn lifecycle_hook_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.lifecycle_hook_name = Some(input.into());
            self
        }
        /// <p>The name of the lifecycle hook.</p>
        pub fn set_lifecycle_hook_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.lifecycle_hook_name = input; self
        }
        /// <p>The lifecycle transition. For Auto Scaling groups, there are two major lifecycle transitions.</p> 
        /// <ul> 
        /// <li> <p>To create a lifecycle hook for scale-out events, specify <code>autoscaling:EC2_INSTANCE_LAUNCHING</code>.</p> </li> 
        /// <li> <p>To create a lifecycle hook for scale-in events, specify <code>autoscaling:EC2_INSTANCE_TERMINATING</code>.</p> </li> 
        /// </ul>
        pub fn lifecycle_transition(mut self, input: impl Into<std::string::String>) -> Self {
            self.lifecycle_transition = Some(input.into());
            self
        }
        /// <p>The lifecycle transition. For Auto Scaling groups, there are two major lifecycle transitions.</p> 
        /// <ul> 
        /// <li> <p>To create a lifecycle hook for scale-out events, specify <code>autoscaling:EC2_INSTANCE_LAUNCHING</code>.</p> </li> 
        /// <li> <p>To create a lifecycle hook for scale-in events, specify <code>autoscaling:EC2_INSTANCE_TERMINATING</code>.</p> </li> 
        /// </ul>
        pub fn set_lifecycle_transition(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.lifecycle_transition = input; self
        }
        /// <p>Additional information that you want to include any time Amazon EC2 Auto Scaling sends a message to the notification target.</p>
        pub fn notification_metadata(mut self, input: impl Into<std::string::String>) -> Self {
            self.notification_metadata = Some(input.into());
            self
        }
        /// <p>Additional information that you want to include any time Amazon EC2 Auto Scaling sends a message to the notification target.</p>
        pub fn set_notification_metadata(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.notification_metadata = input; self
        }
        /// <p>The maximum time, in seconds, that can elapse before the lifecycle hook times out. The range is from <code>30</code> to <code>7200</code> seconds. The default value is <code>3600</code> seconds (1 hour).</p>
        pub fn heartbeat_timeout(mut self, input: i32) -> Self {
            self.heartbeat_timeout = Some(input);
            self
        }
        /// <p>The maximum time, in seconds, that can elapse before the lifecycle hook times out. The range is from <code>30</code> to <code>7200</code> seconds. The default value is <code>3600</code> seconds (1 hour).</p>
        pub fn set_heartbeat_timeout(mut self, input: std::option::Option<i32>) -> Self {
            self.heartbeat_timeout = input; self
        }
        /// <p>The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. The default value is <code>ABANDON</code>.</p> 
        /// <p>Valid values: <code>CONTINUE</code> | <code>ABANDON</code> </p>
        pub fn default_result(mut self, input: impl Into<std::string::String>) -> Self {
            self.default_result = Some(input.into());
            self
        }
        /// <p>The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. The default value is <code>ABANDON</code>.</p> 
        /// <p>Valid values: <code>CONTINUE</code> | <code>ABANDON</code> </p>
        pub fn set_default_result(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.default_result = input; self
        }
        /// <p>The Amazon Resource Name (ARN) of the notification target that Amazon EC2 Auto Scaling sends notifications to when an instance is in a wait state for the lifecycle hook. You can specify an Amazon SNS topic or an Amazon SQS queue.</p>
        pub fn notification_target_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.notification_target_arn = Some(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the notification target that Amazon EC2 Auto Scaling sends notifications to when an instance is in a wait state for the lifecycle hook. You can specify an Amazon SNS topic or an Amazon SQS queue.</p>
        pub fn set_notification_target_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.notification_target_arn = input; self
        }
        /// <p>The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target. For information about creating this role, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/prepare-for-lifecycle-notifications.html#lifecycle-hook-notification-target">Configure a notification target for a lifecycle hook</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> 
        /// <p>Valid only if the notification target is an Amazon SNS topic or an Amazon SQS queue.</p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.role_arn = Some(input.into());
            self
        }
        /// <p>The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target. For information about creating this role, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/prepare-for-lifecycle-notifications.html#lifecycle-hook-notification-target">Configure a notification target for a lifecycle hook</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> 
        /// <p>Valid only if the notification target is an Amazon SNS topic or an Amazon SQS queue.</p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.role_arn = input; self
        }
        /// Consumes the builder and constructs a [`LifecycleHookSpecification`](crate::model::LifecycleHookSpecification).
        pub fn build(self) -> crate::model::LifecycleHookSpecification {
            crate::model::LifecycleHookSpecification {
                lifecycle_hook_name: self.lifecycle_hook_name
                ,
                lifecycle_transition: self.lifecycle_transition
                ,
                notification_metadata: self.notification_metadata
                ,
                heartbeat_timeout: self.heartbeat_timeout
                ,
                default_result: self.default_result
                ,
                notification_target_arn: self.notification_target_arn
                ,
                role_arn: self.role_arn
                ,
            }
        }
    }
    
    
}
impl LifecycleHookSpecification {
    /// Creates a new builder-style object to manufacture [`LifecycleHookSpecification`](crate::model::LifecycleHookSpecification).
    pub fn builder() -> crate::model::lifecycle_hook_specification::Builder {
        crate::model::lifecycle_hook_specification::Builder::default()
    }
}

/// <p>Describes a scheduled action that could not be created, updated, or deleted.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct FailedScheduledUpdateGroupActionRequest  {
    /// <p>The name of the scheduled action.</p>
    #[doc(hidden)]
    pub scheduled_action_name: std::option::Option<std::string::String>,
    /// <p>The error code.</p>
    #[doc(hidden)]
    pub error_code: std::option::Option<std::string::String>,
    /// <p>The error message accompanying the error code.</p>
    #[doc(hidden)]
    pub error_message: std::option::Option<std::string::String>,
}
impl FailedScheduledUpdateGroupActionRequest {
    /// <p>The name of the scheduled action.</p>
    pub fn scheduled_action_name(&self) -> std::option::Option<& str> {
        self.scheduled_action_name.as_deref()
    }
    /// <p>The error code.</p>
    pub fn error_code(&self) -> std::option::Option<& str> {
        self.error_code.as_deref()
    }
    /// <p>The error message accompanying the error code.</p>
    pub fn error_message(&self) -> std::option::Option<& str> {
        self.error_message.as_deref()
    }
}
/// See [`FailedScheduledUpdateGroupActionRequest`](crate::model::FailedScheduledUpdateGroupActionRequest).
pub mod failed_scheduled_update_group_action_request {
    
    /// A builder for [`FailedScheduledUpdateGroupActionRequest`](crate::model::FailedScheduledUpdateGroupActionRequest).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) scheduled_action_name: std::option::Option<std::string::String>,
        pub(crate) error_code: std::option::Option<std::string::String>,
        pub(crate) error_message: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the scheduled action.</p>
        pub fn scheduled_action_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.scheduled_action_name = Some(input.into());
            self
        }
        /// <p>The name of the scheduled action.</p>
        pub fn set_scheduled_action_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.scheduled_action_name = input; self
        }
        /// <p>The error code.</p>
        pub fn error_code(mut self, input: impl Into<std::string::String>) -> Self {
            self.error_code = Some(input.into());
            self
        }
        /// <p>The error code.</p>
        pub fn set_error_code(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.error_code = input; self
        }
        /// <p>The error message accompanying the error code.</p>
        pub fn error_message(mut self, input: impl Into<std::string::String>) -> Self {
            self.error_message = Some(input.into());
            self
        }
        /// <p>The error message accompanying the error code.</p>
        pub fn set_error_message(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.error_message = input; self
        }
        /// Consumes the builder and constructs a [`FailedScheduledUpdateGroupActionRequest`](crate::model::FailedScheduledUpdateGroupActionRequest).
        pub fn build(self) -> crate::model::FailedScheduledUpdateGroupActionRequest {
            crate::model::FailedScheduledUpdateGroupActionRequest {
                scheduled_action_name: self.scheduled_action_name
                ,
                error_code: self.error_code
                ,
                error_message: self.error_message
                ,
            }
        }
    }
    
    
}
impl FailedScheduledUpdateGroupActionRequest {
    /// Creates a new builder-style object to manufacture [`FailedScheduledUpdateGroupActionRequest`](crate::model::FailedScheduledUpdateGroupActionRequest).
    pub fn builder() -> crate::model::failed_scheduled_update_group_action_request::Builder {
        crate::model::failed_scheduled_update_group_action_request::Builder::default()
    }
}

/// <p>Describes information used for one or more scheduled scaling action updates in a <code>BatchPutScheduledUpdateGroupAction</code> operation.</p>
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub struct ScheduledUpdateGroupActionRequest  {
    /// <p>The name of the scaling action.</p>
    #[doc(hidden)]
    pub scheduled_action_name: std::option::Option<std::string::String>,
    /// <p>The date and time for the action to start, in YYYY-MM-DDThh:mm:ssZ format in UTC/GMT only and in quotes (for example, <code>"2019-06-01T00:00:00Z"</code>).</p> 
    /// <p>If you specify <code>Recurrence</code> and <code>StartTime</code>, Amazon EC2 Auto Scaling performs the action at this time, and then performs the action based on the specified recurrence.</p> 
    /// <p>If you try to schedule the action in the past, Amazon EC2 Auto Scaling returns an error message.</p>
    #[doc(hidden)]
    pub start_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The date and time for the recurring schedule to end, in UTC.</p>
    #[doc(hidden)]
    pub end_time: std::option::Option<aws_smithy_types::DateTime>,
    /// <p>The recurring schedule for the action, in Unix cron syntax format. This format consists of five fields separated by white spaces: [Minute] [Hour] [Day_of_Month] [Month_of_Year] [Day_of_Week]. The value must be in quotes (for example, <code>"30 0 1 1,6,12 *"</code>). For more information about this format, see <a href="http://crontab.org">Crontab</a>.</p> 
    /// <p>When <code>StartTime</code> and <code>EndTime</code> are specified with <code>Recurrence</code>, they form the boundaries of when the recurring action starts and stops.</p> 
    /// <p>Cron expressions use Universal Coordinated Time (UTC) by default.</p>
    #[doc(hidden)]
    pub recurrence: std::option::Option<std::string::String>,
    /// <p>The minimum size of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub min_size: std::option::Option<i32>,
    /// <p>The maximum size of the Auto Scaling group.</p>
    #[doc(hidden)]
    pub max_size: std::option::Option<i32>,
    /// <p>The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain.</p>
    #[doc(hidden)]
    pub desired_capacity: std::option::Option<i32>,
    /// <p>Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. </p> 
    /// <p>Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as <code>Etc/GMT+9</code> or <code>Pacific/Tahiti</code>). For more information, see <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">https://en.wikipedia.org/wiki/List_of_tz_database_time_zones</a>.</p>
    #[doc(hidden)]
    pub time_zone: std::option::Option<std::string::String>,
}
impl ScheduledUpdateGroupActionRequest {
    /// <p>The name of the scaling action.</p>
    pub fn scheduled_action_name(&self) -> std::option::Option<& str> {
        self.scheduled_action_name.as_deref()
    }
    /// <p>The date and time for the action to start, in YYYY-MM-DDThh:mm:ssZ format in UTC/GMT only and in quotes (for example, <code>"2019-06-01T00:00:00Z"</code>).</p> 
    /// <p>If you specify <code>Recurrence</code> and <code>StartTime</code>, Amazon EC2 Auto Scaling performs the action at this time, and then performs the action based on the specified recurrence.</p> 
    /// <p>If you try to schedule the action in the past, Amazon EC2 Auto Scaling returns an error message.</p>
    pub fn start_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.start_time.as_ref()
    }
    /// <p>The date and time for the recurring schedule to end, in UTC.</p>
    pub fn end_time(&self) -> std::option::Option<& aws_smithy_types::DateTime> {
        self.end_time.as_ref()
    }
    /// <p>The recurring schedule for the action, in Unix cron syntax format. This format consists of five fields separated by white spaces: [Minute] [Hour] [Day_of_Month] [Month_of_Year] [Day_of_Week]. The value must be in quotes (for example, <code>"30 0 1 1,6,12 *"</code>). For more information about this format, see <a href="http://crontab.org">Crontab</a>.</p> 
    /// <p>When <code>StartTime</code> and <code>EndTime</code> are specified with <code>Recurrence</code>, they form the boundaries of when the recurring action starts and stops.</p> 
    /// <p>Cron expressions use Universal Coordinated Time (UTC) by default.</p>
    pub fn recurrence(&self) -> std::option::Option<& str> {
        self.recurrence.as_deref()
    }
    /// <p>The minimum size of the Auto Scaling group.</p>
    pub fn min_size(&self) -> std::option::Option<i32> {
        self.min_size
    }
    /// <p>The maximum size of the Auto Scaling group.</p>
    pub fn max_size(&self) -> std::option::Option<i32> {
        self.max_size
    }
    /// <p>The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain.</p>
    pub fn desired_capacity(&self) -> std::option::Option<i32> {
        self.desired_capacity
    }
    /// <p>Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. </p> 
    /// <p>Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as <code>Etc/GMT+9</code> or <code>Pacific/Tahiti</code>). For more information, see <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">https://en.wikipedia.org/wiki/List_of_tz_database_time_zones</a>.</p>
    pub fn time_zone(&self) -> std::option::Option<& str> {
        self.time_zone.as_deref()
    }
}
/// See [`ScheduledUpdateGroupActionRequest`](crate::model::ScheduledUpdateGroupActionRequest).
pub mod scheduled_update_group_action_request {
    
    /// A builder for [`ScheduledUpdateGroupActionRequest`](crate::model::ScheduledUpdateGroupActionRequest).
    #[derive(std::clone::Clone, std::cmp::PartialEq, std::default::Default, std::fmt::Debug)]
    pub struct Builder {
        pub(crate) scheduled_action_name: std::option::Option<std::string::String>,
        pub(crate) start_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) end_time: std::option::Option<aws_smithy_types::DateTime>,
        pub(crate) recurrence: std::option::Option<std::string::String>,
        pub(crate) min_size: std::option::Option<i32>,
        pub(crate) max_size: std::option::Option<i32>,
        pub(crate) desired_capacity: std::option::Option<i32>,
        pub(crate) time_zone: std::option::Option<std::string::String>,
    }
    impl Builder {
        /// <p>The name of the scaling action.</p>
        pub fn scheduled_action_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.scheduled_action_name = Some(input.into());
            self
        }
        /// <p>The name of the scaling action.</p>
        pub fn set_scheduled_action_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.scheduled_action_name = input; self
        }
        /// <p>The date and time for the action to start, in YYYY-MM-DDThh:mm:ssZ format in UTC/GMT only and in quotes (for example, <code>"2019-06-01T00:00:00Z"</code>).</p> 
        /// <p>If you specify <code>Recurrence</code> and <code>StartTime</code>, Amazon EC2 Auto Scaling performs the action at this time, and then performs the action based on the specified recurrence.</p> 
        /// <p>If you try to schedule the action in the past, Amazon EC2 Auto Scaling returns an error message.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.start_time = Some(input);
            self
        }
        /// <p>The date and time for the action to start, in YYYY-MM-DDThh:mm:ssZ format in UTC/GMT only and in quotes (for example, <code>"2019-06-01T00:00:00Z"</code>).</p> 
        /// <p>If you specify <code>Recurrence</code> and <code>StartTime</code>, Amazon EC2 Auto Scaling performs the action at this time, and then performs the action based on the specified recurrence.</p> 
        /// <p>If you try to schedule the action in the past, Amazon EC2 Auto Scaling returns an error message.</p>
        pub fn set_start_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.start_time = input; self
        }
        /// <p>The date and time for the recurring schedule to end, in UTC.</p>
        pub fn end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.end_time = Some(input);
            self
        }
        /// <p>The date and time for the recurring schedule to end, in UTC.</p>
        pub fn set_end_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.end_time = input; self
        }
        /// <p>The recurring schedule for the action, in Unix cron syntax format. This format consists of five fields separated by white spaces: [Minute] [Hour] [Day_of_Month] [Month_of_Year] [Day_of_Week]. The value must be in quotes (for example, <code>"30 0 1 1,6,12 *"</code>). For more information about this format, see <a href="http://crontab.org">Crontab</a>.</p> 
        /// <p>When <code>StartTime</code> and <code>EndTime</code> are specified with <code>Recurrence</code>, they form the boundaries of when the recurring action starts and stops.</p> 
        /// <p>Cron expressions use Universal Coordinated Time (UTC) by default.</p>
        pub fn recurrence(mut self, input: impl Into<std::string::String>) -> Self {
            self.recurrence = Some(input.into());
            self
        }
        /// <p>The recurring schedule for the action, in Unix cron syntax format. This format consists of five fields separated by white spaces: [Minute] [Hour] [Day_of_Month] [Month_of_Year] [Day_of_Week]. The value must be in quotes (for example, <code>"30 0 1 1,6,12 *"</code>). For more information about this format, see <a href="http://crontab.org">Crontab</a>.</p> 
        /// <p>When <code>StartTime</code> and <code>EndTime</code> are specified with <code>Recurrence</code>, they form the boundaries of when the recurring action starts and stops.</p> 
        /// <p>Cron expressions use Universal Coordinated Time (UTC) by default.</p>
        pub fn set_recurrence(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.recurrence = input; self
        }
        /// <p>The minimum size of the Auto Scaling group.</p>
        pub fn min_size(mut self, input: i32) -> Self {
            self.min_size = Some(input);
            self
        }
        /// <p>The minimum size of the Auto Scaling group.</p>
        pub fn set_min_size(mut self, input: std::option::Option<i32>) -> Self {
            self.min_size = input; self
        }
        /// <p>The maximum size of the Auto Scaling group.</p>
        pub fn max_size(mut self, input: i32) -> Self {
            self.max_size = Some(input);
            self
        }
        /// <p>The maximum size of the Auto Scaling group.</p>
        pub fn set_max_size(mut self, input: std::option::Option<i32>) -> Self {
            self.max_size = input; self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain.</p>
        pub fn desired_capacity(mut self, input: i32) -> Self {
            self.desired_capacity = Some(input);
            self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain.</p>
        pub fn set_desired_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.desired_capacity = input; self
        }
        /// <p>Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. </p> 
        /// <p>Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as <code>Etc/GMT+9</code> or <code>Pacific/Tahiti</code>). For more information, see <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">https://en.wikipedia.org/wiki/List_of_tz_database_time_zones</a>.</p>
        pub fn time_zone(mut self, input: impl Into<std::string::String>) -> Self {
            self.time_zone = Some(input.into());
            self
        }
        /// <p>Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. </p> 
        /// <p>Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as <code>Etc/GMT+9</code> or <code>Pacific/Tahiti</code>). For more information, see <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">https://en.wikipedia.org/wiki/List_of_tz_database_time_zones</a>.</p>
        pub fn set_time_zone(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.time_zone = input; self
        }
        /// Consumes the builder and constructs a [`ScheduledUpdateGroupActionRequest`](crate::model::ScheduledUpdateGroupActionRequest).
        pub fn build(self) -> crate::model::ScheduledUpdateGroupActionRequest {
            crate::model::ScheduledUpdateGroupActionRequest {
                scheduled_action_name: self.scheduled_action_name
                ,
                start_time: self.start_time
                ,
                end_time: self.end_time
                ,
                recurrence: self.recurrence
                ,
                min_size: self.min_size
                ,
                max_size: self.max_size
                ,
                desired_capacity: self.desired_capacity
                ,
                time_zone: self.time_zone
                ,
            }
        }
    }
    
    
}
impl ScheduledUpdateGroupActionRequest {
    /// Creates a new builder-style object to manufacture [`ScheduledUpdateGroupActionRequest`](crate::model::ScheduledUpdateGroupActionRequest).
    pub fn builder() -> crate::model::scheduled_update_group_action_request::Builder {
        crate::model::scheduled_update_group_action_request::Builder::default()
    }
}

