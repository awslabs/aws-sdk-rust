// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
#[derive(Debug)]
pub(crate) struct Handle {
    pub(crate) client: aws_smithy_client::Client<
        aws_smithy_client::erase::DynConnector,
        aws_smithy_client::erase::DynMiddleware<aws_smithy_client::erase::DynConnector>,
    >,
    pub(crate) conf: crate::Config,
}

/// Client for Auto Scaling
///
/// Client for invoking operations on Auto Scaling. Each operation on Auto Scaling is a method on this
/// this struct. `.send()` MUST be invoked on the generated operations to dispatch the request to the service.
///
/// # Examples
/// **Constructing a client and invoking an operation**
/// ```rust,no_run
/// # async fn docs() {
///     // create a shared configuration. This can be used & shared between multiple service clients.
///     let shared_config = aws_config::load_from_env().await;
///     let client = aws_sdk_autoscaling::Client::new(&shared_config);
///     // invoke an operation
///     /* let rsp = client
///         .<operation_name>().
///         .<param>("some value")
///         .send().await; */
/// # }
/// ```
/// **Constructing a client with custom configuration**
/// ```rust,no_run
/// use aws_config::RetryConfig;
/// # async fn docs() {
/// let shared_config = aws_config::load_from_env().await;
/// let config = aws_sdk_autoscaling::config::Builder::from(&shared_config)
///   .retry_config(RetryConfig::disabled())
///   .build();
/// let client = aws_sdk_autoscaling::Client::from_conf(config);
/// # }
#[derive(std::fmt::Debug)]
pub struct Client {
    handle: std::sync::Arc<Handle>,
}

impl std::clone::Clone for Client {
    fn clone(&self) -> Self {
        Self {
            handle: self.handle.clone(),
        }
    }
}

#[doc(inline)]
pub use aws_smithy_client::Builder;

impl
    From<
        aws_smithy_client::Client<
            aws_smithy_client::erase::DynConnector,
            aws_smithy_client::erase::DynMiddleware<aws_smithy_client::erase::DynConnector>,
        >,
    > for Client
{
    fn from(
        client: aws_smithy_client::Client<
            aws_smithy_client::erase::DynConnector,
            aws_smithy_client::erase::DynMiddleware<aws_smithy_client::erase::DynConnector>,
        >,
    ) -> Self {
        Self::with_config(client, crate::Config::builder().build())
    }
}

impl Client {
    /// Creates a client with the given service configuration.
    pub fn with_config(
        client: aws_smithy_client::Client<
            aws_smithy_client::erase::DynConnector,
            aws_smithy_client::erase::DynMiddleware<aws_smithy_client::erase::DynConnector>,
        >,
        conf: crate::Config,
    ) -> Self {
        Self {
            handle: std::sync::Arc::new(Handle { client, conf }),
        }
    }

    /// Returns the client's configuration.
    pub fn conf(&self) -> &crate::Config {
        &self.handle.conf
    }
}
impl Client {
    /// Constructs a fluent builder for the [`AttachInstances`](crate::client::fluent_builders::AttachInstances) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`instance_ids(Vec<String>)`](crate::client::fluent_builders::AttachInstances::instance_ids) / [`set_instance_ids(Option<Vec<String>>)`](crate::client::fluent_builders::AttachInstances::set_instance_ids): <p>The IDs of the instances. You can specify up to 20 instances.</p>
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::AttachInstances::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::AttachInstances::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    /// - On success, responds with [`AttachInstancesOutput`](crate::output::AttachInstancesOutput)

    /// - On failure, responds with [`SdkError<AttachInstancesError>`](crate::error::AttachInstancesError)
    pub fn attach_instances(&self) -> fluent_builders::AttachInstances {
        fluent_builders::AttachInstances::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`AttachLoadBalancers`](crate::client::fluent_builders::AttachLoadBalancers) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::AttachLoadBalancers::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::AttachLoadBalancers::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`load_balancer_names(Vec<String>)`](crate::client::fluent_builders::AttachLoadBalancers::load_balancer_names) / [`set_load_balancer_names(Option<Vec<String>>)`](crate::client::fluent_builders::AttachLoadBalancers::set_load_balancer_names): <p>The names of the load balancers. You can specify up to 10 load balancers.</p>
    /// - On success, responds with [`AttachLoadBalancersOutput`](crate::output::AttachLoadBalancersOutput)

    /// - On failure, responds with [`SdkError<AttachLoadBalancersError>`](crate::error::AttachLoadBalancersError)
    pub fn attach_load_balancers(&self) -> fluent_builders::AttachLoadBalancers {
        fluent_builders::AttachLoadBalancers::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`AttachLoadBalancerTargetGroups`](crate::client::fluent_builders::AttachLoadBalancerTargetGroups) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::AttachLoadBalancerTargetGroups::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::AttachLoadBalancerTargetGroups::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`target_group_ar_ns(Vec<String>)`](crate::client::fluent_builders::AttachLoadBalancerTargetGroups::target_group_ar_ns) / [`set_target_group_ar_ns(Option<Vec<String>>)`](crate::client::fluent_builders::AttachLoadBalancerTargetGroups::set_target_group_ar_ns): <p>The Amazon Resource Names (ARN) of the target groups. You can specify up to 10 target groups. To get the ARN of a target group, use the Elastic Load Balancing <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
    /// - On success, responds with [`AttachLoadBalancerTargetGroupsOutput`](crate::output::AttachLoadBalancerTargetGroupsOutput)

    /// - On failure, responds with [`SdkError<AttachLoadBalancerTargetGroupsError>`](crate::error::AttachLoadBalancerTargetGroupsError)
    pub fn attach_load_balancer_target_groups(
        &self,
    ) -> fluent_builders::AttachLoadBalancerTargetGroups {
        fluent_builders::AttachLoadBalancerTargetGroups::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`BatchDeleteScheduledAction`](crate::client::fluent_builders::BatchDeleteScheduledAction) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::BatchDeleteScheduledAction::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::BatchDeleteScheduledAction::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`scheduled_action_names(Vec<String>)`](crate::client::fluent_builders::BatchDeleteScheduledAction::scheduled_action_names) / [`set_scheduled_action_names(Option<Vec<String>>)`](crate::client::fluent_builders::BatchDeleteScheduledAction::set_scheduled_action_names): <p>The names of the scheduled actions to delete. The maximum number allowed is 50. </p>
    /// - On success, responds with [`BatchDeleteScheduledActionOutput`](crate::output::BatchDeleteScheduledActionOutput) with field(s):
    ///   - [`failed_scheduled_actions(Option<Vec<FailedScheduledUpdateGroupActionRequest>>)`](crate::output::BatchDeleteScheduledActionOutput::failed_scheduled_actions): <p>The names of the scheduled actions that could not be deleted, including an error message.</p>
    /// - On failure, responds with [`SdkError<BatchDeleteScheduledActionError>`](crate::error::BatchDeleteScheduledActionError)
    pub fn batch_delete_scheduled_action(&self) -> fluent_builders::BatchDeleteScheduledAction {
        fluent_builders::BatchDeleteScheduledAction::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`BatchPutScheduledUpdateGroupAction`](crate::client::fluent_builders::BatchPutScheduledUpdateGroupAction) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::BatchPutScheduledUpdateGroupAction::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::BatchPutScheduledUpdateGroupAction::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`scheduled_update_group_actions(Vec<ScheduledUpdateGroupActionRequest>)`](crate::client::fluent_builders::BatchPutScheduledUpdateGroupAction::scheduled_update_group_actions) / [`set_scheduled_update_group_actions(Option<Vec<ScheduledUpdateGroupActionRequest>>)`](crate::client::fluent_builders::BatchPutScheduledUpdateGroupAction::set_scheduled_update_group_actions): <p>One or more scheduled actions. The maximum number allowed is 50.</p>
    /// - On success, responds with [`BatchPutScheduledUpdateGroupActionOutput`](crate::output::BatchPutScheduledUpdateGroupActionOutput) with field(s):
    ///   - [`failed_scheduled_update_group_actions(Option<Vec<FailedScheduledUpdateGroupActionRequest>>)`](crate::output::BatchPutScheduledUpdateGroupActionOutput::failed_scheduled_update_group_actions): <p>The names of the scheduled actions that could not be created or updated, including an error message.</p>
    /// - On failure, responds with [`SdkError<BatchPutScheduledUpdateGroupActionError>`](crate::error::BatchPutScheduledUpdateGroupActionError)
    pub fn batch_put_scheduled_update_group_action(
        &self,
    ) -> fluent_builders::BatchPutScheduledUpdateGroupAction {
        fluent_builders::BatchPutScheduledUpdateGroupAction::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`CancelInstanceRefresh`](crate::client::fluent_builders::CancelInstanceRefresh) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::CancelInstanceRefresh::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::CancelInstanceRefresh::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    /// - On success, responds with [`CancelInstanceRefreshOutput`](crate::output::CancelInstanceRefreshOutput) with field(s):
    ///   - [`instance_refresh_id(Option<String>)`](crate::output::CancelInstanceRefreshOutput::instance_refresh_id): <p>The instance refresh ID.</p>
    /// - On failure, responds with [`SdkError<CancelInstanceRefreshError>`](crate::error::CancelInstanceRefreshError)
    pub fn cancel_instance_refresh(&self) -> fluent_builders::CancelInstanceRefresh {
        fluent_builders::CancelInstanceRefresh::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`CompleteLifecycleAction`](crate::client::fluent_builders::CompleteLifecycleAction) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`lifecycle_hook_name(impl Into<String>)`](crate::client::fluent_builders::CompleteLifecycleAction::lifecycle_hook_name) / [`set_lifecycle_hook_name(Option<String>)`](crate::client::fluent_builders::CompleteLifecycleAction::set_lifecycle_hook_name): <p>The name of the lifecycle hook.</p>
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::CompleteLifecycleAction::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::CompleteLifecycleAction::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`lifecycle_action_token(impl Into<String>)`](crate::client::fluent_builders::CompleteLifecycleAction::lifecycle_action_token) / [`set_lifecycle_action_token(Option<String>)`](crate::client::fluent_builders::CompleteLifecycleAction::set_lifecycle_action_token): <p>A universally unique identifier (UUID) that identifies a specific lifecycle action associated with an instance. Amazon EC2 Auto Scaling sends this token to the notification target you specified when you created the lifecycle hook.</p>
    ///   - [`lifecycle_action_result(impl Into<String>)`](crate::client::fluent_builders::CompleteLifecycleAction::lifecycle_action_result) / [`set_lifecycle_action_result(Option<String>)`](crate::client::fluent_builders::CompleteLifecycleAction::set_lifecycle_action_result): <p>The action for the group to take. This parameter can be either <code>CONTINUE</code> or <code>ABANDON</code>.</p>
    ///   - [`instance_id(impl Into<String>)`](crate::client::fluent_builders::CompleteLifecycleAction::instance_id) / [`set_instance_id(Option<String>)`](crate::client::fluent_builders::CompleteLifecycleAction::set_instance_id): <p>The ID of the instance.</p>
    /// - On success, responds with [`CompleteLifecycleActionOutput`](crate::output::CompleteLifecycleActionOutput)

    /// - On failure, responds with [`SdkError<CompleteLifecycleActionError>`](crate::error::CompleteLifecycleActionError)
    pub fn complete_lifecycle_action(&self) -> fluent_builders::CompleteLifecycleAction {
        fluent_builders::CompleteLifecycleAction::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`CreateAutoScalingGroup`](crate::client::fluent_builders::CreateAutoScalingGroup) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_auto_scaling_group_name): <p>The name of the Auto Scaling group. This name must be unique per Region per account.</p>
    ///   - [`launch_configuration_name(impl Into<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::launch_configuration_name) / [`set_launch_configuration_name(Option<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_launch_configuration_name): <p>The name of the launch configuration to use to launch instances. </p>  <p>Conditional: You must specify either a launch template (<code>LaunchTemplate</code> or <code>MixedInstancesPolicy</code>) or a launch configuration (<code>LaunchConfigurationName</code> or <code>InstanceId</code>).</p>
    ///   - [`launch_template(LaunchTemplateSpecification)`](crate::client::fluent_builders::CreateAutoScalingGroup::launch_template) / [`set_launch_template(Option<LaunchTemplateSpecification>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_launch_template): <p>Parameters used to specify the launch template and version to use to launch instances. </p>  <p>Conditional: You must specify either a launch template (<code>LaunchTemplate</code> or <code>MixedInstancesPolicy</code>) or a launch configuration (<code>LaunchConfigurationName</code> or <code>InstanceId</code>).</p> <note>   <p>The launch template that is specified must be configured for use with an Auto Scaling group. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-template.html">Creating a launch template for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>  </note>
    ///   - [`mixed_instances_policy(MixedInstancesPolicy)`](crate::client::fluent_builders::CreateAutoScalingGroup::mixed_instances_policy) / [`set_mixed_instances_policy(Option<MixedInstancesPolicy>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_mixed_instances_policy): <p>An embedded object that specifies a mixed instances policy.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html">Auto Scaling groups with multiple instance types and purchase options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`instance_id(impl Into<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::instance_id) / [`set_instance_id(Option<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_instance_id): <p>The ID of the instance used to base the launch configuration on. If specified, Amazon EC2 Auto Scaling uses the configuration values from the specified instance to create a new launch configuration. To get the instance ID, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html">DescribeInstances</a> API operation. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-from-instance.html">Creating an Auto Scaling group using an EC2 instance</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`min_size(i32)`](crate::client::fluent_builders::CreateAutoScalingGroup::min_size) / [`set_min_size(Option<i32>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_min_size): <p>The minimum size of the group.</p>
    ///   - [`max_size(i32)`](crate::client::fluent_builders::CreateAutoScalingGroup::max_size) / [`set_max_size(Option<i32>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_max_size): <p>The maximum size of the group.</p> <note>   <p>With a mixed instances policy that uses instance weighting, Amazon EC2 Auto Scaling may need to go above <code>MaxSize</code> to meet your capacity requirements. In this event, Amazon EC2 Auto Scaling will never go above <code>MaxSize</code> by more than your largest instance weight (weights that define how many units each instance contributes to the desired capacity of the group).</p>  </note>
    ///   - [`desired_capacity(i32)`](crate::client::fluent_builders::CreateAutoScalingGroup::desired_capacity) / [`set_desired_capacity(Option<i32>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_desired_capacity): <p>The desired capacity is the initial capacity of the Auto Scaling group at the time of its creation and the capacity it attempts to maintain. It can scale beyond this capacity if you configure auto scaling. This number must be greater than or equal to the minimum size of the group and less than or equal to the maximum size of the group. If you do not specify a desired capacity, the default is the minimum size of the group.</p>
    ///   - [`default_cooldown(i32)`](crate::client::fluent_builders::CreateAutoScalingGroup::default_cooldown) / [`set_default_cooldown(Option<i32>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_default_cooldown): <p> <i>Only needed if you use simple scaling policies.</i> </p>  <p>The amount of time, in seconds, between one scaling activity ending and another one starting due to simple scaling policies. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>  <p>Default: <code>300</code> seconds</p>
    ///   - [`availability_zones(Vec<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::availability_zones) / [`set_availability_zones(Option<Vec<String>>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_availability_zones): <p>A list of Availability Zones where instances in the Auto Scaling group can be created. This parameter is optional if you specify one or more subnets for <code>VPCZoneIdentifier</code>.</p>  <p>Conditional: If your account supports EC2-Classic and VPC, this parameter is required to launch instances into EC2-Classic.</p>
    ///   - [`load_balancer_names(Vec<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::load_balancer_names) / [`set_load_balancer_names(Option<Vec<String>>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_load_balancer_names): <p>A list of Classic Load Balancers associated with this Auto Scaling group. For Application Load Balancers, Network Load Balancers, and Gateway Load Balancers, specify the <code>TargetGroupARNs</code> property instead.</p>
    ///   - [`target_group_ar_ns(Vec<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::target_group_ar_ns) / [`set_target_group_ar_ns(Option<Vec<String>>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_target_group_ar_ns): <p>The Amazon Resource Names (ARN) of the target groups to associate with the Auto Scaling group. Instances are registered as targets in a target group, and traffic is routed to the target group. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html">Elastic Load Balancing and Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`health_check_type(impl Into<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::health_check_type) / [`set_health_check_type(Option<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_health_check_type): <p>The service to use for the health checks. The valid values are <code>EC2</code> (default) and <code>ELB</code>. If you configure an Auto Scaling group to use load balancer (ELB) health checks, it considers the instance unhealthy if it fails either the EC2 status checks or the load balancer health checks. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html">Health checks for Auto Scaling instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`health_check_grace_period(i32)`](crate::client::fluent_builders::CreateAutoScalingGroup::health_check_grace_period) / [`set_health_check_grace_period(Option<i32>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_health_check_grace_period): <p> <i></i> </p>  <p>The amount of time, in seconds, that Amazon EC2 Auto Scaling waits before checking the health status of an EC2 instance that has come into service and marking it unhealthy due to a failed Elastic Load Balancing or custom health check. This is useful if your instances do not immediately pass these health checks after they enter the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html#health-check-grace-period">Health check grace period</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>  <p>Default: <code>0</code> seconds</p>
    ///   - [`placement_group(impl Into<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::placement_group) / [`set_placement_group(Option<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_placement_group): <p>The name of an existing placement group into which to launch your instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html">Placement groups</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> <note>   <p>A <i>cluster</i> placement group is a logical grouping of instances within a single Availability Zone. You cannot specify multiple Availability Zones and a cluster placement group. </p>  </note>
    ///   - [`vpc_zone_identifier(impl Into<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::vpc_zone_identifier) / [`set_vpc_zone_identifier(Option<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_vpc_zone_identifier): <p>A comma-separated list of subnet IDs for a virtual private cloud (VPC) where instances in the Auto Scaling group can be created. If you specify <code>VPCZoneIdentifier</code> with <code>AvailabilityZones</code>, the subnets that you specify for this parameter must reside in those Availability Zones.</p>  <p>Conditional: If your account supports EC2-Classic and VPC, this parameter is required to launch instances into a VPC.</p>
    ///   - [`termination_policies(Vec<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::termination_policies) / [`set_termination_policies(Option<Vec<String>>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_termination_policies): <p>A policy or a list of policies that are used to select the instance to terminate. These policies are executed in the order that you list them. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html">Controlling which Auto Scaling instances terminate during scale in</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`new_instances_protected_from_scale_in(bool)`](crate::client::fluent_builders::CreateAutoScalingGroup::new_instances_protected_from_scale_in) / [`set_new_instances_protected_from_scale_in(Option<bool>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_new_instances_protected_from_scale_in): <p>Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. For more information about preventing instances from terminating on scale in, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-instance-protection.html">Using instance scale-in protection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`capacity_rebalance(bool)`](crate::client::fluent_builders::CreateAutoScalingGroup::capacity_rebalance) / [`set_capacity_rebalance(Option<bool>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_capacity_rebalance): <p>Indicates whether Capacity Rebalancing is enabled. Otherwise, Capacity Rebalancing is disabled. When you turn on Capacity Rebalancing, Amazon EC2 Auto Scaling attempts to launch a Spot Instance whenever Amazon EC2 notifies that a Spot Instance is at an elevated risk of interruption. After launching a new instance, it then terminates an old instance. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html">Amazon EC2 Auto Scaling Capacity Rebalancing</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`lifecycle_hook_specification_list(Vec<LifecycleHookSpecification>)`](crate::client::fluent_builders::CreateAutoScalingGroup::lifecycle_hook_specification_list) / [`set_lifecycle_hook_specification_list(Option<Vec<LifecycleHookSpecification>>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_lifecycle_hook_specification_list): <p>One or more lifecycle hooks for the group, which specify actions to perform when Amazon EC2 Auto Scaling launches or terminates instances.</p>
    ///   - [`tags(Vec<Tag>)`](crate::client::fluent_builders::CreateAutoScalingGroup::tags) / [`set_tags(Option<Vec<Tag>>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_tags): <p>One or more tags. You can tag your Auto Scaling group and propagate the tags to the Amazon EC2 instances it launches. Tags are not propagated to Amazon EBS volumes. To add tags to Amazon EBS volumes, specify the tags in a launch template but use caution. If the launch template specifies an instance tag with a key that is also specified for the Auto Scaling group, Amazon EC2 Auto Scaling overrides the value of that instance tag with the value specified by the Auto Scaling group. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-tagging.html">Tagging Auto Scaling groups and instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`service_linked_role_arn(impl Into<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::service_linked_role_arn) / [`set_service_linked_role_arn(Option<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_service_linked_role_arn): <p>The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services on your behalf. By default, Amazon EC2 Auto Scaling uses a service-linked role named <code>AWSServiceRoleForAutoScaling</code>, which it creates if it does not exist. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-service-linked-role.html">Service-linked roles</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`max_instance_lifetime(i32)`](crate::client::fluent_builders::CreateAutoScalingGroup::max_instance_lifetime) / [`set_max_instance_lifetime(Option<i32>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_max_instance_lifetime): <p>The maximum amount of time, in seconds, that an instance can be in service. The default is null. If specified, the value must be either 0 or a number equal to or greater than 86,400 seconds (1 day). For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-max-instance-lifetime.html">Replacing Auto Scaling instances based on maximum instance lifetime</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`context(impl Into<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::context) / [`set_context(Option<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_context): <p>Reserved.</p>
    ///   - [`desired_capacity_type(impl Into<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::desired_capacity_type) / [`set_desired_capacity_type(Option<String>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_desired_capacity_type): <p>The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports <code>DesiredCapacityType</code> for attribute-based instance type selection only. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-instance-type-requirements.html">Creating an Auto Scaling group using attribute-based instance type selection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>  <p>By default, Amazon EC2 Auto Scaling specifies <code>units</code>, which translates into number of instances.</p>  <p>Valid values: <code>units</code> | <code>vcpu</code> | <code>memory-mib</code> </p>
    ///   - [`default_instance_warmup(i32)`](crate::client::fluent_builders::CreateAutoScalingGroup::default_instance_warmup) / [`set_default_instance_warmup(Option<i32>)`](crate::client::fluent_builders::CreateAutoScalingGroup::set_default_instance_warmup): <p>The amount of time, in seconds, until a newly launched instance can contribute to the Amazon CloudWatch metrics. This delay lets an instance finish initializing before Amazon EC2 Auto Scaling aggregates instance metrics, resulting in more reliable usage data. Set this value equal to the amount of time that it takes for resource consumption to become stable after an instance reaches the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-default-instance-warmup.html">Set the default instance warmup for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <important>   <p>To manage your warm-up settings at the group level, we recommend that you set the default instance warmup, <i>even if its value is set to 0 seconds</i>. This also optimizes the performance of scaling policies that scale continuously, such as target tracking and step scaling policies. </p>   <p>If you need to remove a value that you previously set, include the property but specify <code>-1</code> for the value. However, we strongly recommend keeping the default instance warmup enabled by specifying a minimum value of <code>0</code>.</p>  </important>  <p>Default: None </p>
    /// - On success, responds with [`CreateAutoScalingGroupOutput`](crate::output::CreateAutoScalingGroupOutput)

    /// - On failure, responds with [`SdkError<CreateAutoScalingGroupError>`](crate::error::CreateAutoScalingGroupError)
    pub fn create_auto_scaling_group(&self) -> fluent_builders::CreateAutoScalingGroup {
        fluent_builders::CreateAutoScalingGroup::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`CreateLaunchConfiguration`](crate::client::fluent_builders::CreateLaunchConfiguration) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`launch_configuration_name(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::launch_configuration_name) / [`set_launch_configuration_name(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_launch_configuration_name): <p>The name of the launch configuration. This name must be unique per Region per account.</p>
    ///   - [`image_id(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::image_id) / [`set_image_id(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_image_id): <p>The ID of the Amazon Machine Image (AMI) that was assigned during registration. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html">Finding an AMI</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>  <p>If you do not specify <code>InstanceId</code>, you must specify <code>ImageId</code>.</p>
    ///   - [`key_name(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::key_name) / [`set_key_name(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_key_name): <p>The name of the key pair. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html">Amazon EC2 Key Pairs</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    ///   - [`security_groups(Vec<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::security_groups) / [`set_security_groups(Option<Vec<String>>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_security_groups): <p>A list that contains the security groups to assign to the instances in the Auto Scaling group.</p>  <p>[EC2-VPC] Specify the security group IDs. For more information, see <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html">Security Groups for Your VPC</a> in the <i>Amazon Virtual Private Cloud User Guide</i>.</p>  <p>[EC2-Classic] Specify either the security group names or the security group IDs. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html">Amazon EC2 Security Groups</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    ///   - [`classic_link_vpc_id(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::classic_link_vpc_id) / [`set_classic_link_vpc_id(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_classic_link_vpc_id): <p> <i>EC2-Classic retires on August 15, 2022. This parameter is not supported after that date.</i> </p>  <p>The ID of a ClassicLink-enabled VPC to link your EC2-Classic instances to. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-classiclink.html">ClassicLink</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    ///   - [`classic_link_vpc_security_groups(Vec<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::classic_link_vpc_security_groups) / [`set_classic_link_vpc_security_groups(Option<Vec<String>>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_classic_link_vpc_security_groups): <p> <i>EC2-Classic retires on August 15, 2022. This parameter is not supported after that date.</i> </p>  <p>The IDs of one or more security groups for the specified ClassicLink-enabled VPC. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-classiclink.html">ClassicLink</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>  <p>If you specify the <code>ClassicLinkVPCId</code> parameter, you must specify this parameter.</p>
    ///   - [`user_data(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::user_data) / [`set_user_data(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_user_data): <p>The user data to make available to the launched EC2 instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Linux) and <a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Windows). If you are using a command line tool, base64-encoding is performed for you, and you can load the text from a file. Otherwise, you must provide base64-encoded text. User data is limited to 16 KB.</p>
    ///   - [`instance_id(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::instance_id) / [`set_instance_id(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_instance_id): <p>The ID of the instance to use to create the launch configuration. The new launch configuration derives attributes from the instance, except for the block device mapping.</p>  <p>To create a launch configuration with a block device mapping or override any other instance attributes, specify them as part of the same request.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-lc-with-instanceID.html">Creating a launch configuration using an EC2 instance</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>  <p>If you do not specify <code>InstanceId</code>, you must specify both <code>ImageId</code> and <code>InstanceType</code>.</p>
    ///   - [`instance_type(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::instance_type) / [`set_instance_type(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_instance_type): <p>Specifies the instance type of the EC2 instance.</p>  <p>For information about available instance types, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#AvailableInstanceTypes">Available Instance Types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>  <p>If you do not specify <code>InstanceId</code>, you must specify <code>InstanceType</code>.</p>
    ///   - [`kernel_id(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::kernel_id) / [`set_kernel_id(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_kernel_id): <p>The ID of the kernel associated with the AMI.</p>
    ///   - [`ramdisk_id(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::ramdisk_id) / [`set_ramdisk_id(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_ramdisk_id): <p>The ID of the RAM disk to select.</p>
    ///   - [`block_device_mappings(Vec<BlockDeviceMapping>)`](crate::client::fluent_builders::CreateLaunchConfiguration::block_device_mappings) / [`set_block_device_mappings(Option<Vec<BlockDeviceMapping>>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_block_device_mappings): <p>A block device mapping, which specifies the block devices for the instance. You can specify virtual devices and EBS volumes. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html">Block Device Mapping</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
    ///   - [`instance_monitoring(InstanceMonitoring)`](crate::client::fluent_builders::CreateLaunchConfiguration::instance_monitoring) / [`set_instance_monitoring(Option<InstanceMonitoring>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_instance_monitoring): <p>Controls whether instances in this group are launched with detailed (<code>true</code>) or basic (<code>false</code>) monitoring.</p>  <p>The default value is <code>true</code> (enabled).</p> <important>   <p>When detailed monitoring is enabled, Amazon CloudWatch generates metrics every minute and your account is charged a fee. When you disable detailed monitoring, CloudWatch generates metrics every 5 minutes. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/latest/userguide/enable-as-instance-metrics.html">Configure Monitoring for Auto Scaling Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>  </important>
    ///   - [`spot_price(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::spot_price) / [`set_spot_price(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_spot_price): <p>The maximum hourly price to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot price. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-launch-spot-instances.html">Requesting Spot Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <note>   <p>When you change your maximum price by creating a new launch configuration, running instances will continue to run as long as the maximum price for those running instances is higher than the current Spot price.</p>  </note>
    ///   - [`iam_instance_profile(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::iam_instance_profile) / [`set_iam_instance_profile(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_iam_instance_profile): <p>The name or the Amazon Resource Name (ARN) of the instance profile associated with the IAM role for the instance. The instance profile contains the IAM role.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/us-iam-role.html">IAM role for applications that run on Amazon EC2 instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`ebs_optimized(bool)`](crate::client::fluent_builders::CreateLaunchConfiguration::ebs_optimized) / [`set_ebs_optimized(Option<bool>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_ebs_optimized): <p>Specifies whether the launch configuration is optimized for EBS I/O (<code>true</code>) or not (<code>false</code>). The optimization provides dedicated throughput to Amazon EBS and an optimized configuration stack to provide optimal I/O performance. This optimization is not available with all instance types. Additional fees are incurred when you enable EBS optimization for an instance type that is not EBS-optimized by default. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html">Amazon EBS-optimized instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>  <p>The default value is <code>false</code>.</p>
    ///   - [`associate_public_ip_address(bool)`](crate::client::fluent_builders::CreateLaunchConfiguration::associate_public_ip_address) / [`set_associate_public_ip_address(Option<bool>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_associate_public_ip_address): <p>For Auto Scaling groups that are running in a virtual private cloud (VPC), specifies whether to assign a public IP address to the group's instances. If you specify <code>true</code>, each instance in the Auto Scaling group receives a unique public IP address. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-in-vpc.html">Launching Auto Scaling instances in a VPC</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>  <p>If you specify this parameter, you must specify at least one subnet for <code>VPCZoneIdentifier</code> when you create your group.</p> <note>   <p>If the instance is launched into a default subnet, the default is to assign a public IP address, unless you disabled the option to assign a public IP address on the subnet. If the instance is launched into a nondefault subnet, the default is not to assign a public IP address, unless you enabled the option to assign a public IP address on the subnet.</p>  </note>
    ///   - [`placement_tenancy(impl Into<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::placement_tenancy) / [`set_placement_tenancy(Option<String>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_placement_tenancy): <p>The tenancy of the instance. An instance with <code>dedicated</code> tenancy runs on isolated, single-tenant hardware and can only be launched into a VPC.</p>  <p>To launch dedicated instances into a shared tenancy VPC (a VPC with the instance placement tenancy attribute set to <code>default</code>), you must set the value of this parameter to <code>dedicated</code>.</p>  <p>If you specify <code>PlacementTenancy</code>, you must specify at least one subnet for <code>VPCZoneIdentifier</code> when you create your group.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-dedicated-instances.html">Configuring instance tenancy with Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>  <p>Valid Values: <code>default</code> | <code>dedicated</code> </p>
    ///   - [`metadata_options(InstanceMetadataOptions)`](crate::client::fluent_builders::CreateLaunchConfiguration::metadata_options) / [`set_metadata_options(Option<InstanceMetadataOptions>)`](crate::client::fluent_builders::CreateLaunchConfiguration::set_metadata_options): <p>The metadata options for the instances. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-config.html#launch-configurations-imds">Configuring the Instance Metadata Options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// - On success, responds with [`CreateLaunchConfigurationOutput`](crate::output::CreateLaunchConfigurationOutput)

    /// - On failure, responds with [`SdkError<CreateLaunchConfigurationError>`](crate::error::CreateLaunchConfigurationError)
    pub fn create_launch_configuration(&self) -> fluent_builders::CreateLaunchConfiguration {
        fluent_builders::CreateLaunchConfiguration::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`CreateOrUpdateTags`](crate::client::fluent_builders::CreateOrUpdateTags) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`tags(Vec<Tag>)`](crate::client::fluent_builders::CreateOrUpdateTags::tags) / [`set_tags(Option<Vec<Tag>>)`](crate::client::fluent_builders::CreateOrUpdateTags::set_tags): <p>One or more tags.</p>
    /// - On success, responds with [`CreateOrUpdateTagsOutput`](crate::output::CreateOrUpdateTagsOutput)

    /// - On failure, responds with [`SdkError<CreateOrUpdateTagsError>`](crate::error::CreateOrUpdateTagsError)
    pub fn create_or_update_tags(&self) -> fluent_builders::CreateOrUpdateTags {
        fluent_builders::CreateOrUpdateTags::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DeleteAutoScalingGroup`](crate::client::fluent_builders::DeleteAutoScalingGroup) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DeleteAutoScalingGroup::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DeleteAutoScalingGroup::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`force_delete(bool)`](crate::client::fluent_builders::DeleteAutoScalingGroup::force_delete) / [`set_force_delete(Option<bool>)`](crate::client::fluent_builders::DeleteAutoScalingGroup::set_force_delete): <p>Specifies that the group is to be deleted along with all instances associated with the group, without waiting for all instances to be terminated. This parameter also deletes any outstanding lifecycle actions associated with the group.</p>
    /// - On success, responds with [`DeleteAutoScalingGroupOutput`](crate::output::DeleteAutoScalingGroupOutput)

    /// - On failure, responds with [`SdkError<DeleteAutoScalingGroupError>`](crate::error::DeleteAutoScalingGroupError)
    pub fn delete_auto_scaling_group(&self) -> fluent_builders::DeleteAutoScalingGroup {
        fluent_builders::DeleteAutoScalingGroup::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DeleteLaunchConfiguration`](crate::client::fluent_builders::DeleteLaunchConfiguration) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`launch_configuration_name(impl Into<String>)`](crate::client::fluent_builders::DeleteLaunchConfiguration::launch_configuration_name) / [`set_launch_configuration_name(Option<String>)`](crate::client::fluent_builders::DeleteLaunchConfiguration::set_launch_configuration_name): <p>The name of the launch configuration.</p>
    /// - On success, responds with [`DeleteLaunchConfigurationOutput`](crate::output::DeleteLaunchConfigurationOutput)

    /// - On failure, responds with [`SdkError<DeleteLaunchConfigurationError>`](crate::error::DeleteLaunchConfigurationError)
    pub fn delete_launch_configuration(&self) -> fluent_builders::DeleteLaunchConfiguration {
        fluent_builders::DeleteLaunchConfiguration::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DeleteLifecycleHook`](crate::client::fluent_builders::DeleteLifecycleHook) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`lifecycle_hook_name(impl Into<String>)`](crate::client::fluent_builders::DeleteLifecycleHook::lifecycle_hook_name) / [`set_lifecycle_hook_name(Option<String>)`](crate::client::fluent_builders::DeleteLifecycleHook::set_lifecycle_hook_name): <p>The name of the lifecycle hook.</p>
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DeleteLifecycleHook::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DeleteLifecycleHook::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    /// - On success, responds with [`DeleteLifecycleHookOutput`](crate::output::DeleteLifecycleHookOutput)

    /// - On failure, responds with [`SdkError<DeleteLifecycleHookError>`](crate::error::DeleteLifecycleHookError)
    pub fn delete_lifecycle_hook(&self) -> fluent_builders::DeleteLifecycleHook {
        fluent_builders::DeleteLifecycleHook::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DeleteNotificationConfiguration`](crate::client::fluent_builders::DeleteNotificationConfiguration) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DeleteNotificationConfiguration::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DeleteNotificationConfiguration::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`topic_arn(impl Into<String>)`](crate::client::fluent_builders::DeleteNotificationConfiguration::topic_arn) / [`set_topic_arn(Option<String>)`](crate::client::fluent_builders::DeleteNotificationConfiguration::set_topic_arn): <p>The Amazon Resource Name (ARN) of the Amazon SNS topic.</p>
    /// - On success, responds with [`DeleteNotificationConfigurationOutput`](crate::output::DeleteNotificationConfigurationOutput)

    /// - On failure, responds with [`SdkError<DeleteNotificationConfigurationError>`](crate::error::DeleteNotificationConfigurationError)
    pub fn delete_notification_configuration(
        &self,
    ) -> fluent_builders::DeleteNotificationConfiguration {
        fluent_builders::DeleteNotificationConfiguration::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DeletePolicy`](crate::client::fluent_builders::DeletePolicy) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DeletePolicy::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DeletePolicy::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`policy_name(impl Into<String>)`](crate::client::fluent_builders::DeletePolicy::policy_name) / [`set_policy_name(Option<String>)`](crate::client::fluent_builders::DeletePolicy::set_policy_name): <p>The name or Amazon Resource Name (ARN) of the policy.</p>
    /// - On success, responds with [`DeletePolicyOutput`](crate::output::DeletePolicyOutput)

    /// - On failure, responds with [`SdkError<DeletePolicyError>`](crate::error::DeletePolicyError)
    pub fn delete_policy(&self) -> fluent_builders::DeletePolicy {
        fluent_builders::DeletePolicy::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DeleteScheduledAction`](crate::client::fluent_builders::DeleteScheduledAction) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DeleteScheduledAction::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DeleteScheduledAction::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`scheduled_action_name(impl Into<String>)`](crate::client::fluent_builders::DeleteScheduledAction::scheduled_action_name) / [`set_scheduled_action_name(Option<String>)`](crate::client::fluent_builders::DeleteScheduledAction::set_scheduled_action_name): <p>The name of the action to delete.</p>
    /// - On success, responds with [`DeleteScheduledActionOutput`](crate::output::DeleteScheduledActionOutput)

    /// - On failure, responds with [`SdkError<DeleteScheduledActionError>`](crate::error::DeleteScheduledActionError)
    pub fn delete_scheduled_action(&self) -> fluent_builders::DeleteScheduledAction {
        fluent_builders::DeleteScheduledAction::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DeleteTags`](crate::client::fluent_builders::DeleteTags) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`tags(Vec<Tag>)`](crate::client::fluent_builders::DeleteTags::tags) / [`set_tags(Option<Vec<Tag>>)`](crate::client::fluent_builders::DeleteTags::set_tags): <p>One or more tags.</p>
    /// - On success, responds with [`DeleteTagsOutput`](crate::output::DeleteTagsOutput)

    /// - On failure, responds with [`SdkError<DeleteTagsError>`](crate::error::DeleteTagsError)
    pub fn delete_tags(&self) -> fluent_builders::DeleteTags {
        fluent_builders::DeleteTags::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DeleteWarmPool`](crate::client::fluent_builders::DeleteWarmPool) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DeleteWarmPool::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DeleteWarmPool::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`force_delete(bool)`](crate::client::fluent_builders::DeleteWarmPool::force_delete) / [`set_force_delete(Option<bool>)`](crate::client::fluent_builders::DeleteWarmPool::set_force_delete): <p>Specifies that the warm pool is to be deleted along with all of its associated instances, without waiting for all instances to be terminated. This parameter also deletes any outstanding lifecycle actions associated with the warm pool instances.</p>
    /// - On success, responds with [`DeleteWarmPoolOutput`](crate::output::DeleteWarmPoolOutput)

    /// - On failure, responds with [`SdkError<DeleteWarmPoolError>`](crate::error::DeleteWarmPoolError)
    pub fn delete_warm_pool(&self) -> fluent_builders::DeleteWarmPool {
        fluent_builders::DeleteWarmPool::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeAccountLimits`](crate::client::fluent_builders::DescribeAccountLimits) operation.
    ///
    /// - The fluent builder takes no input, just [`send`](crate::client::fluent_builders::DescribeAccountLimits::send) it.

    /// - On success, responds with [`DescribeAccountLimitsOutput`](crate::output::DescribeAccountLimitsOutput) with field(s):
    ///   - [`max_number_of_auto_scaling_groups(Option<i32>)`](crate::output::DescribeAccountLimitsOutput::max_number_of_auto_scaling_groups): <p>The maximum number of groups allowed for your account. The default is 200 groups per Region.</p>
    ///   - [`max_number_of_launch_configurations(Option<i32>)`](crate::output::DescribeAccountLimitsOutput::max_number_of_launch_configurations): <p>The maximum number of launch configurations allowed for your account. The default is 200 launch configurations per Region.</p>
    ///   - [`number_of_auto_scaling_groups(Option<i32>)`](crate::output::DescribeAccountLimitsOutput::number_of_auto_scaling_groups): <p>The current number of groups for your account.</p>
    ///   - [`number_of_launch_configurations(Option<i32>)`](crate::output::DescribeAccountLimitsOutput::number_of_launch_configurations): <p>The current number of launch configurations for your account.</p>
    /// - On failure, responds with [`SdkError<DescribeAccountLimitsError>`](crate::error::DescribeAccountLimitsError)
    pub fn describe_account_limits(&self) -> fluent_builders::DescribeAccountLimits {
        fluent_builders::DescribeAccountLimits::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeAdjustmentTypes`](crate::client::fluent_builders::DescribeAdjustmentTypes) operation.
    ///
    /// - The fluent builder takes no input, just [`send`](crate::client::fluent_builders::DescribeAdjustmentTypes::send) it.

    /// - On success, responds with [`DescribeAdjustmentTypesOutput`](crate::output::DescribeAdjustmentTypesOutput) with field(s):
    ///   - [`adjustment_types(Option<Vec<AdjustmentType>>)`](crate::output::DescribeAdjustmentTypesOutput::adjustment_types): <p>The policy adjustment types.</p>
    /// - On failure, responds with [`SdkError<DescribeAdjustmentTypesError>`](crate::error::DescribeAdjustmentTypesError)
    pub fn describe_adjustment_types(&self) -> fluent_builders::DescribeAdjustmentTypes {
        fluent_builders::DescribeAdjustmentTypes::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeAutoScalingGroups`](crate::client::fluent_builders::DescribeAutoScalingGroups) operation.
    /// This operation supports pagination; See [`into_paginator()`](crate::client::fluent_builders::DescribeAutoScalingGroups::into_paginator).
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_names(Vec<String>)`](crate::client::fluent_builders::DescribeAutoScalingGroups::auto_scaling_group_names) / [`set_auto_scaling_group_names(Option<Vec<String>>)`](crate::client::fluent_builders::DescribeAutoScalingGroups::set_auto_scaling_group_names): <p>The names of the Auto Scaling groups. By default, you can only specify up to 50 names. You can optionally increase this limit using the <code>MaxRecords</code> parameter.</p>  <p>If you omit this parameter, all Auto Scaling groups are described.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribeAutoScalingGroups::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribeAutoScalingGroups::set_next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribeAutoScalingGroups::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribeAutoScalingGroups::set_max_records): <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
    ///   - [`filters(Vec<Filter>)`](crate::client::fluent_builders::DescribeAutoScalingGroups::filters) / [`set_filters(Option<Vec<Filter>>)`](crate::client::fluent_builders::DescribeAutoScalingGroups::set_filters): <p>One or more filters to limit the results based on specific tags. </p>
    /// - On success, responds with [`DescribeAutoScalingGroupsOutput`](crate::output::DescribeAutoScalingGroupsOutput) with field(s):
    ///   - [`auto_scaling_groups(Option<Vec<AutoScalingGroup>>)`](crate::output::DescribeAutoScalingGroupsOutput::auto_scaling_groups): <p>The groups.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribeAutoScalingGroupsOutput::next_token): <p>A string that indicates that the response contains more items than can be returned in a single response. To receive additional items, specify this string for the <code>NextToken</code> value when requesting the next set of items. This value is null when there are no more items to return.</p>
    /// - On failure, responds with [`SdkError<DescribeAutoScalingGroupsError>`](crate::error::DescribeAutoScalingGroupsError)
    pub fn describe_auto_scaling_groups(&self) -> fluent_builders::DescribeAutoScalingGroups {
        fluent_builders::DescribeAutoScalingGroups::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeAutoScalingInstances`](crate::client::fluent_builders::DescribeAutoScalingInstances) operation.
    /// This operation supports pagination; See [`into_paginator()`](crate::client::fluent_builders::DescribeAutoScalingInstances::into_paginator).
    ///
    /// - The fluent builder is configurable:
    ///   - [`instance_ids(Vec<String>)`](crate::client::fluent_builders::DescribeAutoScalingInstances::instance_ids) / [`set_instance_ids(Option<Vec<String>>)`](crate::client::fluent_builders::DescribeAutoScalingInstances::set_instance_ids): <p>The IDs of the instances. If you omit this parameter, all Auto Scaling instances are described. If you specify an ID that does not exist, it is ignored with no error.</p>  <p>Array Members: Maximum number of 50 items.</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribeAutoScalingInstances::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribeAutoScalingInstances::set_max_records): <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>50</code>.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribeAutoScalingInstances::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribeAutoScalingInstances::set_next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    /// - On success, responds with [`DescribeAutoScalingInstancesOutput`](crate::output::DescribeAutoScalingInstancesOutput) with field(s):
    ///   - [`auto_scaling_instances(Option<Vec<AutoScalingInstanceDetails>>)`](crate::output::DescribeAutoScalingInstancesOutput::auto_scaling_instances): <p>The instances.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribeAutoScalingInstancesOutput::next_token): <p>A string that indicates that the response contains more items than can be returned in a single response. To receive additional items, specify this string for the <code>NextToken</code> value when requesting the next set of items. This value is null when there are no more items to return.</p>
    /// - On failure, responds with [`SdkError<DescribeAutoScalingInstancesError>`](crate::error::DescribeAutoScalingInstancesError)
    pub fn describe_auto_scaling_instances(&self) -> fluent_builders::DescribeAutoScalingInstances {
        fluent_builders::DescribeAutoScalingInstances::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeAutoScalingNotificationTypes`](crate::client::fluent_builders::DescribeAutoScalingNotificationTypes) operation.
    ///
    /// - The fluent builder takes no input, just [`send`](crate::client::fluent_builders::DescribeAutoScalingNotificationTypes::send) it.

    /// - On success, responds with [`DescribeAutoScalingNotificationTypesOutput`](crate::output::DescribeAutoScalingNotificationTypesOutput) with field(s):
    ///   - [`auto_scaling_notification_types(Option<Vec<String>>)`](crate::output::DescribeAutoScalingNotificationTypesOutput::auto_scaling_notification_types): <p>The notification types.</p>
    /// - On failure, responds with [`SdkError<DescribeAutoScalingNotificationTypesError>`](crate::error::DescribeAutoScalingNotificationTypesError)
    pub fn describe_auto_scaling_notification_types(
        &self,
    ) -> fluent_builders::DescribeAutoScalingNotificationTypes {
        fluent_builders::DescribeAutoScalingNotificationTypes::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeInstanceRefreshes`](crate::client::fluent_builders::DescribeInstanceRefreshes) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DescribeInstanceRefreshes::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DescribeInstanceRefreshes::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`instance_refresh_ids(Vec<String>)`](crate::client::fluent_builders::DescribeInstanceRefreshes::instance_refresh_ids) / [`set_instance_refresh_ids(Option<Vec<String>>)`](crate::client::fluent_builders::DescribeInstanceRefreshes::set_instance_refresh_ids): <p>One or more instance refresh IDs.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribeInstanceRefreshes::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribeInstanceRefreshes::set_next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribeInstanceRefreshes::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribeInstanceRefreshes::set_max_records): <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
    /// - On success, responds with [`DescribeInstanceRefreshesOutput`](crate::output::DescribeInstanceRefreshesOutput) with field(s):
    ///   - [`instance_refreshes(Option<Vec<InstanceRefresh>>)`](crate::output::DescribeInstanceRefreshesOutput::instance_refreshes): <p>The instance refreshes for the specified group.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribeInstanceRefreshesOutput::next_token): <p>A string that indicates that the response contains more items than can be returned in a single response. To receive additional items, specify this string for the <code>NextToken</code> value when requesting the next set of items. This value is null when there are no more items to return.</p>
    /// - On failure, responds with [`SdkError<DescribeInstanceRefreshesError>`](crate::error::DescribeInstanceRefreshesError)
    pub fn describe_instance_refreshes(&self) -> fluent_builders::DescribeInstanceRefreshes {
        fluent_builders::DescribeInstanceRefreshes::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeLaunchConfigurations`](crate::client::fluent_builders::DescribeLaunchConfigurations) operation.
    /// This operation supports pagination; See [`into_paginator()`](crate::client::fluent_builders::DescribeLaunchConfigurations::into_paginator).
    ///
    /// - The fluent builder is configurable:
    ///   - [`launch_configuration_names(Vec<String>)`](crate::client::fluent_builders::DescribeLaunchConfigurations::launch_configuration_names) / [`set_launch_configuration_names(Option<Vec<String>>)`](crate::client::fluent_builders::DescribeLaunchConfigurations::set_launch_configuration_names): <p>The launch configuration names. If you omit this parameter, all launch configurations are described.</p>  <p>Array Members: Maximum number of 50 items.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribeLaunchConfigurations::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribeLaunchConfigurations::set_next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribeLaunchConfigurations::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribeLaunchConfigurations::set_max_records): <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
    /// - On success, responds with [`DescribeLaunchConfigurationsOutput`](crate::output::DescribeLaunchConfigurationsOutput) with field(s):
    ///   - [`launch_configurations(Option<Vec<LaunchConfiguration>>)`](crate::output::DescribeLaunchConfigurationsOutput::launch_configurations): <p>The launch configurations.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribeLaunchConfigurationsOutput::next_token): <p>A string that indicates that the response contains more items than can be returned in a single response. To receive additional items, specify this string for the <code>NextToken</code> value when requesting the next set of items. This value is null when there are no more items to return.</p>
    /// - On failure, responds with [`SdkError<DescribeLaunchConfigurationsError>`](crate::error::DescribeLaunchConfigurationsError)
    pub fn describe_launch_configurations(&self) -> fluent_builders::DescribeLaunchConfigurations {
        fluent_builders::DescribeLaunchConfigurations::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeLifecycleHooks`](crate::client::fluent_builders::DescribeLifecycleHooks) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DescribeLifecycleHooks::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DescribeLifecycleHooks::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`lifecycle_hook_names(Vec<String>)`](crate::client::fluent_builders::DescribeLifecycleHooks::lifecycle_hook_names) / [`set_lifecycle_hook_names(Option<Vec<String>>)`](crate::client::fluent_builders::DescribeLifecycleHooks::set_lifecycle_hook_names): <p>The names of one or more lifecycle hooks. If you omit this parameter, all lifecycle hooks are described.</p>
    /// - On success, responds with [`DescribeLifecycleHooksOutput`](crate::output::DescribeLifecycleHooksOutput) with field(s):
    ///   - [`lifecycle_hooks(Option<Vec<LifecycleHook>>)`](crate::output::DescribeLifecycleHooksOutput::lifecycle_hooks): <p>The lifecycle hooks for the specified group.</p>
    /// - On failure, responds with [`SdkError<DescribeLifecycleHooksError>`](crate::error::DescribeLifecycleHooksError)
    pub fn describe_lifecycle_hooks(&self) -> fluent_builders::DescribeLifecycleHooks {
        fluent_builders::DescribeLifecycleHooks::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeLifecycleHookTypes`](crate::client::fluent_builders::DescribeLifecycleHookTypes) operation.
    ///
    /// - The fluent builder takes no input, just [`send`](crate::client::fluent_builders::DescribeLifecycleHookTypes::send) it.

    /// - On success, responds with [`DescribeLifecycleHookTypesOutput`](crate::output::DescribeLifecycleHookTypesOutput) with field(s):
    ///   - [`lifecycle_hook_types(Option<Vec<String>>)`](crate::output::DescribeLifecycleHookTypesOutput::lifecycle_hook_types): <p>The lifecycle hook types.</p>
    /// - On failure, responds with [`SdkError<DescribeLifecycleHookTypesError>`](crate::error::DescribeLifecycleHookTypesError)
    pub fn describe_lifecycle_hook_types(&self) -> fluent_builders::DescribeLifecycleHookTypes {
        fluent_builders::DescribeLifecycleHookTypes::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeLoadBalancers`](crate::client::fluent_builders::DescribeLoadBalancers) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DescribeLoadBalancers::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DescribeLoadBalancers::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribeLoadBalancers::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribeLoadBalancers::set_next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribeLoadBalancers::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribeLoadBalancers::set_max_records): <p>The maximum number of items to return with this call. The default value is <code>100</code> and the maximum value is <code>100</code>.</p>
    /// - On success, responds with [`DescribeLoadBalancersOutput`](crate::output::DescribeLoadBalancersOutput) with field(s):
    ///   - [`load_balancers(Option<Vec<LoadBalancerState>>)`](crate::output::DescribeLoadBalancersOutput::load_balancers): <p>The load balancers.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribeLoadBalancersOutput::next_token): <p>A string that indicates that the response contains more items than can be returned in a single response. To receive additional items, specify this string for the <code>NextToken</code> value when requesting the next set of items. This value is null when there are no more items to return.</p>
    /// - On failure, responds with [`SdkError<DescribeLoadBalancersError>`](crate::error::DescribeLoadBalancersError)
    pub fn describe_load_balancers(&self) -> fluent_builders::DescribeLoadBalancers {
        fluent_builders::DescribeLoadBalancers::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeLoadBalancerTargetGroups`](crate::client::fluent_builders::DescribeLoadBalancerTargetGroups) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DescribeLoadBalancerTargetGroups::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DescribeLoadBalancerTargetGroups::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribeLoadBalancerTargetGroups::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribeLoadBalancerTargetGroups::set_next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribeLoadBalancerTargetGroups::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribeLoadBalancerTargetGroups::set_max_records): <p>The maximum number of items to return with this call. The default value is <code>100</code> and the maximum value is <code>100</code>.</p>
    /// - On success, responds with [`DescribeLoadBalancerTargetGroupsOutput`](crate::output::DescribeLoadBalancerTargetGroupsOutput) with field(s):
    ///   - [`load_balancer_target_groups(Option<Vec<LoadBalancerTargetGroupState>>)`](crate::output::DescribeLoadBalancerTargetGroupsOutput::load_balancer_target_groups): <p>Information about the target groups.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribeLoadBalancerTargetGroupsOutput::next_token): <p>A string that indicates that the response contains more items than can be returned in a single response. To receive additional items, specify this string for the <code>NextToken</code> value when requesting the next set of items. This value is null when there are no more items to return.</p>
    /// - On failure, responds with [`SdkError<DescribeLoadBalancerTargetGroupsError>`](crate::error::DescribeLoadBalancerTargetGroupsError)
    pub fn describe_load_balancer_target_groups(
        &self,
    ) -> fluent_builders::DescribeLoadBalancerTargetGroups {
        fluent_builders::DescribeLoadBalancerTargetGroups::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeMetricCollectionTypes`](crate::client::fluent_builders::DescribeMetricCollectionTypes) operation.
    ///
    /// - The fluent builder takes no input, just [`send`](crate::client::fluent_builders::DescribeMetricCollectionTypes::send) it.

    /// - On success, responds with [`DescribeMetricCollectionTypesOutput`](crate::output::DescribeMetricCollectionTypesOutput) with field(s):
    ///   - [`metrics(Option<Vec<MetricCollectionType>>)`](crate::output::DescribeMetricCollectionTypesOutput::metrics): <p>One or more metrics.</p>
    ///   - [`granularities(Option<Vec<MetricGranularityType>>)`](crate::output::DescribeMetricCollectionTypesOutput::granularities): <p>The granularities for the metrics.</p>
    /// - On failure, responds with [`SdkError<DescribeMetricCollectionTypesError>`](crate::error::DescribeMetricCollectionTypesError)
    pub fn describe_metric_collection_types(
        &self,
    ) -> fluent_builders::DescribeMetricCollectionTypes {
        fluent_builders::DescribeMetricCollectionTypes::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeNotificationConfigurations`](crate::client::fluent_builders::DescribeNotificationConfigurations) operation.
    /// This operation supports pagination; See [`into_paginator()`](crate::client::fluent_builders::DescribeNotificationConfigurations::into_paginator).
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_names(Vec<String>)`](crate::client::fluent_builders::DescribeNotificationConfigurations::auto_scaling_group_names) / [`set_auto_scaling_group_names(Option<Vec<String>>)`](crate::client::fluent_builders::DescribeNotificationConfigurations::set_auto_scaling_group_names): <p>The name of the Auto Scaling group.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribeNotificationConfigurations::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribeNotificationConfigurations::set_next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribeNotificationConfigurations::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribeNotificationConfigurations::set_max_records): <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
    /// - On success, responds with [`DescribeNotificationConfigurationsOutput`](crate::output::DescribeNotificationConfigurationsOutput) with field(s):
    ///   - [`notification_configurations(Option<Vec<NotificationConfiguration>>)`](crate::output::DescribeNotificationConfigurationsOutput::notification_configurations): <p>The notification configurations.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribeNotificationConfigurationsOutput::next_token): <p>A string that indicates that the response contains more items than can be returned in a single response. To receive additional items, specify this string for the <code>NextToken</code> value when requesting the next set of items. This value is null when there are no more items to return.</p>
    /// - On failure, responds with [`SdkError<DescribeNotificationConfigurationsError>`](crate::error::DescribeNotificationConfigurationsError)
    pub fn describe_notification_configurations(
        &self,
    ) -> fluent_builders::DescribeNotificationConfigurations {
        fluent_builders::DescribeNotificationConfigurations::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribePolicies`](crate::client::fluent_builders::DescribePolicies) operation.
    /// This operation supports pagination; See [`into_paginator()`](crate::client::fluent_builders::DescribePolicies::into_paginator).
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DescribePolicies::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DescribePolicies::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`policy_names(Vec<String>)`](crate::client::fluent_builders::DescribePolicies::policy_names) / [`set_policy_names(Option<Vec<String>>)`](crate::client::fluent_builders::DescribePolicies::set_policy_names): <p>The names of one or more policies. If you omit this parameter, all policies are described. If a group name is provided, the results are limited to that group. If you specify an unknown policy name, it is ignored with no error.</p>  <p>Array Members: Maximum number of 50 items.</p>
    ///   - [`policy_types(Vec<String>)`](crate::client::fluent_builders::DescribePolicies::policy_types) / [`set_policy_types(Option<Vec<String>>)`](crate::client::fluent_builders::DescribePolicies::set_policy_types): <p>One or more policy types. The valid values are <code>SimpleScaling</code>, <code>StepScaling</code>, <code>TargetTrackingScaling</code>, and <code>PredictiveScaling</code>.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribePolicies::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribePolicies::set_next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribePolicies::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribePolicies::set_max_records): <p>The maximum number of items to be returned with each call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
    /// - On success, responds with [`DescribePoliciesOutput`](crate::output::DescribePoliciesOutput) with field(s):
    ///   - [`scaling_policies(Option<Vec<ScalingPolicy>>)`](crate::output::DescribePoliciesOutput::scaling_policies): <p>The scaling policies.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribePoliciesOutput::next_token): <p>A string that indicates that the response contains more items than can be returned in a single response. To receive additional items, specify this string for the <code>NextToken</code> value when requesting the next set of items. This value is null when there are no more items to return.</p>
    /// - On failure, responds with [`SdkError<DescribePoliciesError>`](crate::error::DescribePoliciesError)
    pub fn describe_policies(&self) -> fluent_builders::DescribePolicies {
        fluent_builders::DescribePolicies::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeScalingActivities`](crate::client::fluent_builders::DescribeScalingActivities) operation.
    /// This operation supports pagination; See [`into_paginator()`](crate::client::fluent_builders::DescribeScalingActivities::into_paginator).
    ///
    /// - The fluent builder is configurable:
    ///   - [`activity_ids(Vec<String>)`](crate::client::fluent_builders::DescribeScalingActivities::activity_ids) / [`set_activity_ids(Option<Vec<String>>)`](crate::client::fluent_builders::DescribeScalingActivities::set_activity_ids): <p>The activity IDs of the desired scaling activities. If you omit this parameter, all activities for the past six weeks are described. If unknown activities are requested, they are ignored with no error. If you specify an Auto Scaling group, the results are limited to that group.</p>  <p>Array Members: Maximum number of 50 IDs.</p>
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DescribeScalingActivities::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DescribeScalingActivities::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`include_deleted_groups(bool)`](crate::client::fluent_builders::DescribeScalingActivities::include_deleted_groups) / [`set_include_deleted_groups(Option<bool>)`](crate::client::fluent_builders::DescribeScalingActivities::set_include_deleted_groups): <p>Indicates whether to include scaling activity from deleted Auto Scaling groups.</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribeScalingActivities::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribeScalingActivities::set_max_records): <p>The maximum number of items to return with this call. The default value is <code>100</code> and the maximum value is <code>100</code>.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribeScalingActivities::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribeScalingActivities::set_next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    /// - On success, responds with [`DescribeScalingActivitiesOutput`](crate::output::DescribeScalingActivitiesOutput) with field(s):
    ///   - [`activities(Option<Vec<Activity>>)`](crate::output::DescribeScalingActivitiesOutput::activities): <p>The scaling activities. Activities are sorted by start time. Activities still in progress are described first.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribeScalingActivitiesOutput::next_token): <p>A string that indicates that the response contains more items than can be returned in a single response. To receive additional items, specify this string for the <code>NextToken</code> value when requesting the next set of items. This value is null when there are no more items to return.</p>
    /// - On failure, responds with [`SdkError<DescribeScalingActivitiesError>`](crate::error::DescribeScalingActivitiesError)
    pub fn describe_scaling_activities(&self) -> fluent_builders::DescribeScalingActivities {
        fluent_builders::DescribeScalingActivities::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeScalingProcessTypes`](crate::client::fluent_builders::DescribeScalingProcessTypes) operation.
    ///
    /// - The fluent builder takes no input, just [`send`](crate::client::fluent_builders::DescribeScalingProcessTypes::send) it.

    /// - On success, responds with [`DescribeScalingProcessTypesOutput`](crate::output::DescribeScalingProcessTypesOutput) with field(s):
    ///   - [`processes(Option<Vec<ProcessType>>)`](crate::output::DescribeScalingProcessTypesOutput::processes): <p>The names of the process types.</p>
    /// - On failure, responds with [`SdkError<DescribeScalingProcessTypesError>`](crate::error::DescribeScalingProcessTypesError)
    pub fn describe_scaling_process_types(&self) -> fluent_builders::DescribeScalingProcessTypes {
        fluent_builders::DescribeScalingProcessTypes::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeScheduledActions`](crate::client::fluent_builders::DescribeScheduledActions) operation.
    /// This operation supports pagination; See [`into_paginator()`](crate::client::fluent_builders::DescribeScheduledActions::into_paginator).
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DescribeScheduledActions::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DescribeScheduledActions::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`scheduled_action_names(Vec<String>)`](crate::client::fluent_builders::DescribeScheduledActions::scheduled_action_names) / [`set_scheduled_action_names(Option<Vec<String>>)`](crate::client::fluent_builders::DescribeScheduledActions::set_scheduled_action_names): <p>The names of one or more scheduled actions. If you omit this parameter, all scheduled actions are described. If you specify an unknown scheduled action, it is ignored with no error.</p>  <p>Array Members: Maximum number of 50 actions.</p>
    ///   - [`start_time(DateTime)`](crate::client::fluent_builders::DescribeScheduledActions::start_time) / [`set_start_time(Option<DateTime>)`](crate::client::fluent_builders::DescribeScheduledActions::set_start_time): <p>The earliest scheduled start time to return. If scheduled action names are provided, this parameter is ignored.</p>
    ///   - [`end_time(DateTime)`](crate::client::fluent_builders::DescribeScheduledActions::end_time) / [`set_end_time(Option<DateTime>)`](crate::client::fluent_builders::DescribeScheduledActions::set_end_time): <p>The latest scheduled start time to return. If scheduled action names are provided, this parameter is ignored.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribeScheduledActions::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribeScheduledActions::set_next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribeScheduledActions::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribeScheduledActions::set_max_records): <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
    /// - On success, responds with [`DescribeScheduledActionsOutput`](crate::output::DescribeScheduledActionsOutput) with field(s):
    ///   - [`scheduled_update_group_actions(Option<Vec<ScheduledUpdateGroupAction>>)`](crate::output::DescribeScheduledActionsOutput::scheduled_update_group_actions): <p>The scheduled actions.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribeScheduledActionsOutput::next_token): <p>A string that indicates that the response contains more items than can be returned in a single response. To receive additional items, specify this string for the <code>NextToken</code> value when requesting the next set of items. This value is null when there are no more items to return.</p>
    /// - On failure, responds with [`SdkError<DescribeScheduledActionsError>`](crate::error::DescribeScheduledActionsError)
    pub fn describe_scheduled_actions(&self) -> fluent_builders::DescribeScheduledActions {
        fluent_builders::DescribeScheduledActions::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeTags`](crate::client::fluent_builders::DescribeTags) operation.
    /// This operation supports pagination; See [`into_paginator()`](crate::client::fluent_builders::DescribeTags::into_paginator).
    ///
    /// - The fluent builder is configurable:
    ///   - [`filters(Vec<Filter>)`](crate::client::fluent_builders::DescribeTags::filters) / [`set_filters(Option<Vec<Filter>>)`](crate::client::fluent_builders::DescribeTags::set_filters): <p>One or more filters to scope the tags to return. The maximum number of filters per filter type (for example, <code>auto-scaling-group</code>) is 1000.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribeTags::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribeTags::set_next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribeTags::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribeTags::set_max_records): <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
    /// - On success, responds with [`DescribeTagsOutput`](crate::output::DescribeTagsOutput) with field(s):
    ///   - [`tags(Option<Vec<TagDescription>>)`](crate::output::DescribeTagsOutput::tags): <p>One or more tags.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribeTagsOutput::next_token): <p>A string that indicates that the response contains more items than can be returned in a single response. To receive additional items, specify this string for the <code>NextToken</code> value when requesting the next set of items. This value is null when there are no more items to return.</p>
    /// - On failure, responds with [`SdkError<DescribeTagsError>`](crate::error::DescribeTagsError)
    pub fn describe_tags(&self) -> fluent_builders::DescribeTags {
        fluent_builders::DescribeTags::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeTerminationPolicyTypes`](crate::client::fluent_builders::DescribeTerminationPolicyTypes) operation.
    ///
    /// - The fluent builder takes no input, just [`send`](crate::client::fluent_builders::DescribeTerminationPolicyTypes::send) it.

    /// - On success, responds with [`DescribeTerminationPolicyTypesOutput`](crate::output::DescribeTerminationPolicyTypesOutput) with field(s):
    ///   - [`termination_policy_types(Option<Vec<String>>)`](crate::output::DescribeTerminationPolicyTypesOutput::termination_policy_types): <p>The termination policies supported by Amazon EC2 Auto Scaling: <code>OldestInstance</code>, <code>OldestLaunchConfiguration</code>, <code>NewestInstance</code>, <code>ClosestToNextInstanceHour</code>, <code>Default</code>, <code>OldestLaunchTemplate</code>, and <code>AllocationStrategy</code>.</p>
    /// - On failure, responds with [`SdkError<DescribeTerminationPolicyTypesError>`](crate::error::DescribeTerminationPolicyTypesError)
    pub fn describe_termination_policy_types(
        &self,
    ) -> fluent_builders::DescribeTerminationPolicyTypes {
        fluent_builders::DescribeTerminationPolicyTypes::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DescribeWarmPool`](crate::client::fluent_builders::DescribeWarmPool) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DescribeWarmPool::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DescribeWarmPool::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`max_records(i32)`](crate::client::fluent_builders::DescribeWarmPool::max_records) / [`set_max_records(Option<i32>)`](crate::client::fluent_builders::DescribeWarmPool::set_max_records): <p>The maximum number of instances to return with this call. The maximum value is <code>50</code>.</p>
    ///   - [`next_token(impl Into<String>)`](crate::client::fluent_builders::DescribeWarmPool::next_token) / [`set_next_token(Option<String>)`](crate::client::fluent_builders::DescribeWarmPool::set_next_token): <p>The token for the next set of instances to return. (You received this token from a previous call.)</p>
    /// - On success, responds with [`DescribeWarmPoolOutput`](crate::output::DescribeWarmPoolOutput) with field(s):
    ///   - [`warm_pool_configuration(Option<WarmPoolConfiguration>)`](crate::output::DescribeWarmPoolOutput::warm_pool_configuration): <p>The warm pool configuration details. </p>
    ///   - [`instances(Option<Vec<Instance>>)`](crate::output::DescribeWarmPoolOutput::instances): <p>The instances that are currently in the warm pool.</p>
    ///   - [`next_token(Option<String>)`](crate::output::DescribeWarmPoolOutput::next_token): <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
    /// - On failure, responds with [`SdkError<DescribeWarmPoolError>`](crate::error::DescribeWarmPoolError)
    pub fn describe_warm_pool(&self) -> fluent_builders::DescribeWarmPool {
        fluent_builders::DescribeWarmPool::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DetachInstances`](crate::client::fluent_builders::DetachInstances) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`instance_ids(Vec<String>)`](crate::client::fluent_builders::DetachInstances::instance_ids) / [`set_instance_ids(Option<Vec<String>>)`](crate::client::fluent_builders::DetachInstances::set_instance_ids): <p>The IDs of the instances. You can specify up to 20 instances.</p>
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DetachInstances::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DetachInstances::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`should_decrement_desired_capacity(bool)`](crate::client::fluent_builders::DetachInstances::should_decrement_desired_capacity) / [`set_should_decrement_desired_capacity(Option<bool>)`](crate::client::fluent_builders::DetachInstances::set_should_decrement_desired_capacity): <p>Indicates whether the Auto Scaling group decrements the desired capacity value by the number of instances detached.</p>
    /// - On success, responds with [`DetachInstancesOutput`](crate::output::DetachInstancesOutput) with field(s):
    ///   - [`activities(Option<Vec<Activity>>)`](crate::output::DetachInstancesOutput::activities): <p>The activities related to detaching the instances from the Auto Scaling group.</p>
    /// - On failure, responds with [`SdkError<DetachInstancesError>`](crate::error::DetachInstancesError)
    pub fn detach_instances(&self) -> fluent_builders::DetachInstances {
        fluent_builders::DetachInstances::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DetachLoadBalancers`](crate::client::fluent_builders::DetachLoadBalancers) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DetachLoadBalancers::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DetachLoadBalancers::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`load_balancer_names(Vec<String>)`](crate::client::fluent_builders::DetachLoadBalancers::load_balancer_names) / [`set_load_balancer_names(Option<Vec<String>>)`](crate::client::fluent_builders::DetachLoadBalancers::set_load_balancer_names): <p>The names of the load balancers. You can specify up to 10 load balancers.</p>
    /// - On success, responds with [`DetachLoadBalancersOutput`](crate::output::DetachLoadBalancersOutput)

    /// - On failure, responds with [`SdkError<DetachLoadBalancersError>`](crate::error::DetachLoadBalancersError)
    pub fn detach_load_balancers(&self) -> fluent_builders::DetachLoadBalancers {
        fluent_builders::DetachLoadBalancers::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DetachLoadBalancerTargetGroups`](crate::client::fluent_builders::DetachLoadBalancerTargetGroups) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DetachLoadBalancerTargetGroups::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DetachLoadBalancerTargetGroups::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`target_group_ar_ns(Vec<String>)`](crate::client::fluent_builders::DetachLoadBalancerTargetGroups::target_group_ar_ns) / [`set_target_group_ar_ns(Option<Vec<String>>)`](crate::client::fluent_builders::DetachLoadBalancerTargetGroups::set_target_group_ar_ns): <p>The Amazon Resource Names (ARN) of the target groups. You can specify up to 10 target groups.</p>
    /// - On success, responds with [`DetachLoadBalancerTargetGroupsOutput`](crate::output::DetachLoadBalancerTargetGroupsOutput)

    /// - On failure, responds with [`SdkError<DetachLoadBalancerTargetGroupsError>`](crate::error::DetachLoadBalancerTargetGroupsError)
    pub fn detach_load_balancer_target_groups(
        &self,
    ) -> fluent_builders::DetachLoadBalancerTargetGroups {
        fluent_builders::DetachLoadBalancerTargetGroups::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`DisableMetricsCollection`](crate::client::fluent_builders::DisableMetricsCollection) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::DisableMetricsCollection::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::DisableMetricsCollection::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`metrics(Vec<String>)`](crate::client::fluent_builders::DisableMetricsCollection::metrics) / [`set_metrics(Option<Vec<String>>)`](crate::client::fluent_builders::DisableMetricsCollection::set_metrics): <p>Specifies one or more of the following metrics:</p>  <ul>   <li> <p> <code>GroupMinSize</code> </p> </li>   <li> <p> <code>GroupMaxSize</code> </p> </li>   <li> <p> <code>GroupDesiredCapacity</code> </p> </li>   <li> <p> <code>GroupInServiceInstances</code> </p> </li>   <li> <p> <code>GroupPendingInstances</code> </p> </li>   <li> <p> <code>GroupStandbyInstances</code> </p> </li>   <li> <p> <code>GroupTerminatingInstances</code> </p> </li>   <li> <p> <code>GroupTotalInstances</code> </p> </li>   <li> <p> <code>GroupInServiceCapacity</code> </p> </li>   <li> <p> <code>GroupPendingCapacity</code> </p> </li>   <li> <p> <code>GroupStandbyCapacity</code> </p> </li>   <li> <p> <code>GroupTerminatingCapacity</code> </p> </li>   <li> <p> <code>GroupTotalCapacity</code> </p> </li>   <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li>   <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li>   <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li>   <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li>   <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li>   <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li>   <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li>  </ul>  <p>If you omit this parameter, all metrics are disabled. </p>
    /// - On success, responds with [`DisableMetricsCollectionOutput`](crate::output::DisableMetricsCollectionOutput)

    /// - On failure, responds with [`SdkError<DisableMetricsCollectionError>`](crate::error::DisableMetricsCollectionError)
    pub fn disable_metrics_collection(&self) -> fluent_builders::DisableMetricsCollection {
        fluent_builders::DisableMetricsCollection::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`EnableMetricsCollection`](crate::client::fluent_builders::EnableMetricsCollection) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::EnableMetricsCollection::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::EnableMetricsCollection::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`metrics(Vec<String>)`](crate::client::fluent_builders::EnableMetricsCollection::metrics) / [`set_metrics(Option<Vec<String>>)`](crate::client::fluent_builders::EnableMetricsCollection::set_metrics): <p>Specifies which group-level metrics to start collecting. You can specify one or more of the following metrics:</p>  <ul>   <li> <p> <code>GroupMinSize</code> </p> </li>   <li> <p> <code>GroupMaxSize</code> </p> </li>   <li> <p> <code>GroupDesiredCapacity</code> </p> </li>   <li> <p> <code>GroupInServiceInstances</code> </p> </li>   <li> <p> <code>GroupPendingInstances</code> </p> </li>   <li> <p> <code>GroupStandbyInstances</code> </p> </li>   <li> <p> <code>GroupTerminatingInstances</code> </p> </li>   <li> <p> <code>GroupTotalInstances</code> </p> </li>  </ul>  <p>The instance weighting feature supports the following additional metrics: </p>  <ul>   <li> <p> <code>GroupInServiceCapacity</code> </p> </li>   <li> <p> <code>GroupPendingCapacity</code> </p> </li>   <li> <p> <code>GroupStandbyCapacity</code> </p> </li>   <li> <p> <code>GroupTerminatingCapacity</code> </p> </li>   <li> <p> <code>GroupTotalCapacity</code> </p> </li>  </ul>  <p>The warm pools feature supports the following additional metrics: </p>  <ul>   <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li>   <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li>   <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li>   <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li>   <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li>   <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li>   <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li>  </ul>  <p>If you omit this parameter, all metrics are enabled. </p>
    ///   - [`granularity(impl Into<String>)`](crate::client::fluent_builders::EnableMetricsCollection::granularity) / [`set_granularity(Option<String>)`](crate::client::fluent_builders::EnableMetricsCollection::set_granularity): <p>The granularity to associate with the metrics to collect. The only valid value is <code>1Minute</code>.</p>
    /// - On success, responds with [`EnableMetricsCollectionOutput`](crate::output::EnableMetricsCollectionOutput)

    /// - On failure, responds with [`SdkError<EnableMetricsCollectionError>`](crate::error::EnableMetricsCollectionError)
    pub fn enable_metrics_collection(&self) -> fluent_builders::EnableMetricsCollection {
        fluent_builders::EnableMetricsCollection::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`EnterStandby`](crate::client::fluent_builders::EnterStandby) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`instance_ids(Vec<String>)`](crate::client::fluent_builders::EnterStandby::instance_ids) / [`set_instance_ids(Option<Vec<String>>)`](crate::client::fluent_builders::EnterStandby::set_instance_ids): <p>The IDs of the instances. You can specify up to 20 instances.</p>
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::EnterStandby::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::EnterStandby::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`should_decrement_desired_capacity(bool)`](crate::client::fluent_builders::EnterStandby::should_decrement_desired_capacity) / [`set_should_decrement_desired_capacity(Option<bool>)`](crate::client::fluent_builders::EnterStandby::set_should_decrement_desired_capacity): <p>Indicates whether to decrement the desired capacity of the Auto Scaling group by the number of instances moved to <code>Standby</code> mode.</p>
    /// - On success, responds with [`EnterStandbyOutput`](crate::output::EnterStandbyOutput) with field(s):
    ///   - [`activities(Option<Vec<Activity>>)`](crate::output::EnterStandbyOutput::activities): <p>The activities related to moving instances into <code>Standby</code> mode.</p>
    /// - On failure, responds with [`SdkError<EnterStandbyError>`](crate::error::EnterStandbyError)
    pub fn enter_standby(&self) -> fluent_builders::EnterStandby {
        fluent_builders::EnterStandby::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`ExecutePolicy`](crate::client::fluent_builders::ExecutePolicy) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::ExecutePolicy::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::ExecutePolicy::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`policy_name(impl Into<String>)`](crate::client::fluent_builders::ExecutePolicy::policy_name) / [`set_policy_name(Option<String>)`](crate::client::fluent_builders::ExecutePolicy::set_policy_name): <p>The name or ARN of the policy.</p>
    ///   - [`honor_cooldown(bool)`](crate::client::fluent_builders::ExecutePolicy::honor_cooldown) / [`set_honor_cooldown(Option<bool>)`](crate::client::fluent_builders::ExecutePolicy::set_honor_cooldown): <p>Indicates whether Amazon EC2 Auto Scaling waits for the cooldown period to complete before executing the policy.</p>  <p>Valid only if the policy type is <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`metric_value(f64)`](crate::client::fluent_builders::ExecutePolicy::metric_value) / [`set_metric_value(Option<f64>)`](crate::client::fluent_builders::ExecutePolicy::set_metric_value): <p>The metric value to compare to <code>BreachThreshold</code>. This enables you to execute a policy of type <code>StepScaling</code> and determine which step adjustment to use. For example, if the breach threshold is 50 and you want to use a step adjustment with a lower bound of 0 and an upper bound of 10, you can set the metric value to 59.</p>  <p>If you specify a metric value that doesn't correspond to a step adjustment for the policy, the call returns an error.</p>  <p>Required if the policy type is <code>StepScaling</code> and not supported otherwise.</p>
    ///   - [`breach_threshold(f64)`](crate::client::fluent_builders::ExecutePolicy::breach_threshold) / [`set_breach_threshold(Option<f64>)`](crate::client::fluent_builders::ExecutePolicy::set_breach_threshold): <p>The breach threshold for the alarm.</p>  <p>Required if the policy type is <code>StepScaling</code> and not supported otherwise.</p>
    /// - On success, responds with [`ExecutePolicyOutput`](crate::output::ExecutePolicyOutput)

    /// - On failure, responds with [`SdkError<ExecutePolicyError>`](crate::error::ExecutePolicyError)
    pub fn execute_policy(&self) -> fluent_builders::ExecutePolicy {
        fluent_builders::ExecutePolicy::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`ExitStandby`](crate::client::fluent_builders::ExitStandby) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`instance_ids(Vec<String>)`](crate::client::fluent_builders::ExitStandby::instance_ids) / [`set_instance_ids(Option<Vec<String>>)`](crate::client::fluent_builders::ExitStandby::set_instance_ids): <p>The IDs of the instances. You can specify up to 20 instances.</p>
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::ExitStandby::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::ExitStandby::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    /// - On success, responds with [`ExitStandbyOutput`](crate::output::ExitStandbyOutput) with field(s):
    ///   - [`activities(Option<Vec<Activity>>)`](crate::output::ExitStandbyOutput::activities): <p>The activities related to moving instances out of <code>Standby</code> mode.</p>
    /// - On failure, responds with [`SdkError<ExitStandbyError>`](crate::error::ExitStandbyError)
    pub fn exit_standby(&self) -> fluent_builders::ExitStandby {
        fluent_builders::ExitStandby::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`GetPredictiveScalingForecast`](crate::client::fluent_builders::GetPredictiveScalingForecast) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::GetPredictiveScalingForecast::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::GetPredictiveScalingForecast::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`policy_name(impl Into<String>)`](crate::client::fluent_builders::GetPredictiveScalingForecast::policy_name) / [`set_policy_name(Option<String>)`](crate::client::fluent_builders::GetPredictiveScalingForecast::set_policy_name): <p>The name of the policy.</p>
    ///   - [`start_time(DateTime)`](crate::client::fluent_builders::GetPredictiveScalingForecast::start_time) / [`set_start_time(Option<DateTime>)`](crate::client::fluent_builders::GetPredictiveScalingForecast::set_start_time): <p>The inclusive start time of the time range for the forecast data to get. At most, the date and time can be one year before the current date and time.</p>
    ///   - [`end_time(DateTime)`](crate::client::fluent_builders::GetPredictiveScalingForecast::end_time) / [`set_end_time(Option<DateTime>)`](crate::client::fluent_builders::GetPredictiveScalingForecast::set_end_time): <p>The exclusive end time of the time range for the forecast data to get. The maximum time duration between the start and end time is 30 days. </p>  <p>Although this parameter can accept a date and time that is more than two days in the future, the availability of forecast data has limits. Amazon EC2 Auto Scaling only issues forecasts for periods of two days in advance.</p>
    /// - On success, responds with [`GetPredictiveScalingForecastOutput`](crate::output::GetPredictiveScalingForecastOutput) with field(s):
    ///   - [`load_forecast(Option<Vec<LoadForecast>>)`](crate::output::GetPredictiveScalingForecastOutput::load_forecast): <p>The load forecast.</p>
    ///   - [`capacity_forecast(Option<CapacityForecast>)`](crate::output::GetPredictiveScalingForecastOutput::capacity_forecast): <p>The capacity forecast.</p>
    ///   - [`update_time(Option<DateTime>)`](crate::output::GetPredictiveScalingForecastOutput::update_time): <p>The time the forecast was made.</p>
    /// - On failure, responds with [`SdkError<GetPredictiveScalingForecastError>`](crate::error::GetPredictiveScalingForecastError)
    pub fn get_predictive_scaling_forecast(&self) -> fluent_builders::GetPredictiveScalingForecast {
        fluent_builders::GetPredictiveScalingForecast::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`PutLifecycleHook`](crate::client::fluent_builders::PutLifecycleHook) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`lifecycle_hook_name(impl Into<String>)`](crate::client::fluent_builders::PutLifecycleHook::lifecycle_hook_name) / [`set_lifecycle_hook_name(Option<String>)`](crate::client::fluent_builders::PutLifecycleHook::set_lifecycle_hook_name): <p>The name of the lifecycle hook.</p>
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::PutLifecycleHook::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::PutLifecycleHook::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`lifecycle_transition(impl Into<String>)`](crate::client::fluent_builders::PutLifecycleHook::lifecycle_transition) / [`set_lifecycle_transition(Option<String>)`](crate::client::fluent_builders::PutLifecycleHook::set_lifecycle_transition): <p>The instance state to which you want to attach the lifecycle hook. The valid values are:</p>  <ul>   <li> <p>autoscaling:EC2_INSTANCE_LAUNCHING</p> </li>   <li> <p>autoscaling:EC2_INSTANCE_TERMINATING</p> </li>  </ul>  <p>Required for new lifecycle hooks, but optional when updating existing hooks.</p>
    ///   - [`role_arn(impl Into<String>)`](crate::client::fluent_builders::PutLifecycleHook::role_arn) / [`set_role_arn(Option<String>)`](crate::client::fluent_builders::PutLifecycleHook::set_role_arn): <p>The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target.</p>  <p>Valid only if the notification target is an Amazon SNS topic or an Amazon SQS queue. Required for new lifecycle hooks, but optional when updating existing hooks.</p>
    ///   - [`notification_target_arn(impl Into<String>)`](crate::client::fluent_builders::PutLifecycleHook::notification_target_arn) / [`set_notification_target_arn(Option<String>)`](crate::client::fluent_builders::PutLifecycleHook::set_notification_target_arn): <p>The ARN of the notification target that Amazon EC2 Auto Scaling uses to notify you when an instance is in the transition state for the lifecycle hook. This target can be either an SQS queue or an SNS topic.</p>  <p>If you specify an empty string, this overrides the current ARN.</p>  <p>This operation uses the JSON format when sending notifications to an Amazon SQS queue, and an email key-value pair format when sending notifications to an Amazon SNS topic.</p>  <p>When you specify a notification target, Amazon EC2 Auto Scaling sends it a test message. Test messages contain the following additional key-value pair: <code>"Event": "autoscaling:TEST_NOTIFICATION"</code>.</p>
    ///   - [`notification_metadata(impl Into<String>)`](crate::client::fluent_builders::PutLifecycleHook::notification_metadata) / [`set_notification_metadata(Option<String>)`](crate::client::fluent_builders::PutLifecycleHook::set_notification_metadata): <p>Additional information that you want to include any time Amazon EC2 Auto Scaling sends a message to the notification target.</p>
    ///   - [`heartbeat_timeout(i32)`](crate::client::fluent_builders::PutLifecycleHook::heartbeat_timeout) / [`set_heartbeat_timeout(Option<i32>)`](crate::client::fluent_builders::PutLifecycleHook::set_heartbeat_timeout): <p>The maximum time, in seconds, that can elapse before the lifecycle hook times out. The range is from <code>30</code> to <code>7200</code> seconds. The default value is <code>3600</code> seconds (1 hour).</p>  <p>If the lifecycle hook times out, Amazon EC2 Auto Scaling performs the action that you specified in the <code>DefaultResult</code> parameter. You can prevent the lifecycle hook from timing out by calling the <code>RecordLifecycleActionHeartbeat</code> API.</p>
    ///   - [`default_result(impl Into<String>)`](crate::client::fluent_builders::PutLifecycleHook::default_result) / [`set_default_result(Option<String>)`](crate::client::fluent_builders::PutLifecycleHook::set_default_result): <p>Defines the action the Auto Scaling group should take when the lifecycle hook timeout elapses or if an unexpected failure occurs. This parameter can be either <code>CONTINUE</code> or <code>ABANDON</code>. The default value is <code>ABANDON</code>.</p>
    /// - On success, responds with [`PutLifecycleHookOutput`](crate::output::PutLifecycleHookOutput)

    /// - On failure, responds with [`SdkError<PutLifecycleHookError>`](crate::error::PutLifecycleHookError)
    pub fn put_lifecycle_hook(&self) -> fluent_builders::PutLifecycleHook {
        fluent_builders::PutLifecycleHook::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`PutNotificationConfiguration`](crate::client::fluent_builders::PutNotificationConfiguration) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::PutNotificationConfiguration::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::PutNotificationConfiguration::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`topic_arn(impl Into<String>)`](crate::client::fluent_builders::PutNotificationConfiguration::topic_arn) / [`set_topic_arn(Option<String>)`](crate::client::fluent_builders::PutNotificationConfiguration::set_topic_arn): <p>The Amazon Resource Name (ARN) of the Amazon SNS topic.</p>
    ///   - [`notification_types(Vec<String>)`](crate::client::fluent_builders::PutNotificationConfiguration::notification_types) / [`set_notification_types(Option<Vec<String>>)`](crate::client::fluent_builders::PutNotificationConfiguration::set_notification_types): <p>The type of event that causes the notification to be sent. To query the notification types supported by Amazon EC2 Auto Scaling, call the <code>DescribeAutoScalingNotificationTypes</code> API.</p>
    /// - On success, responds with [`PutNotificationConfigurationOutput`](crate::output::PutNotificationConfigurationOutput)

    /// - On failure, responds with [`SdkError<PutNotificationConfigurationError>`](crate::error::PutNotificationConfigurationError)
    pub fn put_notification_configuration(&self) -> fluent_builders::PutNotificationConfiguration {
        fluent_builders::PutNotificationConfiguration::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`PutScalingPolicy`](crate::client::fluent_builders::PutScalingPolicy) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::PutScalingPolicy::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::PutScalingPolicy::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`policy_name(impl Into<String>)`](crate::client::fluent_builders::PutScalingPolicy::policy_name) / [`set_policy_name(Option<String>)`](crate::client::fluent_builders::PutScalingPolicy::set_policy_name): <p>The name of the policy.</p>
    ///   - [`policy_type(impl Into<String>)`](crate::client::fluent_builders::PutScalingPolicy::policy_type) / [`set_policy_type(Option<String>)`](crate::client::fluent_builders::PutScalingPolicy::set_policy_type): <p>One of the following policy types: </p>  <ul>   <li> <p> <code>TargetTrackingScaling</code> </p> </li>   <li> <p> <code>StepScaling</code> </p> </li>   <li> <p> <code>SimpleScaling</code> (default)</p> </li>   <li> <p> <code>PredictiveScaling</code> </p> </li>  </ul>
    ///   - [`adjustment_type(impl Into<String>)`](crate::client::fluent_builders::PutScalingPolicy::adjustment_type) / [`set_adjustment_type(Option<String>)`](crate::client::fluent_builders::PutScalingPolicy::set_adjustment_type): <p>Specifies how the scaling adjustment is interpreted (for example, an absolute number or a percentage). The valid values are <code>ChangeInCapacity</code>, <code>ExactCapacity</code>, and <code>PercentChangeInCapacity</code>.</p>  <p>Required if the policy type is <code>StepScaling</code> or <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-adjustment">Scaling adjustment types</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`min_adjustment_step(i32)`](crate::client::fluent_builders::PutScalingPolicy::min_adjustment_step) / [`set_min_adjustment_step(Option<i32>)`](crate::client::fluent_builders::PutScalingPolicy::set_min_adjustment_step): <p>Available for backward compatibility. Use <code>MinAdjustmentMagnitude</code> instead.</p>
    ///   - [`min_adjustment_magnitude(i32)`](crate::client::fluent_builders::PutScalingPolicy::min_adjustment_magnitude) / [`set_min_adjustment_magnitude(Option<i32>)`](crate::client::fluent_builders::PutScalingPolicy::set_min_adjustment_magnitude): <p>The minimum value to scale by when the adjustment type is <code>PercentChangeInCapacity</code>. For example, suppose that you create a step scaling policy to scale out an Auto Scaling group by 25 percent and you specify a <code>MinAdjustmentMagnitude</code> of 2. If the group has 4 instances and the scaling policy is performed, 25 percent of 4 is 1. However, because you specified a <code>MinAdjustmentMagnitude</code> of 2, Amazon EC2 Auto Scaling scales out the group by 2 instances.</p>  <p>Valid only if the policy type is <code>StepScaling</code> or <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-adjustment">Scaling adjustment types</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <note>   <p>Some Auto Scaling groups use instance weights. In this case, set the <code>MinAdjustmentMagnitude</code> to a value that is at least as large as your largest instance weight.</p>  </note>
    ///   - [`scaling_adjustment(i32)`](crate::client::fluent_builders::PutScalingPolicy::scaling_adjustment) / [`set_scaling_adjustment(Option<i32>)`](crate::client::fluent_builders::PutScalingPolicy::set_scaling_adjustment): <p>The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity. For exact capacity, you must specify a positive value.</p>  <p>Required if the policy type is <code>SimpleScaling</code>. (Not used with any other policy type.) </p>
    ///   - [`cooldown(i32)`](crate::client::fluent_builders::PutScalingPolicy::cooldown) / [`set_cooldown(Option<i32>)`](crate::client::fluent_builders::PutScalingPolicy::set_cooldown): <p>A cooldown period, in seconds, that applies to a specific simple scaling policy. When a cooldown period is specified here, it overrides the default cooldown.</p>  <p>Valid only if the policy type is <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>  <p>Default: None</p>
    ///   - [`metric_aggregation_type(impl Into<String>)`](crate::client::fluent_builders::PutScalingPolicy::metric_aggregation_type) / [`set_metric_aggregation_type(Option<String>)`](crate::client::fluent_builders::PutScalingPolicy::set_metric_aggregation_type): <p>The aggregation type for the CloudWatch metrics. The valid values are <code>Minimum</code>, <code>Maximum</code>, and <code>Average</code>. If the aggregation type is null, the value is treated as <code>Average</code>.</p>  <p>Valid only if the policy type is <code>StepScaling</code>.</p>
    ///   - [`step_adjustments(Vec<StepAdjustment>)`](crate::client::fluent_builders::PutScalingPolicy::step_adjustments) / [`set_step_adjustments(Option<Vec<StepAdjustment>>)`](crate::client::fluent_builders::PutScalingPolicy::set_step_adjustments): <p>A set of adjustments that enable you to scale based on the size of the alarm breach.</p>  <p>Required if the policy type is <code>StepScaling</code>. (Not used with any other policy type.) </p>
    ///   - [`estimated_instance_warmup(i32)`](crate::client::fluent_builders::PutScalingPolicy::estimated_instance_warmup) / [`set_estimated_instance_warmup(Option<i32>)`](crate::client::fluent_builders::PutScalingPolicy::set_estimated_instance_warmup): <p> <i>Not needed if the default instance warmup is defined for the group.</i> </p>  <p>The estimated time, in seconds, until a newly launched instance can contribute to the CloudWatch metrics. This warm-up period applies to instances launched due to a specific target tracking or step scaling policy. When a warm-up period is specified here, it overrides the default instance warmup.</p>  <p>Valid only if the policy type is <code>TargetTrackingScaling</code> or <code>StepScaling</code>.</p> <note>   <p>The default is to use the value for the default instance warmup defined for the group. If default instance warmup is null, then <code>EstimatedInstanceWarmup</code> falls back to the value of default cooldown.</p>  </note>
    ///   - [`target_tracking_configuration(TargetTrackingConfiguration)`](crate::client::fluent_builders::PutScalingPolicy::target_tracking_configuration) / [`set_target_tracking_configuration(Option<TargetTrackingConfiguration>)`](crate::client::fluent_builders::PutScalingPolicy::set_target_tracking_configuration): <p>A target tracking scaling policy. Provides support for predefined or custom metrics.</p>  <p>The following predefined metrics are available:</p>  <ul>   <li> <p> <code>ASGAverageCPUUtilization</code> </p> </li>   <li> <p> <code>ASGAverageNetworkIn</code> </p> </li>   <li> <p> <code>ASGAverageNetworkOut</code> </p> </li>   <li> <p> <code>ALBRequestCountPerTarget</code> </p> </li>  </ul>  <p>If you specify <code>ALBRequestCountPerTarget</code> for the metric, you must specify the <code>ResourceLabel</code> parameter with the <code>PredefinedMetricSpecification</code>.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_TargetTrackingConfiguration.html">TargetTrackingConfiguration</a> in the <i>Amazon EC2 Auto Scaling API Reference</i>.</p>  <p>Required if the policy type is <code>TargetTrackingScaling</code>.</p>
    ///   - [`enabled(bool)`](crate::client::fluent_builders::PutScalingPolicy::enabled) / [`set_enabled(Option<bool>)`](crate::client::fluent_builders::PutScalingPolicy::set_enabled): <p>Indicates whether the scaling policy is enabled or disabled. The default is enabled. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-enable-disable-scaling-policy.html">Disabling a scaling policy for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`predictive_scaling_configuration(PredictiveScalingConfiguration)`](crate::client::fluent_builders::PutScalingPolicy::predictive_scaling_configuration) / [`set_predictive_scaling_configuration(Option<PredictiveScalingConfiguration>)`](crate::client::fluent_builders::PutScalingPolicy::set_predictive_scaling_configuration): <p>A predictive scaling policy. Provides support for predefined and custom metrics.</p>  <p>Predefined metrics include CPU utilization, network in/out, and the Application Load Balancer request count.</p>  <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_PredictiveScalingConfiguration.html">PredictiveScalingConfiguration</a> in the <i>Amazon EC2 Auto Scaling API Reference</i>.</p>  <p>Required if the policy type is <code>PredictiveScaling</code>.</p>
    /// - On success, responds with [`PutScalingPolicyOutput`](crate::output::PutScalingPolicyOutput) with field(s):
    ///   - [`policy_arn(Option<String>)`](crate::output::PutScalingPolicyOutput::policy_arn): <p>The Amazon Resource Name (ARN) of the policy.</p>
    ///   - [`alarms(Option<Vec<Alarm>>)`](crate::output::PutScalingPolicyOutput::alarms): <p>The CloudWatch alarms created for the target tracking scaling policy.</p>
    /// - On failure, responds with [`SdkError<PutScalingPolicyError>`](crate::error::PutScalingPolicyError)
    pub fn put_scaling_policy(&self) -> fluent_builders::PutScalingPolicy {
        fluent_builders::PutScalingPolicy::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`PutScheduledUpdateGroupAction`](crate::client::fluent_builders::PutScheduledUpdateGroupAction) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`scheduled_action_name(impl Into<String>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::scheduled_action_name) / [`set_scheduled_action_name(Option<String>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::set_scheduled_action_name): <p>The name of this scaling action.</p>
    ///   - [`time(DateTime)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::time) / [`set_time(Option<DateTime>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::set_time): <p>This parameter is no longer used.</p>
    ///   - [`start_time(DateTime)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::start_time) / [`set_start_time(Option<DateTime>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::set_start_time): <p>The date and time for this action to start, in YYYY-MM-DDThh:mm:ssZ format in UTC/GMT only and in quotes (for example, <code>"2019-06-01T00:00:00Z"</code>).</p>  <p>If you specify <code>Recurrence</code> and <code>StartTime</code>, Amazon EC2 Auto Scaling performs the action at this time, and then performs the action based on the specified recurrence.</p>  <p>If you try to schedule your action in the past, Amazon EC2 Auto Scaling returns an error message.</p>
    ///   - [`end_time(DateTime)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::end_time) / [`set_end_time(Option<DateTime>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::set_end_time): <p>The date and time for the recurring schedule to end, in UTC.</p>
    ///   - [`recurrence(impl Into<String>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::recurrence) / [`set_recurrence(Option<String>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::set_recurrence): <p>The recurring schedule for this action. This format consists of five fields separated by white spaces: [Minute] [Hour] [Day_of_Month] [Month_of_Year] [Day_of_Week]. The value must be in quotes (for example, <code>"30 0 1 1,6,12 *"</code>). For more information about this format, see <a href="http://crontab.org">Crontab</a>.</p>  <p>When <code>StartTime</code> and <code>EndTime</code> are specified with <code>Recurrence</code>, they form the boundaries of when the recurring action starts and stops.</p>  <p>Cron expressions use Universal Coordinated Time (UTC) by default.</p>
    ///   - [`min_size(i32)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::min_size) / [`set_min_size(Option<i32>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::set_min_size): <p>The minimum size of the Auto Scaling group.</p>
    ///   - [`max_size(i32)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::max_size) / [`set_max_size(Option<i32>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::set_max_size): <p>The maximum size of the Auto Scaling group.</p>
    ///   - [`desired_capacity(i32)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::desired_capacity) / [`set_desired_capacity(Option<i32>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::set_desired_capacity): <p>The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain. It can scale beyond this capacity if you add more scaling conditions. </p>
    ///   - [`time_zone(impl Into<String>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::time_zone) / [`set_time_zone(Option<String>)`](crate::client::fluent_builders::PutScheduledUpdateGroupAction::set_time_zone): <p>Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. </p>  <p>Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as <code>Etc/GMT+9</code> or <code>Pacific/Tahiti</code>). For more information, see <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">https://en.wikipedia.org/wiki/List_of_tz_database_time_zones</a>.</p>
    /// - On success, responds with [`PutScheduledUpdateGroupActionOutput`](crate::output::PutScheduledUpdateGroupActionOutput)

    /// - On failure, responds with [`SdkError<PutScheduledUpdateGroupActionError>`](crate::error::PutScheduledUpdateGroupActionError)
    pub fn put_scheduled_update_group_action(
        &self,
    ) -> fluent_builders::PutScheduledUpdateGroupAction {
        fluent_builders::PutScheduledUpdateGroupAction::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`PutWarmPool`](crate::client::fluent_builders::PutWarmPool) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::PutWarmPool::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::PutWarmPool::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`max_group_prepared_capacity(i32)`](crate::client::fluent_builders::PutWarmPool::max_group_prepared_capacity) / [`set_max_group_prepared_capacity(Option<i32>)`](crate::client::fluent_builders::PutWarmPool::set_max_group_prepared_capacity): <p>Specifies the maximum number of instances that are allowed to be in the warm pool or in any state except <code>Terminated</code> for the Auto Scaling group. This is an optional property. Specify it only if you do not want the warm pool size to be determined by the difference between the group's maximum capacity and its desired capacity. </p> <important>   <p>If a value for <code>MaxGroupPreparedCapacity</code> is not specified, Amazon EC2 Auto Scaling launches and maintains the difference between the group's maximum capacity and its desired capacity. If you specify a value for <code>MaxGroupPreparedCapacity</code>, Amazon EC2 Auto Scaling uses the difference between the <code>MaxGroupPreparedCapacity</code> and the desired capacity instead. </p>   <p>The size of the warm pool is dynamic. Only when <code>MaxGroupPreparedCapacity</code> and <code>MinSize</code> are set to the same value does the warm pool have an absolute size.</p>  </important>  <p>If the desired capacity of the Auto Scaling group is higher than the <code>MaxGroupPreparedCapacity</code>, the capacity of the warm pool is 0, unless you specify a value for <code>MinSize</code>. To remove a value that you previously set, include the property but specify -1 for the value. </p>
    ///   - [`min_size(i32)`](crate::client::fluent_builders::PutWarmPool::min_size) / [`set_min_size(Option<i32>)`](crate::client::fluent_builders::PutWarmPool::set_min_size): <p>Specifies the minimum number of instances to maintain in the warm pool. This helps you to ensure that there is always a certain number of warmed instances available to handle traffic spikes. Defaults to 0 if not specified.</p>
    ///   - [`pool_state(WarmPoolState)`](crate::client::fluent_builders::PutWarmPool::pool_state) / [`set_pool_state(Option<WarmPoolState>)`](crate::client::fluent_builders::PutWarmPool::set_pool_state): <p>Sets the instance state to transition to after the lifecycle actions are complete. Default is <code>Stopped</code>.</p>
    ///   - [`instance_reuse_policy(InstanceReusePolicy)`](crate::client::fluent_builders::PutWarmPool::instance_reuse_policy) / [`set_instance_reuse_policy(Option<InstanceReusePolicy>)`](crate::client::fluent_builders::PutWarmPool::set_instance_reuse_policy): <p>Indicates whether instances in the Auto Scaling group can be returned to the warm pool on scale in. The default is to terminate instances in the Auto Scaling group when the group scales in.</p>
    /// - On success, responds with [`PutWarmPoolOutput`](crate::output::PutWarmPoolOutput)

    /// - On failure, responds with [`SdkError<PutWarmPoolError>`](crate::error::PutWarmPoolError)
    pub fn put_warm_pool(&self) -> fluent_builders::PutWarmPool {
        fluent_builders::PutWarmPool::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`RecordLifecycleActionHeartbeat`](crate::client::fluent_builders::RecordLifecycleActionHeartbeat) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`lifecycle_hook_name(impl Into<String>)`](crate::client::fluent_builders::RecordLifecycleActionHeartbeat::lifecycle_hook_name) / [`set_lifecycle_hook_name(Option<String>)`](crate::client::fluent_builders::RecordLifecycleActionHeartbeat::set_lifecycle_hook_name): <p>The name of the lifecycle hook.</p>
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::RecordLifecycleActionHeartbeat::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::RecordLifecycleActionHeartbeat::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`lifecycle_action_token(impl Into<String>)`](crate::client::fluent_builders::RecordLifecycleActionHeartbeat::lifecycle_action_token) / [`set_lifecycle_action_token(Option<String>)`](crate::client::fluent_builders::RecordLifecycleActionHeartbeat::set_lifecycle_action_token): <p>A token that uniquely identifies a specific lifecycle action associated with an instance. Amazon EC2 Auto Scaling sends this token to the notification target that you specified when you created the lifecycle hook.</p>
    ///   - [`instance_id(impl Into<String>)`](crate::client::fluent_builders::RecordLifecycleActionHeartbeat::instance_id) / [`set_instance_id(Option<String>)`](crate::client::fluent_builders::RecordLifecycleActionHeartbeat::set_instance_id): <p>The ID of the instance.</p>
    /// - On success, responds with [`RecordLifecycleActionHeartbeatOutput`](crate::output::RecordLifecycleActionHeartbeatOutput)

    /// - On failure, responds with [`SdkError<RecordLifecycleActionHeartbeatError>`](crate::error::RecordLifecycleActionHeartbeatError)
    pub fn record_lifecycle_action_heartbeat(
        &self,
    ) -> fluent_builders::RecordLifecycleActionHeartbeat {
        fluent_builders::RecordLifecycleActionHeartbeat::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`ResumeProcesses`](crate::client::fluent_builders::ResumeProcesses) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::ResumeProcesses::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::ResumeProcesses::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`scaling_processes(Vec<String>)`](crate::client::fluent_builders::ResumeProcesses::scaling_processes) / [`set_scaling_processes(Option<Vec<String>>)`](crate::client::fluent_builders::ResumeProcesses::set_scaling_processes): <p>One or more of the following processes:</p>  <ul>   <li> <p> <code>Launch</code> </p> </li>   <li> <p> <code>Terminate</code> </p> </li>   <li> <p> <code>AddToLoadBalancer</code> </p> </li>   <li> <p> <code>AlarmNotification</code> </p> </li>   <li> <p> <code>AZRebalance</code> </p> </li>   <li> <p> <code>HealthCheck</code> </p> </li>   <li> <p> <code>InstanceRefresh</code> </p> </li>   <li> <p> <code>ReplaceUnhealthy</code> </p> </li>   <li> <p> <code>ScheduledActions</code> </p> </li>  </ul>  <p>If you omit this parameter, all processes are specified.</p>
    /// - On success, responds with [`ResumeProcessesOutput`](crate::output::ResumeProcessesOutput)

    /// - On failure, responds with [`SdkError<ResumeProcessesError>`](crate::error::ResumeProcessesError)
    pub fn resume_processes(&self) -> fluent_builders::ResumeProcesses {
        fluent_builders::ResumeProcesses::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`SetDesiredCapacity`](crate::client::fluent_builders::SetDesiredCapacity) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::SetDesiredCapacity::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::SetDesiredCapacity::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`desired_capacity(i32)`](crate::client::fluent_builders::SetDesiredCapacity::desired_capacity) / [`set_desired_capacity(Option<i32>)`](crate::client::fluent_builders::SetDesiredCapacity::set_desired_capacity): <p>The desired capacity is the initial capacity of the Auto Scaling group after this operation completes and the capacity it attempts to maintain.</p>
    ///   - [`honor_cooldown(bool)`](crate::client::fluent_builders::SetDesiredCapacity::honor_cooldown) / [`set_honor_cooldown(Option<bool>)`](crate::client::fluent_builders::SetDesiredCapacity::set_honor_cooldown): <p>Indicates whether Amazon EC2 Auto Scaling waits for the cooldown period to complete before initiating a scaling activity to set your Auto Scaling group to its new capacity. By default, Amazon EC2 Auto Scaling does not honor the cooldown period during manual scaling activities.</p>
    /// - On success, responds with [`SetDesiredCapacityOutput`](crate::output::SetDesiredCapacityOutput)

    /// - On failure, responds with [`SdkError<SetDesiredCapacityError>`](crate::error::SetDesiredCapacityError)
    pub fn set_desired_capacity(&self) -> fluent_builders::SetDesiredCapacity {
        fluent_builders::SetDesiredCapacity::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`SetInstanceHealth`](crate::client::fluent_builders::SetInstanceHealth) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`instance_id(impl Into<String>)`](crate::client::fluent_builders::SetInstanceHealth::instance_id) / [`set_instance_id(Option<String>)`](crate::client::fluent_builders::SetInstanceHealth::set_instance_id): <p>The ID of the instance.</p>
    ///   - [`health_status(impl Into<String>)`](crate::client::fluent_builders::SetInstanceHealth::health_status) / [`set_health_status(Option<String>)`](crate::client::fluent_builders::SetInstanceHealth::set_health_status): <p>The health status of the instance. Set to <code>Healthy</code> to have the instance remain in service. Set to <code>Unhealthy</code> to have the instance be out of service. Amazon EC2 Auto Scaling terminates and replaces the unhealthy instance.</p>
    ///   - [`should_respect_grace_period(bool)`](crate::client::fluent_builders::SetInstanceHealth::should_respect_grace_period) / [`set_should_respect_grace_period(Option<bool>)`](crate::client::fluent_builders::SetInstanceHealth::set_should_respect_grace_period): <p>If the Auto Scaling group of the specified instance has a <code>HealthCheckGracePeriod</code> specified for the group, by default, this call respects the grace period. Set this to <code>False</code>, to have the call not respect the grace period associated with the group.</p>  <p>For more information about the health check grace period, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_CreateAutoScalingGroup.html">CreateAutoScalingGroup</a> in the <i>Amazon EC2 Auto Scaling API Reference</i>.</p>
    /// - On success, responds with [`SetInstanceHealthOutput`](crate::output::SetInstanceHealthOutput)

    /// - On failure, responds with [`SdkError<SetInstanceHealthError>`](crate::error::SetInstanceHealthError)
    pub fn set_instance_health(&self) -> fluent_builders::SetInstanceHealth {
        fluent_builders::SetInstanceHealth::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`SetInstanceProtection`](crate::client::fluent_builders::SetInstanceProtection) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`instance_ids(Vec<String>)`](crate::client::fluent_builders::SetInstanceProtection::instance_ids) / [`set_instance_ids(Option<Vec<String>>)`](crate::client::fluent_builders::SetInstanceProtection::set_instance_ids): <p>One or more instance IDs. You can specify up to 50 instances.</p>
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::SetInstanceProtection::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::SetInstanceProtection::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`protected_from_scale_in(bool)`](crate::client::fluent_builders::SetInstanceProtection::protected_from_scale_in) / [`set_protected_from_scale_in(Option<bool>)`](crate::client::fluent_builders::SetInstanceProtection::set_protected_from_scale_in): <p>Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
    /// - On success, responds with [`SetInstanceProtectionOutput`](crate::output::SetInstanceProtectionOutput)

    /// - On failure, responds with [`SdkError<SetInstanceProtectionError>`](crate::error::SetInstanceProtectionError)
    pub fn set_instance_protection(&self) -> fluent_builders::SetInstanceProtection {
        fluent_builders::SetInstanceProtection::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`StartInstanceRefresh`](crate::client::fluent_builders::StartInstanceRefresh) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::StartInstanceRefresh::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::StartInstanceRefresh::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`strategy(RefreshStrategy)`](crate::client::fluent_builders::StartInstanceRefresh::strategy) / [`set_strategy(Option<RefreshStrategy>)`](crate::client::fluent_builders::StartInstanceRefresh::set_strategy): <p>The strategy to use for the instance refresh. The only valid value is <code>Rolling</code>.</p>  <p>A rolling update helps you update your instances gradually. A rolling update can fail due to failed health checks or if instances are on standby or are protected from scale in. If the rolling update process fails, any instances that are replaced are not rolled back to their previous configuration. </p>
    ///   - [`desired_configuration(DesiredConfiguration)`](crate::client::fluent_builders::StartInstanceRefresh::desired_configuration) / [`set_desired_configuration(Option<DesiredConfiguration>)`](crate::client::fluent_builders::StartInstanceRefresh::set_desired_configuration): <p>The desired configuration. For example, the desired configuration can specify a new launch template or a new version of the current launch template.</p>  <p>Once the instance refresh succeeds, Amazon EC2 Auto Scaling updates the settings of the Auto Scaling group to reflect the new desired configuration. </p> <note>   <p>When you specify a new launch template or a new version of the current launch template for your desired configuration, consider enabling the <code>SkipMatching</code> property in preferences. If it's enabled, Amazon EC2 Auto Scaling skips replacing instances that already use the specified launch template and version. This can help you reduce the number of replacements that are required to apply updates. </p>  </note>
    ///   - [`preferences(RefreshPreferences)`](crate::client::fluent_builders::StartInstanceRefresh::preferences) / [`set_preferences(Option<RefreshPreferences>)`](crate::client::fluent_builders::StartInstanceRefresh::set_preferences): <p>Set of preferences associated with the instance refresh request. If not provided, the default values are used.</p>
    /// - On success, responds with [`StartInstanceRefreshOutput`](crate::output::StartInstanceRefreshOutput) with field(s):
    ///   - [`instance_refresh_id(Option<String>)`](crate::output::StartInstanceRefreshOutput::instance_refresh_id): <p>A unique ID for tracking the progress of the request.</p>
    /// - On failure, responds with [`SdkError<StartInstanceRefreshError>`](crate::error::StartInstanceRefreshError)
    pub fn start_instance_refresh(&self) -> fluent_builders::StartInstanceRefresh {
        fluent_builders::StartInstanceRefresh::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`SuspendProcesses`](crate::client::fluent_builders::SuspendProcesses) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::SuspendProcesses::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::SuspendProcesses::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`scaling_processes(Vec<String>)`](crate::client::fluent_builders::SuspendProcesses::scaling_processes) / [`set_scaling_processes(Option<Vec<String>>)`](crate::client::fluent_builders::SuspendProcesses::set_scaling_processes): <p>One or more of the following processes:</p>  <ul>   <li> <p> <code>Launch</code> </p> </li>   <li> <p> <code>Terminate</code> </p> </li>   <li> <p> <code>AddToLoadBalancer</code> </p> </li>   <li> <p> <code>AlarmNotification</code> </p> </li>   <li> <p> <code>AZRebalance</code> </p> </li>   <li> <p> <code>HealthCheck</code> </p> </li>   <li> <p> <code>InstanceRefresh</code> </p> </li>   <li> <p> <code>ReplaceUnhealthy</code> </p> </li>   <li> <p> <code>ScheduledActions</code> </p> </li>  </ul>  <p>If you omit this parameter, all processes are specified.</p>
    /// - On success, responds with [`SuspendProcessesOutput`](crate::output::SuspendProcessesOutput)

    /// - On failure, responds with [`SdkError<SuspendProcessesError>`](crate::error::SuspendProcessesError)
    pub fn suspend_processes(&self) -> fluent_builders::SuspendProcesses {
        fluent_builders::SuspendProcesses::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`TerminateInstanceInAutoScalingGroup`](crate::client::fluent_builders::TerminateInstanceInAutoScalingGroup) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`instance_id(impl Into<String>)`](crate::client::fluent_builders::TerminateInstanceInAutoScalingGroup::instance_id) / [`set_instance_id(Option<String>)`](crate::client::fluent_builders::TerminateInstanceInAutoScalingGroup::set_instance_id): <p>The ID of the instance.</p>
    ///   - [`should_decrement_desired_capacity(bool)`](crate::client::fluent_builders::TerminateInstanceInAutoScalingGroup::should_decrement_desired_capacity) / [`set_should_decrement_desired_capacity(Option<bool>)`](crate::client::fluent_builders::TerminateInstanceInAutoScalingGroup::set_should_decrement_desired_capacity): <p>Indicates whether terminating the instance also decrements the size of the Auto Scaling group.</p>
    /// - On success, responds with [`TerminateInstanceInAutoScalingGroupOutput`](crate::output::TerminateInstanceInAutoScalingGroupOutput) with field(s):
    ///   - [`activity(Option<Activity>)`](crate::output::TerminateInstanceInAutoScalingGroupOutput::activity): <p>A scaling activity.</p>
    /// - On failure, responds with [`SdkError<TerminateInstanceInAutoScalingGroupError>`](crate::error::TerminateInstanceInAutoScalingGroupError)
    pub fn terminate_instance_in_auto_scaling_group(
        &self,
    ) -> fluent_builders::TerminateInstanceInAutoScalingGroup {
        fluent_builders::TerminateInstanceInAutoScalingGroup::new(self.handle.clone())
    }
    /// Constructs a fluent builder for the [`UpdateAutoScalingGroup`](crate::client::fluent_builders::UpdateAutoScalingGroup) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`auto_scaling_group_name(impl Into<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::auto_scaling_group_name) / [`set_auto_scaling_group_name(Option<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_auto_scaling_group_name): <p>The name of the Auto Scaling group.</p>
    ///   - [`launch_configuration_name(impl Into<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::launch_configuration_name) / [`set_launch_configuration_name(Option<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_launch_configuration_name): <p>The name of the launch configuration. If you specify <code>LaunchConfigurationName</code> in your update request, you can't specify <code>LaunchTemplate</code> or <code>MixedInstancesPolicy</code>.</p>
    ///   - [`launch_template(LaunchTemplateSpecification)`](crate::client::fluent_builders::UpdateAutoScalingGroup::launch_template) / [`set_launch_template(Option<LaunchTemplateSpecification>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_launch_template): <p>The launch template and version to use to specify the updates. If you specify <code>LaunchTemplate</code> in your update request, you can't specify <code>LaunchConfigurationName</code> or <code>MixedInstancesPolicy</code>.</p>
    ///   - [`mixed_instances_policy(MixedInstancesPolicy)`](crate::client::fluent_builders::UpdateAutoScalingGroup::mixed_instances_policy) / [`set_mixed_instances_policy(Option<MixedInstancesPolicy>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_mixed_instances_policy): <p>An embedded object that specifies a mixed instances policy. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html">Auto Scaling groups with multiple instance types and purchase options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`min_size(i32)`](crate::client::fluent_builders::UpdateAutoScalingGroup::min_size) / [`set_min_size(Option<i32>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_min_size): <p>The minimum size of the Auto Scaling group.</p>
    ///   - [`max_size(i32)`](crate::client::fluent_builders::UpdateAutoScalingGroup::max_size) / [`set_max_size(Option<i32>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_max_size): <p>The maximum size of the Auto Scaling group.</p> <note>   <p>With a mixed instances policy that uses instance weighting, Amazon EC2 Auto Scaling may need to go above <code>MaxSize</code> to meet your capacity requirements. In this event, Amazon EC2 Auto Scaling will never go above <code>MaxSize</code> by more than your largest instance weight (weights that define how many units each instance contributes to the desired capacity of the group).</p>  </note>
    ///   - [`desired_capacity(i32)`](crate::client::fluent_builders::UpdateAutoScalingGroup::desired_capacity) / [`set_desired_capacity(Option<i32>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_desired_capacity): <p>The desired capacity is the initial capacity of the Auto Scaling group after this operation completes and the capacity it attempts to maintain. This number must be greater than or equal to the minimum size of the group and less than or equal to the maximum size of the group.</p>
    ///   - [`default_cooldown(i32)`](crate::client::fluent_builders::UpdateAutoScalingGroup::default_cooldown) / [`set_default_cooldown(Option<i32>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_default_cooldown): <p> <i>Only needed if you use simple scaling policies.</i> </p>  <p>The amount of time, in seconds, between one scaling activity ending and another one starting due to simple scaling policies. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`availability_zones(Vec<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::availability_zones) / [`set_availability_zones(Option<Vec<String>>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_availability_zones): <p>One or more Availability Zones for the group.</p>
    ///   - [`health_check_type(impl Into<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::health_check_type) / [`set_health_check_type(Option<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_health_check_type): <p>The service to use for the health checks. The valid values are <code>EC2</code> and <code>ELB</code>. If you configure an Auto Scaling group to use <code>ELB</code> health checks, it considers the instance unhealthy if it fails either the EC2 status checks or the load balancer health checks.</p>
    ///   - [`health_check_grace_period(i32)`](crate::client::fluent_builders::UpdateAutoScalingGroup::health_check_grace_period) / [`set_health_check_grace_period(Option<i32>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_health_check_grace_period): <p>The amount of time, in seconds, that Amazon EC2 Auto Scaling waits before checking the health status of an EC2 instance that has come into service and marking it unhealthy due to a failed Elastic Load Balancing or custom health check. This is useful if your instances do not immediately pass these health checks after they enter the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html#health-check-grace-period">Health check grace period</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`placement_group(impl Into<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::placement_group) / [`set_placement_group(Option<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_placement_group): <p>The name of an existing placement group into which to launch your instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html">Placement groups</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> <note>   <p>A <i>cluster</i> placement group is a logical grouping of instances within a single Availability Zone. You cannot specify multiple Availability Zones and a cluster placement group. </p>  </note>
    ///   - [`vpc_zone_identifier(impl Into<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::vpc_zone_identifier) / [`set_vpc_zone_identifier(Option<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_vpc_zone_identifier): <p>A comma-separated list of subnet IDs for a virtual private cloud (VPC). If you specify <code>VPCZoneIdentifier</code> with <code>AvailabilityZones</code>, the subnets that you specify for this parameter must reside in those Availability Zones.</p>
    ///   - [`termination_policies(Vec<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::termination_policies) / [`set_termination_policies(Option<Vec<String>>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_termination_policies): <p>A policy or a list of policies that are used to select the instances to terminate. The policies are executed in the order that you list them. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html">Controlling which Auto Scaling instances terminate during scale in</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`new_instances_protected_from_scale_in(bool)`](crate::client::fluent_builders::UpdateAutoScalingGroup::new_instances_protected_from_scale_in) / [`set_new_instances_protected_from_scale_in(Option<bool>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_new_instances_protected_from_scale_in): <p>Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. For more information about preventing instances from terminating on scale in, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-instance-protection.html">Using instance scale-in protection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`service_linked_role_arn(impl Into<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::service_linked_role_arn) / [`set_service_linked_role_arn(Option<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_service_linked_role_arn): <p>The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services on your behalf. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-service-linked-role.html">Service-linked roles</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`max_instance_lifetime(i32)`](crate::client::fluent_builders::UpdateAutoScalingGroup::max_instance_lifetime) / [`set_max_instance_lifetime(Option<i32>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_max_instance_lifetime): <p>The maximum amount of time, in seconds, that an instance can be in service. The default is null. If specified, the value must be either 0 or a number equal to or greater than 86,400 seconds (1 day). To clear a previously set value, specify a new value of 0. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-max-instance-lifetime.html">Replacing Auto Scaling instances based on maximum instance lifetime</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`capacity_rebalance(bool)`](crate::client::fluent_builders::UpdateAutoScalingGroup::capacity_rebalance) / [`set_capacity_rebalance(Option<bool>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_capacity_rebalance): <p>Enables or disables Capacity Rebalancing. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html">Amazon EC2 Auto Scaling Capacity Rebalancing</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    ///   - [`context(impl Into<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::context) / [`set_context(Option<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_context): <p>Reserved.</p>
    ///   - [`desired_capacity_type(impl Into<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::desired_capacity_type) / [`set_desired_capacity_type(Option<String>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_desired_capacity_type): <p>The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports <code>DesiredCapacityType</code> for attribute-based instance type selection only. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-instance-type-requirements.html">Creating an Auto Scaling group using attribute-based instance type selection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>  <p>By default, Amazon EC2 Auto Scaling specifies <code>units</code>, which translates into number of instances.</p>  <p>Valid values: <code>units</code> | <code>vcpu</code> | <code>memory-mib</code> </p>
    ///   - [`default_instance_warmup(i32)`](crate::client::fluent_builders::UpdateAutoScalingGroup::default_instance_warmup) / [`set_default_instance_warmup(Option<i32>)`](crate::client::fluent_builders::UpdateAutoScalingGroup::set_default_instance_warmup): <p>The amount of time, in seconds, until a newly launched instance can contribute to the Amazon CloudWatch metrics. This delay lets an instance finish initializing before Amazon EC2 Auto Scaling aggregates instance metrics, resulting in more reliable usage data. Set this value equal to the amount of time that it takes for resource consumption to become stable after an instance reaches the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-default-instance-warmup.html">Set the default instance warmup for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <important>   <p>To manage your warm-up settings at the group level, we recommend that you set the default instance warmup, <i>even if its value is set to 0 seconds</i>. This also optimizes the performance of scaling policies that scale continuously, such as target tracking and step scaling policies. </p>   <p>If you need to remove a value that you previously set, include the property but specify <code>-1</code> for the value. However, we strongly recommend keeping the default instance warmup enabled by specifying a minimum value of <code>0</code>.</p>  </important>
    /// - On success, responds with [`UpdateAutoScalingGroupOutput`](crate::output::UpdateAutoScalingGroupOutput)

    /// - On failure, responds with [`SdkError<UpdateAutoScalingGroupError>`](crate::error::UpdateAutoScalingGroupError)
    pub fn update_auto_scaling_group(&self) -> fluent_builders::UpdateAutoScalingGroup {
        fluent_builders::UpdateAutoScalingGroup::new(self.handle.clone())
    }
}
pub mod fluent_builders {

    //! Utilities to ergonomically construct a request to the service.
    //!
    //! Fluent builders are created through the [`Client`](crate::client::Client) by calling
    //! one if its operation methods. After parameters are set using the builder methods,
    //! the `send` method can be called to initiate the request.
    /// Fluent builder constructing a request to `AttachInstances`.
    ///
    /// <p>Attaches one or more EC2 instances to the specified Auto Scaling group.</p>
    /// <p>When you attach instances, Amazon EC2 Auto Scaling increases the desired capacity of the group by the number of instances being attached. If the number of instances being attached plus the desired capacity of the group exceeds the maximum size of the group, the operation fails.</p>
    /// <p>If there is a Classic Load Balancer attached to your Auto Scaling group, the instances are also registered with the load balancer. If there are target groups attached to your Auto Scaling group, the instances are also registered with the target groups.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/attach-instance-asg.html">Attach EC2 instances to your Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct AttachInstances {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::attach_instances_input::Builder,
    }
    impl AttachInstances {
        /// Creates a new `AttachInstances`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::AttachInstancesOutput,
            aws_smithy_http::result::SdkError<crate::error::AttachInstancesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Appends an item to `InstanceIds`.
        ///
        /// To override the contents of this collection use [`set_instance_ids`](Self::set_instance_ids).
        ///
        /// <p>The IDs of the instances. You can specify up to 20 instances.</p>
        pub fn instance_ids(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_ids(input.into());
            self
        }
        /// <p>The IDs of the instances. You can specify up to 20 instances.</p>
        pub fn set_instance_ids(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_instance_ids(input);
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `AttachLoadBalancers`.
    ///
    /// <note>
    /// <p>To attach an Application Load Balancer, Network Load Balancer, or Gateway Load Balancer, use the <code>AttachLoadBalancerTargetGroups</code> API operation instead.</p>
    /// </note>
    /// <p>Attaches one or more Classic Load Balancers to the specified Auto Scaling group. Amazon EC2 Auto Scaling registers the running instances with these Classic Load Balancers.</p>
    /// <p>To describe the load balancers for an Auto Scaling group, call the <code>DescribeLoadBalancers</code> API. To detach the load balancer from the Auto Scaling group, call the <code>DetachLoadBalancers</code> API.</p>
    /// <p>This operation is additive and does not detach existing Classic Load Balancers or target groups from the Auto Scaling group.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html">Elastic Load Balancing and Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct AttachLoadBalancers {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::attach_load_balancers_input::Builder,
    }
    impl AttachLoadBalancers {
        /// Creates a new `AttachLoadBalancers`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::AttachLoadBalancersOutput,
            aws_smithy_http::result::SdkError<crate::error::AttachLoadBalancersError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `LoadBalancerNames`.
        ///
        /// To override the contents of this collection use [`set_load_balancer_names`](Self::set_load_balancer_names).
        ///
        /// <p>The names of the load balancers. You can specify up to 10 load balancers.</p>
        pub fn load_balancer_names(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.load_balancer_names(input.into());
            self
        }
        /// <p>The names of the load balancers. You can specify up to 10 load balancers.</p>
        pub fn set_load_balancer_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_load_balancer_names(input);
            self
        }
    }
    /// Fluent builder constructing a request to `AttachLoadBalancerTargetGroups`.
    ///
    /// <p>Attaches one or more target groups to the specified Auto Scaling group.</p>
    /// <p>This operation is used with the following load balancer types: </p>
    /// <ul>
    /// <li> <p> Application Load Balancer - Operates at the application layer (layer 7) and supports HTTP and HTTPS. </p> </li>
    /// <li> <p> Network Load Balancer - Operates at the transport layer (layer 4) and supports TCP, TLS, and UDP. </p> </li>
    /// <li> <p> Gateway Load Balancer - Operates at the network layer (layer 3).</p> </li>
    /// </ul>
    /// <p>To describe the target groups for an Auto Scaling group, call the <code>DescribeLoadBalancerTargetGroups</code> API. To detach the target group from the Auto Scaling group, call the <code>DetachLoadBalancerTargetGroups</code> API.</p>
    /// <p>This operation is additive and does not detach existing target groups or Classic Load Balancers from the Auto Scaling group.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html">Elastic Load Balancing and Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct AttachLoadBalancerTargetGroups {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::attach_load_balancer_target_groups_input::Builder,
    }
    impl AttachLoadBalancerTargetGroups {
        /// Creates a new `AttachLoadBalancerTargetGroups`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::AttachLoadBalancerTargetGroupsOutput,
            aws_smithy_http::result::SdkError<crate::error::AttachLoadBalancerTargetGroupsError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `TargetGroupARNs`.
        ///
        /// To override the contents of this collection use [`set_target_group_ar_ns`](Self::set_target_group_ar_ns).
        ///
        /// <p>The Amazon Resource Names (ARN) of the target groups. You can specify up to 10 target groups. To get the ARN of a target group, use the Elastic Load Balancing <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
        pub fn target_group_ar_ns(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.target_group_ar_ns(input.into());
            self
        }
        /// <p>The Amazon Resource Names (ARN) of the target groups. You can specify up to 10 target groups. To get the ARN of a target group, use the Elastic Load Balancing <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html">DescribeTargetGroups</a> API operation.</p>
        pub fn set_target_group_ar_ns(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_target_group_ar_ns(input);
            self
        }
    }
    /// Fluent builder constructing a request to `BatchDeleteScheduledAction`.
    ///
    /// <p>Deletes one or more scheduled actions for the specified Auto Scaling group.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct BatchDeleteScheduledAction {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::batch_delete_scheduled_action_input::Builder,
    }
    impl BatchDeleteScheduledAction {
        /// Creates a new `BatchDeleteScheduledAction`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::BatchDeleteScheduledActionOutput,
            aws_smithy_http::result::SdkError<crate::error::BatchDeleteScheduledActionError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `ScheduledActionNames`.
        ///
        /// To override the contents of this collection use [`set_scheduled_action_names`](Self::set_scheduled_action_names).
        ///
        /// <p>The names of the scheduled actions to delete. The maximum number allowed is 50. </p>
        pub fn scheduled_action_names(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.scheduled_action_names(input.into());
            self
        }
        /// <p>The names of the scheduled actions to delete. The maximum number allowed is 50. </p>
        pub fn set_scheduled_action_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_scheduled_action_names(input);
            self
        }
    }
    /// Fluent builder constructing a request to `BatchPutScheduledUpdateGroupAction`.
    ///
    /// <p>Creates or updates one or more scheduled scaling actions for an Auto Scaling group.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct BatchPutScheduledUpdateGroupAction {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::batch_put_scheduled_update_group_action_input::Builder,
    }
    impl BatchPutScheduledUpdateGroupAction {
        /// Creates a new `BatchPutScheduledUpdateGroupAction`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::BatchPutScheduledUpdateGroupActionOutput,
            aws_smithy_http::result::SdkError<
                crate::error::BatchPutScheduledUpdateGroupActionError,
            >,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `ScheduledUpdateGroupActions`.
        ///
        /// To override the contents of this collection use [`set_scheduled_update_group_actions`](Self::set_scheduled_update_group_actions).
        ///
        /// <p>One or more scheduled actions. The maximum number allowed is 50.</p>
        pub fn scheduled_update_group_actions(
            mut self,
            input: crate::model::ScheduledUpdateGroupActionRequest,
        ) -> Self {
            self.inner = self.inner.scheduled_update_group_actions(input);
            self
        }
        /// <p>One or more scheduled actions. The maximum number allowed is 50.</p>
        pub fn set_scheduled_update_group_actions(
            mut self,
            input: std::option::Option<
                std::vec::Vec<crate::model::ScheduledUpdateGroupActionRequest>,
            >,
        ) -> Self {
            self.inner = self.inner.set_scheduled_update_group_actions(input);
            self
        }
    }
    /// Fluent builder constructing a request to `CancelInstanceRefresh`.
    ///
    /// <p>Cancels an instance refresh operation in progress. Cancellation does not roll back any replacements that have already been completed, but it prevents new replacements from being started. </p>
    /// <p>This operation is part of the <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-instance-refresh.html">instance refresh feature</a> in Amazon EC2 Auto Scaling, which helps you update instances in your Auto Scaling group after you make configuration changes.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct CancelInstanceRefresh {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::cancel_instance_refresh_input::Builder,
    }
    impl CancelInstanceRefresh {
        /// Creates a new `CancelInstanceRefresh`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::CancelInstanceRefreshOutput,
            aws_smithy_http::result::SdkError<crate::error::CancelInstanceRefreshError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `CompleteLifecycleAction`.
    ///
    /// <p>Completes the lifecycle action for the specified token or instance with the specified result.</p>
    /// <p>This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group:</p>
    /// <ol>
    /// <li> <p>(Optional) Create a launch template or launch configuration with a user data script that runs while an instance is in a wait state due to a lifecycle hook.</p> </li>
    /// <li> <p>(Optional) Create a Lambda function and a rule that allows Amazon EventBridge to invoke your Lambda function when an instance is put into a wait state due to a lifecycle hook.</p> </li>
    /// <li> <p>(Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target.</p> </li>
    /// <li> <p>Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate.</p> </li>
    /// <li> <p>If you need more time, record the lifecycle action heartbeat to keep the instance in a wait state.</p> </li>
    /// <li> <p> <b>If you finish before the timeout period ends, send a callback by using the <code>CompleteLifecycleAction</code> API call.</b> </p> </li>
    /// </ol>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html">Amazon EC2 Auto Scaling lifecycle hooks</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct CompleteLifecycleAction {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::complete_lifecycle_action_input::Builder,
    }
    impl CompleteLifecycleAction {
        /// Creates a new `CompleteLifecycleAction`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::CompleteLifecycleActionOutput,
            aws_smithy_http::result::SdkError<crate::error::CompleteLifecycleActionError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the lifecycle hook.</p>
        pub fn lifecycle_hook_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.lifecycle_hook_name(input.into());
            self
        }
        /// <p>The name of the lifecycle hook.</p>
        pub fn set_lifecycle_hook_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_lifecycle_hook_name(input);
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>A universally unique identifier (UUID) that identifies a specific lifecycle action associated with an instance. Amazon EC2 Auto Scaling sends this token to the notification target you specified when you created the lifecycle hook.</p>
        pub fn lifecycle_action_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.lifecycle_action_token(input.into());
            self
        }
        /// <p>A universally unique identifier (UUID) that identifies a specific lifecycle action associated with an instance. Amazon EC2 Auto Scaling sends this token to the notification target you specified when you created the lifecycle hook.</p>
        pub fn set_lifecycle_action_token(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_lifecycle_action_token(input);
            self
        }
        /// <p>The action for the group to take. This parameter can be either <code>CONTINUE</code> or <code>ABANDON</code>.</p>
        pub fn lifecycle_action_result(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.lifecycle_action_result(input.into());
            self
        }
        /// <p>The action for the group to take. This parameter can be either <code>CONTINUE</code> or <code>ABANDON</code>.</p>
        pub fn set_lifecycle_action_result(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_lifecycle_action_result(input);
            self
        }
        /// <p>The ID of the instance.</p>
        pub fn instance_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_id(input.into());
            self
        }
        /// <p>The ID of the instance.</p>
        pub fn set_instance_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_instance_id(input);
            self
        }
    }
    /// Fluent builder constructing a request to `CreateAutoScalingGroup`.
    ///
    /// <p> <b>We strongly recommend using a launch template when calling this operation to ensure full functionality for Amazon EC2 Auto Scaling and Amazon EC2.</b> </p>
    /// <p>Creates an Auto Scaling group with the specified name and attributes. </p>
    /// <p>If you exceed your maximum limit of Auto Scaling groups, the call fails. To query this limit, call the <code>DescribeAccountLimits</code> API. For information about updating this limit, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-account-limits.html">Amazon EC2 Auto Scaling service quotas</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>For introductory exercises for creating an Auto Scaling group, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/GettingStartedTutorial.html">Getting started with Amazon EC2 Auto Scaling</a> and <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-register-lbs-with-asg.html">Tutorial: Set up a scaled and load-balanced application</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html">Auto Scaling groups</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>Every Auto Scaling group has three size parameters (<code>DesiredCapacity</code>, <code>MaxSize</code>, and <code>MinSize</code>). Usually, you set these sizes based on a specific number of instances. However, if you configure a mixed instances policy that defines weights for the instance types, you must specify these sizes with the same units that you use for weighting instances.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct CreateAutoScalingGroup {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::create_auto_scaling_group_input::Builder,
    }
    impl CreateAutoScalingGroup {
        /// Creates a new `CreateAutoScalingGroup`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::CreateAutoScalingGroupOutput,
            aws_smithy_http::result::SdkError<crate::error::CreateAutoScalingGroupError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group. This name must be unique per Region per account.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group. This name must be unique per Region per account.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The name of the launch configuration to use to launch instances. </p>
        /// <p>Conditional: You must specify either a launch template (<code>LaunchTemplate</code> or <code>MixedInstancesPolicy</code>) or a launch configuration (<code>LaunchConfigurationName</code> or <code>InstanceId</code>).</p>
        pub fn launch_configuration_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.launch_configuration_name(input.into());
            self
        }
        /// <p>The name of the launch configuration to use to launch instances. </p>
        /// <p>Conditional: You must specify either a launch template (<code>LaunchTemplate</code> or <code>MixedInstancesPolicy</code>) or a launch configuration (<code>LaunchConfigurationName</code> or <code>InstanceId</code>).</p>
        pub fn set_launch_configuration_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_launch_configuration_name(input);
            self
        }
        /// <p>Parameters used to specify the launch template and version to use to launch instances. </p>
        /// <p>Conditional: You must specify either a launch template (<code>LaunchTemplate</code> or <code>MixedInstancesPolicy</code>) or a launch configuration (<code>LaunchConfigurationName</code> or <code>InstanceId</code>).</p> <note>
        /// <p>The launch template that is specified must be configured for use with an Auto Scaling group. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-template.html">Creating a launch template for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// </note>
        pub fn launch_template(mut self, input: crate::model::LaunchTemplateSpecification) -> Self {
            self.inner = self.inner.launch_template(input);
            self
        }
        /// <p>Parameters used to specify the launch template and version to use to launch instances. </p>
        /// <p>Conditional: You must specify either a launch template (<code>LaunchTemplate</code> or <code>MixedInstancesPolicy</code>) or a launch configuration (<code>LaunchConfigurationName</code> or <code>InstanceId</code>).</p> <note>
        /// <p>The launch template that is specified must be configured for use with an Auto Scaling group. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-template.html">Creating a launch template for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// </note>
        pub fn set_launch_template(
            mut self,
            input: std::option::Option<crate::model::LaunchTemplateSpecification>,
        ) -> Self {
            self.inner = self.inner.set_launch_template(input);
            self
        }
        /// <p>An embedded object that specifies a mixed instances policy.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html">Auto Scaling groups with multiple instance types and purchase options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn mixed_instances_policy(mut self, input: crate::model::MixedInstancesPolicy) -> Self {
            self.inner = self.inner.mixed_instances_policy(input);
            self
        }
        /// <p>An embedded object that specifies a mixed instances policy.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html">Auto Scaling groups with multiple instance types and purchase options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_mixed_instances_policy(
            mut self,
            input: std::option::Option<crate::model::MixedInstancesPolicy>,
        ) -> Self {
            self.inner = self.inner.set_mixed_instances_policy(input);
            self
        }
        /// <p>The ID of the instance used to base the launch configuration on. If specified, Amazon EC2 Auto Scaling uses the configuration values from the specified instance to create a new launch configuration. To get the instance ID, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html">DescribeInstances</a> API operation. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-from-instance.html">Creating an Auto Scaling group using an EC2 instance</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn instance_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_id(input.into());
            self
        }
        /// <p>The ID of the instance used to base the launch configuration on. If specified, Amazon EC2 Auto Scaling uses the configuration values from the specified instance to create a new launch configuration. To get the instance ID, use the Amazon EC2 <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html">DescribeInstances</a> API operation. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-from-instance.html">Creating an Auto Scaling group using an EC2 instance</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_instance_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_instance_id(input);
            self
        }
        /// <p>The minimum size of the group.</p>
        pub fn min_size(mut self, input: i32) -> Self {
            self.inner = self.inner.min_size(input);
            self
        }
        /// <p>The minimum size of the group.</p>
        pub fn set_min_size(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_min_size(input);
            self
        }
        /// <p>The maximum size of the group.</p> <note>
        /// <p>With a mixed instances policy that uses instance weighting, Amazon EC2 Auto Scaling may need to go above <code>MaxSize</code> to meet your capacity requirements. In this event, Amazon EC2 Auto Scaling will never go above <code>MaxSize</code> by more than your largest instance weight (weights that define how many units each instance contributes to the desired capacity of the group).</p>
        /// </note>
        pub fn max_size(mut self, input: i32) -> Self {
            self.inner = self.inner.max_size(input);
            self
        }
        /// <p>The maximum size of the group.</p> <note>
        /// <p>With a mixed instances policy that uses instance weighting, Amazon EC2 Auto Scaling may need to go above <code>MaxSize</code> to meet your capacity requirements. In this event, Amazon EC2 Auto Scaling will never go above <code>MaxSize</code> by more than your largest instance weight (weights that define how many units each instance contributes to the desired capacity of the group).</p>
        /// </note>
        pub fn set_max_size(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_size(input);
            self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group at the time of its creation and the capacity it attempts to maintain. It can scale beyond this capacity if you configure auto scaling. This number must be greater than or equal to the minimum size of the group and less than or equal to the maximum size of the group. If you do not specify a desired capacity, the default is the minimum size of the group.</p>
        pub fn desired_capacity(mut self, input: i32) -> Self {
            self.inner = self.inner.desired_capacity(input);
            self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group at the time of its creation and the capacity it attempts to maintain. It can scale beyond this capacity if you configure auto scaling. This number must be greater than or equal to the minimum size of the group and less than or equal to the maximum size of the group. If you do not specify a desired capacity, the default is the minimum size of the group.</p>
        pub fn set_desired_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_desired_capacity(input);
            self
        }
        /// <p> <i>Only needed if you use simple scaling policies.</i> </p>
        /// <p>The amount of time, in seconds, between one scaling activity ending and another one starting due to simple scaling policies. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>Default: <code>300</code> seconds</p>
        pub fn default_cooldown(mut self, input: i32) -> Self {
            self.inner = self.inner.default_cooldown(input);
            self
        }
        /// <p> <i>Only needed if you use simple scaling policies.</i> </p>
        /// <p>The amount of time, in seconds, between one scaling activity ending and another one starting due to simple scaling policies. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>Default: <code>300</code> seconds</p>
        pub fn set_default_cooldown(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_default_cooldown(input);
            self
        }
        /// Appends an item to `AvailabilityZones`.
        ///
        /// To override the contents of this collection use [`set_availability_zones`](Self::set_availability_zones).
        ///
        /// <p>A list of Availability Zones where instances in the Auto Scaling group can be created. This parameter is optional if you specify one or more subnets for <code>VPCZoneIdentifier</code>.</p>
        /// <p>Conditional: If your account supports EC2-Classic and VPC, this parameter is required to launch instances into EC2-Classic.</p>
        pub fn availability_zones(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.availability_zones(input.into());
            self
        }
        /// <p>A list of Availability Zones where instances in the Auto Scaling group can be created. This parameter is optional if you specify one or more subnets for <code>VPCZoneIdentifier</code>.</p>
        /// <p>Conditional: If your account supports EC2-Classic and VPC, this parameter is required to launch instances into EC2-Classic.</p>
        pub fn set_availability_zones(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_availability_zones(input);
            self
        }
        /// Appends an item to `LoadBalancerNames`.
        ///
        /// To override the contents of this collection use [`set_load_balancer_names`](Self::set_load_balancer_names).
        ///
        /// <p>A list of Classic Load Balancers associated with this Auto Scaling group. For Application Load Balancers, Network Load Balancers, and Gateway Load Balancers, specify the <code>TargetGroupARNs</code> property instead.</p>
        pub fn load_balancer_names(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.load_balancer_names(input.into());
            self
        }
        /// <p>A list of Classic Load Balancers associated with this Auto Scaling group. For Application Load Balancers, Network Load Balancers, and Gateway Load Balancers, specify the <code>TargetGroupARNs</code> property instead.</p>
        pub fn set_load_balancer_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_load_balancer_names(input);
            self
        }
        /// Appends an item to `TargetGroupARNs`.
        ///
        /// To override the contents of this collection use [`set_target_group_ar_ns`](Self::set_target_group_ar_ns).
        ///
        /// <p>The Amazon Resource Names (ARN) of the target groups to associate with the Auto Scaling group. Instances are registered as targets in a target group, and traffic is routed to the target group. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html">Elastic Load Balancing and Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn target_group_ar_ns(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.target_group_ar_ns(input.into());
            self
        }
        /// <p>The Amazon Resource Names (ARN) of the target groups to associate with the Auto Scaling group. Instances are registered as targets in a target group, and traffic is routed to the target group. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html">Elastic Load Balancing and Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_target_group_ar_ns(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_target_group_ar_ns(input);
            self
        }
        /// <p>The service to use for the health checks. The valid values are <code>EC2</code> (default) and <code>ELB</code>. If you configure an Auto Scaling group to use load balancer (ELB) health checks, it considers the instance unhealthy if it fails either the EC2 status checks or the load balancer health checks. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html">Health checks for Auto Scaling instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn health_check_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.health_check_type(input.into());
            self
        }
        /// <p>The service to use for the health checks. The valid values are <code>EC2</code> (default) and <code>ELB</code>. If you configure an Auto Scaling group to use load balancer (ELB) health checks, it considers the instance unhealthy if it fails either the EC2 status checks or the load balancer health checks. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html">Health checks for Auto Scaling instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_health_check_type(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_health_check_type(input);
            self
        }
        /// <p> <i></i> </p>
        /// <p>The amount of time, in seconds, that Amazon EC2 Auto Scaling waits before checking the health status of an EC2 instance that has come into service and marking it unhealthy due to a failed Elastic Load Balancing or custom health check. This is useful if your instances do not immediately pass these health checks after they enter the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html#health-check-grace-period">Health check grace period</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>Default: <code>0</code> seconds</p>
        pub fn health_check_grace_period(mut self, input: i32) -> Self {
            self.inner = self.inner.health_check_grace_period(input);
            self
        }
        /// <p> <i></i> </p>
        /// <p>The amount of time, in seconds, that Amazon EC2 Auto Scaling waits before checking the health status of an EC2 instance that has come into service and marking it unhealthy due to a failed Elastic Load Balancing or custom health check. This is useful if your instances do not immediately pass these health checks after they enter the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html#health-check-grace-period">Health check grace period</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>Default: <code>0</code> seconds</p>
        pub fn set_health_check_grace_period(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_health_check_grace_period(input);
            self
        }
        /// <p>The name of an existing placement group into which to launch your instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html">Placement groups</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> <note>
        /// <p>A <i>cluster</i> placement group is a logical grouping of instances within a single Availability Zone. You cannot specify multiple Availability Zones and a cluster placement group. </p>
        /// </note>
        pub fn placement_group(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.placement_group(input.into());
            self
        }
        /// <p>The name of an existing placement group into which to launch your instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html">Placement groups</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> <note>
        /// <p>A <i>cluster</i> placement group is a logical grouping of instances within a single Availability Zone. You cannot specify multiple Availability Zones and a cluster placement group. </p>
        /// </note>
        pub fn set_placement_group(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_placement_group(input);
            self
        }
        /// <p>A comma-separated list of subnet IDs for a virtual private cloud (VPC) where instances in the Auto Scaling group can be created. If you specify <code>VPCZoneIdentifier</code> with <code>AvailabilityZones</code>, the subnets that you specify for this parameter must reside in those Availability Zones.</p>
        /// <p>Conditional: If your account supports EC2-Classic and VPC, this parameter is required to launch instances into a VPC.</p>
        pub fn vpc_zone_identifier(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.vpc_zone_identifier(input.into());
            self
        }
        /// <p>A comma-separated list of subnet IDs for a virtual private cloud (VPC) where instances in the Auto Scaling group can be created. If you specify <code>VPCZoneIdentifier</code> with <code>AvailabilityZones</code>, the subnets that you specify for this parameter must reside in those Availability Zones.</p>
        /// <p>Conditional: If your account supports EC2-Classic and VPC, this parameter is required to launch instances into a VPC.</p>
        pub fn set_vpc_zone_identifier(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_vpc_zone_identifier(input);
            self
        }
        /// Appends an item to `TerminationPolicies`.
        ///
        /// To override the contents of this collection use [`set_termination_policies`](Self::set_termination_policies).
        ///
        /// <p>A policy or a list of policies that are used to select the instance to terminate. These policies are executed in the order that you list them. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html">Controlling which Auto Scaling instances terminate during scale in</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn termination_policies(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.termination_policies(input.into());
            self
        }
        /// <p>A policy or a list of policies that are used to select the instance to terminate. These policies are executed in the order that you list them. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html">Controlling which Auto Scaling instances terminate during scale in</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_termination_policies(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_termination_policies(input);
            self
        }
        /// <p>Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. For more information about preventing instances from terminating on scale in, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-instance-protection.html">Using instance scale-in protection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn new_instances_protected_from_scale_in(mut self, input: bool) -> Self {
            self.inner = self.inner.new_instances_protected_from_scale_in(input);
            self
        }
        /// <p>Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. For more information about preventing instances from terminating on scale in, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-instance-protection.html">Using instance scale-in protection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_new_instances_protected_from_scale_in(
            mut self,
            input: std::option::Option<bool>,
        ) -> Self {
            self.inner = self.inner.set_new_instances_protected_from_scale_in(input);
            self
        }
        /// <p>Indicates whether Capacity Rebalancing is enabled. Otherwise, Capacity Rebalancing is disabled. When you turn on Capacity Rebalancing, Amazon EC2 Auto Scaling attempts to launch a Spot Instance whenever Amazon EC2 notifies that a Spot Instance is at an elevated risk of interruption. After launching a new instance, it then terminates an old instance. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html">Amazon EC2 Auto Scaling Capacity Rebalancing</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn capacity_rebalance(mut self, input: bool) -> Self {
            self.inner = self.inner.capacity_rebalance(input);
            self
        }
        /// <p>Indicates whether Capacity Rebalancing is enabled. Otherwise, Capacity Rebalancing is disabled. When you turn on Capacity Rebalancing, Amazon EC2 Auto Scaling attempts to launch a Spot Instance whenever Amazon EC2 notifies that a Spot Instance is at an elevated risk of interruption. After launching a new instance, it then terminates an old instance. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html">Amazon EC2 Auto Scaling Capacity Rebalancing</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_capacity_rebalance(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_capacity_rebalance(input);
            self
        }
        /// Appends an item to `LifecycleHookSpecificationList`.
        ///
        /// To override the contents of this collection use [`set_lifecycle_hook_specification_list`](Self::set_lifecycle_hook_specification_list).
        ///
        /// <p>One or more lifecycle hooks for the group, which specify actions to perform when Amazon EC2 Auto Scaling launches or terminates instances.</p>
        pub fn lifecycle_hook_specification_list(
            mut self,
            input: crate::model::LifecycleHookSpecification,
        ) -> Self {
            self.inner = self.inner.lifecycle_hook_specification_list(input);
            self
        }
        /// <p>One or more lifecycle hooks for the group, which specify actions to perform when Amazon EC2 Auto Scaling launches or terminates instances.</p>
        pub fn set_lifecycle_hook_specification_list(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::LifecycleHookSpecification>>,
        ) -> Self {
            self.inner = self.inner.set_lifecycle_hook_specification_list(input);
            self
        }
        /// Appends an item to `Tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p>One or more tags. You can tag your Auto Scaling group and propagate the tags to the Amazon EC2 instances it launches. Tags are not propagated to Amazon EBS volumes. To add tags to Amazon EBS volumes, specify the tags in a launch template but use caution. If the launch template specifies an instance tag with a key that is also specified for the Auto Scaling group, Amazon EC2 Auto Scaling overrides the value of that instance tag with the value specified by the Auto Scaling group. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-tagging.html">Tagging Auto Scaling groups and instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn tags(mut self, input: crate::model::Tag) -> Self {
            self.inner = self.inner.tags(input);
            self
        }
        /// <p>One or more tags. You can tag your Auto Scaling group and propagate the tags to the Amazon EC2 instances it launches. Tags are not propagated to Amazon EBS volumes. To add tags to Amazon EBS volumes, specify the tags in a launch template but use caution. If the launch template specifies an instance tag with a key that is also specified for the Auto Scaling group, Amazon EC2 Auto Scaling overrides the value of that instance tag with the value specified by the Auto Scaling group. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-tagging.html">Tagging Auto Scaling groups and instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.inner = self.inner.set_tags(input);
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services on your behalf. By default, Amazon EC2 Auto Scaling uses a service-linked role named <code>AWSServiceRoleForAutoScaling</code>, which it creates if it does not exist. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-service-linked-role.html">Service-linked roles</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn service_linked_role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.service_linked_role_arn(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services on your behalf. By default, Amazon EC2 Auto Scaling uses a service-linked role named <code>AWSServiceRoleForAutoScaling</code>, which it creates if it does not exist. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-service-linked-role.html">Service-linked roles</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_service_linked_role_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_service_linked_role_arn(input);
            self
        }
        /// <p>The maximum amount of time, in seconds, that an instance can be in service. The default is null. If specified, the value must be either 0 or a number equal to or greater than 86,400 seconds (1 day). For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-max-instance-lifetime.html">Replacing Auto Scaling instances based on maximum instance lifetime</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn max_instance_lifetime(mut self, input: i32) -> Self {
            self.inner = self.inner.max_instance_lifetime(input);
            self
        }
        /// <p>The maximum amount of time, in seconds, that an instance can be in service. The default is null. If specified, the value must be either 0 or a number equal to or greater than 86,400 seconds (1 day). For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-max-instance-lifetime.html">Replacing Auto Scaling instances based on maximum instance lifetime</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_max_instance_lifetime(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_instance_lifetime(input);
            self
        }
        /// <p>Reserved.</p>
        pub fn context(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.context(input.into());
            self
        }
        /// <p>Reserved.</p>
        pub fn set_context(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_context(input);
            self
        }
        /// <p>The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports <code>DesiredCapacityType</code> for attribute-based instance type selection only. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-instance-type-requirements.html">Creating an Auto Scaling group using attribute-based instance type selection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>By default, Amazon EC2 Auto Scaling specifies <code>units</code>, which translates into number of instances.</p>
        /// <p>Valid values: <code>units</code> | <code>vcpu</code> | <code>memory-mib</code> </p>
        pub fn desired_capacity_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.desired_capacity_type(input.into());
            self
        }
        /// <p>The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports <code>DesiredCapacityType</code> for attribute-based instance type selection only. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-instance-type-requirements.html">Creating an Auto Scaling group using attribute-based instance type selection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>By default, Amazon EC2 Auto Scaling specifies <code>units</code>, which translates into number of instances.</p>
        /// <p>Valid values: <code>units</code> | <code>vcpu</code> | <code>memory-mib</code> </p>
        pub fn set_desired_capacity_type(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_desired_capacity_type(input);
            self
        }
        /// <p>The amount of time, in seconds, until a newly launched instance can contribute to the Amazon CloudWatch metrics. This delay lets an instance finish initializing before Amazon EC2 Auto Scaling aggregates instance metrics, resulting in more reliable usage data. Set this value equal to the amount of time that it takes for resource consumption to become stable after an instance reaches the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-default-instance-warmup.html">Set the default instance warmup for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <important>
        /// <p>To manage your warm-up settings at the group level, we recommend that you set the default instance warmup, <i>even if its value is set to 0 seconds</i>. This also optimizes the performance of scaling policies that scale continuously, such as target tracking and step scaling policies. </p>
        /// <p>If you need to remove a value that you previously set, include the property but specify <code>-1</code> for the value. However, we strongly recommend keeping the default instance warmup enabled by specifying a minimum value of <code>0</code>.</p>
        /// </important>
        /// <p>Default: None </p>
        pub fn default_instance_warmup(mut self, input: i32) -> Self {
            self.inner = self.inner.default_instance_warmup(input);
            self
        }
        /// <p>The amount of time, in seconds, until a newly launched instance can contribute to the Amazon CloudWatch metrics. This delay lets an instance finish initializing before Amazon EC2 Auto Scaling aggregates instance metrics, resulting in more reliable usage data. Set this value equal to the amount of time that it takes for resource consumption to become stable after an instance reaches the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-default-instance-warmup.html">Set the default instance warmup for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <important>
        /// <p>To manage your warm-up settings at the group level, we recommend that you set the default instance warmup, <i>even if its value is set to 0 seconds</i>. This also optimizes the performance of scaling policies that scale continuously, such as target tracking and step scaling policies. </p>
        /// <p>If you need to remove a value that you previously set, include the property but specify <code>-1</code> for the value. However, we strongly recommend keeping the default instance warmup enabled by specifying a minimum value of <code>0</code>.</p>
        /// </important>
        /// <p>Default: None </p>
        pub fn set_default_instance_warmup(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_default_instance_warmup(input);
            self
        }
    }
    /// Fluent builder constructing a request to `CreateLaunchConfiguration`.
    ///
    /// <p>Creates a launch configuration.</p>
    /// <p>If you exceed your maximum limit of launch configurations, the call fails. To query this limit, call the <code>DescribeAccountLimits</code> API. For information about updating this limit, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-account-limits.html">Amazon EC2 Auto Scaling service quotas</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/LaunchConfiguration.html">Launch configurations</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct CreateLaunchConfiguration {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::create_launch_configuration_input::Builder,
    }
    impl CreateLaunchConfiguration {
        /// Creates a new `CreateLaunchConfiguration`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::CreateLaunchConfigurationOutput,
            aws_smithy_http::result::SdkError<crate::error::CreateLaunchConfigurationError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the launch configuration. This name must be unique per Region per account.</p>
        pub fn launch_configuration_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.launch_configuration_name(input.into());
            self
        }
        /// <p>The name of the launch configuration. This name must be unique per Region per account.</p>
        pub fn set_launch_configuration_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_launch_configuration_name(input);
            self
        }
        /// <p>The ID of the Amazon Machine Image (AMI) that was assigned during registration. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html">Finding an AMI</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        /// <p>If you do not specify <code>InstanceId</code>, you must specify <code>ImageId</code>.</p>
        pub fn image_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.image_id(input.into());
            self
        }
        /// <p>The ID of the Amazon Machine Image (AMI) that was assigned during registration. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html">Finding an AMI</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        /// <p>If you do not specify <code>InstanceId</code>, you must specify <code>ImageId</code>.</p>
        pub fn set_image_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_image_id(input);
            self
        }
        /// <p>The name of the key pair. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html">Amazon EC2 Key Pairs</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn key_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.key_name(input.into());
            self
        }
        /// <p>The name of the key pair. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html">Amazon EC2 Key Pairs</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn set_key_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_key_name(input);
            self
        }
        /// Appends an item to `SecurityGroups`.
        ///
        /// To override the contents of this collection use [`set_security_groups`](Self::set_security_groups).
        ///
        /// <p>A list that contains the security groups to assign to the instances in the Auto Scaling group.</p>
        /// <p>[EC2-VPC] Specify the security group IDs. For more information, see <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html">Security Groups for Your VPC</a> in the <i>Amazon Virtual Private Cloud User Guide</i>.</p>
        /// <p>[EC2-Classic] Specify either the security group names or the security group IDs. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html">Amazon EC2 Security Groups</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn security_groups(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.security_groups(input.into());
            self
        }
        /// <p>A list that contains the security groups to assign to the instances in the Auto Scaling group.</p>
        /// <p>[EC2-VPC] Specify the security group IDs. For more information, see <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html">Security Groups for Your VPC</a> in the <i>Amazon Virtual Private Cloud User Guide</i>.</p>
        /// <p>[EC2-Classic] Specify either the security group names or the security group IDs. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html">Amazon EC2 Security Groups</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn set_security_groups(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_security_groups(input);
            self
        }
        /// <p> <i>EC2-Classic retires on August 15, 2022. This parameter is not supported after that date.</i> </p>
        /// <p>The ID of a ClassicLink-enabled VPC to link your EC2-Classic instances to. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-classiclink.html">ClassicLink</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn classic_link_vpc_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.classic_link_vpc_id(input.into());
            self
        }
        /// <p> <i>EC2-Classic retires on August 15, 2022. This parameter is not supported after that date.</i> </p>
        /// <p>The ID of a ClassicLink-enabled VPC to link your EC2-Classic instances to. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-classiclink.html">ClassicLink</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn set_classic_link_vpc_id(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_classic_link_vpc_id(input);
            self
        }
        /// Appends an item to `ClassicLinkVPCSecurityGroups`.
        ///
        /// To override the contents of this collection use [`set_classic_link_vpc_security_groups`](Self::set_classic_link_vpc_security_groups).
        ///
        /// <p> <i>EC2-Classic retires on August 15, 2022. This parameter is not supported after that date.</i> </p>
        /// <p>The IDs of one or more security groups for the specified ClassicLink-enabled VPC. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-classiclink.html">ClassicLink</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        /// <p>If you specify the <code>ClassicLinkVPCId</code> parameter, you must specify this parameter.</p>
        pub fn classic_link_vpc_security_groups(
            mut self,
            input: impl Into<std::string::String>,
        ) -> Self {
            self.inner = self.inner.classic_link_vpc_security_groups(input.into());
            self
        }
        /// <p> <i>EC2-Classic retires on August 15, 2022. This parameter is not supported after that date.</i> </p>
        /// <p>The IDs of one or more security groups for the specified ClassicLink-enabled VPC. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-classiclink.html">ClassicLink</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        /// <p>If you specify the <code>ClassicLinkVPCId</code> parameter, you must specify this parameter.</p>
        pub fn set_classic_link_vpc_security_groups(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_classic_link_vpc_security_groups(input);
            self
        }
        /// <p>The user data to make available to the launched EC2 instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Linux) and <a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Windows). If you are using a command line tool, base64-encoding is performed for you, and you can load the text from a file. Otherwise, you must provide base64-encoded text. User data is limited to 16 KB.</p>
        pub fn user_data(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.user_data(input.into());
            self
        }
        /// <p>The user data to make available to the launched EC2 instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Linux) and <a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-instance-metadata.html">Instance metadata and user data</a> (Windows). If you are using a command line tool, base64-encoding is performed for you, and you can load the text from a file. Otherwise, you must provide base64-encoded text. User data is limited to 16 KB.</p>
        pub fn set_user_data(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_user_data(input);
            self
        }
        /// <p>The ID of the instance to use to create the launch configuration. The new launch configuration derives attributes from the instance, except for the block device mapping.</p>
        /// <p>To create a launch configuration with a block device mapping or override any other instance attributes, specify them as part of the same request.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-lc-with-instanceID.html">Creating a launch configuration using an EC2 instance</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>If you do not specify <code>InstanceId</code>, you must specify both <code>ImageId</code> and <code>InstanceType</code>.</p>
        pub fn instance_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_id(input.into());
            self
        }
        /// <p>The ID of the instance to use to create the launch configuration. The new launch configuration derives attributes from the instance, except for the block device mapping.</p>
        /// <p>To create a launch configuration with a block device mapping or override any other instance attributes, specify them as part of the same request.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-lc-with-instanceID.html">Creating a launch configuration using an EC2 instance</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>If you do not specify <code>InstanceId</code>, you must specify both <code>ImageId</code> and <code>InstanceType</code>.</p>
        pub fn set_instance_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_instance_id(input);
            self
        }
        /// <p>Specifies the instance type of the EC2 instance.</p>
        /// <p>For information about available instance types, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#AvailableInstanceTypes">Available Instance Types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        /// <p>If you do not specify <code>InstanceId</code>, you must specify <code>InstanceType</code>.</p>
        pub fn instance_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_type(input.into());
            self
        }
        /// <p>Specifies the instance type of the EC2 instance.</p>
        /// <p>For information about available instance types, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#AvailableInstanceTypes">Available Instance Types</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        /// <p>If you do not specify <code>InstanceId</code>, you must specify <code>InstanceType</code>.</p>
        pub fn set_instance_type(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_instance_type(input);
            self
        }
        /// <p>The ID of the kernel associated with the AMI.</p>
        pub fn kernel_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.kernel_id(input.into());
            self
        }
        /// <p>The ID of the kernel associated with the AMI.</p>
        pub fn set_kernel_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_kernel_id(input);
            self
        }
        /// <p>The ID of the RAM disk to select.</p>
        pub fn ramdisk_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.ramdisk_id(input.into());
            self
        }
        /// <p>The ID of the RAM disk to select.</p>
        pub fn set_ramdisk_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_ramdisk_id(input);
            self
        }
        /// Appends an item to `BlockDeviceMappings`.
        ///
        /// To override the contents of this collection use [`set_block_device_mappings`](Self::set_block_device_mappings).
        ///
        /// <p>A block device mapping, which specifies the block devices for the instance. You can specify virtual devices and EBS volumes. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html">Block Device Mapping</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn block_device_mappings(mut self, input: crate::model::BlockDeviceMapping) -> Self {
            self.inner = self.inner.block_device_mappings(input);
            self
        }
        /// <p>A block device mapping, which specifies the block devices for the instance. You can specify virtual devices and EBS volumes. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html">Block Device Mapping</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        pub fn set_block_device_mappings(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::BlockDeviceMapping>>,
        ) -> Self {
            self.inner = self.inner.set_block_device_mappings(input);
            self
        }
        /// <p>Controls whether instances in this group are launched with detailed (<code>true</code>) or basic (<code>false</code>) monitoring.</p>
        /// <p>The default value is <code>true</code> (enabled).</p> <important>
        /// <p>When detailed monitoring is enabled, Amazon CloudWatch generates metrics every minute and your account is charged a fee. When you disable detailed monitoring, CloudWatch generates metrics every 5 minutes. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/latest/userguide/enable-as-instance-metrics.html">Configure Monitoring for Auto Scaling Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// </important>
        pub fn instance_monitoring(mut self, input: crate::model::InstanceMonitoring) -> Self {
            self.inner = self.inner.instance_monitoring(input);
            self
        }
        /// <p>Controls whether instances in this group are launched with detailed (<code>true</code>) or basic (<code>false</code>) monitoring.</p>
        /// <p>The default value is <code>true</code> (enabled).</p> <important>
        /// <p>When detailed monitoring is enabled, Amazon CloudWatch generates metrics every minute and your account is charged a fee. When you disable detailed monitoring, CloudWatch generates metrics every 5 minutes. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/latest/userguide/enable-as-instance-metrics.html">Configure Monitoring for Auto Scaling Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// </important>
        pub fn set_instance_monitoring(
            mut self,
            input: std::option::Option<crate::model::InstanceMonitoring>,
        ) -> Self {
            self.inner = self.inner.set_instance_monitoring(input);
            self
        }
        /// <p>The maximum hourly price to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot price. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-launch-spot-instances.html">Requesting Spot Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <note>
        /// <p>When you change your maximum price by creating a new launch configuration, running instances will continue to run as long as the maximum price for those running instances is higher than the current Spot price.</p>
        /// </note>
        pub fn spot_price(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.spot_price(input.into());
            self
        }
        /// <p>The maximum hourly price to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot price. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-launch-spot-instances.html">Requesting Spot Instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <note>
        /// <p>When you change your maximum price by creating a new launch configuration, running instances will continue to run as long as the maximum price for those running instances is higher than the current Spot price.</p>
        /// </note>
        pub fn set_spot_price(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_spot_price(input);
            self
        }
        /// <p>The name or the Amazon Resource Name (ARN) of the instance profile associated with the IAM role for the instance. The instance profile contains the IAM role.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/us-iam-role.html">IAM role for applications that run on Amazon EC2 instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn iam_instance_profile(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.iam_instance_profile(input.into());
            self
        }
        /// <p>The name or the Amazon Resource Name (ARN) of the instance profile associated with the IAM role for the instance. The instance profile contains the IAM role.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/us-iam-role.html">IAM role for applications that run on Amazon EC2 instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_iam_instance_profile(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_iam_instance_profile(input);
            self
        }
        /// <p>Specifies whether the launch configuration is optimized for EBS I/O (<code>true</code>) or not (<code>false</code>). The optimization provides dedicated throughput to Amazon EBS and an optimized configuration stack to provide optimal I/O performance. This optimization is not available with all instance types. Additional fees are incurred when you enable EBS optimization for an instance type that is not EBS-optimized by default. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html">Amazon EBS-optimized instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        /// <p>The default value is <code>false</code>.</p>
        pub fn ebs_optimized(mut self, input: bool) -> Self {
            self.inner = self.inner.ebs_optimized(input);
            self
        }
        /// <p>Specifies whether the launch configuration is optimized for EBS I/O (<code>true</code>) or not (<code>false</code>). The optimization provides dedicated throughput to Amazon EBS and an optimized configuration stack to provide optimal I/O performance. This optimization is not available with all instance types. Additional fees are incurred when you enable EBS optimization for an instance type that is not EBS-optimized by default. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html">Amazon EBS-optimized instances</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p>
        /// <p>The default value is <code>false</code>.</p>
        pub fn set_ebs_optimized(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_ebs_optimized(input);
            self
        }
        /// <p>For Auto Scaling groups that are running in a virtual private cloud (VPC), specifies whether to assign a public IP address to the group's instances. If you specify <code>true</code>, each instance in the Auto Scaling group receives a unique public IP address. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-in-vpc.html">Launching Auto Scaling instances in a VPC</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>If you specify this parameter, you must specify at least one subnet for <code>VPCZoneIdentifier</code> when you create your group.</p> <note>
        /// <p>If the instance is launched into a default subnet, the default is to assign a public IP address, unless you disabled the option to assign a public IP address on the subnet. If the instance is launched into a nondefault subnet, the default is not to assign a public IP address, unless you enabled the option to assign a public IP address on the subnet.</p>
        /// </note>
        pub fn associate_public_ip_address(mut self, input: bool) -> Self {
            self.inner = self.inner.associate_public_ip_address(input);
            self
        }
        /// <p>For Auto Scaling groups that are running in a virtual private cloud (VPC), specifies whether to assign a public IP address to the group's instances. If you specify <code>true</code>, each instance in the Auto Scaling group receives a unique public IP address. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-in-vpc.html">Launching Auto Scaling instances in a VPC</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>If you specify this parameter, you must specify at least one subnet for <code>VPCZoneIdentifier</code> when you create your group.</p> <note>
        /// <p>If the instance is launched into a default subnet, the default is to assign a public IP address, unless you disabled the option to assign a public IP address on the subnet. If the instance is launched into a nondefault subnet, the default is not to assign a public IP address, unless you enabled the option to assign a public IP address on the subnet.</p>
        /// </note>
        pub fn set_associate_public_ip_address(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_associate_public_ip_address(input);
            self
        }
        /// <p>The tenancy of the instance. An instance with <code>dedicated</code> tenancy runs on isolated, single-tenant hardware and can only be launched into a VPC.</p>
        /// <p>To launch dedicated instances into a shared tenancy VPC (a VPC with the instance placement tenancy attribute set to <code>default</code>), you must set the value of this parameter to <code>dedicated</code>.</p>
        /// <p>If you specify <code>PlacementTenancy</code>, you must specify at least one subnet for <code>VPCZoneIdentifier</code> when you create your group.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-dedicated-instances.html">Configuring instance tenancy with Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>Valid Values: <code>default</code> | <code>dedicated</code> </p>
        pub fn placement_tenancy(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.placement_tenancy(input.into());
            self
        }
        /// <p>The tenancy of the instance. An instance with <code>dedicated</code> tenancy runs on isolated, single-tenant hardware and can only be launched into a VPC.</p>
        /// <p>To launch dedicated instances into a shared tenancy VPC (a VPC with the instance placement tenancy attribute set to <code>default</code>), you must set the value of this parameter to <code>dedicated</code>.</p>
        /// <p>If you specify <code>PlacementTenancy</code>, you must specify at least one subnet for <code>VPCZoneIdentifier</code> when you create your group.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-dedicated-instances.html">Configuring instance tenancy with Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>Valid Values: <code>default</code> | <code>dedicated</code> </p>
        pub fn set_placement_tenancy(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_placement_tenancy(input);
            self
        }
        /// <p>The metadata options for the instances. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-config.html#launch-configurations-imds">Configuring the Instance Metadata Options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn metadata_options(mut self, input: crate::model::InstanceMetadataOptions) -> Self {
            self.inner = self.inner.metadata_options(input);
            self
        }
        /// <p>The metadata options for the instances. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-config.html#launch-configurations-imds">Configuring the Instance Metadata Options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_metadata_options(
            mut self,
            input: std::option::Option<crate::model::InstanceMetadataOptions>,
        ) -> Self {
            self.inner = self.inner.set_metadata_options(input);
            self
        }
    }
    /// Fluent builder constructing a request to `CreateOrUpdateTags`.
    ///
    /// <p>Creates or updates tags for the specified Auto Scaling group.</p>
    /// <p>When you specify a tag with a key that already exists, the operation overwrites the previous tag definition, and you do not get an error message.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-tagging.html">Tagging Auto Scaling groups and instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct CreateOrUpdateTags {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::create_or_update_tags_input::Builder,
    }
    impl CreateOrUpdateTags {
        /// Creates a new `CreateOrUpdateTags`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::CreateOrUpdateTagsOutput,
            aws_smithy_http::result::SdkError<crate::error::CreateOrUpdateTagsError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Appends an item to `Tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p>One or more tags.</p>
        pub fn tags(mut self, input: crate::model::Tag) -> Self {
            self.inner = self.inner.tags(input);
            self
        }
        /// <p>One or more tags.</p>
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.inner = self.inner.set_tags(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DeleteAutoScalingGroup`.
    ///
    /// <p>Deletes the specified Auto Scaling group.</p>
    /// <p>If the group has instances or scaling activities in progress, you must specify the option to force the deletion in order for it to succeed.</p>
    /// <p>If the group has policies, deleting the group deletes the policies, the underlying alarm actions, and any alarm that no longer has an associated action.</p>
    /// <p>To remove instances from the Auto Scaling group before deleting it, call the <code>DetachInstances</code> API with the list of instances and the option to decrement the desired capacity. This ensures that Amazon EC2 Auto Scaling does not launch replacement instances.</p>
    /// <p>To terminate all instances before deleting the Auto Scaling group, call the <code>UpdateAutoScalingGroup</code> API and set the minimum size and desired capacity of the Auto Scaling group to zero.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DeleteAutoScalingGroup {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::delete_auto_scaling_group_input::Builder,
    }
    impl DeleteAutoScalingGroup {
        /// Creates a new `DeleteAutoScalingGroup`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteAutoScalingGroupOutput,
            aws_smithy_http::result::SdkError<crate::error::DeleteAutoScalingGroupError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>Specifies that the group is to be deleted along with all instances associated with the group, without waiting for all instances to be terminated. This parameter also deletes any outstanding lifecycle actions associated with the group.</p>
        pub fn force_delete(mut self, input: bool) -> Self {
            self.inner = self.inner.force_delete(input);
            self
        }
        /// <p>Specifies that the group is to be deleted along with all instances associated with the group, without waiting for all instances to be terminated. This parameter also deletes any outstanding lifecycle actions associated with the group.</p>
        pub fn set_force_delete(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_force_delete(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DeleteLaunchConfiguration`.
    ///
    /// <p>Deletes the specified launch configuration.</p>
    /// <p>The launch configuration must not be attached to an Auto Scaling group. When this call completes, the launch configuration is no longer available for use.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DeleteLaunchConfiguration {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::delete_launch_configuration_input::Builder,
    }
    impl DeleteLaunchConfiguration {
        /// Creates a new `DeleteLaunchConfiguration`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteLaunchConfigurationOutput,
            aws_smithy_http::result::SdkError<crate::error::DeleteLaunchConfigurationError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the launch configuration.</p>
        pub fn launch_configuration_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.launch_configuration_name(input.into());
            self
        }
        /// <p>The name of the launch configuration.</p>
        pub fn set_launch_configuration_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_launch_configuration_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DeleteLifecycleHook`.
    ///
    /// <p>Deletes the specified lifecycle hook.</p>
    /// <p>If there are any outstanding lifecycle actions, they are completed first (<code>ABANDON</code> for launching instances, <code>CONTINUE</code> for terminating instances).</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DeleteLifecycleHook {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::delete_lifecycle_hook_input::Builder,
    }
    impl DeleteLifecycleHook {
        /// Creates a new `DeleteLifecycleHook`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteLifecycleHookOutput,
            aws_smithy_http::result::SdkError<crate::error::DeleteLifecycleHookError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the lifecycle hook.</p>
        pub fn lifecycle_hook_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.lifecycle_hook_name(input.into());
            self
        }
        /// <p>The name of the lifecycle hook.</p>
        pub fn set_lifecycle_hook_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_lifecycle_hook_name(input);
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DeleteNotificationConfiguration`.
    ///
    /// <p>Deletes the specified notification.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DeleteNotificationConfiguration {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::delete_notification_configuration_input::Builder,
    }
    impl DeleteNotificationConfiguration {
        /// Creates a new `DeleteNotificationConfiguration`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteNotificationConfigurationOutput,
            aws_smithy_http::result::SdkError<crate::error::DeleteNotificationConfigurationError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the Amazon SNS topic.</p>
        pub fn topic_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.topic_arn(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the Amazon SNS topic.</p>
        pub fn set_topic_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_topic_arn(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DeletePolicy`.
    ///
    /// <p>Deletes the specified scaling policy.</p>
    /// <p>Deleting either a step scaling policy or a simple scaling policy deletes the underlying alarm action, but does not delete the alarm, even if it no longer has an associated action.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/deleting-scaling-policy.html">Deleting a scaling policy</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DeletePolicy {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::delete_policy_input::Builder,
    }
    impl DeletePolicy {
        /// Creates a new `DeletePolicy`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeletePolicyOutput,
            aws_smithy_http::result::SdkError<crate::error::DeletePolicyError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The name or Amazon Resource Name (ARN) of the policy.</p>
        pub fn policy_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.policy_name(input.into());
            self
        }
        /// <p>The name or Amazon Resource Name (ARN) of the policy.</p>
        pub fn set_policy_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_policy_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DeleteScheduledAction`.
    ///
    /// <p>Deletes the specified scheduled action.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DeleteScheduledAction {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::delete_scheduled_action_input::Builder,
    }
    impl DeleteScheduledAction {
        /// Creates a new `DeleteScheduledAction`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteScheduledActionOutput,
            aws_smithy_http::result::SdkError<crate::error::DeleteScheduledActionError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The name of the action to delete.</p>
        pub fn scheduled_action_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.scheduled_action_name(input.into());
            self
        }
        /// <p>The name of the action to delete.</p>
        pub fn set_scheduled_action_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_scheduled_action_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DeleteTags`.
    ///
    /// <p>Deletes the specified tags.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DeleteTags {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::delete_tags_input::Builder,
    }
    impl DeleteTags {
        /// Creates a new `DeleteTags`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteTagsOutput,
            aws_smithy_http::result::SdkError<crate::error::DeleteTagsError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Appends an item to `Tags`.
        ///
        /// To override the contents of this collection use [`set_tags`](Self::set_tags).
        ///
        /// <p>One or more tags.</p>
        pub fn tags(mut self, input: crate::model::Tag) -> Self {
            self.inner = self.inner.tags(input);
            self
        }
        /// <p>One or more tags.</p>
        pub fn set_tags(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Tag>>,
        ) -> Self {
            self.inner = self.inner.set_tags(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DeleteWarmPool`.
    ///
    /// <p>Deletes the warm pool for the specified Auto Scaling group.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-warm-pools.html">Warm pools for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DeleteWarmPool {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::delete_warm_pool_input::Builder,
    }
    impl DeleteWarmPool {
        /// Creates a new `DeleteWarmPool`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DeleteWarmPoolOutput,
            aws_smithy_http::result::SdkError<crate::error::DeleteWarmPoolError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>Specifies that the warm pool is to be deleted along with all of its associated instances, without waiting for all instances to be terminated. This parameter also deletes any outstanding lifecycle actions associated with the warm pool instances.</p>
        pub fn force_delete(mut self, input: bool) -> Self {
            self.inner = self.inner.force_delete(input);
            self
        }
        /// <p>Specifies that the warm pool is to be deleted along with all of its associated instances, without waiting for all instances to be terminated. This parameter also deletes any outstanding lifecycle actions associated with the warm pool instances.</p>
        pub fn set_force_delete(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_force_delete(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeAccountLimits`.
    ///
    /// <p>Describes the current Amazon EC2 Auto Scaling resource quotas for your account.</p>
    /// <p>When you establish an Amazon Web Services account, the account has initial quotas on the maximum number of Auto Scaling groups and launch configurations that you can create in a given Region. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-account-limits.html">Amazon EC2 Auto Scaling service quotas</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeAccountLimits {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_account_limits_input::Builder,
    }
    impl DescribeAccountLimits {
        /// Creates a new `DescribeAccountLimits`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeAccountLimitsOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeAccountLimitsError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
    }
    /// Fluent builder constructing a request to `DescribeAdjustmentTypes`.
    ///
    /// <p>Describes the available adjustment types for step scaling and simple scaling policies.</p>
    /// <p>The following adjustment types are supported:</p>
    /// <ul>
    /// <li> <p> <code>ChangeInCapacity</code> </p> </li>
    /// <li> <p> <code>ExactCapacity</code> </p> </li>
    /// <li> <p> <code>PercentChangeInCapacity</code> </p> </li>
    /// </ul>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeAdjustmentTypes {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_adjustment_types_input::Builder,
    }
    impl DescribeAdjustmentTypes {
        /// Creates a new `DescribeAdjustmentTypes`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeAdjustmentTypesOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeAdjustmentTypesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
    }
    /// Fluent builder constructing a request to `DescribeAutoScalingGroups`.
    ///
    /// <p>Gets information about the Auto Scaling groups in the account and Region.</p>
    /// <p>If you specify Auto Scaling group names, the output includes information for only the specified Auto Scaling groups. If you specify filters, the output includes information for only those Auto Scaling groups that meet the filter criteria. If you do not specify group names or filters, the output includes information for all Auto Scaling groups. </p>
    /// <p>This operation also returns information about instances in Auto Scaling groups. To retrieve information about the instances in a warm pool, you must call the <code>DescribeWarmPool</code> API. </p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeAutoScalingGroups {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_auto_scaling_groups_input::Builder,
    }
    impl DescribeAutoScalingGroups {
        /// Creates a new `DescribeAutoScalingGroups`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeAutoScalingGroupsOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeAutoScalingGroupsError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Create a paginator for this request
        ///
        /// Paginators are used by calling [`send().await`](crate::paginator::DescribeAutoScalingGroupsPaginator::send) which returns a [`Stream`](tokio_stream::Stream).
        pub fn into_paginator(self) -> crate::paginator::DescribeAutoScalingGroupsPaginator {
            crate::paginator::DescribeAutoScalingGroupsPaginator::new(self.handle, self.inner)
        }
        /// Appends an item to `AutoScalingGroupNames`.
        ///
        /// To override the contents of this collection use [`set_auto_scaling_group_names`](Self::set_auto_scaling_group_names).
        ///
        /// <p>The names of the Auto Scaling groups. By default, you can only specify up to 50 names. You can optionally increase this limit using the <code>MaxRecords</code> parameter.</p>
        /// <p>If you omit this parameter, all Auto Scaling groups are described.</p>
        pub fn auto_scaling_group_names(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_names(input.into());
            self
        }
        /// <p>The names of the Auto Scaling groups. By default, you can only specify up to 50 names. You can optionally increase this limit using the <code>MaxRecords</code> parameter.</p>
        /// <p>If you omit this parameter, all Auto Scaling groups are described.</p>
        pub fn set_auto_scaling_group_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_names(input);
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
        /// Appends an item to `Filters`.
        ///
        /// To override the contents of this collection use [`set_filters`](Self::set_filters).
        ///
        /// <p>One or more filters to limit the results based on specific tags. </p>
        pub fn filters(mut self, input: crate::model::Filter) -> Self {
            self.inner = self.inner.filters(input);
            self
        }
        /// <p>One or more filters to limit the results based on specific tags. </p>
        pub fn set_filters(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Filter>>,
        ) -> Self {
            self.inner = self.inner.set_filters(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeAutoScalingInstances`.
    ///
    /// <p>Gets information about the Auto Scaling instances in the account and Region.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeAutoScalingInstances {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_auto_scaling_instances_input::Builder,
    }
    impl DescribeAutoScalingInstances {
        /// Creates a new `DescribeAutoScalingInstances`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeAutoScalingInstancesOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeAutoScalingInstancesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Create a paginator for this request
        ///
        /// Paginators are used by calling [`send().await`](crate::paginator::DescribeAutoScalingInstancesPaginator::send) which returns a [`Stream`](tokio_stream::Stream).
        pub fn into_paginator(self) -> crate::paginator::DescribeAutoScalingInstancesPaginator {
            crate::paginator::DescribeAutoScalingInstancesPaginator::new(self.handle, self.inner)
        }
        /// Appends an item to `InstanceIds`.
        ///
        /// To override the contents of this collection use [`set_instance_ids`](Self::set_instance_ids).
        ///
        /// <p>The IDs of the instances. If you omit this parameter, all Auto Scaling instances are described. If you specify an ID that does not exist, it is ignored with no error.</p>
        /// <p>Array Members: Maximum number of 50 items.</p>
        pub fn instance_ids(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_ids(input.into());
            self
        }
        /// <p>The IDs of the instances. If you omit this parameter, all Auto Scaling instances are described. If you specify an ID that does not exist, it is ignored with no error.</p>
        /// <p>Array Members: Maximum number of 50 items.</p>
        pub fn set_instance_ids(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_instance_ids(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>50</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>50</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeAutoScalingNotificationTypes`.
    ///
    /// <p>Describes the notification types that are supported by Amazon EC2 Auto Scaling.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeAutoScalingNotificationTypes {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_auto_scaling_notification_types_input::Builder,
    }
    impl DescribeAutoScalingNotificationTypes {
        /// Creates a new `DescribeAutoScalingNotificationTypes`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeAutoScalingNotificationTypesOutput,
            aws_smithy_http::result::SdkError<
                crate::error::DescribeAutoScalingNotificationTypesError,
            >,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
    }
    /// Fluent builder constructing a request to `DescribeInstanceRefreshes`.
    ///
    /// <p>Gets information about the instance refreshes for the specified Auto Scaling group.</p>
    /// <p>This operation is part of the <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-instance-refresh.html">instance refresh feature</a> in Amazon EC2 Auto Scaling, which helps you update instances in your Auto Scaling group after you make configuration changes.</p>
    /// <p>To help you determine the status of an instance refresh, this operation returns information about the instance refreshes you previously initiated, including their status, end time, the percentage of the instance refresh that is complete, and the number of instances remaining to update before the instance refresh is complete.</p>
    /// <p>The following are the possible statuses: </p>
    /// <ul>
    /// <li> <p> <code>Pending</code> - The request was created, but the operation has not started.</p> </li>
    /// <li> <p> <code>InProgress</code> - The operation is in progress.</p> </li>
    /// <li> <p> <code>Successful</code> - The operation completed successfully.</p> </li>
    /// <li> <p> <code>Failed</code> - The operation failed to complete. You can troubleshoot using the status reason and the scaling activities. </p> </li>
    /// <li> <p> <code>Cancelling</code> - An ongoing operation is being cancelled. Cancellation does not roll back any replacements that have already been completed, but it prevents new replacements from being started. </p> </li>
    /// <li> <p> <code>Cancelled</code> - The operation is cancelled. </p> </li>
    /// </ul>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeInstanceRefreshes {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_instance_refreshes_input::Builder,
    }
    impl DescribeInstanceRefreshes {
        /// Creates a new `DescribeInstanceRefreshes`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeInstanceRefreshesOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeInstanceRefreshesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `InstanceRefreshIds`.
        ///
        /// To override the contents of this collection use [`set_instance_refresh_ids`](Self::set_instance_refresh_ids).
        ///
        /// <p>One or more instance refresh IDs.</p>
        pub fn instance_refresh_ids(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_refresh_ids(input.into());
            self
        }
        /// <p>One or more instance refresh IDs.</p>
        pub fn set_instance_refresh_ids(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_instance_refresh_ids(input);
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeLaunchConfigurations`.
    ///
    /// <p>Gets information about the launch configurations in the account and Region.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeLaunchConfigurations {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_launch_configurations_input::Builder,
    }
    impl DescribeLaunchConfigurations {
        /// Creates a new `DescribeLaunchConfigurations`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeLaunchConfigurationsOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeLaunchConfigurationsError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Create a paginator for this request
        ///
        /// Paginators are used by calling [`send().await`](crate::paginator::DescribeLaunchConfigurationsPaginator::send) which returns a [`Stream`](tokio_stream::Stream).
        pub fn into_paginator(self) -> crate::paginator::DescribeLaunchConfigurationsPaginator {
            crate::paginator::DescribeLaunchConfigurationsPaginator::new(self.handle, self.inner)
        }
        /// Appends an item to `LaunchConfigurationNames`.
        ///
        /// To override the contents of this collection use [`set_launch_configuration_names`](Self::set_launch_configuration_names).
        ///
        /// <p>The launch configuration names. If you omit this parameter, all launch configurations are described.</p>
        /// <p>Array Members: Maximum number of 50 items.</p>
        pub fn launch_configuration_names(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.launch_configuration_names(input.into());
            self
        }
        /// <p>The launch configuration names. If you omit this parameter, all launch configurations are described.</p>
        /// <p>Array Members: Maximum number of 50 items.</p>
        pub fn set_launch_configuration_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_launch_configuration_names(input);
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeLifecycleHooks`.
    ///
    /// <p>Gets information about the lifecycle hooks for the specified Auto Scaling group.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeLifecycleHooks {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_lifecycle_hooks_input::Builder,
    }
    impl DescribeLifecycleHooks {
        /// Creates a new `DescribeLifecycleHooks`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeLifecycleHooksOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeLifecycleHooksError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `LifecycleHookNames`.
        ///
        /// To override the contents of this collection use [`set_lifecycle_hook_names`](Self::set_lifecycle_hook_names).
        ///
        /// <p>The names of one or more lifecycle hooks. If you omit this parameter, all lifecycle hooks are described.</p>
        pub fn lifecycle_hook_names(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.lifecycle_hook_names(input.into());
            self
        }
        /// <p>The names of one or more lifecycle hooks. If you omit this parameter, all lifecycle hooks are described.</p>
        pub fn set_lifecycle_hook_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_lifecycle_hook_names(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeLifecycleHookTypes`.
    ///
    /// <p>Describes the available types of lifecycle hooks.</p>
    /// <p>The following hook types are supported:</p>
    /// <ul>
    /// <li> <p> <code>autoscaling:EC2_INSTANCE_LAUNCHING</code> </p> </li>
    /// <li> <p> <code>autoscaling:EC2_INSTANCE_TERMINATING</code> </p> </li>
    /// </ul>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeLifecycleHookTypes {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_lifecycle_hook_types_input::Builder,
    }
    impl DescribeLifecycleHookTypes {
        /// Creates a new `DescribeLifecycleHookTypes`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeLifecycleHookTypesOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeLifecycleHookTypesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
    }
    /// Fluent builder constructing a request to `DescribeLoadBalancers`.
    ///
    /// <p>Gets information about the load balancers for the specified Auto Scaling group.</p>
    /// <p>This operation describes only Classic Load Balancers. If you have Application Load Balancers, Network Load Balancers, or Gateway Load Balancers, use the <code>DescribeLoadBalancerTargetGroups</code> API instead.</p>
    /// <p>To determine the availability of registered instances, use the <code>State</code> element in the response. When you attach a load balancer to an Auto Scaling group, the initial <code>State</code> value is <code>Adding</code>. The state transitions to <code>Added</code> after all Auto Scaling instances are registered with the load balancer. If Elastic Load Balancing health checks are enabled for the Auto Scaling group, the state transitions to <code>InService</code> after at least one Auto Scaling instance passes the health check. When the load balancer is in the <code>InService</code> state, Amazon EC2 Auto Scaling can terminate and replace any instances that are reported as unhealthy. If no registered instances pass the health checks, the load balancer doesn't enter the <code>InService</code> state. </p>
    /// <p>Load balancers also have an <code>InService</code> state if you attach them in the <code>CreateAutoScalingGroup</code> API call. If your load balancer state is <code>InService</code>, but it is not working properly, check the scaling activities by calling <code>DescribeScalingActivities</code> and take any corrective actions necessary.</p>
    /// <p>For help with failed health checks, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ts-as-healthchecks.html">Troubleshooting Amazon EC2 Auto Scaling: Health checks</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html">Elastic Load Balancing and Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeLoadBalancers {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_load_balancers_input::Builder,
    }
    impl DescribeLoadBalancers {
        /// Creates a new `DescribeLoadBalancers`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeLoadBalancersOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeLoadBalancersError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>100</code> and the maximum value is <code>100</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>100</code> and the maximum value is <code>100</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeLoadBalancerTargetGroups`.
    ///
    /// <p>Gets information about the load balancer target groups for the specified Auto Scaling group.</p>
    /// <p>To determine the availability of registered instances, use the <code>State</code> element in the response. When you attach a target group to an Auto Scaling group, the initial <code>State</code> value is <code>Adding</code>. The state transitions to <code>Added</code> after all Auto Scaling instances are registered with the target group. If Elastic Load Balancing health checks are enabled for the Auto Scaling group, the state transitions to <code>InService</code> after at least one Auto Scaling instance passes the health check. When the target group is in the <code>InService</code> state, Amazon EC2 Auto Scaling can terminate and replace any instances that are reported as unhealthy. If no registered instances pass the health checks, the target group doesn't enter the <code>InService</code> state. </p>
    /// <p>Target groups also have an <code>InService</code> state if you attach them in the <code>CreateAutoScalingGroup</code> API call. If your target group state is <code>InService</code>, but it is not working properly, check the scaling activities by calling <code>DescribeScalingActivities</code> and take any corrective actions necessary.</p>
    /// <p>For help with failed health checks, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ts-as-healthchecks.html">Troubleshooting Amazon EC2 Auto Scaling: Health checks</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html">Elastic Load Balancing and Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeLoadBalancerTargetGroups {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_load_balancer_target_groups_input::Builder,
    }
    impl DescribeLoadBalancerTargetGroups {
        /// Creates a new `DescribeLoadBalancerTargetGroups`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeLoadBalancerTargetGroupsOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeLoadBalancerTargetGroupsError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>100</code> and the maximum value is <code>100</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>100</code> and the maximum value is <code>100</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeMetricCollectionTypes`.
    ///
    /// <p>Describes the available CloudWatch metrics for Amazon EC2 Auto Scaling.</p>
    /// <p>The <code>GroupStandbyInstances</code> metric is not returned by default. You must explicitly request this metric when calling the <code>EnableMetricsCollection</code> API.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeMetricCollectionTypes {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_metric_collection_types_input::Builder,
    }
    impl DescribeMetricCollectionTypes {
        /// Creates a new `DescribeMetricCollectionTypes`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeMetricCollectionTypesOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeMetricCollectionTypesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
    }
    /// Fluent builder constructing a request to `DescribeNotificationConfigurations`.
    ///
    /// <p>Gets information about the Amazon SNS notifications that are configured for one or more Auto Scaling groups.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeNotificationConfigurations {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_notification_configurations_input::Builder,
    }
    impl DescribeNotificationConfigurations {
        /// Creates a new `DescribeNotificationConfigurations`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeNotificationConfigurationsOutput,
            aws_smithy_http::result::SdkError<
                crate::error::DescribeNotificationConfigurationsError,
            >,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Create a paginator for this request
        ///
        /// Paginators are used by calling [`send().await`](crate::paginator::DescribeNotificationConfigurationsPaginator::send) which returns a [`Stream`](tokio_stream::Stream).
        pub fn into_paginator(
            self,
        ) -> crate::paginator::DescribeNotificationConfigurationsPaginator {
            crate::paginator::DescribeNotificationConfigurationsPaginator::new(
                self.handle,
                self.inner,
            )
        }
        /// Appends an item to `AutoScalingGroupNames`.
        ///
        /// To override the contents of this collection use [`set_auto_scaling_group_names`](Self::set_auto_scaling_group_names).
        ///
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_names(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_names(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_names(input);
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribePolicies`.
    ///
    /// <p>Gets information about the scaling policies in the account and Region.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribePolicies {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_policies_input::Builder,
    }
    impl DescribePolicies {
        /// Creates a new `DescribePolicies`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribePoliciesOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribePoliciesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Create a paginator for this request
        ///
        /// Paginators are used by calling [`send().await`](crate::paginator::DescribePoliciesPaginator::send) which returns a [`Stream`](tokio_stream::Stream).
        pub fn into_paginator(self) -> crate::paginator::DescribePoliciesPaginator {
            crate::paginator::DescribePoliciesPaginator::new(self.handle, self.inner)
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `PolicyNames`.
        ///
        /// To override the contents of this collection use [`set_policy_names`](Self::set_policy_names).
        ///
        /// <p>The names of one or more policies. If you omit this parameter, all policies are described. If a group name is provided, the results are limited to that group. If you specify an unknown policy name, it is ignored with no error.</p>
        /// <p>Array Members: Maximum number of 50 items.</p>
        pub fn policy_names(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.policy_names(input.into());
            self
        }
        /// <p>The names of one or more policies. If you omit this parameter, all policies are described. If a group name is provided, the results are limited to that group. If you specify an unknown policy name, it is ignored with no error.</p>
        /// <p>Array Members: Maximum number of 50 items.</p>
        pub fn set_policy_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_policy_names(input);
            self
        }
        /// Appends an item to `PolicyTypes`.
        ///
        /// To override the contents of this collection use [`set_policy_types`](Self::set_policy_types).
        ///
        /// <p>One or more policy types. The valid values are <code>SimpleScaling</code>, <code>StepScaling</code>, <code>TargetTrackingScaling</code>, and <code>PredictiveScaling</code>.</p>
        pub fn policy_types(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.policy_types(input.into());
            self
        }
        /// <p>One or more policy types. The valid values are <code>SimpleScaling</code>, <code>StepScaling</code>, <code>TargetTrackingScaling</code>, and <code>PredictiveScaling</code>.</p>
        pub fn set_policy_types(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_policy_types(input);
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>The maximum number of items to be returned with each call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of items to be returned with each call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeScalingActivities`.
    ///
    /// <p>Gets information about the scaling activities in the account and Region.</p>
    /// <p>When scaling events occur, you see a record of the scaling activity in the scaling activities. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-verify-scaling-activity.html">Verifying a scaling activity for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>If the scaling event succeeds, the value of the <code>StatusCode</code> element in the response is <code>Successful</code>. If an attempt to launch instances failed, the <code>StatusCode</code> value is <code>Failed</code> or <code>Cancelled</code> and the <code>StatusMessage</code> element in the response indicates the cause of the failure. For help interpreting the <code>StatusMessage</code>, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/CHAP_Troubleshooting.html">Troubleshooting Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>. </p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeScalingActivities {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_scaling_activities_input::Builder,
    }
    impl DescribeScalingActivities {
        /// Creates a new `DescribeScalingActivities`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeScalingActivitiesOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeScalingActivitiesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Create a paginator for this request
        ///
        /// Paginators are used by calling [`send().await`](crate::paginator::DescribeScalingActivitiesPaginator::send) which returns a [`Stream`](tokio_stream::Stream).
        pub fn into_paginator(self) -> crate::paginator::DescribeScalingActivitiesPaginator {
            crate::paginator::DescribeScalingActivitiesPaginator::new(self.handle, self.inner)
        }
        /// Appends an item to `ActivityIds`.
        ///
        /// To override the contents of this collection use [`set_activity_ids`](Self::set_activity_ids).
        ///
        /// <p>The activity IDs of the desired scaling activities. If you omit this parameter, all activities for the past six weeks are described. If unknown activities are requested, they are ignored with no error. If you specify an Auto Scaling group, the results are limited to that group.</p>
        /// <p>Array Members: Maximum number of 50 IDs.</p>
        pub fn activity_ids(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.activity_ids(input.into());
            self
        }
        /// <p>The activity IDs of the desired scaling activities. If you omit this parameter, all activities for the past six weeks are described. If unknown activities are requested, they are ignored with no error. If you specify an Auto Scaling group, the results are limited to that group.</p>
        /// <p>Array Members: Maximum number of 50 IDs.</p>
        pub fn set_activity_ids(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_activity_ids(input);
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>Indicates whether to include scaling activity from deleted Auto Scaling groups.</p>
        pub fn include_deleted_groups(mut self, input: bool) -> Self {
            self.inner = self.inner.include_deleted_groups(input);
            self
        }
        /// <p>Indicates whether to include scaling activity from deleted Auto Scaling groups.</p>
        pub fn set_include_deleted_groups(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_include_deleted_groups(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>100</code> and the maximum value is <code>100</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>100</code> and the maximum value is <code>100</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeScalingProcessTypes`.
    ///
    /// <p>Describes the scaling process types for use with the <code>ResumeProcesses</code> and <code>SuspendProcesses</code> APIs.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeScalingProcessTypes {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_scaling_process_types_input::Builder,
    }
    impl DescribeScalingProcessTypes {
        /// Creates a new `DescribeScalingProcessTypes`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeScalingProcessTypesOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeScalingProcessTypesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
    }
    /// Fluent builder constructing a request to `DescribeScheduledActions`.
    ///
    /// <p>Gets information about the scheduled actions that haven't run or that have not reached their end time.</p>
    /// <p>To describe the scaling activities for scheduled actions that have already run, call the <code>DescribeScalingActivities</code> API.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeScheduledActions {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_scheduled_actions_input::Builder,
    }
    impl DescribeScheduledActions {
        /// Creates a new `DescribeScheduledActions`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeScheduledActionsOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeScheduledActionsError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Create a paginator for this request
        ///
        /// Paginators are used by calling [`send().await`](crate::paginator::DescribeScheduledActionsPaginator::send) which returns a [`Stream`](tokio_stream::Stream).
        pub fn into_paginator(self) -> crate::paginator::DescribeScheduledActionsPaginator {
            crate::paginator::DescribeScheduledActionsPaginator::new(self.handle, self.inner)
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `ScheduledActionNames`.
        ///
        /// To override the contents of this collection use [`set_scheduled_action_names`](Self::set_scheduled_action_names).
        ///
        /// <p>The names of one or more scheduled actions. If you omit this parameter, all scheduled actions are described. If you specify an unknown scheduled action, it is ignored with no error.</p>
        /// <p>Array Members: Maximum number of 50 actions.</p>
        pub fn scheduled_action_names(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.scheduled_action_names(input.into());
            self
        }
        /// <p>The names of one or more scheduled actions. If you omit this parameter, all scheduled actions are described. If you specify an unknown scheduled action, it is ignored with no error.</p>
        /// <p>Array Members: Maximum number of 50 actions.</p>
        pub fn set_scheduled_action_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_scheduled_action_names(input);
            self
        }
        /// <p>The earliest scheduled start time to return. If scheduled action names are provided, this parameter is ignored.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.inner = self.inner.start_time(input);
            self
        }
        /// <p>The earliest scheduled start time to return. If scheduled action names are provided, this parameter is ignored.</p>
        pub fn set_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.inner = self.inner.set_start_time(input);
            self
        }
        /// <p>The latest scheduled start time to return. If scheduled action names are provided, this parameter is ignored.</p>
        pub fn end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.inner = self.inner.end_time(input);
            self
        }
        /// <p>The latest scheduled start time to return. If scheduled action names are provided, this parameter is ignored.</p>
        pub fn set_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.inner = self.inner.set_end_time(input);
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeTags`.
    ///
    /// <p>Describes the specified tags.</p>
    /// <p>You can use filters to limit the results. For example, you can query for the tags for a specific Auto Scaling group. You can specify multiple values for a filter. A tag must match at least one of the specified values for it to be included in the results.</p>
    /// <p>You can also specify multiple filters. The result includes information for a particular tag only if it matches all the filters. If there's no match, no special message is returned.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-tagging.html">Tagging Auto Scaling groups and instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeTags {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_tags_input::Builder,
    }
    impl DescribeTags {
        /// Creates a new `DescribeTags`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeTagsOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeTagsError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Create a paginator for this request
        ///
        /// Paginators are used by calling [`send().await`](crate::paginator::DescribeTagsPaginator::send) which returns a [`Stream`](tokio_stream::Stream).
        pub fn into_paginator(self) -> crate::paginator::DescribeTagsPaginator {
            crate::paginator::DescribeTagsPaginator::new(self.handle, self.inner)
        }
        /// Appends an item to `Filters`.
        ///
        /// To override the contents of this collection use [`set_filters`](Self::set_filters).
        ///
        /// <p>One or more filters to scope the tags to return. The maximum number of filters per filter type (for example, <code>auto-scaling-group</code>) is 1000.</p>
        pub fn filters(mut self, input: crate::model::Filter) -> Self {
            self.inner = self.inner.filters(input);
            self
        }
        /// <p>One or more filters to scope the tags to return. The maximum number of filters per filter type (for example, <code>auto-scaling-group</code>) is 1000.</p>
        pub fn set_filters(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::Filter>>,
        ) -> Self {
            self.inner = self.inner.set_filters(input);
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of items to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of items to return with this call. The default value is <code>50</code> and the maximum value is <code>100</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DescribeTerminationPolicyTypes`.
    ///
    /// <p>Describes the termination policies supported by Amazon EC2 Auto Scaling.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html">Controlling which Auto Scaling instances terminate during scale in</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeTerminationPolicyTypes {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_termination_policy_types_input::Builder,
    }
    impl DescribeTerminationPolicyTypes {
        /// Creates a new `DescribeTerminationPolicyTypes`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeTerminationPolicyTypesOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeTerminationPolicyTypesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
    }
    /// Fluent builder constructing a request to `DescribeWarmPool`.
    ///
    /// <p>Gets information about a warm pool and its instances.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-warm-pools.html">Warm pools for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DescribeWarmPool {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::describe_warm_pool_input::Builder,
    }
    impl DescribeWarmPool {
        /// Creates a new `DescribeWarmPool`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DescribeWarmPoolOutput,
            aws_smithy_http::result::SdkError<crate::error::DescribeWarmPoolError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The maximum number of instances to return with this call. The maximum value is <code>50</code>.</p>
        pub fn max_records(mut self, input: i32) -> Self {
            self.inner = self.inner.max_records(input);
            self
        }
        /// <p>The maximum number of instances to return with this call. The maximum value is <code>50</code>.</p>
        pub fn set_max_records(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_records(input);
            self
        }
        /// <p>The token for the next set of instances to return. (You received this token from a previous call.)</p>
        pub fn next_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.next_token(input.into());
            self
        }
        /// <p>The token for the next set of instances to return. (You received this token from a previous call.)</p>
        pub fn set_next_token(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_next_token(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DetachInstances`.
    ///
    /// <p>Removes one or more instances from the specified Auto Scaling group.</p>
    /// <p>After the instances are detached, you can manage them independent of the Auto Scaling group.</p>
    /// <p>If you do not specify the option to decrement the desired capacity, Amazon EC2 Auto Scaling launches instances to replace the ones that are detached.</p>
    /// <p>If there is a Classic Load Balancer attached to the Auto Scaling group, the instances are deregistered from the load balancer. If there are target groups attached to the Auto Scaling group, the instances are deregistered from the target groups.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/detach-instance-asg.html">Detach EC2 instances from your Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DetachInstances {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::detach_instances_input::Builder,
    }
    impl DetachInstances {
        /// Creates a new `DetachInstances`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DetachInstancesOutput,
            aws_smithy_http::result::SdkError<crate::error::DetachInstancesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Appends an item to `InstanceIds`.
        ///
        /// To override the contents of this collection use [`set_instance_ids`](Self::set_instance_ids).
        ///
        /// <p>The IDs of the instances. You can specify up to 20 instances.</p>
        pub fn instance_ids(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_ids(input.into());
            self
        }
        /// <p>The IDs of the instances. You can specify up to 20 instances.</p>
        pub fn set_instance_ids(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_instance_ids(input);
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>Indicates whether the Auto Scaling group decrements the desired capacity value by the number of instances detached.</p>
        pub fn should_decrement_desired_capacity(mut self, input: bool) -> Self {
            self.inner = self.inner.should_decrement_desired_capacity(input);
            self
        }
        /// <p>Indicates whether the Auto Scaling group decrements the desired capacity value by the number of instances detached.</p>
        pub fn set_should_decrement_desired_capacity(
            mut self,
            input: std::option::Option<bool>,
        ) -> Self {
            self.inner = self.inner.set_should_decrement_desired_capacity(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DetachLoadBalancers`.
    ///
    /// <p>Detaches one or more Classic Load Balancers from the specified Auto Scaling group.</p>
    /// <p>This operation detaches only Classic Load Balancers. If you have Application Load Balancers, Network Load Balancers, or Gateway Load Balancers, use the <code>DetachLoadBalancerTargetGroups</code> API instead.</p>
    /// <p>When you detach a load balancer, it enters the <code>Removing</code> state while deregistering the instances in the group. When all instances are deregistered, then you can no longer describe the load balancer using the <code>DescribeLoadBalancers</code> API call. The instances remain running.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DetachLoadBalancers {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::detach_load_balancers_input::Builder,
    }
    impl DetachLoadBalancers {
        /// Creates a new `DetachLoadBalancers`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DetachLoadBalancersOutput,
            aws_smithy_http::result::SdkError<crate::error::DetachLoadBalancersError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `LoadBalancerNames`.
        ///
        /// To override the contents of this collection use [`set_load_balancer_names`](Self::set_load_balancer_names).
        ///
        /// <p>The names of the load balancers. You can specify up to 10 load balancers.</p>
        pub fn load_balancer_names(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.load_balancer_names(input.into());
            self
        }
        /// <p>The names of the load balancers. You can specify up to 10 load balancers.</p>
        pub fn set_load_balancer_names(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_load_balancer_names(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DetachLoadBalancerTargetGroups`.
    ///
    /// <p>Detaches one or more target groups from the specified Auto Scaling group.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DetachLoadBalancerTargetGroups {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::detach_load_balancer_target_groups_input::Builder,
    }
    impl DetachLoadBalancerTargetGroups {
        /// Creates a new `DetachLoadBalancerTargetGroups`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DetachLoadBalancerTargetGroupsOutput,
            aws_smithy_http::result::SdkError<crate::error::DetachLoadBalancerTargetGroupsError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `TargetGroupARNs`.
        ///
        /// To override the contents of this collection use [`set_target_group_ar_ns`](Self::set_target_group_ar_ns).
        ///
        /// <p>The Amazon Resource Names (ARN) of the target groups. You can specify up to 10 target groups.</p>
        pub fn target_group_ar_ns(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.target_group_ar_ns(input.into());
            self
        }
        /// <p>The Amazon Resource Names (ARN) of the target groups. You can specify up to 10 target groups.</p>
        pub fn set_target_group_ar_ns(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_target_group_ar_ns(input);
            self
        }
    }
    /// Fluent builder constructing a request to `DisableMetricsCollection`.
    ///
    /// <p>Disables group metrics for the specified Auto Scaling group.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct DisableMetricsCollection {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::disable_metrics_collection_input::Builder,
    }
    impl DisableMetricsCollection {
        /// Creates a new `DisableMetricsCollection`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::DisableMetricsCollectionOutput,
            aws_smithy_http::result::SdkError<crate::error::DisableMetricsCollectionError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `Metrics`.
        ///
        /// To override the contents of this collection use [`set_metrics`](Self::set_metrics).
        ///
        /// <p>Specifies one or more of the following metrics:</p>
        /// <ul>
        /// <li> <p> <code>GroupMinSize</code> </p> </li>
        /// <li> <p> <code>GroupMaxSize</code> </p> </li>
        /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>GroupInServiceInstances</code> </p> </li>
        /// <li> <p> <code>GroupPendingInstances</code> </p> </li>
        /// <li> <p> <code>GroupStandbyInstances</code> </p> </li>
        /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li>
        /// <li> <p> <code>GroupTotalInstances</code> </p> </li>
        /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li>
        /// <li> <p> <code>GroupPendingCapacity</code> </p> </li>
        /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li>
        /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li>
        /// <li> <p> <code>GroupTotalCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li>
        /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li>
        /// </ul>
        /// <p>If you omit this parameter, all metrics are disabled. </p>
        pub fn metrics(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.metrics(input.into());
            self
        }
        /// <p>Specifies one or more of the following metrics:</p>
        /// <ul>
        /// <li> <p> <code>GroupMinSize</code> </p> </li>
        /// <li> <p> <code>GroupMaxSize</code> </p> </li>
        /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>GroupInServiceInstances</code> </p> </li>
        /// <li> <p> <code>GroupPendingInstances</code> </p> </li>
        /// <li> <p> <code>GroupStandbyInstances</code> </p> </li>
        /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li>
        /// <li> <p> <code>GroupTotalInstances</code> </p> </li>
        /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li>
        /// <li> <p> <code>GroupPendingCapacity</code> </p> </li>
        /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li>
        /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li>
        /// <li> <p> <code>GroupTotalCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li>
        /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li>
        /// </ul>
        /// <p>If you omit this parameter, all metrics are disabled. </p>
        pub fn set_metrics(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_metrics(input);
            self
        }
    }
    /// Fluent builder constructing a request to `EnableMetricsCollection`.
    ///
    /// <p>Enables group metrics for the specified Auto Scaling group. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-monitoring.html">Monitoring CloudWatch metrics for your Auto Scaling groups and instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct EnableMetricsCollection {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::enable_metrics_collection_input::Builder,
    }
    impl EnableMetricsCollection {
        /// Creates a new `EnableMetricsCollection`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::EnableMetricsCollectionOutput,
            aws_smithy_http::result::SdkError<crate::error::EnableMetricsCollectionError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `Metrics`.
        ///
        /// To override the contents of this collection use [`set_metrics`](Self::set_metrics).
        ///
        /// <p>Specifies which group-level metrics to start collecting. You can specify one or more of the following metrics:</p>
        /// <ul>
        /// <li> <p> <code>GroupMinSize</code> </p> </li>
        /// <li> <p> <code>GroupMaxSize</code> </p> </li>
        /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>GroupInServiceInstances</code> </p> </li>
        /// <li> <p> <code>GroupPendingInstances</code> </p> </li>
        /// <li> <p> <code>GroupStandbyInstances</code> </p> </li>
        /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li>
        /// <li> <p> <code>GroupTotalInstances</code> </p> </li>
        /// </ul>
        /// <p>The instance weighting feature supports the following additional metrics: </p>
        /// <ul>
        /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li>
        /// <li> <p> <code>GroupPendingCapacity</code> </p> </li>
        /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li>
        /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li>
        /// <li> <p> <code>GroupTotalCapacity</code> </p> </li>
        /// </ul>
        /// <p>The warm pools feature supports the following additional metrics: </p>
        /// <ul>
        /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li>
        /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li>
        /// </ul>
        /// <p>If you omit this parameter, all metrics are enabled. </p>
        pub fn metrics(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.metrics(input.into());
            self
        }
        /// <p>Specifies which group-level metrics to start collecting. You can specify one or more of the following metrics:</p>
        /// <ul>
        /// <li> <p> <code>GroupMinSize</code> </p> </li>
        /// <li> <p> <code>GroupMaxSize</code> </p> </li>
        /// <li> <p> <code>GroupDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>GroupInServiceInstances</code> </p> </li>
        /// <li> <p> <code>GroupPendingInstances</code> </p> </li>
        /// <li> <p> <code>GroupStandbyInstances</code> </p> </li>
        /// <li> <p> <code>GroupTerminatingInstances</code> </p> </li>
        /// <li> <p> <code>GroupTotalInstances</code> </p> </li>
        /// </ul>
        /// <p>The instance weighting feature supports the following additional metrics: </p>
        /// <ul>
        /// <li> <p> <code>GroupInServiceCapacity</code> </p> </li>
        /// <li> <p> <code>GroupPendingCapacity</code> </p> </li>
        /// <li> <p> <code>GroupStandbyCapacity</code> </p> </li>
        /// <li> <p> <code>GroupTerminatingCapacity</code> </p> </li>
        /// <li> <p> <code>GroupTotalCapacity</code> </p> </li>
        /// </ul>
        /// <p>The warm pools feature supports the following additional metrics: </p>
        /// <ul>
        /// <li> <p> <code>WarmPoolDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolWarmedCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolPendingCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolTerminatingCapacity</code> </p> </li>
        /// <li> <p> <code>WarmPoolTotalCapacity</code> </p> </li>
        /// <li> <p> <code>GroupAndWarmPoolDesiredCapacity</code> </p> </li>
        /// <li> <p> <code>GroupAndWarmPoolTotalCapacity</code> </p> </li>
        /// </ul>
        /// <p>If you omit this parameter, all metrics are enabled. </p>
        pub fn set_metrics(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_metrics(input);
            self
        }
        /// <p>The granularity to associate with the metrics to collect. The only valid value is <code>1Minute</code>.</p>
        pub fn granularity(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.granularity(input.into());
            self
        }
        /// <p>The granularity to associate with the metrics to collect. The only valid value is <code>1Minute</code>.</p>
        pub fn set_granularity(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_granularity(input);
            self
        }
    }
    /// Fluent builder constructing a request to `EnterStandby`.
    ///
    /// <p>Moves the specified instances into the standby state.</p>
    /// <p>If you choose to decrement the desired capacity of the Auto Scaling group, the instances can enter standby as long as the desired capacity of the Auto Scaling group after the instances are placed into standby is equal to or greater than the minimum capacity of the group.</p>
    /// <p>If you choose not to decrement the desired capacity of the Auto Scaling group, the Auto Scaling group launches new instances to replace the instances on standby.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-enter-exit-standby.html">Temporarily removing instances from your Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct EnterStandby {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::enter_standby_input::Builder,
    }
    impl EnterStandby {
        /// Creates a new `EnterStandby`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::EnterStandbyOutput,
            aws_smithy_http::result::SdkError<crate::error::EnterStandbyError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Appends an item to `InstanceIds`.
        ///
        /// To override the contents of this collection use [`set_instance_ids`](Self::set_instance_ids).
        ///
        /// <p>The IDs of the instances. You can specify up to 20 instances.</p>
        pub fn instance_ids(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_ids(input.into());
            self
        }
        /// <p>The IDs of the instances. You can specify up to 20 instances.</p>
        pub fn set_instance_ids(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_instance_ids(input);
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>Indicates whether to decrement the desired capacity of the Auto Scaling group by the number of instances moved to <code>Standby</code> mode.</p>
        pub fn should_decrement_desired_capacity(mut self, input: bool) -> Self {
            self.inner = self.inner.should_decrement_desired_capacity(input);
            self
        }
        /// <p>Indicates whether to decrement the desired capacity of the Auto Scaling group by the number of instances moved to <code>Standby</code> mode.</p>
        pub fn set_should_decrement_desired_capacity(
            mut self,
            input: std::option::Option<bool>,
        ) -> Self {
            self.inner = self.inner.set_should_decrement_desired_capacity(input);
            self
        }
    }
    /// Fluent builder constructing a request to `ExecutePolicy`.
    ///
    /// <p>Executes the specified policy. This can be useful for testing the design of your scaling policy.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct ExecutePolicy {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::execute_policy_input::Builder,
    }
    impl ExecutePolicy {
        /// Creates a new `ExecutePolicy`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ExecutePolicyOutput,
            aws_smithy_http::result::SdkError<crate::error::ExecutePolicyError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The name or ARN of the policy.</p>
        pub fn policy_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.policy_name(input.into());
            self
        }
        /// <p>The name or ARN of the policy.</p>
        pub fn set_policy_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_policy_name(input);
            self
        }
        /// <p>Indicates whether Amazon EC2 Auto Scaling waits for the cooldown period to complete before executing the policy.</p>
        /// <p>Valid only if the policy type is <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn honor_cooldown(mut self, input: bool) -> Self {
            self.inner = self.inner.honor_cooldown(input);
            self
        }
        /// <p>Indicates whether Amazon EC2 Auto Scaling waits for the cooldown period to complete before executing the policy.</p>
        /// <p>Valid only if the policy type is <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_honor_cooldown(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_honor_cooldown(input);
            self
        }
        /// <p>The metric value to compare to <code>BreachThreshold</code>. This enables you to execute a policy of type <code>StepScaling</code> and determine which step adjustment to use. For example, if the breach threshold is 50 and you want to use a step adjustment with a lower bound of 0 and an upper bound of 10, you can set the metric value to 59.</p>
        /// <p>If you specify a metric value that doesn't correspond to a step adjustment for the policy, the call returns an error.</p>
        /// <p>Required if the policy type is <code>StepScaling</code> and not supported otherwise.</p>
        pub fn metric_value(mut self, input: f64) -> Self {
            self.inner = self.inner.metric_value(input);
            self
        }
        /// <p>The metric value to compare to <code>BreachThreshold</code>. This enables you to execute a policy of type <code>StepScaling</code> and determine which step adjustment to use. For example, if the breach threshold is 50 and you want to use a step adjustment with a lower bound of 0 and an upper bound of 10, you can set the metric value to 59.</p>
        /// <p>If you specify a metric value that doesn't correspond to a step adjustment for the policy, the call returns an error.</p>
        /// <p>Required if the policy type is <code>StepScaling</code> and not supported otherwise.</p>
        pub fn set_metric_value(mut self, input: std::option::Option<f64>) -> Self {
            self.inner = self.inner.set_metric_value(input);
            self
        }
        /// <p>The breach threshold for the alarm.</p>
        /// <p>Required if the policy type is <code>StepScaling</code> and not supported otherwise.</p>
        pub fn breach_threshold(mut self, input: f64) -> Self {
            self.inner = self.inner.breach_threshold(input);
            self
        }
        /// <p>The breach threshold for the alarm.</p>
        /// <p>Required if the policy type is <code>StepScaling</code> and not supported otherwise.</p>
        pub fn set_breach_threshold(mut self, input: std::option::Option<f64>) -> Self {
            self.inner = self.inner.set_breach_threshold(input);
            self
        }
    }
    /// Fluent builder constructing a request to `ExitStandby`.
    ///
    /// <p>Moves the specified instances out of the standby state.</p>
    /// <p>After you put the instances back in service, the desired capacity is incremented.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-enter-exit-standby.html">Temporarily removing instances from your Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct ExitStandby {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::exit_standby_input::Builder,
    }
    impl ExitStandby {
        /// Creates a new `ExitStandby`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ExitStandbyOutput,
            aws_smithy_http::result::SdkError<crate::error::ExitStandbyError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Appends an item to `InstanceIds`.
        ///
        /// To override the contents of this collection use [`set_instance_ids`](Self::set_instance_ids).
        ///
        /// <p>The IDs of the instances. You can specify up to 20 instances.</p>
        pub fn instance_ids(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_ids(input.into());
            self
        }
        /// <p>The IDs of the instances. You can specify up to 20 instances.</p>
        pub fn set_instance_ids(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_instance_ids(input);
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
    }
    /// Fluent builder constructing a request to `GetPredictiveScalingForecast`.
    ///
    /// <p>Retrieves the forecast data for a predictive scaling policy.</p>
    /// <p>Load forecasts are predictions of the hourly load values using historical load data from CloudWatch and an analysis of historical trends. Capacity forecasts are represented as predicted values for the minimum capacity that is needed on an hourly basis, based on the hourly load forecast.</p>
    /// <p>A minimum of 24 hours of data is required to create the initial forecasts. However, having a full 14 days of historical data results in more accurate forecasts.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-predictive-scaling.html">Predictive scaling for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct GetPredictiveScalingForecast {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::get_predictive_scaling_forecast_input::Builder,
    }
    impl GetPredictiveScalingForecast {
        /// Creates a new `GetPredictiveScalingForecast`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::GetPredictiveScalingForecastOutput,
            aws_smithy_http::result::SdkError<crate::error::GetPredictiveScalingForecastError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The name of the policy.</p>
        pub fn policy_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.policy_name(input.into());
            self
        }
        /// <p>The name of the policy.</p>
        pub fn set_policy_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_policy_name(input);
            self
        }
        /// <p>The inclusive start time of the time range for the forecast data to get. At most, the date and time can be one year before the current date and time.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.inner = self.inner.start_time(input);
            self
        }
        /// <p>The inclusive start time of the time range for the forecast data to get. At most, the date and time can be one year before the current date and time.</p>
        pub fn set_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.inner = self.inner.set_start_time(input);
            self
        }
        /// <p>The exclusive end time of the time range for the forecast data to get. The maximum time duration between the start and end time is 30 days. </p>
        /// <p>Although this parameter can accept a date and time that is more than two days in the future, the availability of forecast data has limits. Amazon EC2 Auto Scaling only issues forecasts for periods of two days in advance.</p>
        pub fn end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.inner = self.inner.end_time(input);
            self
        }
        /// <p>The exclusive end time of the time range for the forecast data to get. The maximum time duration between the start and end time is 30 days. </p>
        /// <p>Although this parameter can accept a date and time that is more than two days in the future, the availability of forecast data has limits. Amazon EC2 Auto Scaling only issues forecasts for periods of two days in advance.</p>
        pub fn set_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.inner = self.inner.set_end_time(input);
            self
        }
    }
    /// Fluent builder constructing a request to `PutLifecycleHook`.
    ///
    /// <p>Creates or updates a lifecycle hook for the specified Auto Scaling group.</p>
    /// <p>Lifecycle hooks let you create solutions that are aware of events in the Auto Scaling instance lifecycle, and then perform a custom action on instances when the corresponding lifecycle event occurs.</p>
    /// <p>This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group:</p>
    /// <ol>
    /// <li> <p>(Optional) Create a launch template or launch configuration with a user data script that runs while an instance is in a wait state due to a lifecycle hook.</p> </li>
    /// <li> <p>(Optional) Create a Lambda function and a rule that allows Amazon EventBridge to invoke your Lambda function when an instance is put into a wait state due to a lifecycle hook.</p> </li>
    /// <li> <p>(Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target.</p> </li>
    /// <li> <p> <b>Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate.</b> </p> </li>
    /// <li> <p>If you need more time, record the lifecycle action heartbeat to keep the instance in a wait state using the <code>RecordLifecycleActionHeartbeat</code> API call.</p> </li>
    /// <li> <p>If you finish before the timeout period ends, send a callback by using the <code>CompleteLifecycleAction</code> API call.</p> </li>
    /// </ol>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html">Amazon EC2 Auto Scaling lifecycle hooks</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>If you exceed your maximum limit of lifecycle hooks, which by default is 50 per Auto Scaling group, the call fails.</p>
    /// <p>You can view the lifecycle hooks for an Auto Scaling group using the <code>DescribeLifecycleHooks</code> API call. If you are no longer using a lifecycle hook, you can delete it by calling the <code>DeleteLifecycleHook</code> API.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct PutLifecycleHook {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::put_lifecycle_hook_input::Builder,
    }
    impl PutLifecycleHook {
        /// Creates a new `PutLifecycleHook`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::PutLifecycleHookOutput,
            aws_smithy_http::result::SdkError<crate::error::PutLifecycleHookError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the lifecycle hook.</p>
        pub fn lifecycle_hook_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.lifecycle_hook_name(input.into());
            self
        }
        /// <p>The name of the lifecycle hook.</p>
        pub fn set_lifecycle_hook_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_lifecycle_hook_name(input);
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The instance state to which you want to attach the lifecycle hook. The valid values are:</p>
        /// <ul>
        /// <li> <p>autoscaling:EC2_INSTANCE_LAUNCHING</p> </li>
        /// <li> <p>autoscaling:EC2_INSTANCE_TERMINATING</p> </li>
        /// </ul>
        /// <p>Required for new lifecycle hooks, but optional when updating existing hooks.</p>
        pub fn lifecycle_transition(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.lifecycle_transition(input.into());
            self
        }
        /// <p>The instance state to which you want to attach the lifecycle hook. The valid values are:</p>
        /// <ul>
        /// <li> <p>autoscaling:EC2_INSTANCE_LAUNCHING</p> </li>
        /// <li> <p>autoscaling:EC2_INSTANCE_TERMINATING</p> </li>
        /// </ul>
        /// <p>Required for new lifecycle hooks, but optional when updating existing hooks.</p>
        pub fn set_lifecycle_transition(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_lifecycle_transition(input);
            self
        }
        /// <p>The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target.</p>
        /// <p>Valid only if the notification target is an Amazon SNS topic or an Amazon SQS queue. Required for new lifecycle hooks, but optional when updating existing hooks.</p>
        pub fn role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.role_arn(input.into());
            self
        }
        /// <p>The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target.</p>
        /// <p>Valid only if the notification target is an Amazon SNS topic or an Amazon SQS queue. Required for new lifecycle hooks, but optional when updating existing hooks.</p>
        pub fn set_role_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_role_arn(input);
            self
        }
        /// <p>The ARN of the notification target that Amazon EC2 Auto Scaling uses to notify you when an instance is in the transition state for the lifecycle hook. This target can be either an SQS queue or an SNS topic.</p>
        /// <p>If you specify an empty string, this overrides the current ARN.</p>
        /// <p>This operation uses the JSON format when sending notifications to an Amazon SQS queue, and an email key-value pair format when sending notifications to an Amazon SNS topic.</p>
        /// <p>When you specify a notification target, Amazon EC2 Auto Scaling sends it a test message. Test messages contain the following additional key-value pair: <code>"Event": "autoscaling:TEST_NOTIFICATION"</code>.</p>
        pub fn notification_target_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.notification_target_arn(input.into());
            self
        }
        /// <p>The ARN of the notification target that Amazon EC2 Auto Scaling uses to notify you when an instance is in the transition state for the lifecycle hook. This target can be either an SQS queue or an SNS topic.</p>
        /// <p>If you specify an empty string, this overrides the current ARN.</p>
        /// <p>This operation uses the JSON format when sending notifications to an Amazon SQS queue, and an email key-value pair format when sending notifications to an Amazon SNS topic.</p>
        /// <p>When you specify a notification target, Amazon EC2 Auto Scaling sends it a test message. Test messages contain the following additional key-value pair: <code>"Event": "autoscaling:TEST_NOTIFICATION"</code>.</p>
        pub fn set_notification_target_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_notification_target_arn(input);
            self
        }
        /// <p>Additional information that you want to include any time Amazon EC2 Auto Scaling sends a message to the notification target.</p>
        pub fn notification_metadata(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.notification_metadata(input.into());
            self
        }
        /// <p>Additional information that you want to include any time Amazon EC2 Auto Scaling sends a message to the notification target.</p>
        pub fn set_notification_metadata(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_notification_metadata(input);
            self
        }
        /// <p>The maximum time, in seconds, that can elapse before the lifecycle hook times out. The range is from <code>30</code> to <code>7200</code> seconds. The default value is <code>3600</code> seconds (1 hour).</p>
        /// <p>If the lifecycle hook times out, Amazon EC2 Auto Scaling performs the action that you specified in the <code>DefaultResult</code> parameter. You can prevent the lifecycle hook from timing out by calling the <code>RecordLifecycleActionHeartbeat</code> API.</p>
        pub fn heartbeat_timeout(mut self, input: i32) -> Self {
            self.inner = self.inner.heartbeat_timeout(input);
            self
        }
        /// <p>The maximum time, in seconds, that can elapse before the lifecycle hook times out. The range is from <code>30</code> to <code>7200</code> seconds. The default value is <code>3600</code> seconds (1 hour).</p>
        /// <p>If the lifecycle hook times out, Amazon EC2 Auto Scaling performs the action that you specified in the <code>DefaultResult</code> parameter. You can prevent the lifecycle hook from timing out by calling the <code>RecordLifecycleActionHeartbeat</code> API.</p>
        pub fn set_heartbeat_timeout(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_heartbeat_timeout(input);
            self
        }
        /// <p>Defines the action the Auto Scaling group should take when the lifecycle hook timeout elapses or if an unexpected failure occurs. This parameter can be either <code>CONTINUE</code> or <code>ABANDON</code>. The default value is <code>ABANDON</code>.</p>
        pub fn default_result(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.default_result(input.into());
            self
        }
        /// <p>Defines the action the Auto Scaling group should take when the lifecycle hook timeout elapses or if an unexpected failure occurs. This parameter can be either <code>CONTINUE</code> or <code>ABANDON</code>. The default value is <code>ABANDON</code>.</p>
        pub fn set_default_result(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_default_result(input);
            self
        }
    }
    /// Fluent builder constructing a request to `PutNotificationConfiguration`.
    ///
    /// <p>Configures an Auto Scaling group to send notifications when specified events take place. Subscribers to the specified topic can have messages delivered to an endpoint such as a web server or an email address.</p>
    /// <p>This configuration overwrites any existing configuration.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ASGettingNotifications.html">Getting Amazon SNS notifications when your Auto Scaling group scales</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>If you exceed your maximum limit of SNS topics, which is 10 per Auto Scaling group, the call fails.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct PutNotificationConfiguration {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::put_notification_configuration_input::Builder,
    }
    impl PutNotificationConfiguration {
        /// Creates a new `PutNotificationConfiguration`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::PutNotificationConfigurationOutput,
            aws_smithy_http::result::SdkError<crate::error::PutNotificationConfigurationError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the Amazon SNS topic.</p>
        pub fn topic_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.topic_arn(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the Amazon SNS topic.</p>
        pub fn set_topic_arn(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_topic_arn(input);
            self
        }
        /// Appends an item to `NotificationTypes`.
        ///
        /// To override the contents of this collection use [`set_notification_types`](Self::set_notification_types).
        ///
        /// <p>The type of event that causes the notification to be sent. To query the notification types supported by Amazon EC2 Auto Scaling, call the <code>DescribeAutoScalingNotificationTypes</code> API.</p>
        pub fn notification_types(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.notification_types(input.into());
            self
        }
        /// <p>The type of event that causes the notification to be sent. To query the notification types supported by Amazon EC2 Auto Scaling, call the <code>DescribeAutoScalingNotificationTypes</code> API.</p>
        pub fn set_notification_types(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_notification_types(input);
            self
        }
    }
    /// Fluent builder constructing a request to `PutScalingPolicy`.
    ///
    /// <p>Creates or updates a scaling policy for an Auto Scaling group. Scaling policies are used to scale an Auto Scaling group based on configurable metrics. If no policies are defined, the dynamic scaling and predictive scaling features are not used. </p>
    /// <p>For more information about using dynamic scaling, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-target-tracking.html">Target tracking scaling policies</a> and <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html">Step and simple scaling policies</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>For more information about using predictive scaling, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-predictive-scaling.html">Predictive scaling for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>You can view the scaling policies for an Auto Scaling group using the <code>DescribePolicies</code> API call. If you are no longer using a scaling policy, you can delete it by calling the <code>DeletePolicy</code> API.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct PutScalingPolicy {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::put_scaling_policy_input::Builder,
    }
    impl PutScalingPolicy {
        /// Creates a new `PutScalingPolicy`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::PutScalingPolicyOutput,
            aws_smithy_http::result::SdkError<crate::error::PutScalingPolicyError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The name of the policy.</p>
        pub fn policy_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.policy_name(input.into());
            self
        }
        /// <p>The name of the policy.</p>
        pub fn set_policy_name(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_policy_name(input);
            self
        }
        /// <p>One of the following policy types: </p>
        /// <ul>
        /// <li> <p> <code>TargetTrackingScaling</code> </p> </li>
        /// <li> <p> <code>StepScaling</code> </p> </li>
        /// <li> <p> <code>SimpleScaling</code> (default)</p> </li>
        /// <li> <p> <code>PredictiveScaling</code> </p> </li>
        /// </ul>
        pub fn policy_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.policy_type(input.into());
            self
        }
        /// <p>One of the following policy types: </p>
        /// <ul>
        /// <li> <p> <code>TargetTrackingScaling</code> </p> </li>
        /// <li> <p> <code>StepScaling</code> </p> </li>
        /// <li> <p> <code>SimpleScaling</code> (default)</p> </li>
        /// <li> <p> <code>PredictiveScaling</code> </p> </li>
        /// </ul>
        pub fn set_policy_type(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_policy_type(input);
            self
        }
        /// <p>Specifies how the scaling adjustment is interpreted (for example, an absolute number or a percentage). The valid values are <code>ChangeInCapacity</code>, <code>ExactCapacity</code>, and <code>PercentChangeInCapacity</code>.</p>
        /// <p>Required if the policy type is <code>StepScaling</code> or <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-adjustment">Scaling adjustment types</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn adjustment_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.adjustment_type(input.into());
            self
        }
        /// <p>Specifies how the scaling adjustment is interpreted (for example, an absolute number or a percentage). The valid values are <code>ChangeInCapacity</code>, <code>ExactCapacity</code>, and <code>PercentChangeInCapacity</code>.</p>
        /// <p>Required if the policy type is <code>StepScaling</code> or <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-adjustment">Scaling adjustment types</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_adjustment_type(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_adjustment_type(input);
            self
        }
        /// <p>Available for backward compatibility. Use <code>MinAdjustmentMagnitude</code> instead.</p>
        pub fn min_adjustment_step(mut self, input: i32) -> Self {
            self.inner = self.inner.min_adjustment_step(input);
            self
        }
        /// <p>Available for backward compatibility. Use <code>MinAdjustmentMagnitude</code> instead.</p>
        pub fn set_min_adjustment_step(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_min_adjustment_step(input);
            self
        }
        /// <p>The minimum value to scale by when the adjustment type is <code>PercentChangeInCapacity</code>. For example, suppose that you create a step scaling policy to scale out an Auto Scaling group by 25 percent and you specify a <code>MinAdjustmentMagnitude</code> of 2. If the group has 4 instances and the scaling policy is performed, 25 percent of 4 is 1. However, because you specified a <code>MinAdjustmentMagnitude</code> of 2, Amazon EC2 Auto Scaling scales out the group by 2 instances.</p>
        /// <p>Valid only if the policy type is <code>StepScaling</code> or <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-adjustment">Scaling adjustment types</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <note>
        /// <p>Some Auto Scaling groups use instance weights. In this case, set the <code>MinAdjustmentMagnitude</code> to a value that is at least as large as your largest instance weight.</p>
        /// </note>
        pub fn min_adjustment_magnitude(mut self, input: i32) -> Self {
            self.inner = self.inner.min_adjustment_magnitude(input);
            self
        }
        /// <p>The minimum value to scale by when the adjustment type is <code>PercentChangeInCapacity</code>. For example, suppose that you create a step scaling policy to scale out an Auto Scaling group by 25 percent and you specify a <code>MinAdjustmentMagnitude</code> of 2. If the group has 4 instances and the scaling policy is performed, 25 percent of 4 is 1. However, because you specified a <code>MinAdjustmentMagnitude</code> of 2, Amazon EC2 Auto Scaling scales out the group by 2 instances.</p>
        /// <p>Valid only if the policy type is <code>StepScaling</code> or <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-adjustment">Scaling adjustment types</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <note>
        /// <p>Some Auto Scaling groups use instance weights. In this case, set the <code>MinAdjustmentMagnitude</code> to a value that is at least as large as your largest instance weight.</p>
        /// </note>
        pub fn set_min_adjustment_magnitude(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_min_adjustment_magnitude(input);
            self
        }
        /// <p>The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity. For exact capacity, you must specify a positive value.</p>
        /// <p>Required if the policy type is <code>SimpleScaling</code>. (Not used with any other policy type.) </p>
        pub fn scaling_adjustment(mut self, input: i32) -> Self {
            self.inner = self.inner.scaling_adjustment(input);
            self
        }
        /// <p>The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity. For exact capacity, you must specify a positive value.</p>
        /// <p>Required if the policy type is <code>SimpleScaling</code>. (Not used with any other policy type.) </p>
        pub fn set_scaling_adjustment(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_scaling_adjustment(input);
            self
        }
        /// <p>A cooldown period, in seconds, that applies to a specific simple scaling policy. When a cooldown period is specified here, it overrides the default cooldown.</p>
        /// <p>Valid only if the policy type is <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>Default: None</p>
        pub fn cooldown(mut self, input: i32) -> Self {
            self.inner = self.inner.cooldown(input);
            self
        }
        /// <p>A cooldown period, in seconds, that applies to a specific simple scaling policy. When a cooldown period is specified here, it overrides the default cooldown.</p>
        /// <p>Valid only if the policy type is <code>SimpleScaling</code>. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>Default: None</p>
        pub fn set_cooldown(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_cooldown(input);
            self
        }
        /// <p>The aggregation type for the CloudWatch metrics. The valid values are <code>Minimum</code>, <code>Maximum</code>, and <code>Average</code>. If the aggregation type is null, the value is treated as <code>Average</code>.</p>
        /// <p>Valid only if the policy type is <code>StepScaling</code>.</p>
        pub fn metric_aggregation_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.metric_aggregation_type(input.into());
            self
        }
        /// <p>The aggregation type for the CloudWatch metrics. The valid values are <code>Minimum</code>, <code>Maximum</code>, and <code>Average</code>. If the aggregation type is null, the value is treated as <code>Average</code>.</p>
        /// <p>Valid only if the policy type is <code>StepScaling</code>.</p>
        pub fn set_metric_aggregation_type(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_metric_aggregation_type(input);
            self
        }
        /// Appends an item to `StepAdjustments`.
        ///
        /// To override the contents of this collection use [`set_step_adjustments`](Self::set_step_adjustments).
        ///
        /// <p>A set of adjustments that enable you to scale based on the size of the alarm breach.</p>
        /// <p>Required if the policy type is <code>StepScaling</code>. (Not used with any other policy type.) </p>
        pub fn step_adjustments(mut self, input: crate::model::StepAdjustment) -> Self {
            self.inner = self.inner.step_adjustments(input);
            self
        }
        /// <p>A set of adjustments that enable you to scale based on the size of the alarm breach.</p>
        /// <p>Required if the policy type is <code>StepScaling</code>. (Not used with any other policy type.) </p>
        pub fn set_step_adjustments(
            mut self,
            input: std::option::Option<std::vec::Vec<crate::model::StepAdjustment>>,
        ) -> Self {
            self.inner = self.inner.set_step_adjustments(input);
            self
        }
        /// <p> <i>Not needed if the default instance warmup is defined for the group.</i> </p>
        /// <p>The estimated time, in seconds, until a newly launched instance can contribute to the CloudWatch metrics. This warm-up period applies to instances launched due to a specific target tracking or step scaling policy. When a warm-up period is specified here, it overrides the default instance warmup.</p>
        /// <p>Valid only if the policy type is <code>TargetTrackingScaling</code> or <code>StepScaling</code>.</p> <note>
        /// <p>The default is to use the value for the default instance warmup defined for the group. If default instance warmup is null, then <code>EstimatedInstanceWarmup</code> falls back to the value of default cooldown.</p>
        /// </note>
        pub fn estimated_instance_warmup(mut self, input: i32) -> Self {
            self.inner = self.inner.estimated_instance_warmup(input);
            self
        }
        /// <p> <i>Not needed if the default instance warmup is defined for the group.</i> </p>
        /// <p>The estimated time, in seconds, until a newly launched instance can contribute to the CloudWatch metrics. This warm-up period applies to instances launched due to a specific target tracking or step scaling policy. When a warm-up period is specified here, it overrides the default instance warmup.</p>
        /// <p>Valid only if the policy type is <code>TargetTrackingScaling</code> or <code>StepScaling</code>.</p> <note>
        /// <p>The default is to use the value for the default instance warmup defined for the group. If default instance warmup is null, then <code>EstimatedInstanceWarmup</code> falls back to the value of default cooldown.</p>
        /// </note>
        pub fn set_estimated_instance_warmup(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_estimated_instance_warmup(input);
            self
        }
        /// <p>A target tracking scaling policy. Provides support for predefined or custom metrics.</p>
        /// <p>The following predefined metrics are available:</p>
        /// <ul>
        /// <li> <p> <code>ASGAverageCPUUtilization</code> </p> </li>
        /// <li> <p> <code>ASGAverageNetworkIn</code> </p> </li>
        /// <li> <p> <code>ASGAverageNetworkOut</code> </p> </li>
        /// <li> <p> <code>ALBRequestCountPerTarget</code> </p> </li>
        /// </ul>
        /// <p>If you specify <code>ALBRequestCountPerTarget</code> for the metric, you must specify the <code>ResourceLabel</code> parameter with the <code>PredefinedMetricSpecification</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_TargetTrackingConfiguration.html">TargetTrackingConfiguration</a> in the <i>Amazon EC2 Auto Scaling API Reference</i>.</p>
        /// <p>Required if the policy type is <code>TargetTrackingScaling</code>.</p>
        pub fn target_tracking_configuration(
            mut self,
            input: crate::model::TargetTrackingConfiguration,
        ) -> Self {
            self.inner = self.inner.target_tracking_configuration(input);
            self
        }
        /// <p>A target tracking scaling policy. Provides support for predefined or custom metrics.</p>
        /// <p>The following predefined metrics are available:</p>
        /// <ul>
        /// <li> <p> <code>ASGAverageCPUUtilization</code> </p> </li>
        /// <li> <p> <code>ASGAverageNetworkIn</code> </p> </li>
        /// <li> <p> <code>ASGAverageNetworkOut</code> </p> </li>
        /// <li> <p> <code>ALBRequestCountPerTarget</code> </p> </li>
        /// </ul>
        /// <p>If you specify <code>ALBRequestCountPerTarget</code> for the metric, you must specify the <code>ResourceLabel</code> parameter with the <code>PredefinedMetricSpecification</code>.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_TargetTrackingConfiguration.html">TargetTrackingConfiguration</a> in the <i>Amazon EC2 Auto Scaling API Reference</i>.</p>
        /// <p>Required if the policy type is <code>TargetTrackingScaling</code>.</p>
        pub fn set_target_tracking_configuration(
            mut self,
            input: std::option::Option<crate::model::TargetTrackingConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_target_tracking_configuration(input);
            self
        }
        /// <p>Indicates whether the scaling policy is enabled or disabled. The default is enabled. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-enable-disable-scaling-policy.html">Disabling a scaling policy for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn enabled(mut self, input: bool) -> Self {
            self.inner = self.inner.enabled(input);
            self
        }
        /// <p>Indicates whether the scaling policy is enabled or disabled. The default is enabled. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-enable-disable-scaling-policy.html">Disabling a scaling policy for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_enabled(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_enabled(input);
            self
        }
        /// <p>A predictive scaling policy. Provides support for predefined and custom metrics.</p>
        /// <p>Predefined metrics include CPU utilization, network in/out, and the Application Load Balancer request count.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_PredictiveScalingConfiguration.html">PredictiveScalingConfiguration</a> in the <i>Amazon EC2 Auto Scaling API Reference</i>.</p>
        /// <p>Required if the policy type is <code>PredictiveScaling</code>.</p>
        pub fn predictive_scaling_configuration(
            mut self,
            input: crate::model::PredictiveScalingConfiguration,
        ) -> Self {
            self.inner = self.inner.predictive_scaling_configuration(input);
            self
        }
        /// <p>A predictive scaling policy. Provides support for predefined and custom metrics.</p>
        /// <p>Predefined metrics include CPU utilization, network in/out, and the Application Load Balancer request count.</p>
        /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_PredictiveScalingConfiguration.html">PredictiveScalingConfiguration</a> in the <i>Amazon EC2 Auto Scaling API Reference</i>.</p>
        /// <p>Required if the policy type is <code>PredictiveScaling</code>.</p>
        pub fn set_predictive_scaling_configuration(
            mut self,
            input: std::option::Option<crate::model::PredictiveScalingConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_predictive_scaling_configuration(input);
            self
        }
    }
    /// Fluent builder constructing a request to `PutScheduledUpdateGroupAction`.
    ///
    /// <p>Creates or updates a scheduled scaling action for an Auto Scaling group.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/schedule_time.html">Scheduled scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>You can view the scheduled actions for an Auto Scaling group using the <code>DescribeScheduledActions</code> API call. If you are no longer using a scheduled action, you can delete it by calling the <code>DeleteScheduledAction</code> API.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct PutScheduledUpdateGroupAction {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::put_scheduled_update_group_action_input::Builder,
    }
    impl PutScheduledUpdateGroupAction {
        /// Creates a new `PutScheduledUpdateGroupAction`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::PutScheduledUpdateGroupActionOutput,
            aws_smithy_http::result::SdkError<crate::error::PutScheduledUpdateGroupActionError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The name of this scaling action.</p>
        pub fn scheduled_action_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.scheduled_action_name(input.into());
            self
        }
        /// <p>The name of this scaling action.</p>
        pub fn set_scheduled_action_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_scheduled_action_name(input);
            self
        }
        /// <p>This parameter is no longer used.</p>
        pub fn time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.inner = self.inner.time(input);
            self
        }
        /// <p>This parameter is no longer used.</p>
        pub fn set_time(mut self, input: std::option::Option<aws_smithy_types::DateTime>) -> Self {
            self.inner = self.inner.set_time(input);
            self
        }
        /// <p>The date and time for this action to start, in YYYY-MM-DDThh:mm:ssZ format in UTC/GMT only and in quotes (for example, <code>"2019-06-01T00:00:00Z"</code>).</p>
        /// <p>If you specify <code>Recurrence</code> and <code>StartTime</code>, Amazon EC2 Auto Scaling performs the action at this time, and then performs the action based on the specified recurrence.</p>
        /// <p>If you try to schedule your action in the past, Amazon EC2 Auto Scaling returns an error message.</p>
        pub fn start_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.inner = self.inner.start_time(input);
            self
        }
        /// <p>The date and time for this action to start, in YYYY-MM-DDThh:mm:ssZ format in UTC/GMT only and in quotes (for example, <code>"2019-06-01T00:00:00Z"</code>).</p>
        /// <p>If you specify <code>Recurrence</code> and <code>StartTime</code>, Amazon EC2 Auto Scaling performs the action at this time, and then performs the action based on the specified recurrence.</p>
        /// <p>If you try to schedule your action in the past, Amazon EC2 Auto Scaling returns an error message.</p>
        pub fn set_start_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.inner = self.inner.set_start_time(input);
            self
        }
        /// <p>The date and time for the recurring schedule to end, in UTC.</p>
        pub fn end_time(mut self, input: aws_smithy_types::DateTime) -> Self {
            self.inner = self.inner.end_time(input);
            self
        }
        /// <p>The date and time for the recurring schedule to end, in UTC.</p>
        pub fn set_end_time(
            mut self,
            input: std::option::Option<aws_smithy_types::DateTime>,
        ) -> Self {
            self.inner = self.inner.set_end_time(input);
            self
        }
        /// <p>The recurring schedule for this action. This format consists of five fields separated by white spaces: [Minute] [Hour] [Day_of_Month] [Month_of_Year] [Day_of_Week]. The value must be in quotes (for example, <code>"30 0 1 1,6,12 *"</code>). For more information about this format, see <a href="http://crontab.org">Crontab</a>.</p>
        /// <p>When <code>StartTime</code> and <code>EndTime</code> are specified with <code>Recurrence</code>, they form the boundaries of when the recurring action starts and stops.</p>
        /// <p>Cron expressions use Universal Coordinated Time (UTC) by default.</p>
        pub fn recurrence(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.recurrence(input.into());
            self
        }
        /// <p>The recurring schedule for this action. This format consists of five fields separated by white spaces: [Minute] [Hour] [Day_of_Month] [Month_of_Year] [Day_of_Week]. The value must be in quotes (for example, <code>"30 0 1 1,6,12 *"</code>). For more information about this format, see <a href="http://crontab.org">Crontab</a>.</p>
        /// <p>When <code>StartTime</code> and <code>EndTime</code> are specified with <code>Recurrence</code>, they form the boundaries of when the recurring action starts and stops.</p>
        /// <p>Cron expressions use Universal Coordinated Time (UTC) by default.</p>
        pub fn set_recurrence(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_recurrence(input);
            self
        }
        /// <p>The minimum size of the Auto Scaling group.</p>
        pub fn min_size(mut self, input: i32) -> Self {
            self.inner = self.inner.min_size(input);
            self
        }
        /// <p>The minimum size of the Auto Scaling group.</p>
        pub fn set_min_size(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_min_size(input);
            self
        }
        /// <p>The maximum size of the Auto Scaling group.</p>
        pub fn max_size(mut self, input: i32) -> Self {
            self.inner = self.inner.max_size(input);
            self
        }
        /// <p>The maximum size of the Auto Scaling group.</p>
        pub fn set_max_size(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_size(input);
            self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain. It can scale beyond this capacity if you add more scaling conditions. </p>
        pub fn desired_capacity(mut self, input: i32) -> Self {
            self.inner = self.inner.desired_capacity(input);
            self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain. It can scale beyond this capacity if you add more scaling conditions. </p>
        pub fn set_desired_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_desired_capacity(input);
            self
        }
        /// <p>Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. </p>
        /// <p>Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as <code>Etc/GMT+9</code> or <code>Pacific/Tahiti</code>). For more information, see <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">https://en.wikipedia.org/wiki/List_of_tz_database_time_zones</a>.</p>
        pub fn time_zone(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.time_zone(input.into());
            self
        }
        /// <p>Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. </p>
        /// <p>Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as <code>Etc/GMT+9</code> or <code>Pacific/Tahiti</code>). For more information, see <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">https://en.wikipedia.org/wiki/List_of_tz_database_time_zones</a>.</p>
        pub fn set_time_zone(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_time_zone(input);
            self
        }
    }
    /// Fluent builder constructing a request to `PutWarmPool`.
    ///
    /// <p>Creates or updates a warm pool for the specified Auto Scaling group. A warm pool is a pool of pre-initialized EC2 instances that sits alongside the Auto Scaling group. Whenever your application needs to scale out, the Auto Scaling group can draw on the warm pool to meet its new desired capacity. For more information and example configurations, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-warm-pools.html">Warm pools for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>This operation must be called from the Region in which the Auto Scaling group was created. This operation cannot be called on an Auto Scaling group that has a mixed instances policy or a launch template or launch configuration that requests Spot Instances.</p>
    /// <p>You can view the instances in the warm pool using the <code>DescribeWarmPool</code> API call. If you are no longer using a warm pool, you can delete it by calling the <code>DeleteWarmPool</code> API.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct PutWarmPool {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::put_warm_pool_input::Builder,
    }
    impl PutWarmPool {
        /// Creates a new `PutWarmPool`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::PutWarmPoolOutput,
            aws_smithy_http::result::SdkError<crate::error::PutWarmPoolError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>Specifies the maximum number of instances that are allowed to be in the warm pool or in any state except <code>Terminated</code> for the Auto Scaling group. This is an optional property. Specify it only if you do not want the warm pool size to be determined by the difference between the group's maximum capacity and its desired capacity. </p> <important>
        /// <p>If a value for <code>MaxGroupPreparedCapacity</code> is not specified, Amazon EC2 Auto Scaling launches and maintains the difference between the group's maximum capacity and its desired capacity. If you specify a value for <code>MaxGroupPreparedCapacity</code>, Amazon EC2 Auto Scaling uses the difference between the <code>MaxGroupPreparedCapacity</code> and the desired capacity instead. </p>
        /// <p>The size of the warm pool is dynamic. Only when <code>MaxGroupPreparedCapacity</code> and <code>MinSize</code> are set to the same value does the warm pool have an absolute size.</p>
        /// </important>
        /// <p>If the desired capacity of the Auto Scaling group is higher than the <code>MaxGroupPreparedCapacity</code>, the capacity of the warm pool is 0, unless you specify a value for <code>MinSize</code>. To remove a value that you previously set, include the property but specify -1 for the value. </p>
        pub fn max_group_prepared_capacity(mut self, input: i32) -> Self {
            self.inner = self.inner.max_group_prepared_capacity(input);
            self
        }
        /// <p>Specifies the maximum number of instances that are allowed to be in the warm pool or in any state except <code>Terminated</code> for the Auto Scaling group. This is an optional property. Specify it only if you do not want the warm pool size to be determined by the difference between the group's maximum capacity and its desired capacity. </p> <important>
        /// <p>If a value for <code>MaxGroupPreparedCapacity</code> is not specified, Amazon EC2 Auto Scaling launches and maintains the difference between the group's maximum capacity and its desired capacity. If you specify a value for <code>MaxGroupPreparedCapacity</code>, Amazon EC2 Auto Scaling uses the difference between the <code>MaxGroupPreparedCapacity</code> and the desired capacity instead. </p>
        /// <p>The size of the warm pool is dynamic. Only when <code>MaxGroupPreparedCapacity</code> and <code>MinSize</code> are set to the same value does the warm pool have an absolute size.</p>
        /// </important>
        /// <p>If the desired capacity of the Auto Scaling group is higher than the <code>MaxGroupPreparedCapacity</code>, the capacity of the warm pool is 0, unless you specify a value for <code>MinSize</code>. To remove a value that you previously set, include the property but specify -1 for the value. </p>
        pub fn set_max_group_prepared_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_group_prepared_capacity(input);
            self
        }
        /// <p>Specifies the minimum number of instances to maintain in the warm pool. This helps you to ensure that there is always a certain number of warmed instances available to handle traffic spikes. Defaults to 0 if not specified.</p>
        pub fn min_size(mut self, input: i32) -> Self {
            self.inner = self.inner.min_size(input);
            self
        }
        /// <p>Specifies the minimum number of instances to maintain in the warm pool. This helps you to ensure that there is always a certain number of warmed instances available to handle traffic spikes. Defaults to 0 if not specified.</p>
        pub fn set_min_size(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_min_size(input);
            self
        }
        /// <p>Sets the instance state to transition to after the lifecycle actions are complete. Default is <code>Stopped</code>.</p>
        pub fn pool_state(mut self, input: crate::model::WarmPoolState) -> Self {
            self.inner = self.inner.pool_state(input);
            self
        }
        /// <p>Sets the instance state to transition to after the lifecycle actions are complete. Default is <code>Stopped</code>.</p>
        pub fn set_pool_state(
            mut self,
            input: std::option::Option<crate::model::WarmPoolState>,
        ) -> Self {
            self.inner = self.inner.set_pool_state(input);
            self
        }
        /// <p>Indicates whether instances in the Auto Scaling group can be returned to the warm pool on scale in. The default is to terminate instances in the Auto Scaling group when the group scales in.</p>
        pub fn instance_reuse_policy(mut self, input: crate::model::InstanceReusePolicy) -> Self {
            self.inner = self.inner.instance_reuse_policy(input);
            self
        }
        /// <p>Indicates whether instances in the Auto Scaling group can be returned to the warm pool on scale in. The default is to terminate instances in the Auto Scaling group when the group scales in.</p>
        pub fn set_instance_reuse_policy(
            mut self,
            input: std::option::Option<crate::model::InstanceReusePolicy>,
        ) -> Self {
            self.inner = self.inner.set_instance_reuse_policy(input);
            self
        }
    }
    /// Fluent builder constructing a request to `RecordLifecycleActionHeartbeat`.
    ///
    /// <p>Records a heartbeat for the lifecycle action associated with the specified token or instance. This extends the timeout by the length of time defined using the <code>PutLifecycleHook</code> API call.</p>
    /// <p>This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group:</p>
    /// <ol>
    /// <li> <p>(Optional) Create a launch template or launch configuration with a user data script that runs while an instance is in a wait state due to a lifecycle hook.</p> </li>
    /// <li> <p>(Optional) Create a Lambda function and a rule that allows Amazon EventBridge to invoke your Lambda function when an instance is put into a wait state due to a lifecycle hook.</p> </li>
    /// <li> <p>(Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target.</p> </li>
    /// <li> <p>Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate.</p> </li>
    /// <li> <p> <b>If you need more time, record the lifecycle action heartbeat to keep the instance in a wait state.</b> </p> </li>
    /// <li> <p>If you finish before the timeout period ends, send a callback by using the <code>CompleteLifecycleAction</code> API call.</p> </li>
    /// </ol>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html">Amazon EC2 Auto Scaling lifecycle hooks</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct RecordLifecycleActionHeartbeat {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::record_lifecycle_action_heartbeat_input::Builder,
    }
    impl RecordLifecycleActionHeartbeat {
        /// Creates a new `RecordLifecycleActionHeartbeat`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::RecordLifecycleActionHeartbeatOutput,
            aws_smithy_http::result::SdkError<crate::error::RecordLifecycleActionHeartbeatError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the lifecycle hook.</p>
        pub fn lifecycle_hook_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.lifecycle_hook_name(input.into());
            self
        }
        /// <p>The name of the lifecycle hook.</p>
        pub fn set_lifecycle_hook_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_lifecycle_hook_name(input);
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>A token that uniquely identifies a specific lifecycle action associated with an instance. Amazon EC2 Auto Scaling sends this token to the notification target that you specified when you created the lifecycle hook.</p>
        pub fn lifecycle_action_token(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.lifecycle_action_token(input.into());
            self
        }
        /// <p>A token that uniquely identifies a specific lifecycle action associated with an instance. Amazon EC2 Auto Scaling sends this token to the notification target that you specified when you created the lifecycle hook.</p>
        pub fn set_lifecycle_action_token(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_lifecycle_action_token(input);
            self
        }
        /// <p>The ID of the instance.</p>
        pub fn instance_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_id(input.into());
            self
        }
        /// <p>The ID of the instance.</p>
        pub fn set_instance_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_instance_id(input);
            self
        }
    }
    /// Fluent builder constructing a request to `ResumeProcesses`.
    ///
    /// <p>Resumes the specified suspended auto scaling processes, or all suspended process, for the specified Auto Scaling group.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-suspend-resume-processes.html">Suspending and resuming scaling processes</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct ResumeProcesses {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::resume_processes_input::Builder,
    }
    impl ResumeProcesses {
        /// Creates a new `ResumeProcesses`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::ResumeProcessesOutput,
            aws_smithy_http::result::SdkError<crate::error::ResumeProcessesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `ScalingProcesses`.
        ///
        /// To override the contents of this collection use [`set_scaling_processes`](Self::set_scaling_processes).
        ///
        /// <p>One or more of the following processes:</p>
        /// <ul>
        /// <li> <p> <code>Launch</code> </p> </li>
        /// <li> <p> <code>Terminate</code> </p> </li>
        /// <li> <p> <code>AddToLoadBalancer</code> </p> </li>
        /// <li> <p> <code>AlarmNotification</code> </p> </li>
        /// <li> <p> <code>AZRebalance</code> </p> </li>
        /// <li> <p> <code>HealthCheck</code> </p> </li>
        /// <li> <p> <code>InstanceRefresh</code> </p> </li>
        /// <li> <p> <code>ReplaceUnhealthy</code> </p> </li>
        /// <li> <p> <code>ScheduledActions</code> </p> </li>
        /// </ul>
        /// <p>If you omit this parameter, all processes are specified.</p>
        pub fn scaling_processes(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.scaling_processes(input.into());
            self
        }
        /// <p>One or more of the following processes:</p>
        /// <ul>
        /// <li> <p> <code>Launch</code> </p> </li>
        /// <li> <p> <code>Terminate</code> </p> </li>
        /// <li> <p> <code>AddToLoadBalancer</code> </p> </li>
        /// <li> <p> <code>AlarmNotification</code> </p> </li>
        /// <li> <p> <code>AZRebalance</code> </p> </li>
        /// <li> <p> <code>HealthCheck</code> </p> </li>
        /// <li> <p> <code>InstanceRefresh</code> </p> </li>
        /// <li> <p> <code>ReplaceUnhealthy</code> </p> </li>
        /// <li> <p> <code>ScheduledActions</code> </p> </li>
        /// </ul>
        /// <p>If you omit this parameter, all processes are specified.</p>
        pub fn set_scaling_processes(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_scaling_processes(input);
            self
        }
    }
    /// Fluent builder constructing a request to `SetDesiredCapacity`.
    ///
    /// <p>Sets the size of the specified Auto Scaling group.</p>
    /// <p>If a scale-in activity occurs as a result of a new <code>DesiredCapacity</code> value that is lower than the current size of the group, the Auto Scaling group uses its termination policy to determine which instances to terminate. </p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-manual-scaling.html">Manual scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct SetDesiredCapacity {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::set_desired_capacity_input::Builder,
    }
    impl SetDesiredCapacity {
        /// Creates a new `SetDesiredCapacity`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::SetDesiredCapacityOutput,
            aws_smithy_http::result::SdkError<crate::error::SetDesiredCapacityError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group after this operation completes and the capacity it attempts to maintain.</p>
        pub fn desired_capacity(mut self, input: i32) -> Self {
            self.inner = self.inner.desired_capacity(input);
            self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group after this operation completes and the capacity it attempts to maintain.</p>
        pub fn set_desired_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_desired_capacity(input);
            self
        }
        /// <p>Indicates whether Amazon EC2 Auto Scaling waits for the cooldown period to complete before initiating a scaling activity to set your Auto Scaling group to its new capacity. By default, Amazon EC2 Auto Scaling does not honor the cooldown period during manual scaling activities.</p>
        pub fn honor_cooldown(mut self, input: bool) -> Self {
            self.inner = self.inner.honor_cooldown(input);
            self
        }
        /// <p>Indicates whether Amazon EC2 Auto Scaling waits for the cooldown period to complete before initiating a scaling activity to set your Auto Scaling group to its new capacity. By default, Amazon EC2 Auto Scaling does not honor the cooldown period during manual scaling activities.</p>
        pub fn set_honor_cooldown(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_honor_cooldown(input);
            self
        }
    }
    /// Fluent builder constructing a request to `SetInstanceHealth`.
    ///
    /// <p>Sets the health status of the specified instance.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html">Health checks for Auto Scaling instances</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct SetInstanceHealth {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::set_instance_health_input::Builder,
    }
    impl SetInstanceHealth {
        /// Creates a new `SetInstanceHealth`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::SetInstanceHealthOutput,
            aws_smithy_http::result::SdkError<crate::error::SetInstanceHealthError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The ID of the instance.</p>
        pub fn instance_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_id(input.into());
            self
        }
        /// <p>The ID of the instance.</p>
        pub fn set_instance_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_instance_id(input);
            self
        }
        /// <p>The health status of the instance. Set to <code>Healthy</code> to have the instance remain in service. Set to <code>Unhealthy</code> to have the instance be out of service. Amazon EC2 Auto Scaling terminates and replaces the unhealthy instance.</p>
        pub fn health_status(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.health_status(input.into());
            self
        }
        /// <p>The health status of the instance. Set to <code>Healthy</code> to have the instance remain in service. Set to <code>Unhealthy</code> to have the instance be out of service. Amazon EC2 Auto Scaling terminates and replaces the unhealthy instance.</p>
        pub fn set_health_status(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_health_status(input);
            self
        }
        /// <p>If the Auto Scaling group of the specified instance has a <code>HealthCheckGracePeriod</code> specified for the group, by default, this call respects the grace period. Set this to <code>False</code>, to have the call not respect the grace period associated with the group.</p>
        /// <p>For more information about the health check grace period, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_CreateAutoScalingGroup.html">CreateAutoScalingGroup</a> in the <i>Amazon EC2 Auto Scaling API Reference</i>.</p>
        pub fn should_respect_grace_period(mut self, input: bool) -> Self {
            self.inner = self.inner.should_respect_grace_period(input);
            self
        }
        /// <p>If the Auto Scaling group of the specified instance has a <code>HealthCheckGracePeriod</code> specified for the group, by default, this call respects the grace period. Set this to <code>False</code>, to have the call not respect the grace period associated with the group.</p>
        /// <p>For more information about the health check grace period, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_CreateAutoScalingGroup.html">CreateAutoScalingGroup</a> in the <i>Amazon EC2 Auto Scaling API Reference</i>.</p>
        pub fn set_should_respect_grace_period(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_should_respect_grace_period(input);
            self
        }
    }
    /// Fluent builder constructing a request to `SetInstanceProtection`.
    ///
    /// <p>Updates the instance protection settings of the specified instances. This operation cannot be called on instances in a warm pool.</p>
    /// <p>For more information about preventing instances that are part of an Auto Scaling group from terminating on scale in, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-instance-protection.html">Using instance scale-in protection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>If you exceed your maximum limit of instance IDs, which is 50 per Auto Scaling group, the call fails.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct SetInstanceProtection {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::set_instance_protection_input::Builder,
    }
    impl SetInstanceProtection {
        /// Creates a new `SetInstanceProtection`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::SetInstanceProtectionOutput,
            aws_smithy_http::result::SdkError<crate::error::SetInstanceProtectionError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// Appends an item to `InstanceIds`.
        ///
        /// To override the contents of this collection use [`set_instance_ids`](Self::set_instance_ids).
        ///
        /// <p>One or more instance IDs. You can specify up to 50 instances.</p>
        pub fn instance_ids(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_ids(input.into());
            self
        }
        /// <p>One or more instance IDs. You can specify up to 50 instances.</p>
        pub fn set_instance_ids(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_instance_ids(input);
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
        pub fn protected_from_scale_in(mut self, input: bool) -> Self {
            self.inner = self.inner.protected_from_scale_in(input);
            self
        }
        /// <p>Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.</p>
        pub fn set_protected_from_scale_in(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_protected_from_scale_in(input);
            self
        }
    }
    /// Fluent builder constructing a request to `StartInstanceRefresh`.
    ///
    /// <p>Starts a new instance refresh operation. An instance refresh performs a rolling replacement of all or some instances in an Auto Scaling group. Each instance is terminated first and then replaced, which temporarily reduces the capacity available within your Auto Scaling group.</p>
    /// <p>This operation is part of the <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-instance-refresh.html">instance refresh feature</a> in Amazon EC2 Auto Scaling, which helps you update instances in your Auto Scaling group. This feature is helpful, for example, when you have a new AMI or a new user data script. You just need to create a new launch template that specifies the new AMI or user data script. Then start an instance refresh to immediately begin the process of updating instances in the group. </p>
    /// <p>If the call succeeds, it creates a new instance refresh request with a unique ID that you can use to track its progress. To query its status, call the <code>DescribeInstanceRefreshes</code> API. To describe the instance refreshes that have already run, call the <code>DescribeInstanceRefreshes</code> API. To cancel an instance refresh operation in progress, use the <code>CancelInstanceRefresh</code> API. </p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct StartInstanceRefresh {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::start_instance_refresh_input::Builder,
    }
    impl StartInstanceRefresh {
        /// Creates a new `StartInstanceRefresh`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::StartInstanceRefreshOutput,
            aws_smithy_http::result::SdkError<crate::error::StartInstanceRefreshError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The strategy to use for the instance refresh. The only valid value is <code>Rolling</code>.</p>
        /// <p>A rolling update helps you update your instances gradually. A rolling update can fail due to failed health checks or if instances are on standby or are protected from scale in. If the rolling update process fails, any instances that are replaced are not rolled back to their previous configuration. </p>
        pub fn strategy(mut self, input: crate::model::RefreshStrategy) -> Self {
            self.inner = self.inner.strategy(input);
            self
        }
        /// <p>The strategy to use for the instance refresh. The only valid value is <code>Rolling</code>.</p>
        /// <p>A rolling update helps you update your instances gradually. A rolling update can fail due to failed health checks or if instances are on standby or are protected from scale in. If the rolling update process fails, any instances that are replaced are not rolled back to their previous configuration. </p>
        pub fn set_strategy(
            mut self,
            input: std::option::Option<crate::model::RefreshStrategy>,
        ) -> Self {
            self.inner = self.inner.set_strategy(input);
            self
        }
        /// <p>The desired configuration. For example, the desired configuration can specify a new launch template or a new version of the current launch template.</p>
        /// <p>Once the instance refresh succeeds, Amazon EC2 Auto Scaling updates the settings of the Auto Scaling group to reflect the new desired configuration. </p> <note>
        /// <p>When you specify a new launch template or a new version of the current launch template for your desired configuration, consider enabling the <code>SkipMatching</code> property in preferences. If it's enabled, Amazon EC2 Auto Scaling skips replacing instances that already use the specified launch template and version. This can help you reduce the number of replacements that are required to apply updates. </p>
        /// </note>
        pub fn desired_configuration(mut self, input: crate::model::DesiredConfiguration) -> Self {
            self.inner = self.inner.desired_configuration(input);
            self
        }
        /// <p>The desired configuration. For example, the desired configuration can specify a new launch template or a new version of the current launch template.</p>
        /// <p>Once the instance refresh succeeds, Amazon EC2 Auto Scaling updates the settings of the Auto Scaling group to reflect the new desired configuration. </p> <note>
        /// <p>When you specify a new launch template or a new version of the current launch template for your desired configuration, consider enabling the <code>SkipMatching</code> property in preferences. If it's enabled, Amazon EC2 Auto Scaling skips replacing instances that already use the specified launch template and version. This can help you reduce the number of replacements that are required to apply updates. </p>
        /// </note>
        pub fn set_desired_configuration(
            mut self,
            input: std::option::Option<crate::model::DesiredConfiguration>,
        ) -> Self {
            self.inner = self.inner.set_desired_configuration(input);
            self
        }
        /// <p>Set of preferences associated with the instance refresh request. If not provided, the default values are used.</p>
        pub fn preferences(mut self, input: crate::model::RefreshPreferences) -> Self {
            self.inner = self.inner.preferences(input);
            self
        }
        /// <p>Set of preferences associated with the instance refresh request. If not provided, the default values are used.</p>
        pub fn set_preferences(
            mut self,
            input: std::option::Option<crate::model::RefreshPreferences>,
        ) -> Self {
            self.inner = self.inner.set_preferences(input);
            self
        }
    }
    /// Fluent builder constructing a request to `SuspendProcesses`.
    ///
    /// <p>Suspends the specified auto scaling processes, or all processes, for the specified Auto Scaling group.</p>
    /// <p>If you suspend either the <code>Launch</code> or <code>Terminate</code> process types, it can prevent other process types from functioning properly. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-suspend-resume-processes.html">Suspending and resuming scaling processes</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    /// <p>To resume processes that have been suspended, call the <code>ResumeProcesses</code> API.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct SuspendProcesses {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::suspend_processes_input::Builder,
    }
    impl SuspendProcesses {
        /// Creates a new `SuspendProcesses`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::SuspendProcessesOutput,
            aws_smithy_http::result::SdkError<crate::error::SuspendProcessesError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// Appends an item to `ScalingProcesses`.
        ///
        /// To override the contents of this collection use [`set_scaling_processes`](Self::set_scaling_processes).
        ///
        /// <p>One or more of the following processes:</p>
        /// <ul>
        /// <li> <p> <code>Launch</code> </p> </li>
        /// <li> <p> <code>Terminate</code> </p> </li>
        /// <li> <p> <code>AddToLoadBalancer</code> </p> </li>
        /// <li> <p> <code>AlarmNotification</code> </p> </li>
        /// <li> <p> <code>AZRebalance</code> </p> </li>
        /// <li> <p> <code>HealthCheck</code> </p> </li>
        /// <li> <p> <code>InstanceRefresh</code> </p> </li>
        /// <li> <p> <code>ReplaceUnhealthy</code> </p> </li>
        /// <li> <p> <code>ScheduledActions</code> </p> </li>
        /// </ul>
        /// <p>If you omit this parameter, all processes are specified.</p>
        pub fn scaling_processes(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.scaling_processes(input.into());
            self
        }
        /// <p>One or more of the following processes:</p>
        /// <ul>
        /// <li> <p> <code>Launch</code> </p> </li>
        /// <li> <p> <code>Terminate</code> </p> </li>
        /// <li> <p> <code>AddToLoadBalancer</code> </p> </li>
        /// <li> <p> <code>AlarmNotification</code> </p> </li>
        /// <li> <p> <code>AZRebalance</code> </p> </li>
        /// <li> <p> <code>HealthCheck</code> </p> </li>
        /// <li> <p> <code>InstanceRefresh</code> </p> </li>
        /// <li> <p> <code>ReplaceUnhealthy</code> </p> </li>
        /// <li> <p> <code>ScheduledActions</code> </p> </li>
        /// </ul>
        /// <p>If you omit this parameter, all processes are specified.</p>
        pub fn set_scaling_processes(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_scaling_processes(input);
            self
        }
    }
    /// Fluent builder constructing a request to `TerminateInstanceInAutoScalingGroup`.
    ///
    /// <p>Terminates the specified instance and optionally adjusts the desired group size. This operation cannot be called on instances in a warm pool.</p>
    /// <p>This call simply makes a termination request. The instance is not terminated immediately. When an instance is terminated, the instance status changes to <code>terminated</code>. You can't connect to or start an instance after you've terminated it.</p>
    /// <p>If you do not specify the option to decrement the desired capacity, Amazon EC2 Auto Scaling launches instances to replace the ones that are terminated. </p>
    /// <p>By default, Amazon EC2 Auto Scaling balances instances across all Availability Zones. If you decrement the desired capacity, your Auto Scaling group can become unbalanced between Availability Zones. Amazon EC2 Auto Scaling tries to rebalance the group, and rebalancing might terminate instances in other zones. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-benefits.html#AutoScalingBehavior.InstanceUsage">Rebalancing activities</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct TerminateInstanceInAutoScalingGroup {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::terminate_instance_in_auto_scaling_group_input::Builder,
    }
    impl TerminateInstanceInAutoScalingGroup {
        /// Creates a new `TerminateInstanceInAutoScalingGroup`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::TerminateInstanceInAutoScalingGroupOutput,
            aws_smithy_http::result::SdkError<
                crate::error::TerminateInstanceInAutoScalingGroupError,
            >,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The ID of the instance.</p>
        pub fn instance_id(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.instance_id(input.into());
            self
        }
        /// <p>The ID of the instance.</p>
        pub fn set_instance_id(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_instance_id(input);
            self
        }
        /// <p>Indicates whether terminating the instance also decrements the size of the Auto Scaling group.</p>
        pub fn should_decrement_desired_capacity(mut self, input: bool) -> Self {
            self.inner = self.inner.should_decrement_desired_capacity(input);
            self
        }
        /// <p>Indicates whether terminating the instance also decrements the size of the Auto Scaling group.</p>
        pub fn set_should_decrement_desired_capacity(
            mut self,
            input: std::option::Option<bool>,
        ) -> Self {
            self.inner = self.inner.set_should_decrement_desired_capacity(input);
            self
        }
    }
    /// Fluent builder constructing a request to `UpdateAutoScalingGroup`.
    ///
    /// <p> <b>We strongly recommend that all Auto Scaling groups use launch templates to ensure full functionality for Amazon EC2 Auto Scaling and Amazon EC2.</b> </p>
    /// <p>Updates the configuration for the specified Auto Scaling group.</p>
    /// <p>To update an Auto Scaling group, specify the name of the group and the parameter that you want to change. Any parameters that you don't specify are not changed by this update request. The new settings take effect on any scaling activities after this call returns. </p>
    /// <p>If you associate a new launch configuration or template with an Auto Scaling group, all new instances will get the updated configuration. Existing instances continue to run with the configuration that they were originally launched with. When you update a group to specify a mixed instances policy instead of a launch configuration or template, existing instances may be replaced to match the new purchasing options that you specified in the policy. For example, if the group currently has 100% On-Demand capacity and the policy specifies 50% Spot capacity, this means that half of your instances will be gradually terminated and relaunched as Spot Instances. When replacing instances, Amazon EC2 Auto Scaling launches new instances before terminating the old ones, so that updating your group does not compromise the performance or availability of your application.</p>
    /// <p>Note the following about changing <code>DesiredCapacity</code>, <code>MaxSize</code>, or <code>MinSize</code>:</p>
    /// <ul>
    /// <li> <p>If a scale-in activity occurs as a result of a new <code>DesiredCapacity</code> value that is lower than the current size of the group, the Auto Scaling group uses its termination policy to determine which instances to terminate.</p> </li>
    /// <li> <p>If you specify a new value for <code>MinSize</code> without specifying a value for <code>DesiredCapacity</code>, and the new <code>MinSize</code> is larger than the current size of the group, this sets the group's <code>DesiredCapacity</code> to the new <code>MinSize</code> value.</p> </li>
    /// <li> <p>If you specify a new value for <code>MaxSize</code> without specifying a value for <code>DesiredCapacity</code>, and the new <code>MaxSize</code> is smaller than the current size of the group, this sets the group's <code>DesiredCapacity</code> to the new <code>MaxSize</code> value.</p> </li>
    /// </ul>
    /// <p>To see which parameters have been set, call the <code>DescribeAutoScalingGroups</code> API. To view the scaling policies for an Auto Scaling group, call the <code>DescribePolicies</code> API. If the group has scaling policies, you can update them by calling the <code>PutScalingPolicy</code> API.</p>
    #[derive(std::clone::Clone, std::fmt::Debug)]
    pub struct UpdateAutoScalingGroup {
        handle: std::sync::Arc<super::Handle>,
        inner: crate::input::update_auto_scaling_group_input::Builder,
    }
    impl UpdateAutoScalingGroup {
        /// Creates a new `UpdateAutoScalingGroup`.
        pub(crate) fn new(handle: std::sync::Arc<super::Handle>) -> Self {
            Self {
                handle,
                inner: Default::default(),
            }
        }

        /// Sends the request and returns the response.
        ///
        /// If an error occurs, an `SdkError` will be returned with additional details that
        /// can be matched against.
        ///
        /// By default, any retryable failures will be retried twice. Retry behavior
        /// is configurable with the [RetryConfig](aws_smithy_types::retry::RetryConfig), which can be
        /// set when configuring the client.
        pub async fn send(
            self,
        ) -> std::result::Result<
            crate::output::UpdateAutoScalingGroupOutput,
            aws_smithy_http::result::SdkError<crate::error::UpdateAutoScalingGroupError>,
        > {
            let op = self
                .inner
                .build()
                .map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?
                .make_operation(&self.handle.conf)
                .await
                .map_err(|err| {
                    aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
                })?;
            self.handle.client.call(op).await
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn auto_scaling_group_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.auto_scaling_group_name(input.into());
            self
        }
        /// <p>The name of the Auto Scaling group.</p>
        pub fn set_auto_scaling_group_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_auto_scaling_group_name(input);
            self
        }
        /// <p>The name of the launch configuration. If you specify <code>LaunchConfigurationName</code> in your update request, you can't specify <code>LaunchTemplate</code> or <code>MixedInstancesPolicy</code>.</p>
        pub fn launch_configuration_name(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.launch_configuration_name(input.into());
            self
        }
        /// <p>The name of the launch configuration. If you specify <code>LaunchConfigurationName</code> in your update request, you can't specify <code>LaunchTemplate</code> or <code>MixedInstancesPolicy</code>.</p>
        pub fn set_launch_configuration_name(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_launch_configuration_name(input);
            self
        }
        /// <p>The launch template and version to use to specify the updates. If you specify <code>LaunchTemplate</code> in your update request, you can't specify <code>LaunchConfigurationName</code> or <code>MixedInstancesPolicy</code>.</p>
        pub fn launch_template(mut self, input: crate::model::LaunchTemplateSpecification) -> Self {
            self.inner = self.inner.launch_template(input);
            self
        }
        /// <p>The launch template and version to use to specify the updates. If you specify <code>LaunchTemplate</code> in your update request, you can't specify <code>LaunchConfigurationName</code> or <code>MixedInstancesPolicy</code>.</p>
        pub fn set_launch_template(
            mut self,
            input: std::option::Option<crate::model::LaunchTemplateSpecification>,
        ) -> Self {
            self.inner = self.inner.set_launch_template(input);
            self
        }
        /// <p>An embedded object that specifies a mixed instances policy. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html">Auto Scaling groups with multiple instance types and purchase options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn mixed_instances_policy(mut self, input: crate::model::MixedInstancesPolicy) -> Self {
            self.inner = self.inner.mixed_instances_policy(input);
            self
        }
        /// <p>An embedded object that specifies a mixed instances policy. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html">Auto Scaling groups with multiple instance types and purchase options</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_mixed_instances_policy(
            mut self,
            input: std::option::Option<crate::model::MixedInstancesPolicy>,
        ) -> Self {
            self.inner = self.inner.set_mixed_instances_policy(input);
            self
        }
        /// <p>The minimum size of the Auto Scaling group.</p>
        pub fn min_size(mut self, input: i32) -> Self {
            self.inner = self.inner.min_size(input);
            self
        }
        /// <p>The minimum size of the Auto Scaling group.</p>
        pub fn set_min_size(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_min_size(input);
            self
        }
        /// <p>The maximum size of the Auto Scaling group.</p> <note>
        /// <p>With a mixed instances policy that uses instance weighting, Amazon EC2 Auto Scaling may need to go above <code>MaxSize</code> to meet your capacity requirements. In this event, Amazon EC2 Auto Scaling will never go above <code>MaxSize</code> by more than your largest instance weight (weights that define how many units each instance contributes to the desired capacity of the group).</p>
        /// </note>
        pub fn max_size(mut self, input: i32) -> Self {
            self.inner = self.inner.max_size(input);
            self
        }
        /// <p>The maximum size of the Auto Scaling group.</p> <note>
        /// <p>With a mixed instances policy that uses instance weighting, Amazon EC2 Auto Scaling may need to go above <code>MaxSize</code> to meet your capacity requirements. In this event, Amazon EC2 Auto Scaling will never go above <code>MaxSize</code> by more than your largest instance weight (weights that define how many units each instance contributes to the desired capacity of the group).</p>
        /// </note>
        pub fn set_max_size(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_size(input);
            self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group after this operation completes and the capacity it attempts to maintain. This number must be greater than or equal to the minimum size of the group and less than or equal to the maximum size of the group.</p>
        pub fn desired_capacity(mut self, input: i32) -> Self {
            self.inner = self.inner.desired_capacity(input);
            self
        }
        /// <p>The desired capacity is the initial capacity of the Auto Scaling group after this operation completes and the capacity it attempts to maintain. This number must be greater than or equal to the minimum size of the group and less than or equal to the maximum size of the group.</p>
        pub fn set_desired_capacity(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_desired_capacity(input);
            self
        }
        /// <p> <i>Only needed if you use simple scaling policies.</i> </p>
        /// <p>The amount of time, in seconds, between one scaling activity ending and another one starting due to simple scaling policies. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn default_cooldown(mut self, input: i32) -> Self {
            self.inner = self.inner.default_cooldown(input);
            self
        }
        /// <p> <i>Only needed if you use simple scaling policies.</i> </p>
        /// <p>The amount of time, in seconds, between one scaling activity ending and another one starting due to simple scaling policies. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html">Scaling cooldowns for Amazon EC2 Auto Scaling</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_default_cooldown(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_default_cooldown(input);
            self
        }
        /// Appends an item to `AvailabilityZones`.
        ///
        /// To override the contents of this collection use [`set_availability_zones`](Self::set_availability_zones).
        ///
        /// <p>One or more Availability Zones for the group.</p>
        pub fn availability_zones(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.availability_zones(input.into());
            self
        }
        /// <p>One or more Availability Zones for the group.</p>
        pub fn set_availability_zones(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_availability_zones(input);
            self
        }
        /// <p>The service to use for the health checks. The valid values are <code>EC2</code> and <code>ELB</code>. If you configure an Auto Scaling group to use <code>ELB</code> health checks, it considers the instance unhealthy if it fails either the EC2 status checks or the load balancer health checks.</p>
        pub fn health_check_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.health_check_type(input.into());
            self
        }
        /// <p>The service to use for the health checks. The valid values are <code>EC2</code> and <code>ELB</code>. If you configure an Auto Scaling group to use <code>ELB</code> health checks, it considers the instance unhealthy if it fails either the EC2 status checks or the load balancer health checks.</p>
        pub fn set_health_check_type(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_health_check_type(input);
            self
        }
        /// <p>The amount of time, in seconds, that Amazon EC2 Auto Scaling waits before checking the health status of an EC2 instance that has come into service and marking it unhealthy due to a failed Elastic Load Balancing or custom health check. This is useful if your instances do not immediately pass these health checks after they enter the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html#health-check-grace-period">Health check grace period</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn health_check_grace_period(mut self, input: i32) -> Self {
            self.inner = self.inner.health_check_grace_period(input);
            self
        }
        /// <p>The amount of time, in seconds, that Amazon EC2 Auto Scaling waits before checking the health status of an EC2 instance that has come into service and marking it unhealthy due to a failed Elastic Load Balancing or custom health check. This is useful if your instances do not immediately pass these health checks after they enter the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html#health-check-grace-period">Health check grace period</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_health_check_grace_period(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_health_check_grace_period(input);
            self
        }
        /// <p>The name of an existing placement group into which to launch your instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html">Placement groups</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> <note>
        /// <p>A <i>cluster</i> placement group is a logical grouping of instances within a single Availability Zone. You cannot specify multiple Availability Zones and a cluster placement group. </p>
        /// </note>
        pub fn placement_group(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.placement_group(input.into());
            self
        }
        /// <p>The name of an existing placement group into which to launch your instances. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html">Placement groups</a> in the <i>Amazon EC2 User Guide for Linux Instances</i>.</p> <note>
        /// <p>A <i>cluster</i> placement group is a logical grouping of instances within a single Availability Zone. You cannot specify multiple Availability Zones and a cluster placement group. </p>
        /// </note>
        pub fn set_placement_group(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_placement_group(input);
            self
        }
        /// <p>A comma-separated list of subnet IDs for a virtual private cloud (VPC). If you specify <code>VPCZoneIdentifier</code> with <code>AvailabilityZones</code>, the subnets that you specify for this parameter must reside in those Availability Zones.</p>
        pub fn vpc_zone_identifier(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.vpc_zone_identifier(input.into());
            self
        }
        /// <p>A comma-separated list of subnet IDs for a virtual private cloud (VPC). If you specify <code>VPCZoneIdentifier</code> with <code>AvailabilityZones</code>, the subnets that you specify for this parameter must reside in those Availability Zones.</p>
        pub fn set_vpc_zone_identifier(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_vpc_zone_identifier(input);
            self
        }
        /// Appends an item to `TerminationPolicies`.
        ///
        /// To override the contents of this collection use [`set_termination_policies`](Self::set_termination_policies).
        ///
        /// <p>A policy or a list of policies that are used to select the instances to terminate. The policies are executed in the order that you list them. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html">Controlling which Auto Scaling instances terminate during scale in</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn termination_policies(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.termination_policies(input.into());
            self
        }
        /// <p>A policy or a list of policies that are used to select the instances to terminate. The policies are executed in the order that you list them. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html">Controlling which Auto Scaling instances terminate during scale in</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_termination_policies(
            mut self,
            input: std::option::Option<std::vec::Vec<std::string::String>>,
        ) -> Self {
            self.inner = self.inner.set_termination_policies(input);
            self
        }
        /// <p>Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. For more information about preventing instances from terminating on scale in, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-instance-protection.html">Using instance scale-in protection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn new_instances_protected_from_scale_in(mut self, input: bool) -> Self {
            self.inner = self.inner.new_instances_protected_from_scale_in(input);
            self
        }
        /// <p>Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. For more information about preventing instances from terminating on scale in, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-instance-protection.html">Using instance scale-in protection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_new_instances_protected_from_scale_in(
            mut self,
            input: std::option::Option<bool>,
        ) -> Self {
            self.inner = self.inner.set_new_instances_protected_from_scale_in(input);
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services on your behalf. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-service-linked-role.html">Service-linked roles</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn service_linked_role_arn(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.service_linked_role_arn(input.into());
            self
        }
        /// <p>The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services on your behalf. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-service-linked-role.html">Service-linked roles</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_service_linked_role_arn(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_service_linked_role_arn(input);
            self
        }
        /// <p>The maximum amount of time, in seconds, that an instance can be in service. The default is null. If specified, the value must be either 0 or a number equal to or greater than 86,400 seconds (1 day). To clear a previously set value, specify a new value of 0. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-max-instance-lifetime.html">Replacing Auto Scaling instances based on maximum instance lifetime</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn max_instance_lifetime(mut self, input: i32) -> Self {
            self.inner = self.inner.max_instance_lifetime(input);
            self
        }
        /// <p>The maximum amount of time, in seconds, that an instance can be in service. The default is null. If specified, the value must be either 0 or a number equal to or greater than 86,400 seconds (1 day). To clear a previously set value, specify a new value of 0. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-max-instance-lifetime.html">Replacing Auto Scaling instances based on maximum instance lifetime</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_max_instance_lifetime(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_max_instance_lifetime(input);
            self
        }
        /// <p>Enables or disables Capacity Rebalancing. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html">Amazon EC2 Auto Scaling Capacity Rebalancing</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn capacity_rebalance(mut self, input: bool) -> Self {
            self.inner = self.inner.capacity_rebalance(input);
            self
        }
        /// <p>Enables or disables Capacity Rebalancing. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html">Amazon EC2 Auto Scaling Capacity Rebalancing</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        pub fn set_capacity_rebalance(mut self, input: std::option::Option<bool>) -> Self {
            self.inner = self.inner.set_capacity_rebalance(input);
            self
        }
        /// <p>Reserved.</p>
        pub fn context(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.context(input.into());
            self
        }
        /// <p>Reserved.</p>
        pub fn set_context(mut self, input: std::option::Option<std::string::String>) -> Self {
            self.inner = self.inner.set_context(input);
            self
        }
        /// <p>The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports <code>DesiredCapacityType</code> for attribute-based instance type selection only. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-instance-type-requirements.html">Creating an Auto Scaling group using attribute-based instance type selection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>By default, Amazon EC2 Auto Scaling specifies <code>units</code>, which translates into number of instances.</p>
        /// <p>Valid values: <code>units</code> | <code>vcpu</code> | <code>memory-mib</code> </p>
        pub fn desired_capacity_type(mut self, input: impl Into<std::string::String>) -> Self {
            self.inner = self.inner.desired_capacity_type(input.into());
            self
        }
        /// <p>The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports <code>DesiredCapacityType</code> for attribute-based instance type selection only. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-instance-type-requirements.html">Creating an Auto Scaling group using attribute-based instance type selection</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p>
        /// <p>By default, Amazon EC2 Auto Scaling specifies <code>units</code>, which translates into number of instances.</p>
        /// <p>Valid values: <code>units</code> | <code>vcpu</code> | <code>memory-mib</code> </p>
        pub fn set_desired_capacity_type(
            mut self,
            input: std::option::Option<std::string::String>,
        ) -> Self {
            self.inner = self.inner.set_desired_capacity_type(input);
            self
        }
        /// <p>The amount of time, in seconds, until a newly launched instance can contribute to the Amazon CloudWatch metrics. This delay lets an instance finish initializing before Amazon EC2 Auto Scaling aggregates instance metrics, resulting in more reliable usage data. Set this value equal to the amount of time that it takes for resource consumption to become stable after an instance reaches the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-default-instance-warmup.html">Set the default instance warmup for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <important>
        /// <p>To manage your warm-up settings at the group level, we recommend that you set the default instance warmup, <i>even if its value is set to 0 seconds</i>. This also optimizes the performance of scaling policies that scale continuously, such as target tracking and step scaling policies. </p>
        /// <p>If you need to remove a value that you previously set, include the property but specify <code>-1</code> for the value. However, we strongly recommend keeping the default instance warmup enabled by specifying a minimum value of <code>0</code>.</p>
        /// </important>
        pub fn default_instance_warmup(mut self, input: i32) -> Self {
            self.inner = self.inner.default_instance_warmup(input);
            self
        }
        /// <p>The amount of time, in seconds, until a newly launched instance can contribute to the Amazon CloudWatch metrics. This delay lets an instance finish initializing before Amazon EC2 Auto Scaling aggregates instance metrics, resulting in more reliable usage data. Set this value equal to the amount of time that it takes for resource consumption to become stable after an instance reaches the <code>InService</code> state. For more information, see <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-default-instance-warmup.html">Set the default instance warmup for an Auto Scaling group</a> in the <i>Amazon EC2 Auto Scaling User Guide</i>.</p> <important>
        /// <p>To manage your warm-up settings at the group level, we recommend that you set the default instance warmup, <i>even if its value is set to 0 seconds</i>. This also optimizes the performance of scaling policies that scale continuously, such as target tracking and step scaling policies. </p>
        /// <p>If you need to remove a value that you previously set, include the property but specify <code>-1</code> for the value. However, we strongly recommend keeping the default instance warmup enabled by specifying a minimum value of <code>0</code>.</p>
        /// </important>
        pub fn set_default_instance_warmup(mut self, input: std::option::Option<i32>) -> Self {
            self.inner = self.inner.set_default_instance_warmup(input);
            self
        }
    }
}

impl Client {
    /// Creates a client with the given service config and connector override.
    pub fn from_conf_conn<C, E>(conf: crate::Config, conn: C) -> Self
    where
        C: aws_smithy_client::bounds::SmithyConnector<Error = E> + Send + 'static,
        E: Into<aws_smithy_http::result::ConnectorError>,
    {
        let retry_config = conf.retry_config.as_ref().cloned().unwrap_or_default();
        let timeout_config = conf.timeout_config.as_ref().cloned().unwrap_or_default();
        let sleep_impl = conf.sleep_impl.clone();
        let mut builder = aws_smithy_client::Builder::new()
            .connector(aws_smithy_client::erase::DynConnector::new(conn))
            .middleware(aws_smithy_client::erase::DynMiddleware::new(
                crate::middleware::DefaultMiddleware::new(),
            ));
        builder.set_retry_config(retry_config.into());
        builder.set_timeout_config(timeout_config);
        if let Some(sleep_impl) = sleep_impl {
            builder.set_sleep_impl(Some(sleep_impl));
        }
        let client = builder.build();
        Self {
            handle: std::sync::Arc::new(Handle { client, conf }),
        }
    }

    /// Creates a new client from a shared config.
    #[cfg(any(feature = "rustls", feature = "native-tls"))]
    pub fn new(sdk_config: &aws_types::sdk_config::SdkConfig) -> Self {
        Self::from_conf(sdk_config.into())
    }

    /// Creates a new client from the service [`Config`](crate::Config).
    #[cfg(any(feature = "rustls", feature = "native-tls"))]
    pub fn from_conf(conf: crate::Config) -> Self {
        let retry_config = conf.retry_config.as_ref().cloned().unwrap_or_default();
        let timeout_config = conf.timeout_config.as_ref().cloned().unwrap_or_default();
        let sleep_impl = conf.sleep_impl.clone();
        let mut builder = aws_smithy_client::Builder::dyn_https().middleware(
            aws_smithy_client::erase::DynMiddleware::new(
                crate::middleware::DefaultMiddleware::new(),
            ),
        );
        builder.set_retry_config(retry_config.into());
        builder.set_timeout_config(timeout_config);
        // the builder maintains a try-state. To avoid suppressing the warning when sleep is unset,
        // only set it if we actually have a sleep impl.
        if let Some(sleep_impl) = sleep_impl {
            builder.set_sleep_impl(Some(sleep_impl));
        }
        let client = builder.build();

        Self {
            handle: std::sync::Arc::new(Handle { client, conf }),
        }
    }
}
