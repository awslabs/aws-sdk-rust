// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`GetModelInvocationJob`](crate::operation::get_model_invocation_job::builders::GetModelInvocationJobFluentBuilder) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`job_identifier(impl Into<String>)`](crate::operation::get_model_invocation_job::builders::GetModelInvocationJobFluentBuilder::job_identifier) / [`set_job_identifier(Option<String>)`](crate::operation::get_model_invocation_job::builders::GetModelInvocationJobFluentBuilder::set_job_identifier):<br>required: **true**<br><p>The Amazon Resource Name (ARN) of the batch inference job.</p><br>
    /// - On success, responds with [`GetModelInvocationJobOutput`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput) with field(s):
    ///   - [`job_arn(String)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::job_arn): <p>The Amazon Resource Name (ARN) of the batch inference job.</p>
    ///   - [`job_name(Option<String>)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::job_name): <p>The name of the batch inference job.</p>
    ///   - [`model_id(String)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::model_id): <p>The unique identifier of the foundation model used for model inference.</p>
    ///   - [`client_request_token(Option<String>)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::client_request_token): <p>A unique, case-sensitive identifier to ensure that the API request completes no more than one time. If this token matches a previous request, Amazon Bedrock ignores the request, but does not return an error. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/Run_Instance_Idempotency.html">Ensuring idempotency</a>.</p>
    ///   - [`role_arn(String)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::role_arn): <p>The Amazon Resource Name (ARN) of the service role with permissions to carry out and manage batch inference. You can use the console to create a default service role or follow the steps at <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/batch-iam-sr.html">Create a service role for batch inference</a>.</p>
    ///   - [`status(Option<ModelInvocationJobStatus>)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::status): <p>The status of the batch inference job.</p>
    ///   - [`message(Option<String>)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::message): <p>If the batch inference job failed, this field contains a message describing why the job failed.</p>
    ///   - [`submit_time(DateTime)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::submit_time): <p>The time at which the batch inference job was submitted.</p>
    ///   - [`last_modified_time(Option<DateTime>)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::last_modified_time): <p>The time at which the batch inference job was last modified.</p>
    ///   - [`end_time(Option<DateTime>)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::end_time): <p>The time at which the batch inference job ended.</p>
    ///   - [`input_data_config(Option<ModelInvocationJobInputDataConfig>)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::input_data_config): <p>Details about the location of the input to the batch inference job.</p>
    ///   - [`output_data_config(Option<ModelInvocationJobOutputDataConfig>)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::output_data_config): <p>Details about the location of the output of the batch inference job.</p>
    ///   - [`vpc_config(Option<VpcConfig>)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::vpc_config): <p>The configuration of the Virtual Private Cloud (VPC) for the data in the batch inference job. For more information, see <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-vpc">Protect batch inference jobs using a VPC</a>.</p>
    ///   - [`timeout_duration_in_hours(Option<i32>)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::timeout_duration_in_hours): <p>The number of hours after which batch inference job was set to time out.</p>
    ///   - [`job_expiration_time(Option<DateTime>)`](crate::operation::get_model_invocation_job::GetModelInvocationJobOutput::job_expiration_time): <p>The time at which the batch inference job times or timed out.</p>
    /// - On failure, responds with [`SdkError<GetModelInvocationJobError>`](crate::operation::get_model_invocation_job::GetModelInvocationJobError)
    pub fn get_model_invocation_job(&self) -> crate::operation::get_model_invocation_job::builders::GetModelInvocationJobFluentBuilder {
        crate::operation::get_model_invocation_job::builders::GetModelInvocationJobFluentBuilder::new(self.handle.clone())
    }
}
