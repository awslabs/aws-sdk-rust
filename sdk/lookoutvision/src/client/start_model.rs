// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`StartModel`](crate::operation::start_model::builders::StartModelFluentBuilder) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`project_name(impl Into<String>)`](crate::operation::start_model::builders::StartModelFluentBuilder::project_name) / [`set_project_name(Option<String>)`](crate::operation::start_model::builders::StartModelFluentBuilder::set_project_name):<br>required: **true**<br><p>The name of the project that contains the model that you want to start.</p><br>
    ///   - [`model_version(impl Into<String>)`](crate::operation::start_model::builders::StartModelFluentBuilder::model_version) / [`set_model_version(Option<String>)`](crate::operation::start_model::builders::StartModelFluentBuilder::set_model_version):<br>required: **true**<br><p>The version of the model that you want to start.</p><br>
    ///   - [`min_inference_units(i32)`](crate::operation::start_model::builders::StartModelFluentBuilder::min_inference_units) / [`set_min_inference_units(Option<i32>)`](crate::operation::start_model::builders::StartModelFluentBuilder::set_min_inference_units):<br>required: **true**<br><p>The minimum number of inference units to use. A single inference unit represents 1 hour of processing. Use a higher number to increase the TPS throughput of your model. You are charged for the number of inference units that you use. </p><br>
    ///   - [`client_token(impl Into<String>)`](crate::operation::start_model::builders::StartModelFluentBuilder::client_token) / [`set_client_token(Option<String>)`](crate::operation::start_model::builders::StartModelFluentBuilder::set_client_token):<br>required: **false**<br><p>ClientToken is an idempotency token that ensures a call to <code>StartModel</code> completes only once. You choose the value to pass. For example, An issue might prevent you from getting a response from <code>StartModel</code>. In this case, safely retry your call to <code>StartModel</code> by using the same <code>ClientToken</code> parameter value. </p>  <p>If you don't supply a value for <code>ClientToken</code>, the AWS SDK you are using inserts a value for you. This prevents retries after a network error from making multiple start requests. You'll need to provide your own value for other use cases. </p>  <p>An error occurs if the other input parameters are not the same as in the first request. Using a different value for <code>ClientToken</code> is considered a new call to <code>StartModel</code>. An idempotency token is active for 8 hours. </p><br>
    ///   - [`max_inference_units(i32)`](crate::operation::start_model::builders::StartModelFluentBuilder::max_inference_units) / [`set_max_inference_units(Option<i32>)`](crate::operation::start_model::builders::StartModelFluentBuilder::set_max_inference_units):<br>required: **false**<br><p>The maximum number of inference units to use for auto-scaling the model. If you don't specify a value, Amazon Lookout for Vision doesn't auto-scale the model.</p><br>
    /// - On success, responds with [`StartModelOutput`](crate::operation::start_model::StartModelOutput) with field(s):
    ///   - [`status(Option<ModelHostingStatus>)`](crate::operation::start_model::StartModelOutput::status): <p>The current running status of the model.</p>
    /// - On failure, responds with [`SdkError<StartModelError>`](crate::operation::start_model::StartModelError)
    pub fn start_model(&self) -> crate::operation::start_model::builders::StartModelFluentBuilder {
        crate::operation::start_model::builders::StartModelFluentBuilder::new(self.handle.clone())
    }
}
